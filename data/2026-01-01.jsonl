{"id": "2512.24621", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.24621", "abs": "https://arxiv.org/abs/2512.24621", "authors": ["Lucas A. Souza"], "title": "Forward-Oriented Causal Observables for Non-Stationary Financial Markets", "comment": null, "summary": "We study short-horizon forecasting in financial time series under strict causal constraints, treating the market as a non-stationary stochastic system in which any predictive observable must be computable online from information available up to the decision time. Rather than proposing a machine-learning predictor or a direct price-forecast model, we focus on \\emph{constructing} an interpretable causal signal from heterogeneous micro-features that encode complementary aspects of the dynamics (momentum, volume pressure, trend acceleration, and volatility-normalized price location). The construction combines (i) causal centering, (ii) linear aggregation into a composite observable, (iii) causal stabilization via a one-dimensional Kalman filter, and (iv) an adaptive ``forward-like'' operator that mixes the composite signal with a smoothed causal derivative term. The resulting observable is mapped into a transparent decision functional and evaluated through realized cumulative returns and turnover. An application to high-frequency EURUSDT (1-minute) illustrates that causally constructed observables can exhibit substantial economic relevance in specific regimes, while degrading under subsequent regime shifts, highlighting both the potential and the limitations of causal signal design in non-stationary markets."}
{"id": "2512.24714", "categories": ["math.NA", "math.PR", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.24714", "abs": "https://arxiv.org/abs/2512.24714", "authors": ["Xiang Gao", "Cody Hyndman"], "title": "Boundary error control for numerical solution of BSDEs by the convolution-FFT method", "comment": "15 pages, 3 figures, 1 table", "summary": "We first review the convolution fast-Fourier-transform (CFFT) approach for the numerical solution of backward stochastic differential equations (BSDEs) introduced in (Hyndman and Oyono Ngou, 2017). We then propose a method for improving the boundary errors obtained when valuing options using this approach. We modify the damping and shifting schemes used in the original formulation, which transforms the target function into a bounded periodic function so that Fourier transforms can be applied successfully. Time-dependent shifting reduces boundary error significantly. We present numerical results for our implementation and provide a detailed error analysis showing the improved accuracy and convergence of the modified convolution method."}
{"id": "2512.25017", "categories": ["math.NA", "cs.LG", "q-fin.CP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.25017", "abs": "https://arxiv.org/abs/2512.25017", "authors": ["Chenguang Liu", "Antonis Papapantoleon", "Jasper Rou"], "title": "Convergence of the generalization error for deep gradient flow methods for PDEs", "comment": "28 pages", "summary": "The aim of this article is to provide a firm mathematical foundation for the application of deep gradient flow methods (DGFMs) for the solution of (high-dimensional) partial differential equations (PDEs). We decompose the generalization error of DGFMs into an approximation and a training error. We first show that the solution of PDEs that satisfy reasonable and verifiable assumptions can be approximated by neural networks, thus the approximation error tends to zero as the number of neurons tends to infinity. Then, we derive the gradient flow that the training process follows in the ``wide network limit'' and analyze the limit of this flow as the training time tends to infinity. These results combined show that the generalization error of DGFMs tends to zero as the number of neurons and the training time tend to infinity."}
{"id": "2512.23724", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.23724", "abs": "https://arxiv.org/abs/2512.23724", "authors": ["SeongJin Kwon", "Kyung-Hwan Jin", "Jong Eun Han", "Siwon Lee", "ChoongJae Won", "Sang-Wook Cheong", "Han Woong Yeom"], "title": "Yu-Shiba-Rusinov bound states of exciton condensate", "comment": null, "summary": "Quantum condensed states in solids often reveal their fundamental nature via interactions with impurities, as epitomized by Yu-Shiba-Rusinov (YSR) bound states at magnetic impurities in superconductors. Although analogous YSR bound states were predicted within quantum condensates of excitons several decades ago, their existence has been elusive. Here, we directly visualize in-gap electronic states bound to impurities inside an exciton condensate phase of a van der Waals crystal Ta2Pd3Te5, utilizing scanning tunneling microscopy and spectroscopy. We find that the energies of in-gap states are strongly correlated with the excitonic band gap, which is systematically tuned by local strain and carrier injection. Our theoretical analyses reveal that these in-gap states are induced by charge dipoles associated with Ta vacancies through a charge-exciton version of the YSR mechanism. Our findings establish both the YSR physics in exciton condensates and a novel microscopic tool to probe and control quantum properties in exciton condensates persisting up to room temperature."}
{"id": "2512.24122", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24122", "abs": "https://arxiv.org/abs/2512.24122", "authors": ["Kristóf Benedek", "Géza Ódor"], "title": "The effect of HVDC lines in power-grids via Kuramoto modelling", "comment": null, "summary": "We present a numerical study on the synchronization and cascade failure behaviour by solving the adaptive second-order Kuramoto model on a large high voltage (HV) European power-grid. This non-perturbative analysis takes into account non-linear effects, which occur even when phase differences are large, when the system is away from the steady state, and even during a blackout cascade. Our dynamical simulations show that improvements in the phase synchronziation stabilization as well as the in the cascade sizes can be related to the finite size scaling behaviour of the second order Kuramoto on graphs with $d_s<4$ spectral dimensions. On the other hand drawbacks in the frequency spread and Braess effects also occur by varying the total transmitted power at large and small global couplings, presumably when the fluctuations are small, causing a freezing in the dynamics. We compare simulations of the fully AC model with those of static or adaptive High Voltage Direct Current (HVDC) line replacements. The adaptive (local frequency difference-based) HVDC lines are more efficient in the steady state, at the expense of very long relaxation times."}
{"id": "2512.24315", "categories": ["hep-lat", "hep-ph", "nucl-ex", "nucl-th"], "pdf": "https://arxiv.org/pdf/2512.24315", "abs": "https://arxiv.org/abs/2512.24315", "authors": ["Dian-Jun Zhao", "Long Chen", "Hongxin Dong", "Xiangdong Ji", "Liuming Liu", "Zhuoyi Pang", "Peng Sun", "Yi-Bo Yang", "Jian-Hui Zhang", "Shiyi Zhong"], "title": "Total Gluon Helicity Contribution to Proton Spin from Lattice QCD", "comment": null, "summary": "We report a state-of-the-art lattice QCD calculation of the total gluon helicity contribution to proton spin, $ΔG$. The calculation is done on ensembles at three different lattice spacings $a=\\{0.08, 0.09, 0.11\\}$ fm. By employing distillation + momentum smearing for proton external states, we extract the bare matrix elements of the topological current $K^μ$ under the 5-HYP smeared Coulomb gauge fixing configurations. Furthermore, we apply a non-perturbative $\\mathrm{RI/MOM}$ renormalization scheme augmented with the Cluster Decomposition Error Reduction (CDER) technique to determine the renormalization constants of $K^μ$. The results obtained from different components $K^{t,i}$ (with $i$ being the direction of proton momentum or polarization) are consistent with Lorentz covariance within uncertainties. After extrapolating to the continuum limit, $ΔG$ is found to be $ΔG = 0.231(17)^{\\mathrm{sta.}}(33)^{\\mathrm{sym.}}$ at the $\\overline{\\mathrm{MS}}$ scale $μ^2=10\\ \\mathrm{GeV}^2$, which constitutes approximately $46(7)\\%$ of the proton spin."}
{"id": "2512.23804", "categories": ["math.OC", "math.AP", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23804", "abs": "https://arxiv.org/abs/2512.23804", "authors": ["Zhendong Li", "Akwum Onwunta", "Bedřich Sousedík"], "title": "Stochastic Galerkin Method and Hierarchical Preconditioning for PDE-constrained Optimization", "comment": null, "summary": "We develop efficient hierarchical preconditioners for optimal control problems governed by partial differential equations with uncertain coefficients. Adopting a discretize-then-optimize framework that integrates finite element discretization, stochastic Galerkin approximation, and advanced time-discretization schemes, the approach addresses the challenge of large-scale, ill-conditioned linear systems arising in uncertainty quantification. By exploiting the sparsity inherent in generalized polynomial chaos expansions, we derive hierarchical preconditioners based on truncated stochastic expansion that strike an effective balance between computational cost and preconditioning quality. Numerical experiments demonstrate that the proposed preconditioners significantly accelerate the convergence of iterative solvers compared to existing methods, providing robust and efficient solvers for both steady-state and time-dependent optimal control applications under uncertainty."}
{"id": "2512.23833", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23833", "abs": "https://arxiv.org/abs/2512.23833", "authors": ["Ernesto S. Loscar"], "title": "Finite-time effects on a first-order irreversible phase transition", "comment": "26 pages, 9 figures", "summary": "The first-order irreversible phase transition (FOIPT) of the ZGB model [Ziff, Gulari, Barshad, Phys. Rev. Lett. \\textbf{56} (1986) 2553] for the catalytic oxidation of carbon monoxide is studied numerically in the presence of a slowly time-dependent, spatially uniform carbon monoxide pressure, with standard constant pressure simulations. This method allows us to observe finite-time effects close to the FOIPT, as well as evidence that a dynamic phase transition occurs. The location of this transition is measured very precisely and compared with previous results in the literature."}
{"id": "2512.23807", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.23807", "abs": "https://arxiv.org/abs/2512.23807", "authors": ["Marco Zank"], "title": "A note on the space-time variational formulation for the wave equation with source term in $L^2(Q)$", "comment": "8 pages", "summary": "We derive a variational formulation for the scalar wave equation in the second-order formulation on bounded Lipschitz domains and homogeneous initial conditions. We investigate a variational framework in a bounded space-time cylinder $Q$ with a new solution space and the test space $L^2(Q)$ for source terms in $L^2(Q)$. Using existence and uniqueness results in $H^1(Q)$, we prove that this variational setting fits the inf-sup theory, including an isomorphism as solution operator. Moreover, we show that the new solution space is not a subspace of $H^2(Q)$. This new uniqueness and solvability result is not only crucial for discretizations using space-time methods, including least-squares approaches, but also important for regularity results and the analysis of related space-time boundary integral equations, which form the basis for space-time boundary element methods."}
{"id": "2512.23919", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.23919", "abs": "https://arxiv.org/abs/2512.23919", "authors": ["Boleslaw K. Szymanski", "Yongtao Zhang", "Brian Uzzi", "Mohammed Shahid Modi"], "title": "Analysis of Collaboration in CS Prizewinning with a Nobel-Turing Comparison", "comment": "19 pages, 9 figures", "summary": "In the scientific community, prizes play a pivotal role in shaping research trajectories by conferring credibility and offering financial incentives to researchers. Yet, we know little about the relationship between academic collaborations and prizewinning. By analyzing over 100 scientific prizes and the collaboration behaviors of over 5,000 prizewinners in CS, we find that prizewinners collaborate earlier and more frequently with other prizewinners than researchers who have not yet received similar recognition. Moreover, CS researchers across age groups collaborate more with prizewinners after winning their first prize, and collaborating with prizewinners after their first win increases the likelihood of the collaborator winning an award. We find that recipients of general CS prizes collaborate more than recipients of more specialized prizes, who collaborate less frequently. With Coarsened Exact Matching (CEM) and regression, we find an increase in prizewinning odds with strength of prizewinner collaboration. We examine the context of recent Nobel Prizes going to CS researchers by showing how an increasing share of Physics awards go to Physics-CS collaborations, and contrast Nobel-Turing winning author's trajectories. Our findings shed light on the relationship between prizewinning and collaboration."}
{"id": "2512.23715", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.23715", "abs": "https://arxiv.org/abs/2512.23715", "authors": ["Osama A. Marzouk"], "title": "Wind Speed Weibull Model Identification in Oman, and Computed Normalized Annual Energy Production (NAEP) From Wind Turbines Based on Data From Weather Stations", "comment": "25 pages, 21 figures, 8 tables, published journal article, peer-reviewed, open access", "summary": "Using observation records of wind speeds from weather stations in the Sultanate of Oman between 2000 and 2023, we compute estimators of the two Weibull distribution parameters (namely, the Weibull distribution's shape parameter and the Weibull distribution's scale parameter) in 10 weather station locations within eight Omani governorates. The 10 weather station locations in Oman and their corresponding governorates are Seeb (in Muscat), Salalah (in Dhofar), Buraimi (in Al Buraimi), Masirah (in Ash Sharqiyah South), Thumrait (in Dhofar), Sur (in Ash Sharqiyah South), Khasab (in Musandam), Sohar (in Sohar), Fahud (in Az Zahirah), and Saiq (in Ad Dakhiliyah). The obtained wind speed distributions at these weather stations are then used to predict the annual energy production (AEP) for a proposed reference amount of 1 MWp of wind turbine capacity, and this specific AEP is designated here by the term \"normalized annual energy production (NAEP).\" The direction of the wind is also analyzed statistically over the same period to identify the more probable wind directions. Four locations were clearly distinguishable as being windy compared to the others. The simulated probability of exceeding a feasible 6 m/s (21.6 km/h) wind speed in these locations is 41.71% in Thumrait, 37.77% in Masirah, 29.53% in Sur, and 17.03% in Fahud. The NAEP values in these four locations are estimated as 1.727 GWh/MWp/year, 1.419 GWh/MWp/year, 1.038 GWh/MWp/year, and 0.602 GWh/MWp/year, respectively. The wind in the location of Thumrait is not only the fastest (on average) among the selected locations but also the most unidirectional, blowing almost always from the south-south-east (SSE) direction, and both features make this non-coastal location in southern Oman, with an altitude of about 467 m, an attractive site for utility-scale wind farms."}
{"id": "2512.23900", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23900", "abs": "https://arxiv.org/abs/2512.23900", "authors": ["Hesam Khoshkbari", "Georges Kaddoum", "Bassant Selim", "Omid Abbasi", "Halim Yanikomeroglu"], "title": "Distributed Beamforming in Massive MIMO Communication for a Constellation of Airborne Platform Stations", "comment": null, "summary": "Non-terrestrial base stations (NTBSs), including high-altitude platform stations (HAPSs) and hot-air balloons (HABs), are integral to next-generation wireless networks, offering coverage in remote areas and enhancing capacity in dense regions. In this paper, we propose a distributed beamforming framework for a massive MIMO network with a constellation of aerial platform stations (APSs). Our approach leverages an entropy-based multi-agent deep reinforcement learning (DRL) model, where each APS operates as an independent agent using imperfect channel state information (CSI) in both training and testing phases. Unlike conventional methods, our model does not require CSI sharing among APSs, significantly reducing overhead. Simulations results demonstrate that our method outperforms zero forcing (ZF) and maximum ratio transmission (MRT) techniques, particularly in high-interference scenarios, while remaining robust to CSI imperfections. Additionally, our framework exhibits scalability, maintaining stable performance over an increasing number of users and various cluster configurations. Therefore, the proposed method holds promise for dynamic and interference-rich NTBS networks, advancing scalable and robust wireless solutions."}
{"id": "2512.23731", "categories": ["physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.23731", "abs": "https://arxiv.org/abs/2512.23731", "authors": ["Alessio Kandiah", "Alexander B. Movchan", "Vladimir Frid"], "title": "When the Earth and Sky Dance: Seismic Shakes Meet Weather Patterns", "comment": "8 pages, 6 figures", "summary": "A new modelling approach shows how the Earth's hidden vibrations may drive global weather dynamics and atmospheric pressure variations, hinting that the planet's own beat could be imprinted on our climate. The atmospheric rotational patterns of the mean sea level pressure, in connection to the development of powerful storms, are shown to be caused by Earth's rotational elastic dynamics and earthquake-induced oscillations. These seismic excitations are discussed in relation to storm formation and the global atmospheric patterns of high-pressure regions."}
{"id": "2512.23900", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23900", "abs": "https://arxiv.org/abs/2512.23900", "authors": ["Hesam Khoshkbari", "Georges Kaddoum", "Bassant Selim", "Omid Abbasi", "Halim Yanikomeroglu"], "title": "Distributed Beamforming in Massive MIMO Communication for a Constellation of Airborne Platform Stations", "comment": null, "summary": "Non-terrestrial base stations (NTBSs), including high-altitude platform stations (HAPSs) and hot-air balloons (HABs), are integral to next-generation wireless networks, offering coverage in remote areas and enhancing capacity in dense regions. In this paper, we propose a distributed beamforming framework for a massive MIMO network with a constellation of aerial platform stations (APSs). Our approach leverages an entropy-based multi-agent deep reinforcement learning (DRL) model, where each APS operates as an independent agent using imperfect channel state information (CSI) in both training and testing phases. Unlike conventional methods, our model does not require CSI sharing among APSs, significantly reducing overhead. Simulations results demonstrate that our method outperforms zero forcing (ZF) and maximum ratio transmission (MRT) techniques, particularly in high-interference scenarios, while remaining robust to CSI imperfections. Additionally, our framework exhibits scalability, maintaining stable performance over an increasing number of users and various cluster configurations. Therefore, the proposed method holds promise for dynamic and interference-rich NTBS networks, advancing scalable and robust wireless solutions."}
{"id": "2512.23772", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.23772", "abs": "https://arxiv.org/abs/2512.23772", "authors": ["Amélie Artis", "Achmad Choiruddin", "Jean-François Coeurjolly", "Frédérique Letué"], "title": "Marked point processes intensity estimation using sparse group Lasso method applied to locations of lucrative and cooperative banks in mainland France", "comment": null, "summary": "In this paper, we model the locations of five major banks in mainland France, two lucrative and three cooperative institutions based on socio-economic considerations. Locations of banks are collected using web scrapping and constitute a bivariate spatial point process for which we estimate nonparametrically summary functions (intensity, Ripley and cross-Ripley's K functions). This shows that the pattern is highly inhomogenenous and exhibits a clustering effect especially at small scales, and thus a significant departure to the bivariate (inhomogeneous) Poisson point process is pointed out. We also collect socio-economic datasets (at the living area level) from INSEE and propose a parametric modelling of the intensity function using these covariates. We propose a group-penalized bivariate composite likelihood method to estimate the model parameters, and we establish its asymptotic properties. The application of the methodology to the banking dataset provides new insights into the specificity of the cooperative model within the sector, particularly in relation to the theories of institutional isomorphism."}
{"id": "2512.23922", "categories": ["cond-mat.dis-nn", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.23922", "abs": "https://arxiv.org/abs/2512.23922", "authors": ["Luca Falorsi", "Gianni V. Vinci", "Maurizio Mattia"], "title": "Non-stationary dynamics of interspike intervals in neuronal populations", "comment": "10 pages, 4 figures", "summary": "We study the joint dynamics of membrane potential and time since the last spike in a population of integrate-and-fire neurons using a population density framework. This leads to a two-dimensional Fokker-Planck equation that captures the evolution of the full neuronal state, along with a one-dimensional hierarchy of equations for the moments of the inter-spike interval (ISI). The formalism allows us to characterize the time-dependent ISI distribution, even when the population is far from stationarity, such as under time-varying external input or during network oscillations. By performing a perturbative expansion around the stationary state, we also derive an analytic expression for the linear response of the ISI distribution to weak input modulations."}
{"id": "2512.24765", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.24765", "abs": "https://arxiv.org/abs/2512.24765", "authors": ["Gug Young Kim", "Mi Jin Lee", "Seung-Woo Son"], "title": "Predicting the Oscillatory Regimes of Global Synchrony Induced by Secondary Clusters", "comment": "17 pages, 5 figures. Preprint; submitted to a journal", "summary": "Synchronization systems with effective inertia, such as power grid networks and coupled electromechanical oscillators, are commonly modeled by the second-order Kuramoto model. In the forward process, numerical simulations exhibit a staircase-like growth of global synchrony, reflecting temporal oscillations induced by secondary synchronized clusters of whirling oscillators. While this behavior has been observed previously, its governing conditions have not been quantitatively determined in terms of analytical criteria. Here, we develop a self-consistent theoretical framework that explicitly characterizes the secondary synchronized clusters. This analysis identifies an onset crossover mass $\\tilde{m}^* \\simeq 3.865$ for the emergence of secondary clusters and yields quantitative criteria for predicting both the crossover mass and the termination coupling strength at which they vanish. As a result, we determine the oscillatory regimes of coupling strengths over which global synchrony shows temporal oscillations, providing practical guidance for controlling and avoiding undesirable oscillatory behavior in inertial synchronization systems, such as power grids."}
{"id": "2512.23721", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23721", "abs": "https://arxiv.org/abs/2512.23721", "authors": ["Mikołaj Sienicki", "Krzysztof Sienicki"], "title": "Notes on Crowther and the \"Interpretation\" of Quantum Mechanics (arXiv:2512.14315)", "comment": "13 pages, many references, notes on arXiv:2512.14315", "summary": "We read Karen Crowther's \\emph{Another 100 Years of Quantum Interpretation?} with two practical goals. First, we spell out what she means by interpretation'': an attempt to provide understanding (not just predictions), which may be representationalist or non-representationalist, and which she contrasts with deeper \\emph{reductive} (inter-theoretic) explanation -- especially in the quantum-gravity setting. Second, we list twelve points where the paper's physics-facing wording could be sharpened. In our view, several claims are directionally well-motivated but stated more strongly than the underlying physics supports, or they run together distinct notions (e.g.\\ degrees of freedom,'' singularity,'' and different senses of locality'') that need careful separation. We end by suggesting that the philosophical question is genuinely worthwhile, but the physics should be phrased more cautiously so that heuristic motivation is not mistaken for strict implication."}
{"id": "2512.23840", "categories": ["physics.comp-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23840", "abs": "https://arxiv.org/abs/2512.23840", "authors": ["Edoardo Monti", "Peter Yatsyshin", "Konstantinos Gkagkas", "Andrew B. Duncan"], "title": "Learning Density Functionals to Bridge Particle and Continuum Scales", "comment": null, "summary": "Predicting interfacial thermodynamics across molecular and continuum scales remains a central challenge in computational science. Classical density functional theory (cDFT) provides a first-principles route to connect microscopic interactions with macroscopic observables, but its predictive accuracy depends on approximate free-energy functionals that are difficult to generalize. Here we introduce a physics-informed learning framework that augments cDFT with neural corrections trained directly against molecular-dynamics data through adjoint optimization. Rather than replacing the theory with a black-box surrogate, we embed compact neural networks within the Helmholtz free-energy functional, learning local and nonlocal corrections that preserve thermodynamic consistency while capturing missing correlations. Applied to Lennard-Jones fluids, the resulting augmented excess free-energy functional quantitatively reproduces equilibrium density profiles, coexistence curves, and surface tensions across a broad temperature range, and accurately predicts contact angles and droplet shapes far beyond the training regime. This approach combines the interpretability of statistical mechanics with the adaptability of modern machine learning, establishing a general route to learned thermodynamic functionals that bridge molecular simulations and continuum-scale models."}
{"id": "2512.23741", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.23741", "abs": "https://arxiv.org/abs/2512.23741", "authors": ["Prasoon Saurabh"], "title": "Quantization of Physical Interaction Strengths via Singular Moduli", "comment": "8 pages, 5 figures (SI math not included)", "summary": "Since the 2019 redefinition of the SI units, precision metrology has sought to anchor all physical quantities to fundamental constants and integer invariants. While the optical frequency comb revolutionized timekeeping by discretizing the continuum of light into countable teeth, and the Quantum Hall Effect standardized resistance via topological invariants, a comparable standard for interaction strength remains elusive. Currently, measuring the coupling constant ($g$) between quantum systems is an estimation problem, inherently subject to drift, noise, and fabrication variance. Here, we introduce Interaction Metrology, a protocol that transforms the measurement of coupling strengths from an analog estimation into a topological counting problem. By engineering a specific class of algebraic catastrophe -- the Unimodal $X_9$ singularity -- in a driven-dissipative lattice, we prove that the system's interaction moduli are topologically forced to take discrete, quantized values, forming a \"Geometric $k$-Comb.\" We derive the universality class of this quantization, showing that it arises from the discrepancy between the Milnor ($μ$) and Tjurina ($τ$) numbers of the effective potential, a strictly non-Hermitian effect forbidden in standard quantum mechanics. Finally, we provide an ab-initio blueprint for a silicon nitride implementation, demonstrating that this quantization is robust against disorder levels exceeding current foundry tolerances. This discovery establishes a universal standard for force sensing and quantum logic gates, enabling the calibration of interaction strengths with topological certainty."}
{"id": "2512.23720", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2512.23720", "abs": "https://arxiv.org/abs/2512.23720", "authors": ["Matt Bowring", "Ben Anderdson", "Ben Tiffany"], "title": "An Electronic Ising Machine", "comment": null, "summary": "We develop a custom printed circuit board (PCB) as a low-power and high-speed accelerator for NP-Hard graph problems. Based on the annealing principle, it uses an analog computing architecture of coupled nonlinear electronic oscillators. Using an energy-based representation of the input problem, the system is shown to naturally follow the gradient towards stable phase alignments that encode solutions. We introduce the motivational theory, give an overview of our detailed circuit design, simulations, and experiments, and provide insight on the emerging development of novel physics-based computing devices."}
{"id": "2512.23979", "categories": ["math.ST", "cs.LG", "math.PR", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23979", "abs": "https://arxiv.org/abs/2512.23979", "authors": ["Sarvesh Ravichandran Iyer", "Himadri Mandal", "Dhruman Gupta", "Rushil Gupta", "Agniv Bandhyopadhyay", "Achal Bassamboo", "Varun Gupta", "Sandeep Juneja"], "title": "Fundamental limits for weighted empirical approximations of tilted distributions", "comment": "84 pages, 6 figures", "summary": "Consider the task of generating samples from a tilted distribution of a random vector whose underlying distribution is unknown, but samples from it are available. This finds applications in fields such as finance and climate science, and in rare event simulation. In this article, we discuss the asymptotic efficiency of a self-normalized importance sampler of the tilted distribution. We provide a sharp characterization of its accuracy, given the number of samples and the degree of tilt. Our findings reveal a surprising dichotomy: while the number of samples needed to accurately tilt a bounded random vector increases polynomially in the tilt amount, it increases at a super polynomial rate for unbounded distributions."}
{"id": "2512.23798", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23798", "abs": "https://arxiv.org/abs/2512.23798", "authors": ["Ryan Mays", "Predrag Nikolić"], "title": "Hedgehog lattices induced by chiral spin interactions", "comment": "13 pages, 14 figures", "summary": "We analyze a classical Heisenberg spin model on the simple cubic lattice which is invariant under time reversal and contains multiple chiral spin interactions. The modelled dynamics is appropriate either for local moments coupled to itinerant Weyl electrons, or localized electrons with a strong spin-orbit coupling that would produce a Weyl spectrum away from half filling. Using a Monte Carlo method, we find a robust $4Q$ bipartite lattice of hedgehogs and antihedgehogs which melts through a first order phase transition at a critical temperature in certain segments of the phase diagram. The density of hedgehogs is a non-linear function of the Dzyaloshinskii-Moriya interaction, and a linear function of the multiple-spin chiral interaction which plays the fundamental role of a ``magnetic flux'' or a hedgehog chemical potential. These findings are related to the observations of hedgehog lattices in MnGe, MnSi$_{1-x}$Ge$_x$ and SrFeO$_3$, and indirectly support the possible existence of incompressible quantum-disordered hedgehog liquids."}
{"id": "2512.24270", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.24270", "abs": "https://arxiv.org/abs/2512.24270", "authors": ["Sandro Claudio Lera", "Andreas Haupt"], "title": "Strategic Network Abandonment", "comment": null, "summary": "Socio-economic networks, from cities and firms to collaborative projects, often appear resilient for long periods before experiencing rapid, cascading decline as participation erodes. We explain such dynamics through a framework of strategic network abandonment, in which interconnected agents choose activity levels in a network game and remain active only if participation yields higher utility than an improving outside option. As outside opportunities rise, agents exit endogenously, triggering equilibrium readjustments that may either dissipate locally or propagate through the network. The resulting decay dynamics are governed by the strength of strategic complementarities, measuring how strongly an agent's incentives depend on the actions of others. When complementarities are weak, decay follows a heterogeneous threshold process analogous to bootstrap percolation: failures are driven by local neighborhoods, vulnerable clusters can be identified ex ante, and large cascades emerge only through bottom-up accumulation of fragility. When complementarities are strong, departures propagate globally, producing rupture-like dynamics characterized by metastable plateaus, abrupt system-wide collapse, and limited predictive power of standard spectral or structural indicators. The comparative effective of intervention depends on the strength of complementarity as well: Supporting central agents is most effective under strong complementarities, whereas targeting marginal agents is essential when complementarities are weak. Together, our results reveal how outside options, network structure, and strategic interdependence jointly determine both the fragility of socio-economic networks and the policies required to sustain them."}
{"id": "2512.24508", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2512.24508", "abs": "https://arxiv.org/abs/2512.24508", "authors": ["Wilder Schaaf", "Stephen R. Sharpe"], "title": "Implementing the three-neutron quantization condition", "comment": "50 pages including references, 8 figures", "summary": "We describe in detail the implementation of the relativistic three-neutron finite-volume quantization condition derived in Ref. [1]. In particular, we show how the complications due to Wigner rotations acting on spins are included, and present concrete formulas for the case when the angular momenta within pairs is restricted to be less than 2. We describe the symmetries of the matrices appearing in the quantization condition, and decompose solutions into irreducible representations of the appropriate doubled finite-volume symmetry groups. We present an implementation of the three-particle K matrix, keeping the two lowest-order terms in the threshold expansion. We provide numerical predictions for the finite-volume spectrum for a setup with nearly physical parameters, including two-particle interactions that are based on experimental results. This exploratory study shows the how lattice QCD calculations of the three-neutron spectrum with sufficient precision can provide detailed information on both two- and three-particle interactions."}
{"id": "2512.23843", "categories": ["math.OC", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23843", "abs": "https://arxiv.org/abs/2512.23843", "authors": ["Manish Krishan Lal"], "title": "The Flow-Limit of Reflect-Reflect-Relax: Existence, Stability, and Discrete-Time Behavior", "comment": null, "summary": "We study the Reflect-Reflect-Relax (RRR) algorithm in its small-step (flow-limit) regime. In the smooth transversal setting, we show that the transverse dynamics form a hyperbolic sink, yielding exponential decay of a natural gap measure. Under uniform geometric assumptions, we construct a tubular neighborhood of the feasible manifold on which the squared gap defines a strict Lyapunov function, excluding recurrent dynamics and chaotic behavior within this basin.\n  In the discrete setting, the induced flow is piecewise constant on W-domains and supports Filippov sliding along convergent boundaries, leading to finite-time capture into a solution domain. We prove that small-step RRR is a forward-Euler discretization of this flow, so that solution times measured in rescaled units converge to a finite limit while iteration counts diverge, explaining the emergence of iteration-optimal relaxation parameters. Finally, we introduce a heuristic mesoscopic framework based on percolation and renormalization group to organize performance deterioration near the Douglas-Rachford limit."}
{"id": "2512.23930", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.23930", "abs": "https://arxiv.org/abs/2512.23930", "authors": ["Maximilian Schebek", "Jiajun He", "Emil Hoffmann", "Yuanqi Du", "Frank Noé", "Jutta Rogal"], "title": "Assessing generative modeling approaches for free energy estimates in condensed matter", "comment": null, "summary": "The accurate estimation of free energy differences between two states is a long-standing challenge in molecular simulations. Traditional approaches generally rely on sampling multiple intermediate states to ensure sufficient overlap in phase space and are, consequently, computationally expensive. Several generative-model-based methods have recently addressed this challenge by learning a direct bridge between distributions, bypassing the need for intermediate states. However, it remains unclear which approaches provide the best trade-off between efficiency, accuracy, and scalability. In this work, we systematically review these methods and benchmark selected approaches with a focus on condensed-matter systems. In particular, we investigate the performance of discrete and continuous normalizing flows in the context of targeted free energy perturbation as well as FEAT (Free energy Estimators with Adaptive Transport) together with the escorted Jarzynski equality, using coarse-grained monatomic ice and Lennard-Jones solids as benchmark systems. We evaluate accuracy, data efficiency, computational cost, and scalability with system size. Our results provide a quantitative framework for selecting effective free energy estimation strategies in condensed-phase systems."}
{"id": "2512.23814", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23814", "abs": "https://arxiv.org/abs/2512.23814", "authors": ["Filip Bělík", "Yanlai Chen", "Akil Narayan"], "title": "Greedy Rational Approximation for Frequency-Domain Model Reduction of Parametric LTI Systems", "comment": null, "summary": "We investigate model reduction of parametric linear time-invariant (LTI) dynamical systems. When posed in the frequency domain, this problem can be formulated as seeking a low-order rational function approximation of a high-order rational function. We propose to use a standard reduced basis method (RBM) to construct this low-order rational function. Algorithmically, this procedure is an iterative greedy approach, where the greedy objective is evaluated through an error estimator that exploits the linearity of the frequency domain representation. The greedy framework is motivated through theoretical results of rational approximability of functions. This framework provides a principled approach to rational compression of high-order rational functions, and provides a computational pathway for model reduction of parametric LTI systems."}
{"id": "2512.23973", "categories": ["cs.SI", "cs.AI", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.23973", "abs": "https://arxiv.org/abs/2512.23973", "authors": ["Eliot W. Robson", "Abhishek K. Umrawal"], "title": "A Community-Aware Framework for Influence Maximization with Explicit Accounting for Inter-Community Influence", "comment": "7 pages, 4 figures, and 1 table", "summary": "Influence Maximization (IM) seeks to identify a small set of seed nodes in a social network to maximize expected information spread under a diffusion model. While community-based approaches improve scalability by exploiting modular structure, they typically assume independence between communities, overlooking inter-community influence$\\unicode{x2014}$a limitation that reduces effectiveness in real-world networks. We introduce Community-IM++, a scalable framework that explicitly models cross-community diffusion through a principled heuristic based on community-based diffusion degree (CDD) and a progressive budgeting strategy. The algorithm partitions the network, computes CDD to prioritize bridging nodes, and allocates seeds adaptively across communities using lazy evaluation to minimize redundant computations. Experiments on large real-world social networks under different edge weight models show that Community-IM++ achieves near-greedy influence spread at up to 100 times lower runtime, while outperforming Community-IM and degree heuristics across budgets and structural conditions. These results demonstrate the practicality of Community-IM++ for large-scale applications such as viral marketing, misinformation control, and public health campaigns, where efficiency and cross-community reach are critical."}
{"id": "2512.23719", "categories": ["cs.CE", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23719", "abs": "https://arxiv.org/abs/2512.23719", "authors": ["Steven Owen", "Nathan Brown", "Nikos Chrisochoides", "Rao Garimella", "Xianfeng Gu", "Franck Ledoux", "Na Lei", "Roshan Quadros", "Navamita Ray", "Nicolas Winovich", "Yongjie Jessica Zhang"], "title": "A Survey of AI Methods for Geometry Preparation and Mesh Generation in Engineering Simulation", "comment": "35 pages, 0 figure, accepted by the International Meshing Roundtable conference 2026", "summary": "Artificial intelligence is beginning to ease long-standing bottlenecks in the CAD-to-mesh pipeline. This survey reviews recent advances where machine learning aids part classification, mesh quality prediction, and defeaturing. We explore methods that improve unstructured and block-structured meshing, support volumetric parameterizations, and accelerate parallel mesh generation. We also examine emerging tools for scripting automation, including reinforcement learning and large language models. Across these efforts, AI acts as an assistive technology, extending the capabilities of traditional geometry and meshing tools. The survey highlights representative methods, practical deployments, and key research challenges that will shape the next generation of data-driven meshing workflows."}
{"id": "2512.23914", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23914", "abs": "https://arxiv.org/abs/2512.23914", "authors": ["Bin Xu", "Ayan Banerjee", "Sandeep Gupta"], "title": "Hardware Acceleration for Neural Networks: A Comprehensive Survey", "comment": null, "summary": "Neural networks have become a dominant computational workload across cloud and edge platforms, but rapid growth in model size and deployment diversity has exposed hardware bottlenecks increasingly dominated by memory movement, communication, and irregular operators rather than peak arithmetic throughput. This survey reviews the technology landscape for hardware acceleration of deep learning, spanning GPUs and tensor-core architectures; domain-specific accelerators (e.g., TPUs/NPUs); FPGA-based designs; ASIC inference engines; and emerging LLM-serving accelerators such as LPUs (language processing units), alongside in-/near-memory computing and neuromorphic/analog approaches. We organize the space using a unified taxonomy across (i) workloads (CNNs, RNNs, GNNs, and Transformers/LLMs), (ii) execution settings (training vs.\\ inference; datacenter vs.\\ edge), and (iii) optimization levers (reduced precision, sparsity and pruning, operator fusion, compilation and scheduling, and memory-system/interconnect design). We synthesize key architectural ideas including systolic arrays, vector and SIMD engines, specialized attention and softmax kernels, quantization-aware datapaths, and high-bandwidth memory, and we discuss how software stacks and compilers bridge model semantics to hardware. Finally, we highlight open challenges -- including efficient long-context LLM inference (KV-cache management), robust support for dynamic and sparse workloads, energy- and security-aware deployment, and fair benchmarking -- and point to promising directions for the next generation of neural acceleration."}
{"id": "2512.24202", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.24202", "abs": "https://arxiv.org/abs/2512.24202", "authors": ["Guillaume Chagnaud", "Chris M Taylor", "Lawrence S Jackson", "Anne Barber", "Helen Burns", "John H Marsham", "Cathryn E Birch"], "title": "Mesoscale soil moisture heterogeneity can locally amplify humid heat", "comment": null, "summary": "Soil moisture is a key ingredient of humid heat through supplying moisture and modifying boundary layer properties. Soil moisture heterogeneity due to e.g., antecedent rainfall, can strongly influence weather patterns; yet, its effect on humid heat is poorly understood. Idealized numerical simulations are performed with a cloud-resolving ($Δx$=500 m), coupled land-atmosphere model wherein wet patches on length-scales $λ\\in$ 25-150 km are prescribed. Compared to experiments with uniform soil moisture, humid heat is locally amplified by 1-4$^\\circ$C, with maximum amplification for the critical soil moisture length-scale $λ_c=$ 50 km. Subsidence associated with a soil moisture-induced mesoscale circulation concentrates warm, humid air in a shallower boundary layer. The background wind and the magnitude of the wet-dry contrast control the relationship between $λ_c$ and the humid heat amplification. Based on observed soil moisture patterns, these results will help to predict extreme humid heat at city and county scales across the Tropics."}
{"id": "2512.23914", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.23914", "abs": "https://arxiv.org/abs/2512.23914", "authors": ["Bin Xu", "Ayan Banerjee", "Sandeep Gupta"], "title": "Hardware Acceleration for Neural Networks: A Comprehensive Survey", "comment": null, "summary": "Neural networks have become a dominant computational workload across cloud and edge platforms, but rapid growth in model size and deployment diversity has exposed hardware bottlenecks increasingly dominated by memory movement, communication, and irregular operators rather than peak arithmetic throughput. This survey reviews the technology landscape for hardware acceleration of deep learning, spanning GPUs and tensor-core architectures; domain-specific accelerators (e.g., TPUs/NPUs); FPGA-based designs; ASIC inference engines; and emerging LLM-serving accelerators such as LPUs (language processing units), alongside in-/near-memory computing and neuromorphic/analog approaches. We organize the space using a unified taxonomy across (i) workloads (CNNs, RNNs, GNNs, and Transformers/LLMs), (ii) execution settings (training vs.\\ inference; datacenter vs.\\ edge), and (iii) optimization levers (reduced precision, sparsity and pruning, operator fusion, compilation and scheduling, and memory-system/interconnect design). We synthesize key architectural ideas including systolic arrays, vector and SIMD engines, specialized attention and softmax kernels, quantization-aware datapaths, and high-bandwidth memory, and we discuss how software stacks and compilers bridge model semantics to hardware. Finally, we highlight open challenges -- including efficient long-context LLM inference (KV-cache management), robust support for dynamic and sparse workloads, energy- and security-aware deployment, and fair benchmarking -- and point to promising directions for the next generation of neural acceleration."}
{"id": "2512.23866", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.23866", "abs": "https://arxiv.org/abs/2512.23866", "authors": ["Carlos Henrique Trigo Nasser Felix", "Nancy Lopes Garcia", "Alex Rodrigo dos Santos Sousa"], "title": "A Fuzzy Approach for Randomized Confidence Intervals", "comment": null, "summary": "We propose randomized confidence intervals based on the Neyman-Pearson lemma, in order to make them more broadly applicable to distributions that do not satisfy regularity conditions. This is achieved by using the definition of fuzzy confidence intervals. These intervals are compared with methods described in the literature for well-known distributions such as normal, binomial, and Poisson. The results show that in high-variance situations, the new intervals provide better performance. Furthermore, through these intervals, it is possible to compute a lower bound for the expected length, demonstrating that they achieve the minimal maximum expected length for a Bernoulli trial observation."}
{"id": "2512.24738", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.24738", "abs": "https://arxiv.org/abs/2512.24738", "authors": ["Michael Hilke"], "title": "The disordered Su-Schrieffer-Heeger model", "comment": null, "summary": "Quantum topology categorizes physical systems in integer invariants, which are robust to some deformations and certain types of disorder. A prime example is the Su-Schrieffer-Heeger (SSH) model, which has two distinct topological phases, the trivial phase with no edge states and the non-trivial phase with zero-energy edge states. The energy dispersion of the SSH model is dominated by a gap around zero energy, which suppresses the transmission. This exponential suppression of the transmission with system length is determined by the Lyapounov exponent. Here we find an analytical expression of the Lyapounov as a function of energy in the presence of both diagonal and off-diagonal disorder. We obtain this result by finding a recurrence relation for the local density, which can be averaged over different disorder configurations. There is excellent agreement between our analytical expression and the numerical results over a wide range of disorder strengths and disorder types. The real space winding number is evaluated as a function of off-diagonal and on-site disorder for possible applications of quantum topology."}
{"id": "2512.25057", "categories": ["physics.hist-ph", "gr-qc", "math-ph", "math.LO"], "pdf": "https://arxiv.org/pdf/2512.25057", "abs": "https://arxiv.org/abs/2512.25057", "authors": ["Eren Volkan Küçük"], "title": "The Logical Structure of Physical Laws: A Fixed Point Reconstruction", "comment": null, "summary": "We formalise the self referential definition of physical laws using monotone operators on a lattice of theories, resolving the pathologies of naive set theoretic formulations. By invoking Tarski fixed point theorem, we identify physical theories as least fixed points of admissibility constraints derived from Galois connections. We demonstrate that QED and General Relativity can be represented in such a logical structure with respect to their symmetry and locality principles."}
{"id": "2512.24534", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.24534", "abs": "https://arxiv.org/abs/2512.24534", "authors": ["Xizhe Xie", "Wengu Chen", "Weiming Li", "Peng Song", "Han Wang"], "title": "BF-APNN: A Low-Memory Method for Accelerating the Solution of Radiative Transfer Equations", "comment": null, "summary": "The Radiative Transfer Equations (RTEs) exhibit high dimensionality and multiscale characteristics, rendering conventional numerical methods computationally intensive. Existing deep learning methods perform well in low-dimensional or linear RTEs, but still face many challenges with high-dimensional or nonlinear RTEs. To overcome these challenges, we propose the Basis Function Asymptotically Preserving Neural Network (BF-APNN), a framework that inherits the advantages of Radiative Transfer Asymptotically Preserving Neural Network (RT-APNN) and accelerates the solution process. By employing basis function expansion on the microscopic component, derived from micro-macro decomposition, BF-APNN effectively mitigates the computational burden associated with evaluating high-dimensional integrals during training. Numerical experiments, which involve challenging RTE scenarios featuring, nonlinearity, discontinuities, and multiscale behavior, demonstrate that BF-APNN substantially reduces training time compared to RT-APNN while preserving high solution accuracy. Moreover, BF-APNN exhibits superior performance in addressing complex, high-dimensional RTE problems, underscoring its potential as a robust tool for radiative transfer computations."}
{"id": "2512.23751", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.23751", "abs": "https://arxiv.org/abs/2512.23751", "authors": ["Lorenzo Pirovano"], "title": "Landauer cost in a continuous vacuum/no-vacuum measurement", "comment": "11 pages, 1 figure", "summary": "We study the thermodynamic cost of maintaining a continuous binary record of a vacuum or no-vacuum measurement. Modeling the monitoring as a time-binned click or no-click process with finite bandwidth, we treat the outcomes as a classical register that is reset after each bin. Landauer's principle then yields an operational lower bound on the dissipated heat rate set by the Shannon entropy rate of the measurement record. We discuss the role of coarse-graining, extend the analysis to many monitored modes, including correlations and compressibility, and provide parameter estimates for circuit-QED photon monitoring, with a speculative horizon-based bookkeeping illustration."}
{"id": "2512.23734", "categories": ["cs.ET", "cs.LO"], "pdf": "https://arxiv.org/pdf/2512.23734", "abs": "https://arxiv.org/abs/2512.23734", "authors": ["Han Huang", "Chengzhi Ma", "Yuxin Zhao", "Qingyao Wang", "Xinglong Xiao", "Xiulin Shu", "Zhifeng Hao"], "title": "Biochemical Computing Mode for Sequential Logic", "comment": "23 pages, 1 figures, 4 tables", "summary": "Recent years have witnessed the growing scholarly interest in the next-generation general-purpose computers. Various innovative computing modes have been proposed, such as optical, quantum phenomena, and DNA-based modes. Sequential logic circuits are a critical factor that enables these modes to function as general-purpose computers, given their essential role in facilitating continuous computation and memory storage through their ability to store states. However, compared to computability, it is often overlooked due to the difficulty of its implementation. In this paper, we first demonstrate sequential mapping, a crucial necessary condition for electronic computers to realize sequential logic circuits, and highlight this distinctive property of general-purpose computers in the context of logic gate circuits. To achieve computational functionalities comparable to those of electronic computers, we utilize the control effect of enzymes on enzymatic reactions to design a logic gate model that is composed of small molecules and driven by enzymes, subsequently propose a biochemical computing mode. Furthermore, we mathematically analyze the static and dynamic input-output properties of biochemical logic gate components and prove that the biochemical computing mode satisfies sequential mapping similar to electronic computers. When combined with the storage characteristics of NOT-AND gates, it can realize sequential logic circuits. The findings can serve as a theoretical foundation for developing general-purpose biochemical computers."}
{"id": "2512.24042", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.24042", "abs": "https://arxiv.org/abs/2512.24042", "authors": ["Chunhao Cai"], "title": "Local Asymptotic Normality for Mixed Fractional Brownian Motion with $0<H<3/4$", "comment": null, "summary": "This paper establishes the Local Asymptotic Normality (LAN) property for the mixed fractional Brownian motion under high-frequency observations with Hurst index $H \\in (0, 3/4)$. The simultaneous estimation of the volatility and the Hurst index encounters a degeneracy problem in the Fisher information matrix."}
{"id": "2512.24580", "categories": ["q-fin.RM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24580", "abs": "https://arxiv.org/abs/2512.24580", "authors": ["Shanyu Han", "Yangbo He", "Yang Liu"], "title": "Robust Bayesian Dynamic Programming for On-policy Risk-sensitive Reinforcement Learning", "comment": "63 pages", "summary": "We propose a novel framework for risk-sensitive reinforcement learning (RSRL) that incorporates robustness against transition uncertainty. We define two distinct yet coupled risk measures: an inner risk measure addressing state and cost randomness and an outer risk measure capturing transition dynamics uncertainty. Our framework unifies and generalizes most existing RL frameworks by permitting general coherent risk measures for both inner and outer risk measures. Within this framework, we construct a risk-sensitive robust Markov decision process (RSRMDP), derive its Bellman equation, and provide error analysis under a given posterior distribution. We further develop a Bayesian Dynamic Programming (Bayesian DP) algorithm that alternates between posterior updates and value iteration. The approach employs an estimator for the risk-based Bellman operator that combines Monte Carlo sampling with convex optimization, for which we prove strong consistency guarantees. Furthermore, we demonstrate that the algorithm converges to a near-optimal policy in the training environment and analyze both the sample complexity and the computational complexity under the Dirichlet posterior and CVaR. Finally, we validate our approach through two numerical experiments. The results exhibit excellent convergence properties while providing intuitive demonstrations of its advantages in both risk-sensitivity and robustness. Empirically, we further demonstrate the advantages of the proposed algorithm through an application on option hedging."}
{"id": "2512.24337", "categories": ["nlin.CG", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.24337", "abs": "https://arxiv.org/abs/2512.24337", "authors": ["Henryk Fukś"], "title": "Solving the initial value problem for cellular automata by pattern decomposition", "comment": "27 pages, 6 figures", "summary": "For many cellular automata, it is possible to express the state of a given cell after $n$ iterations as an explicit function of the initial configuration. We say that for such rules the solution of the initial value problem can be obtained. In some cases, one can construct the solution formula for the initial value problem by analyzing the spatiotemporal pattern generated by the rule and decomposing it into simpler segments which one can then describe algebraically. We show an example of a rule when such approach is successful, namely elementary rule 156. Solution of the initial value problem for this rule is constructed and then used to compute the density of ones after $n$ iterations, starting from a random initial condition. We also show how to obtain probabilities of occurrence of longer blocks of symbols."}
{"id": "2512.23912", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.23912", "abs": "https://arxiv.org/abs/2512.23912", "authors": ["Ruei-Jiun Hung", "Matthew Weingarten", "Shuo Ma", "Steven M. Day"], "title": "Inelastic dilatancy as a mechanism for coseismic fluid depressurization of a shallow fault zone", "comment": null, "summary": "Hydrologic observations and experimental studies indicate that inelastic dilation from coseismic fault damage can cause substantial pore pressure reduction, yet most near-fault hydromechanical models ignore such inelastic effects. Here, we present a 3-D groundwater flow model incorporating the effects of inelastic dilation based on an earthquake dynamic rupture model with inelastic off fault deformation, both on pore pressure and permeability enhancement. Our results show that inelastic dilation causes mostly notable depressurization within 1 to 2 km off the fault at shallow depths (< 3 km). We found agreement between our model predictions and recent field observations, namely that both sides of the fault can experience large magnitude (~tens of meters) water level drawdowns. For comparison, simulations considering only elastic strain produced smaller water level changes (~several meters) and contrasting signs of water level change on either side of the fault. The models show that inelastic dilation is a mechanism for coseismic fault depressurization at shallow depths. While the inelastic dilation is a localized phenomenon which is most pronounced in the fault zone, the pressure gradients produced in the coseismic phase have a broader effect, increasing fluid migration back into the fault zone in the postseismic phase. We suggest field hydrologic measurements in the very near field (1 to 2 km) of active faults could capture damage-related pore pressure signals produced by inelastic dilation, helping improve our understanding of fault mechanics and groundwater management near active faults."}
{"id": "2512.23883", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23883", "abs": "https://arxiv.org/abs/2512.23883", "authors": ["Achyut Tiwari", "Maxim Wenzel", "Renjith Mathew Roy", "Christian Prange", "Bruno Gompf", "Martin Dressel"], "title": "Origin of insulating state in bulk $1T$-TaS$_2$ revealed by out-of-plane dimerization", "comment": null, "summary": "The commensurate charge-density-wave phase in the protoypical transition metal dichalcogenide $1T$-TaS$_2$ is investigated by temperature and polarization-dependent infrared spectroscopy revealing the fundamentally different charge dynamics parallel and perpendicular to the layers. Supported by density-functional-theory calculations, we demonstrate that the out-of-plane response is governed by a quasi-one-dimensional, Peierls-like dimerization of the two-dimensional star-of-David layers. In particular, our results identifies this dimerization as the primary driving mechanism of the metal-to-insulator transition, ruling out a significant role of electronic correlations."}
{"id": "2512.24332", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2512.24332", "abs": "https://arxiv.org/abs/2512.24332", "authors": ["Junhong Liu", "Nan Zhou", "Minda Ma", "Kairui You"], "title": "Decarbonizing China's private passenger vehicles: A dynamic material flow assessment of metal demands and embodied emissions", "comment": null, "summary": "The continuous growth of China's private passenger vehicle fleet has intensified material demand and embodied carbon emissions, underscoring the need for effective decarbonization pathways. This study develops a transferable, dynamic material flow analysis framework to assess vehicle stocks, metal flows (steel, aluminum, and copper), and embodied emissions from 2000 to 2070, and to quantify the contributions of demand-side and technology-side efficiency measures. The results reveal that: (1) The vehicle fleet is projected to peak at 327-507 million vehicles by mid-century, with new energy vehicles dominating both in-use stocks and end-of-life flows by the 2040s. (2) Cumulative metal demand is projected to reach 1914-2990 million tonnes over the upcoming five decades, with 879-1320 million tonnes supplied from secondary sources under baseline conditions. Technology-oriented measures substantially enhance recycling performance, enabling secondary steel to fully meet manufacturing demand and allowing aluminum and copper cycles to approach near closure by 2070. (3) Correspondingly, cumulative embodied carbon emissions from vehicle metals by 2070 range from 4958 to 9218 megatonnes of carbon dioxide, with technological upgrading reducing emissions by 1051-1619 megatonnes. In collaborative scenarios, demand management accounts for 64.3% of total emission reductions, while technology-oriented measures become increasingly important over the medium to long term. Overall, the findings demonstrate that unmanaged demand growth can substantially offset technological mitigation gains, highlighting the necessity of integrated demand- and technology-oriented strategies. This study provides a systemic and transferable framework to guide circular economy development and deep decarbonization transitions in vehicle fleets in China and other emerging economies."}
{"id": "2512.24836", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.24836", "abs": "https://arxiv.org/abs/2512.24836", "authors": ["Sandip Maiti", "Debasish Banerjee", "Shailesh Chandrasekharan", "Marina K. Marinkovic"], "title": "Symmetric mass generation as a multicritical point with enhanced symmetry", "comment": "6 pages, 4 figures", "summary": "We explore the phase diagram of a lattice fermion model that exhibits three distinct phases: a massless fermion (MF) phase; a massive fermion phase with spontaneous symmetry breaking (SSB) induced by a fermion bilinear condensate; and a massive fermion phase with symmetric mass generation (SMG). Using the fermion-bag Monte Carlo method on large cubical lattices, we find evidence for traditional second-order critical points separating the first two and the latter two phases. Remarkably, these critical points appear to merge at a multicritical point with enhanced symmetry when the symmetry breaking parameter is tuned to zero, giving rise to the recently discovered direct second-order transition between the massless and symmetric massive fermion phases."}
{"id": "2512.24056", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24056", "abs": "https://arxiv.org/abs/2512.24056", "authors": ["Wenye Li", "Hongxu Chen", "Jiacai Liu", "Ke Wei"], "title": "Policy Mirror Descent with Temporal Difference Learning: Sample Complexity under Online Markov Data", "comment": null, "summary": "This paper studies the policy mirror descent (PMD) method, which is a general policy optimization framework in reinforcement learning and can cover a wide range of policy gradient methods by specifying difference mirror maps. Existing sample complexity analysis for policy mirror descent either focuses on the generative sampling model, or the Markovian sampling model but with the action values being explicitly approximated to certain pre-specified accuracy. In contrast, we consider the sample complexity of policy mirror descent with temporal difference (TD) learning under the Markovian sampling model. Two algorithms called Expected TD-PMD and Approximate TD-PMD have been presented, which are off-policy and mixed policy algorithms respectively. Under a small enough constant policy update step size, the $\\tilde{O}(\\varepsilon^{-2})$ (a logarithm factor about $\\varepsilon$ is hidden in $\\tilde{O}(\\cdot)$) sample complexity can be established for them to achieve average-time $\\varepsilon$-optimality. The sample complexity is further improved to $O(\\varepsilon^{-2})$ (without the hidden logarithm factor) to achieve the last-iterate $\\varepsilon$-optimality based on adaptive policy update step sizes."}
{"id": "2512.24359", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24359", "abs": "https://arxiv.org/abs/2512.24359", "authors": ["Debraj Das", "Luca Giuggioli"], "title": "Tethering effects on first-passage variables of lattice random walks in linear and quadratic focal point potentials", "comment": "23 pages, 11 figures", "summary": "Diffusion in a confining potential offers a minimal setting to understand the interplay between random motion and deterministic forces driving a particle towards a focal point or potential minimum. In continuous space and time, two extensively studied examples are Brownian motion in a linear (V-shaped) or a quadratic (U-shaped) potential. The deterministic bias towards the minimum is represented, respectively, by a constant force for the former and by an elastic restoring force that increases proportionally with distance for the latter. Surprisingly, unlike Brownian walks, random walks under focal point potentials in discrete space and time have received little attention. Here, we bridge this gap by analysing the dynamics of lattice random walkers in the presence of a V-shaped potential, both in a finite and an infinite spatial domain, and a finite U-shaped potential. For the V-potential in unbounded space, we find the generating function of the occupation probability and analyse the time dependence of the mean number of distinct sites visited, demonstrating that its long-time growth is logarithmic. We also study the first-passage probability and show that its mean may display a minimum as a function of bias strength, depending on the location of the initial and target sites relative to the focal point. Qualitatively similar dependencies in the first-passage probability and its mean appear for the finite U-potential. As a comparative analysis to the U-potential, we construct the bounded V-potential and superimpose in both cases a resetting process, in which the walker returns at random times to a site distinct from the focal point with some probability. We quantify the different effects of resetting on the steady-state probability and the first-passage dynamics in the two cases, and show a motion-limited regime emerges even for relatively moderate resetting probabilities."}
{"id": "2512.23829", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23829", "abs": "https://arxiv.org/abs/2512.23829", "authors": ["Oluwatosin Akande", "Gabriel P. Langlois", "Akwum Onwunta"], "title": "Deep learning methods for inverse problems using connections between proximal operators and Hamilton-Jacobi equations", "comment": null, "summary": "Inverse problems are important mathematical problems that seek to recover model parameters from noisy data. Since inverse problems are often ill-posed, they require regularization or incorporation of prior information about the underlying model or unknown variables. Proximal operators, ubiquitous in nonsmooth optimization, are central to this because they provide a flexible and convenient way to encode priors and build efficient iterative algorithms. They have also recently become key to modern machine learning methods, e.g., for plug-and-play methods for learned denoisers and deep neural architectures for learning priors of proximal operators. The latter was developed partly due to recent work characterizing proximal operators of nonconvex priors as subdifferential of convex potentials. In this work, we propose to leverage connections between proximal operators and Hamilton-Jacobi partial differential equations (HJ PDEs) to develop novel deep learning architectures for learning the prior. In contrast to other existing methods, we learn the prior directly without recourse to inverting the prior after training. We present several numerical results that demonstrate the efficiency of the proposed method in high dimensions."}
{"id": "2512.24336", "categories": ["cs.SI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.24336", "abs": "https://arxiv.org/abs/2512.24336", "authors": ["Sara Geremia", "Michael Fop", "Domenico De Stefano"], "title": "A density-based framework for community detection in attributed networks", "comment": null, "summary": "Community structure in social and collaborative networks often emerges from a complex interplay between structural mechanisms, such as degree heterogeneity and leader-driven attraction, and homophily on node attributes. Existing community detection methods typically focus on these dimensions in isolation, limiting their ability to recover interpretable communities in presence of such mechanisms. In this paper, we propose AttDeCoDe, an attribute-driven extension of a density-based community detection framework, developed to analyse networks where node characteristics play a central role in group formation. Instead of defining density purely from network topology, AttDeCoDe estimates node-wise density in the attribute space, allowing communities to form around attribute-based community representatives while preserving structural connectivity constraints. This approach naturally captures homophily-driven aggregation while remaining sensitive to leader influence. We evaluate the proposed method through a simulation study based on a novel generative model that extends the degree-corrected stochastic block model by incorporating attribute-driven leader attraction, reflecting key features of collaborative research networks. We perform an empirical application to research collaboration data from the Horizon programmes, where organisations are characterised by project-level thematic descriptors. Both results show that AttDeCoDe offers a flexible and interpretable framework for community detection in attributed networks achieving competitive performance relative to topology-based and attribute-assisted benchmarks."}
{"id": "2512.24487", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2512.24487", "abs": "https://arxiv.org/abs/2512.24487", "authors": ["Lecheng Zheng", "Jian Ni", "Chris Zobel", "John R Birge"], "title": "Networked Markets, Fragmented Data: Adaptive Graph Learning for Customer Risk Analytics and Policy Design", "comment": null, "summary": "Financial institutions face escalating challenges in identifying high-risk customer behaviors within massive transaction networks, where fraudulent activities exploit market fragmentation and institutional boundaries. We address three fundamental problems in customer risk analytics: data silos preventing holistic relationship assessment, extreme behavioral class imbalance, and suboptimal customer intervention strategies that fail to balance compliance costs with relationship value. We develop an integrated customer intelligence framework combining federated learning, relational network analysis, and adaptive targeting policies. Our federated graph neural network enables collaborative behavior modeling across competing institutions without compromising proprietary customer data, using privacy-preserving embeddings to capture cross-market relational patterns. We introduce cross-bank Personalized PageRank to identify coordinated behavioral clusters providing interpretable customer network segmentation for risk managers. A hierarchical reinforcement learning mechanism optimizes dynamic intervention targeting, calibrating escalation policies to maximize prevention value while minimizing customer friction and operational costs. Analyzing 1.4 million customer transactions across seven markets, our approach reduces false positive and false negative rates to 4.64% and 11.07%, substantially outperforming single-institution models. The framework prevents 79.25% of potential losses versus 49.41% under fixed-rule policies, with optimal market-specific targeting thresholds reflecting heterogeneous customer base characteristics. These findings demonstrate that federated customer analytics materially improve both risk management effectiveness and customer relationship outcomes in networked competitive markets."}
{"id": "2512.24101", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24101", "abs": "https://arxiv.org/abs/2512.24101", "authors": ["Rößler Nicolas", "Khan Irfan", "Schade Thomas", "Wellmann Christoph", "Cao Xinyuan", "Kopynske Milan", "Xia Feihong", "Savelsberg Rene", "Andert Jakob"], "title": "Economic and Technical Feasibility of V2G in Non-Road Mobile Machinery sector", "comment": "Conference publication", "summary": "This paper investigates the economic and technical feasibility of integrating Vehicle-to-Grid (V2G) technology in the Non-Road Mobile Machinery (NRMM) sector. These often-idling assets, with their substantial battery capacities, present a unique opportunity to participate in energy markets, providing grid services and generating additional revenue. A novel methodology is introduced that integrates Bayesian Optimization (BO) to optimize the energy infrastructure together with an operating strategy optimization to reduce the electricity costs while enhancing grid interaction. While the focus lies on the methodology, the financial opportunities for the use-case of an electric NRMM rental service will be presented. However, the study is limited by the availability of real-world data on the usage of electric NRMM and does not address regulatory challenges of V2G. Further research is needed to extend the model accuracy and validate these findings."}
{"id": "2512.24440", "categories": ["physics.ao-ph", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.24440", "abs": "https://arxiv.org/abs/2512.24440", "authors": ["Theodore MacMillan", "Nicholas T. Ouellette"], "title": "Towards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features", "comment": "18 pages, 13 figures", "summary": "Large data-driven physics models like DeepMind's weather model GraphCast have empirically succeeded in parameterizing time operators for complex dynamical systems with an accuracy reaching or in some cases exceeding that of traditional physics-based solvers. Unfortunately, how these data-driven models perform computations is largely unknown and whether their internal representations are interpretable or physically consistent is an open question. Here, we adapt tools from interpretability research in Large Language Models to analyze intermediate computational layers in GraphCast, leveraging sparse autoencoders to discover interpretable features in the neuron space of the model. We uncover distinct features on a wide range of length and time scales that correspond to tropical cyclones, atmospheric rivers, diurnal and seasonal behavior, large-scale precipitation patterns, specific geographical coding, and sea-ice extent, among others. We further demonstrate how the precise abstraction of these features can be probed via interventions on the prediction steps of the model. As a case study, we sparsely modify a feature corresponding to tropical cyclones in GraphCast and observe interpretable and physically consistent modifications to evolving hurricanes. Such methods offer a window into the black-box behavior of data-driven physics models and are a step towards realizing their potential as trustworthy predictors and scientifically valuable tools for discovery."}
{"id": "2512.24101", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24101", "abs": "https://arxiv.org/abs/2512.24101", "authors": ["Rößler Nicolas", "Khan Irfan", "Schade Thomas", "Wellmann Christoph", "Cao Xinyuan", "Kopynske Milan", "Xia Feihong", "Savelsberg Rene", "Andert Jakob"], "title": "Economic and Technical Feasibility of V2G in Non-Road Mobile Machinery sector", "comment": "Conference publication", "summary": "This paper investigates the economic and technical feasibility of integrating Vehicle-to-Grid (V2G) technology in the Non-Road Mobile Machinery (NRMM) sector. These often-idling assets, with their substantial battery capacities, present a unique opportunity to participate in energy markets, providing grid services and generating additional revenue. A novel methodology is introduced that integrates Bayesian Optimization (BO) to optimize the energy infrastructure together with an operating strategy optimization to reduce the electricity costs while enhancing grid interaction. While the focus lies on the methodology, the financial opportunities for the use-case of an electric NRMM rental service will be presented. However, the study is limited by the availability of real-world data on the usage of electric NRMM and does not address regulatory challenges of V2G. Further research is needed to extend the model accuracy and validate these findings."}
{"id": "2512.23993", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.23993", "abs": "https://arxiv.org/abs/2512.23993", "authors": ["Landon Hurley"], "title": "Completing and studentising Spearman's correlation in the presence of ties", "comment": null, "summary": "Non-parametric correlation coefficients have been widely used for analysing arbitrary random variables upon common populations, when requiring an explicit error distribution to be known is an unacceptable assumption. We examine an \\(\\ell_{2}\\) representation of a correlation coefficient (Emond and Mason, 2002) from the perspective of a statistical estimator upon random variables, and verify a number of interesting and highly desirable mathematical properties, mathematically similar to the Whitney embedding of a Hilbert space into the \\(\\ell_{2}\\)-norm space. In particular, we show here that, in comparison to the traditional Spearman (1904) \\(ρ\\), the proposed Kemeny \\(ρ_κ\\) correlation coefficient satisfies Gauss-Markov conditions in the presence or absence of ties, thereby allowing both discrete and continuous marginal random variables. We also prove under standard regularity conditions a number of desirable scenarios, including the construction of a null hypothesis distribution which is Student-t distributed, parallel to standard practice with Pearson's r, but without requiring either continuous random variables nor particular Gaussian errors. Simulations in particular focus upon highly kurtotic data, with highly nominal empirical coverage consistent with theoretical expectation."}
{"id": "2512.24774", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.24774", "abs": "https://arxiv.org/abs/2512.24774", "authors": ["A. D. Berezner", "V. A. Fedorov", "N. S. Perov", "G. V. Grigoriev"], "title": "Novel exact solutions of the Duffing equation: stability analysis and application to real non-linear deformation tests", "comment": "preprint article, 29 pages, 21 figures", "summary": "In this study, novel exact solutions of the Duffing equation with their phase portraits have been proposed and reasoned. It is shown that phase trajectories are initially elliptical and become distorted in the unstable area within the growth of the variable parameter. Instability criteria of identified solutions have been determined together with the Fourier series transformation up to the first and high harmonics in a sense of the physical interpretation. An explicit form for the differential operator, corresponding to considered functions, has been derived with evaluation of its main functional spectrum. Non-isothermal creep tests of different materials were completely described using the Duffing equation via noted solutions up to the fracture as processes with personal deformation response. We successfully examined a relationship between the thermal and magnetic properties of the ferromagnetic amorphous alloy under its non-linear deformation, using the critical exponents. With a high linear correlation between our model and experiments, behaviour of organic and metallic systems is well predicted at the same thermo-mechanical testing conditions on the mesoscale."}
{"id": "2512.24970", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.24970", "abs": "https://arxiv.org/abs/2512.24970", "authors": ["Chen Chen", "Jiuyang Liang", "Zhenli Xu", "Qianru Zhang"], "title": "Random Batch Sum-of-Gaussians Method for Molecular Dynamics of Born-Mayer-Huggins Systems", "comment": "18 pages, 5 figures, 3 tables", "summary": "The Born-Mayer-Huggins (BMH) potential, which combines Coulomb interactions with dispersion and short-range exponential repulsion, is widely used for ionic materials such as molten salts. However, large-scale molecular dynamics simulations of BMH systems are often limited by computation, communication, and memory costs. We recently proposed the random batch sum-of-Gaussians (RBSOG) method, which accelerates Coulomb calculations by using a sum-of-Gaussians (SOG) decomposition to split the potential into short- and long-range parts and by applying importance sampling in Fourier space for the long-range part. In this work, we extend the RBSOG to BMH systems and incorporate a random batch list (RBL) scheme to further accelerate the short-range part, yielding a unified framework for efficient simulations with the BMH potential. The combination of the SOG decomposition and the RBL enables an efficient and scalable treatment of both long- and short-range interactions in BMH system, particularly the RBL well handles the medium-range exponential repulsion and dispersion by the random batch neighbor list. Error estimate is provided to show the theoretical convergence of the RBL force. We evaluate the framework on molten NaCl and mixed alkali halide with up to $5\\times10^6$ atoms on $2048$ CPU cores. Compared to the Ewald-based particle-particle particle-mesh method and the RBSOG-only method, our method achieves approximately $4\\sim10\\times$ and $2\\times$ speedups while using $1000$ cores, respectively, under the same level of structural and thermodynamic accuracy and with a reduced memory usage. These results demonstrate the attractive performance of our method in accuracy and scalability for MD simulations with long-range interactions."}
{"id": "2512.23759", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23759", "abs": "https://arxiv.org/abs/2512.23759", "authors": ["Kirill F. Sheberstov"], "title": "Aliphatic Chains as One-Dimensional XY Spin Chains", "comment": null, "summary": "Spin waves are propagating disturbances of spin order in lattices with nearest-neighbor interactions. They are traditionally observed in magnetically ordered solids using inelastic neutron, light, or electron scattering, and ferromagnetic resonance. Here, we show that analogous spin dynamics can arise in liquid-state nuclear magnetic resonance (NMR) of molecules containing aliphatic chains. In such molecules, each CH_2 group must have a distinct chemical shift and be magnetically inequivalent via out-of-pair couplings. Under these conditions, singlet state populations of geminal protons propagate along (CH_2)_n segments forming magnetically silent spin waves. For a chain with translational symmetry, the spin Hamiltonian factorizes into subspaces formally equivalent to the one-dimensional XY model. This correspondence yields analytic expressions for eigenstates and eigenenergies in a spectroscopy we term spin-chain zero-quantum NMR. We identify molecular systems in which these conditions are met. Their collective dynamics rapidly exceed classical computational tractability, making them targets for quantum-computer simulations of spin transport and many-body dynamics."}
{"id": "2512.23736", "categories": ["cs.ET", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.23736", "abs": "https://arxiv.org/abs/2512.23736", "authors": ["Unhyeon Kang", "Jaesang Lee", "Seungmin Oh", "Hanchan Song", "Jongkil Park", "Jaewook Kim", "Seongsik Park", "Hyun Jae Jang", "Sangbum Kim", "Su-in Yi", "Suhas Kumar", "Suyoun Lee"], "title": "Ovonic switches enable energy-efficient dendrite-like computing", "comment": "17 pages, 5 figures, 1 table. Published in Nano Letters (2025). This document is the unedited Author's version of a Submitted Work that was subsequently accepted for publication in Nano Letters, copyright (c) American Chemical Society after peer review. To access the final edited and published work see https://pubs.acs.org/doi/full/10.1021/acs.nanolett.5c04348", "summary": "Over the last decade, dendrites within individual biological neurons, which were previously thought to generally perform information pooling and networking, have now been shown to express complex temporal dynamics, Boolean-like logic, arithmetic, signal discrimination, and edge detection for image and sound recognition. Mimicking this rich functional density could offer a powerful primitive for neuromorphic computing, which has sought to replace the aging digital computing paradigms using biological inspirations. Here, using electrically driven Ovonic threshold switching in Sb-Te-doped GeSe, we demonstrate a single two-terminal component capable of self-sustained dynamics and universal Boolean logic, in addition to XOR operations (which is traditionally thought to require a network of active components). We then employ logic-driven dynamics in a single component to detect and estimate the gradients of edges in images, a task that otherwise requires elaborate circuits. A network of Ovonic switches exhibits properties of a half adder and a full adder, in addition to discriminative logic accommodating inhibitory and excitatory signals. We show that this computational primitive is not only seemingly simpler, but also offers many orders of magnitude improved energy efficiency compared to prevailing digital solutions. As such, this work paves the path for potentially emulating dendrites for efficient post-digital neuromorphic computing."}
{"id": "2512.24128", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.24128", "abs": "https://arxiv.org/abs/2512.24128", "authors": ["Bruno Ebner", "Daniel Hlubinka"], "title": "A goodness-of-fit test for the Zeta distribution with unknown parameter", "comment": "14 pages, 1 table", "summary": "We introduce a new goodness-of-fit test for count data on $\\mathbb{N}$ for the Zeta distribution with unknown parameter. The test is built on a Stein-type characterization that uses, as Stein operator, the infinitesimal generator of a birth-death process whose stationary distribution is Zeta. The resulting $L^2$-type statistic is shown to be omnibus consistent, and we establish the limit null behavior as well as the validity of the associated parametric bootstrap procedure. In a Monte Carlo simulation study, we compare the proposed test with the only existing Zeta-specific procedure of Meintanis (2009), as well as with more general competitors based on empirical distribution functions, kernel Stein discrepancies and other Stein-type characterizations."}
{"id": "2512.24747", "categories": ["q-fin.RM", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24747", "abs": "https://arxiv.org/abs/2512.24747", "authors": ["Tim J. Boonen", "Xinyue Fan", "Zixiao Quan"], "title": "Fairness-Aware Insurance Pricing: A Multi-Objective Optimization Approach", "comment": null, "summary": "Machine learning improves predictive accuracy in insurance pricing but exacerbates trade-offs between competing fairness criteria across different discrimination measures, challenging regulators and insurers to reconcile profitability with equitable outcomes. While existing fairness-aware models offer partial solutions under GLM and XGBoost estimation methods, they remain constrained by single-objective optimization, failing to holistically navigate a conflicting landscape of accuracy, group fairness, individual fairness, and counterfactual fairness. To address this, we propose a novel multi-objective optimization framework that jointly optimizes all four criteria via the Non-dominated Sorting Genetic Algorithm II (NSGA-II), generating a diverse Pareto front of trade-off solutions. We use a specific selection mechanism to extract a premium on this front. Our results show that XGBoost outperforms GLM in accuracy but amplifies fairness disparities; the Orthogonal model excels in group fairness, while Synthetic Control leads in individual and counterfactual fairness. Our method consistently achieves a balanced compromise, outperforming single-model approaches."}
{"id": "2512.24365", "categories": ["physics.geo-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24365", "abs": "https://arxiv.org/abs/2512.24365", "authors": ["Krishna Kumar"], "title": "Deep Learning in Geotechnical Engineering: A Critical Assessment of PINNs and Operator Learning", "comment": null, "summary": "Deep learning methods -- physics-informed neural networks (PINNs), deep operator networks (DeepONet), and graph network simulators (GNS) -- are increasingly proposed for geotechnical problems. This paper tests these methods against traditional solvers on canonical problems: wave propagation and beam-foundation interaction. PINNs run 90,000 times slower than finite difference with larger errors. DeepONet requires thousands of training simulations and breaks even only after millions of evaluations. Multi-layer perceptrons fail catastrophically when extrapolating beyond training data -- the common case in geotechnical prediction. GNS shows promise for geometry-agnostic simulation but faces scaling limits and cannot capture path-dependent soil behavior. For inverse problems, automatic differentiation through traditional solvers recovers material parameters with sub-percent accuracy in seconds. We recommend: use automatic differentiation for inverse problems; apply site-based cross-validation to account for spatial autocorrelation; reserve neural networks for problems where traditional solvers are genuinely expensive and predictions remain within the training envelope. When a method is four orders of magnitude slower with less accuracy, it is not a viable replacement for proven solvers."}
{"id": "2512.23962", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.supr-con", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.23962", "abs": "https://arxiv.org/abs/2512.23962", "authors": ["Subir Sachdev"], "title": "Lectures on insulating and conducting quantum spin liquids", "comment": "60 pages, 32 figures. Advanced School and Conference on Quantum Matter, Dec 1-12, 2025, ICTP, Trieste. Links to lecture videos in manuscript", "summary": "Two of the iconic phases of the hole-doped cuprate materials are the intermediate temperature pseudogap metal and the lower temperature $d$-wave superconductor. Following the prescient suggestion of P.W. Anderson, there were numerous early theories of these phases as doped quantum spin liquids. However, these theories have had difficulties with two prominent observations:\n  (i) angle-dependent magnetoresistance measurements (ADMR), including observation of the Yamaji effect, present convincing evidence of small hole pockets which can tunnel coherently between square lattice layers, and\n  (ii) the velocities of the nodal Bogoliubov quasiparticles in the $d$-wave superconductor are highly anisotropic, with $v_F \\gg v_Δ$.\n  These lecture notes review how the fractionalized Fermi Liquid (FL*) state, which dopes quantum spin liquids with gauge-neutral electron-like quasiparticles, resolves both difficulties. Theories of insulating quantum spin liquids employing fractionalization of the electron spin into bosonic or fermionic partons are discussed. Doping the bosonic parton theory leads to a holon metal theory: while not appropriate for the cuprate pseudogap, this theory is argued to apply to the Lieb lattice. Doping the fermionic parton theory leads to a $d$-wave superconductor with nearly isotropic quasiparticle velocities. The construction of the FL* state is described using a quantum dimer model, followed by a more realistic description using the Ancilla Layer Model (ALM), which is then used to obtain the theory of the pseudogap and the $d$-wave superconductor."}
{"id": "2512.24765", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2512.24765", "abs": "https://arxiv.org/abs/2512.24765", "authors": ["Gug Young Kim", "Mi Jin Lee", "Seung-Woo Son"], "title": "Predicting the Oscillatory Regimes of Global Synchrony Induced by Secondary Clusters", "comment": "17 pages, 5 figures. Preprint; submitted to a journal", "summary": "Synchronization systems with effective inertia, such as power grid networks and coupled electromechanical oscillators, are commonly modeled by the second-order Kuramoto model. In the forward process, numerical simulations exhibit a staircase-like growth of global synchrony, reflecting temporal oscillations induced by secondary synchronized clusters of whirling oscillators. While this behavior has been observed previously, its governing conditions have not been quantitatively determined in terms of analytical criteria. Here, we develop a self-consistent theoretical framework that explicitly characterizes the secondary synchronized clusters. This analysis identifies an onset crossover mass $\\tilde{m}^* \\simeq 3.865$ for the emergence of secondary clusters and yields quantitative criteria for predicting both the crossover mass and the termination coupling strength at which they vanish. As a result, we determine the oscillatory regimes of coupling strengths over which global synchrony shows temporal oscillations, providing practical guidance for controlling and avoiding undesirable oscillatory behavior in inertial synchronization systems, such as power grids."}
{"id": "2512.24418", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.24418", "abs": "https://arxiv.org/abs/2512.24418", "authors": ["Yevgeny Bar Lev", "Jad C. Halimeh", "Achilleas Lazarides"], "title": "Dissipation-Stabilized Quantum Revivals in a Non-Hermitian Lattice Gauge Theory", "comment": "$9$ pages, $4$ figures", "summary": "With the advent of quantum simulation experiments of lattice gauge theories (LGTs), an open question is the effect of non-Hermiticity on their rich physics. The well-known PXP model, a U$(1)$ LGT with a two-level electric field in one spatial dimension, has become a paradigm of exotic physics in and out of equilibrium. Here, we introduce a non-Hermitian version in which the spin-flip rate differs between the two spin directions. While the naive expectation is that non-Hermiticity might suppress coherent phenomena such as quantum many-body scars, we find that when the facilitating direction of the spin is disfavored, the oscillations are instead \\emph{enhanced}, decaying much slower than in the PXP limit. We demonstrate that this can be understood through a similarity transformation that maps our model to the standard PXP model, revealing that the oscillations are enhanced versions of the PXP scars. Our work provides an analytically tractable and conceptually simple example where non-Hermiticity enhances the stability of dynamically non-trivial coherent many-body modes."}
{"id": "2512.24059", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24059", "abs": "https://arxiv.org/abs/2512.24059", "authors": ["Hao Zhang", "Naoki Marumo", "Ting Kei Pong", "Akiko Takeda"], "title": "Complexity and convergence analysis of a single-loop SDCAM for Lipschitz composite optimization and beyond", "comment": null, "summary": "We develop and analyze a single-loop algorithm for minimizing the sum of a Lipschitz differentiable function $f$, a prox-friendly proper closed function $g$ (with a closed domain on which $g$ is continuous) and the composition of another prox-friendly proper closed function $h$ (whose domain is closed on which $h$ is continuous) with a continuously differentiable mapping $c$ (that is Lipschitz continuous and Lipschitz differentiable on the convex closure of the domain of $g$). Such models arise naturally in many contemporary applications, where $f$ is the loss function for data misfit, and $g$ and $h$ are nonsmooth functions for inducing desirable structures in $x$ and $c(x)$. Existing single-loop algorithms mainly focus either on the case where $h$ is Lipschitz continuous or the case where $h$ is an indicator function of a closed convex set. In this paper, we develop a single-loop algorithm for more general possibly non-Lipschitz $h$. Our algorithm is a single-loop variant of the successive difference-of-convex approximation method (SDCAM) proposed in [22]. We show that when $h$ is Lipschitz, our algorithm exhibits an iteration complexity that matches the best known complexity result for obtaining an $(ε_1,ε_2,0)$-stationary point. Moreover, we show that, by assuming additionally that dom $g$ is compact, our algorithm exhibits an iteration complexity of $\\tilde{O}(ε^{-4})$ for obtaining an $(ε,ε,ε)$-stationary point when $h$ is merely continuous and real-valued. Furthermore, we consider a scenario where $h$ does not have full domain and establish vanishing bounds on successive changes of iterates. Finally, in all three cases mentioned above, we show that one can construct a subsequence such that any accumulation point $x^*$ satisfies $c(x^*)\\in$ dom $h$, and if a standard constraint qualification holds at $x^*$, then $x^*$ is a stationary point."}
{"id": "2512.24540", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24540", "abs": "https://arxiv.org/abs/2512.24540", "authors": ["Samuel. H. DAmbrosia", "Adrianne Zhong", "Michael R. DeWeese"], "title": "Higher-order response theory in stochastic thermodynamics and optimal control", "comment": "17 pages, 4 figures", "summary": "Linear response theory has found many applications in statistical physics. One of these is to compute minimal-work protocols that drive nonequilibrium systems between different thermodynamic states, which are useful for designing engineered nanoscale systems and understanding biomolecular machines. We compare and explore the relationships between linear-response-based approximations used to study optimal protocols in different driving regimes by showing that they arise as controlled truncations of a general causal response (Volterra) expansion. We then construct higher-order response terms and discuss the drawbacks and utility of their inclusion. We illustrate our results for an overdamped particle in a harmonic trap, ultimately showing that the inclusion of higher-order response in calculating optimal protocols provides marginal improvement in effectiveness despite incurring a significant computational expense, while introducing the possibility of predicting arbitrarily low and unphysical negative excess work."}
{"id": "2512.23965", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.23965", "abs": "https://arxiv.org/abs/2512.23965", "authors": ["Xiaojie Wang", "Xiaoyan Zhang"], "title": "Multimodal sampling via Schrödinger-Föllmer samplers with temperatures", "comment": null, "summary": "Generating samples from complex and high-dimensional distributions is ubiquitous in various scientific fields of statistical physics, Bayesian inference, scientific computing and machine learning. Very recently, Huang et al. (IEEE Trans. Inform. Theory, 2025) proposed new Schrödinger-Föllmer samplers (SFS), based on the Euler discretization of the Schrödinger-Föllmer diffusion evolving on the unit interval $[0, 1]$. There, a convergence rate of order $\\mathcal{O}(\\sqrt{h})$ in the $L^2$-Wasserstein distance was obtained for the Euler discretization with a uniform time step-size $h>0$.\n  By incorporating a temperature parameter, different samplers are introduced in this paper, based on the Euler discretization of the Schrödinger-Föllmer process with temperatures. As revealed by numerical experiments, high temperatures are vital, particularly in sampling from multimodal distributions. Further, a novel approach of error analysis is developed for the time discretization and an enhanced convergence rate of order ${ \\mathcal{O}(h)}$ is obtained in the $L^2$-Wasserstein distance, under certain smoothness conditions on the drift. This significantly improves the existing order-half convergence in the aforementioned paper. Unlike Langevin samplers, SFS is of gradient-free, works in a unit interval $[0, 1]$ and does not require any ergodicity. Numerical experiments confirm the convergence rate and show that, the SFS substantially outperforms vanilla Langevin samplers, particularly in sampling from multimodal distributions."}
{"id": "2512.24519", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2512.24519", "abs": "https://arxiv.org/abs/2512.24519", "authors": ["Khalil Al Handawi", "Fabian Bastin"], "title": "Analyzing Airline Alliances through Multi-Attribute Graph Partitioning to Maximize Competition and Market Penetration Capability", "comment": null, "summary": "The air transportation market is highly competitive and dynamic. Airlines often form alliances to expand their network reach, improve operational efficiency, and enhance customer experience. However, the impact of these alliances on market competition and operational efficiency is not fully understood. In this paper, we propose a novel approach to analyze airline alliances using multi\\mfabian{-}attribute graph partitioning. We develop metrics to quantify the competitiveness of flight segments and the market penetration capability of airlines based on their alliance memberships. We formulate a bi\\mfabian{-}objective optimization problem to maximize both competition and market penetration simultaneously. We also propose algorithms to solve this optimization problem and demonstrate their effectiveness using real-world flight schedule data. Our results provide insights into the structure of airline alliances and their implications for market competition and operational efficiency."}
{"id": "2512.24170", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24170", "abs": "https://arxiv.org/abs/2512.24170", "authors": ["Mehdi Baharizadeh", "Mohammad Sadegh Golsorkhi", "Neda Keshavarzi", "Thomas Ebel"], "title": "Hybrid Voltage and Current Control Method for Harmonic Mitigation of Single-Phase AC Loads in DC Microgrids", "comment": "This manuscript has been submitted to IEEE-IAS for journal publication", "summary": "DC microgrids provide an efficient framework for the interconnection of DC distributed energy resources (DERs) and DC loads. To continue to supply legacy single-phase AC loads, DC/AC converters can be integrated in the DC microgrid. The oscillatory instantaneous power of the single-phase AC load translates into a harmonic current on the converter's DC side, which increases the losses and causes unwanted voltage harmonics in the DC microgrid. To mitigate this issue, this paper proposes a hybrid voltage and current control method (HCM) for DERs. This scheme consists of an inner current control loop and an outer control layer which determines the reference for the inner loop. The outer control layer combines the DC voltage control loop with an output harmonic current control loop. This hybrid structure enables simultaneous regulation of the DC components of the DER output voltage and control of the harmonic component of the DER output current in accordance with the local single-phase AC load's demand. Frequency-domain analysis of the proposed method is presented to demonstrate the DC voltage and harmonic current loops are decoupled and there is no unwanted interaction between them. Additionally, time-domain response of the proposed scheme is validated through hardware-in-the-loop test results."}
{"id": "2512.24525", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.24525", "abs": "https://arxiv.org/abs/2512.24525", "authors": ["Fenwick C. Cooper", "Shruti Nath", "Andrew T. T. McRae", "Bobby Antonio", "Antje Weisheimer", "Tim Palmer", "Masilin Gudoshava", "Nishadh Kalladath", "Ahmed Amidhun", "Jason Kinyua", "Hannah Kimani", "David Koros", "Zacharia Mwai", "Christine Maswi", "Benard Chanzu", "Samrawit Abebe", "Bekalu Tamene", "Bekele Kebebe", "Asaminew Teshome", "Florian Pappenberger", "Matthew Chantry", "Isaac Obai", "Jesse Mason"], "title": "Rainfall forecasts in daily use over East Africa improved by machine learning", "comment": "15 pages, 10 figures", "summary": "Ensemble forecasting has proven over the years to be a vital tool for predicting extreme or only partially predictable weather events. In particular life-threatening weather events. Many National Meteorological Services in East Africa do not have the computing resources to enable them to run their local area models in full ensemble mode over the full period of the 2 week medium range. As a result, weather users in these countries are not being given sufficient information about weather risk that is needed to make reliable decisions about taking preventative action. Consequently, society in many parts of the world is not as resilient to weather events as they could be. In this paper we test the performance of our forecast system, cGAN, which is the only high-resolution (10 km) ensemble rainfall product that does real-time, probabilistic correction of global forecasts for East Africa. Compared to existing state-of-the-art AI models, our system offers higher spatial resolution. It is cheap to train/run and requires no additional post-processing. It is run on laptops and can generate many thousands of ensemble members at little computational cost (compared with physical local area models). It is ideally suited to Meteorological Services with limited computational facilities."}
{"id": "2512.24170", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24170", "abs": "https://arxiv.org/abs/2512.24170", "authors": ["Mehdi Baharizadeh", "Mohammad Sadegh Golsorkhi", "Neda Keshavarzi", "Thomas Ebel"], "title": "Hybrid Voltage and Current Control Method for Harmonic Mitigation of Single-Phase AC Loads in DC Microgrids", "comment": "This manuscript has been submitted to IEEE-IAS for journal publication", "summary": "DC microgrids provide an efficient framework for the interconnection of DC distributed energy resources (DERs) and DC loads. To continue to supply legacy single-phase AC loads, DC/AC converters can be integrated in the DC microgrid. The oscillatory instantaneous power of the single-phase AC load translates into a harmonic current on the converter's DC side, which increases the losses and causes unwanted voltage harmonics in the DC microgrid. To mitigate this issue, this paper proposes a hybrid voltage and current control method (HCM) for DERs. This scheme consists of an inner current control loop and an outer control layer which determines the reference for the inner loop. The outer control layer combines the DC voltage control loop with an output harmonic current control loop. This hybrid structure enables simultaneous regulation of the DC components of the DER output voltage and control of the harmonic component of the DER output current in accordance with the local single-phase AC load's demand. Frequency-domain analysis of the proposed method is presented to demonstrate the DC voltage and harmonic current loops are decoupled and there is no unwanted interaction between them. Additionally, time-domain response of the proposed scheme is validated through hardware-in-the-loop test results."}
{"id": "2512.24005", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24005", "abs": "https://arxiv.org/abs/2512.24005", "authors": ["Brijesh Kumar Jha", "Subhra Sankar Dhar", "Akash Ashirbad Panda"], "title": "Least Square Estimation: SDEs Perturbed by Lévy Noise with Sparse Sample Paths", "comment": null, "summary": "This article investigates the least squares estimators (LSE) for the unknown parameters in stochastic differential equations (SDEs) that are affected by Lévy noise, particularly when the sample paths are sparse. Specifically, given $n$ sparsely observed curves related to this model, we derive the least squares estimators for the unknown parameters: the drift coefficient, the diffusion coefficient, and the jump-diffusion coefficient. We also establish the asymptotic rate of convergence for the proposed LSE estimators. Additionally, in the supplementary materials, the proposed methodology is applied to a benchmark dataset of functional data/curves, and a small simulation study is conducted to illustrate the findings."}
{"id": "2512.24976", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2512.24976", "abs": "https://arxiv.org/abs/2512.24976", "authors": ["Pietro Valigi", "M. Ángeles Serrano", "Claudio Castellano", "Lorenzo Cirigliano"], "title": "Graphicality of power-law and double power-law degree sequences", "comment": "16 pages, 7 figures", "summary": "The graphicality problem -- whether or not a sequence of integers can be used to create a simple graph -- is a key question in network theory and combinatorics, with many important practical applications. In this work, we study the graphicality of degree sequences distributed as a power-law with a size-dependent cutoff and as a double power-law with a size-dependent crossover. We combine the application of exact sufficient conditions for graphicality with heuristic conditions for nongraphicality which allow us to elucidate the physical reasons why some sequences are not graphical. For single power-laws we recover the known phase-diagram, we highlight the subtle interplay of distinct mechanisms violating graphicality and we explain why the infinite-size limit behavior is in some cases very far from being observed for finite sequences. For double power-laws we derive the graphicality of infinite sequences for all possible values of the degree exponents $γ_1$ and $γ_2$, uncovering a rich phase-diagram and pointing out the existence of five qualitatively distinct ways graphicality can be violated. The validity of theoretical arguments is supported by extensive numerical analysis."}
{"id": "2512.25007", "categories": ["physics.comp-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.25007", "abs": "https://arxiv.org/abs/2512.25007", "authors": ["Will Barker"], "title": "Fast Poisson brackets and constraint algebras in canonical gravity", "comment": "43 pages, 2 figures", "summary": "In the study of alternative or extended theories of gravity, Dirac's Hamiltonian constraint algorithm is invaluable for enumerating the propagating modes and gauge symmetries. For gravity, this canonical approach is frequently applied as a means for finding pathologies such as strongly coupled modes; more generally it facilitates the reconstruction of gauge symmetries and the quantization of gauge theories. For gravity, however, the algorithm can become notoriously arduous to implement. We present a simple computer algebra package for efficiently computing Poisson brackets and reconstructing constraint algebras. The tools are stress-tested against pure general relativity and modified gravity, including the order reduction of general relativity at two loops."}
{"id": "2512.23771", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23771", "abs": "https://arxiv.org/abs/2512.23771", "authors": ["D. M. F. Bischoff van Heemskerck"], "title": "Euler-Korteweg vortices: A fluid-mechanical analogue to the Schrödinger and Klein-Gordon equations", "comment": null, "summary": "Quantum theory and relativity exhibit several formal analogies with fluid mechanics. This paper examines under which conditions a classical fluid model may reproduce the most basic mathematical formalism of both theories. By assuming that the angular momentum of an irrotational vortex in an inviscid, barotropic, isothermal fluid with sound speed c is equal in magnitude to the reduced Planck constant, and incorporating Korteweg capillary stress, a complex wave equation describing the momentum and continuity equations of a Euler-Korteweg vortex is obtained. When uniform convection is introduced, the weak field approximation of this wave equation is equivalent to Schrödinger's equation. The model is shown to yield classical analogues to de Broglie wavelength, the Einstein-Planck relation, the Born rule and the uncertainty principle. Accounting for the retarded propagation of the wavefield of a vortex in convection produces the Lorentz transformation and the Klein-Gordon equation, with Schrödinger's equation appearing as the low-Mach-number limit. These results demonstrate that, under explicit assumptions, a classical continuum can reproduce the mathematical formalism of quantum and relativistic theory in their simplest form, without assuming the postulates principal to those theories."}
{"id": "2512.23975", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23975", "abs": "https://arxiv.org/abs/2512.23975", "authors": ["Youdong Zhang", "Xu He", "Xiaolin Meng"], "title": "Exploring the Potential of Spiking Neural Networks in UWB Channel Estimation", "comment": null, "summary": "Although existing deep learning-based Ultra-Wide Band (UWB) channel estimation methods achieve high accuracy, their computational intensity clashes sharply with the resource constraints of low-cost edge devices. Motivated by this, this letter explores the potential of Spiking Neural Networks (SNNs) for this task and develops a fully unsupervised SNN solution. To enable a comprehensive performance analysis, we devise an extensive set of comparative strategies and evaluate them on a compelling public benchmark. Experimental results show that our unsupervised approach still attains 80% test accuracy, on par with several supervised deep learning-based strategies. Moreover, compared with complex deep learning methods, our SNN implementation is inherently suited to neuromorphic deployment and offers a drastic reduction in model complexity, bringing significant advantages for future neuromorphic practice."}
{"id": "2512.24152", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24152", "abs": "https://arxiv.org/abs/2512.24152", "authors": ["M. J. Wainwright"], "title": "Score-based sampling without diffusions: Guidance from a simple and modular scheme", "comment": null, "summary": "Sampling based on score diffusions has led to striking empirical results, and has attracted considerable attention from various research communities. It depends on availability of (approximate) Stein score functions for various levels of additive noise. We describe and analyze a modular scheme that reduces score-based sampling to solving a short sequence of ``nice'' sampling problems, for which high-accuracy samplers are known. We show how to design forward trajectories such that both (a) the terminal distribution, and (b) each of the backward conditional distribution is defined by a strongly log concave (SLC) distribution. This modular reduction allows us to exploit \\emph{any} SLC sampling algorithm in order to traverse the backwards path, and we establish novel guarantees with short proofs for both uni-modal and multi-modal densities. The use of high-accuracy routines yields $\\varepsilon$-accurate answers, in either KL or Wasserstein distances, with polynomial dependence on $\\log(1/\\varepsilon)$ and $\\sqrt{d}$ dependence on the dimension."}
{"id": "2512.23731", "categories": ["physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2512.23731", "abs": "https://arxiv.org/abs/2512.23731", "authors": ["Alessio Kandiah", "Alexander B. Movchan", "Vladimir Frid"], "title": "When the Earth and Sky Dance: Seismic Shakes Meet Weather Patterns", "comment": "8 pages, 6 figures", "summary": "A new modelling approach shows how the Earth's hidden vibrations may drive global weather dynamics and atmospheric pressure variations, hinting that the planet's own beat could be imprinted on our climate. The atmospheric rotational patterns of the mean sea level pressure, in connection to the development of powerful storms, are shown to be caused by Earth's rotational elastic dynamics and earthquake-induced oscillations. These seismic excitations are discussed in relation to storm formation and the global atmospheric patterns of high-pressure regions."}
{"id": "2512.23963", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.23963", "abs": "https://arxiv.org/abs/2512.23963", "authors": ["Haiyan Lu"], "title": "Correlated 5f electronic states and phase stability in americium under high pressure: Insights from DFT+DMFT calculations", "comment": "11 pages, 7 figures", "summary": "We investigate the electronic structure of americium (Am) across its four experimentally confirmed high-pressure phases Am-I (P63/mmc), Am-II (Fm-3m), Am-III (Fddd), and Am-IV (Pnma) up to 100 GPa, using density functional theory combined with embedded dynamical mean-field theory. Our results successfully reproduce the prominent localized 5f peak observed in ultraviolet photoelectron spectroscopy around -2.8 eV below the Fermi level in the Am-I phase. While 5f electrons in Am-I and Am-II remain strongly localized, those in Am-III and Am-IV manifest discernible signatures of increased hybridization: a noticeable shift of spectral weight toward the Fermi level, enhanced hybridization strength, and the emergence of distinct multi-peak structures. These changes indicate that 5f electrons begin to participate in bonding and undergo partial delocalization under pressure. Nevertheless, the spectral weight of 5f electrons near the Fermi level in Am-IV remains relatively low, indicating that, compared to U and Pu, Am retains stronger localized 5f electrons even under high pressure. Analysis of the electronic configurations reveals pressure-enhanced valence state fluctuation, characterized by the mixing of 5f5, 5f6, and 5f7 electronic configurations. The X-ray absorption branching ratio further shows that the angular-momentum coupling scheme approaches the jj limit. Additionally, we demonstrate that the stability of the low-symmetry high-pressure phases (Am-III and Am-IV) is governed by a Peierls-like distortion mechanism, which reduces the total energy through symmetry-lowering lattice distortions accompanied by electronic reconstruction. This study offers a new microscopic perspective on high-pressure phase transitions and emergent quantum phenomena in actinide materials."}
{"id": "2512.24262", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24262", "abs": "https://arxiv.org/abs/2512.24262", "authors": ["Simão N. Stelmastchuk"], "title": "Complete lift of control system", "comment": "17 pages", "summary": "We study affine control systems on smooth manifolds and their complete lifts to the tangent bundle, providing an explicit geometric description of the solutions of the lifted system. We show that, although controllability of the complete lift implies controllability of the original system, the lifted system is never controllable due to intrinsic geometric constraints. By introducing chain controllability, we prove that controllability of the original system guarantees chain controllability of its complete lift."}
{"id": "2512.24648", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24648", "abs": "https://arxiv.org/abs/2512.24648", "authors": ["Hemant Mishra", "Shubham Singh", "Rajeev Singh", "Amit Raj Singh"], "title": "Quantum Computing Inspired Approach for Self-Avoiding Walk (SAWs): 2D lattice and 3D lattice SAWs for single chain enumeration", "comment": "13pages, 8 figures", "summary": "We investigate the application of quantum computing algorithms to enhance the efficiency of enumerating self-avoiding walks (SAWs), utilizing quantum properties such as superposition and interference. A Quantum Amplitude Estimation (QAE)-based algorithm is developed to enumerate SAWs on both 2D and 3D lattices. In case of 2D square lattice, SAWs up to N=71 steps are successfully enumerated within 26.9 minutes - significantly improving upon the classical algorithm, which required approximately 231 hours(Jensen et al., 2012, J. Phys. A: Math. Theor. 45, 115202). The algorithm is further extended to 3D cubic lattices, where SAWs up to N=40 steps are enumerated in 13.06 minutes, compared to the classical result of N=36 in 250 hours (Schram et al., 2011, J. Stat. Mech. P06019). These results demonstrate a substantial reduction in computational time, highlighting the potential of quantum computing for combinatorial enumeration problems."}
{"id": "2512.24121", "categories": ["math.NA", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.24121", "abs": "https://arxiv.org/abs/2512.24121", "authors": ["Stefano Muzzolon", "Michael Dumbser", "Olindo Zanotti", "Elena Gaburro"], "title": "High order numerical discretizations of the Einstein-Euler equations in the Generalized Harmonic formulation", "comment": null, "summary": "We propose two new alternative numerical schemes to solve the coupled Einstein-Euler equations in the Generalized Harmonic formulation. The first one is a finite difference (FD) Central Weighted Essentially Non-Oscillatory (CWENO) scheme on a traditional Cartesian mesh, while the second one is an ADER (Arbitrary high order Derivatives) discontinuous Galerkin (DG) scheme on 2D unstructured polygonal meshes. The latter, in particular, represents a preliminary step in view of a full 3D numerical relativity calculation on moving meshes. Both schemes are equipped with a well-balancing (WB) property, which allows to preserve the equilibrium of a priori known stationary solutions exactly at the discrete level. We validate our numerical approaches by successfully reproducing standard vacuum test cases, such as the robust stability, the linearized wave, and the gauge wave tests, as well as achieving long-term stable evolutions of stationary black holes, including Kerr black holes with extreme spin. Concerning the coupling with matter, modeled by the relativistic Euler equations, we perform a classical test of spherical accretion onto a Schwarzschild black hole, as well as an evolution of a perturbed non-rotating neutron star, demonstrating the capability of our schemes to operate also on the full Einstein-Euler system. Altogether, these results provide a solid foundation for addressing more complex and challenging simulations of astrophysical sources through DG schemes on unstructured 3D meshes."}
{"id": "2512.24841", "categories": ["cs.SI", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.24841", "abs": "https://arxiv.org/abs/2512.24841", "authors": ["Zongyue Teng", "Jun Yan", "Dandan Liu", "Panpan Zhang"], "title": "When Does the Silhouette Score Work? A Comprehensive Study in Network Clustering", "comment": null, "summary": "Selecting the number of communities is a fundamental challenge in network clustering. The silhouette score offers an intuitive, model-free criterion that balances within-cluster cohesion and between-cluster separation. Albeit its widespread use in clustering analysis, its performance in network-based community detection remains insufficiently characterized. In this study, we comprehensively evaluate the performance of the silhouette score across unweighted, weighted, and fully connected networks, examining how network size, separation strength, and community size imbalance influence its performance. Simulation studies show that the silhouette score accurately identifies the true number of communities when clusters are well separated and balanced, but it tends to underestimate under strong imbalance or weak separation and to overestimate in sparse networks. Extending the evaluation to a real airline reachability network, we demonstrate that the silhouette-based clustering can recover geographically interpretable and market-oriented clusters. These findings provide empirical guidance for applying the silhouette score in network clustering and clarify the conditions under which its use is most reliable."}
{"id": "2512.24179", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24179", "abs": "https://arxiv.org/abs/2512.24179", "authors": ["Joonhee Lee", "Kichang Lee", "Jeonggil Ko"], "title": "Now or Never: Continuous Surveillance AIoT System for Ephemeral Events in Intermittent Sensor Networks", "comment": null, "summary": "Wilderness monitoring tasks, such as poaching surveillance and forest fire detection, require pervasive and high-accuracy sensing. While AIoT offers a promising path, covering vast, inaccessible regions necessitates the massive deployment of maintenance-free, battery-less nodes with limited computational resources. However, these constraints create a critical `Availability Gap.' Conventional intermittent operations prioritize computation throughput, forcing sensors to sleep during energy buffering. Consequently, systems miss ephemeral, `now-or-never' events (e.g., Vocalizations of natural monuments or Fire), which is fatal for detecting rare but high-stakes anomalies. To address this, we propose an Energy-aware Elastic Split Computing Algorithm that prioritizes continuous sensing by dynamically offloading tasks to energy-rich neighbors. Preliminary results demonstrate stable monitoring of an additional $2,496\\;\\text{m}^2$ and the capture of approximately 103 more critical events per day. Ultimately, this algorithm establishes a robust foundation for building resilient, fail-safe surveillance systems even on resource-constrained nodes."}
{"id": "2512.24865", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2512.24865", "abs": "https://arxiv.org/abs/2512.24865", "authors": ["Cristina Sgattoni", "Luca Sgheri", "Matthias Chung", "Michele Martinazzo"], "title": "Latent Twins: A Framework for Scene Recognition and Fast Radiative Transfer Inversion in FORUM All-Sky Observations", "comment": null, "summary": "The FORUM (Far-infrared Outgoing Radiation Understanding and Monitoring) mission will provide, for the first time, systematic far-infrared spectral measurements of Earth's outgoing radiation, enabling improved understanding of atmospheric processes and the radiation budget. Retrieving atmospheric states from these observations constitutes a high-dimensional, ill-posed inverse problem, particularly under cloudy-sky conditions where multiple-scattering effects are present. In this work, we develop a data-driven, physics-aware inversion framework for FORUM all-sky retrievals based on latent twins: coupled autoencoders for atmospheric states and spectra, combined with bidirectional latent-space mappings. A lightweight model-consistency correction ensures physically plausible cloud variable reconstructions. The resulting framework demonstrates potential for retrievals of atmospheric, cloud and surface variables, providing information that can serve as a prior, initial guess, or surrogate for computationally expensive full-physics inversion methods. It also enables robust scene classification and near-instantaneous inference, making it suitable for operational near-real-time applications. We demonstrate its performance on synthetic FORUM-like data and discuss implications for future data assimilation and climate studies."}
{"id": "2512.24179", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24179", "abs": "https://arxiv.org/abs/2512.24179", "authors": ["Joonhee Lee", "Kichang Lee", "Jeonggil Ko"], "title": "Now or Never: Continuous Surveillance AIoT System for Ephemeral Events in Intermittent Sensor Networks", "comment": null, "summary": "Wilderness monitoring tasks, such as poaching surveillance and forest fire detection, require pervasive and high-accuracy sensing. While AIoT offers a promising path, covering vast, inaccessible regions necessitates the massive deployment of maintenance-free, battery-less nodes with limited computational resources. However, these constraints create a critical `Availability Gap.' Conventional intermittent operations prioritize computation throughput, forcing sensors to sleep during energy buffering. Consequently, systems miss ephemeral, `now-or-never' events (e.g., Vocalizations of natural monuments or Fire), which is fatal for detecting rare but high-stakes anomalies. To address this, we propose an Energy-aware Elastic Split Computing Algorithm that prioritizes continuous sensing by dynamically offloading tasks to energy-rich neighbors. Preliminary results demonstrate stable monitoring of an additional $2,496\\;\\text{m}^2$ and the capture of approximately 103 more critical events per day. Ultimately, this algorithm establishes a robust foundation for building resilient, fail-safe surveillance systems even on resource-constrained nodes."}
{"id": "2512.24009", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.24009", "abs": "https://arxiv.org/abs/2512.24009", "authors": ["Landon Hurley"], "title": "An exact unbiased semi-parametric maximum quasi-likelihood framework which is complete in the presence of ties", "comment": null, "summary": "This paper introduces a novel quasi-likelihood extension of the generalised Kendall \\(τ_{a}\\) estimator, together with an extension of the Kemeny metric and its associated covariance and correlation forms. The central contribution is to show that the U-statistic structure of the proposed coefficient \\(τ_κ\\) naturally induces a quasi-maximum likelihood estimation (QMLE) framework, yielding consistent Wald and likelihood ratio test statistics. The development builds on the uncentred correlation inner-product (Hilbert space) formulation of Emond and Mason (2002) and resolves the associated sub-Gaussian likelihood optimisation problem under the \\(\\ell_{2}\\)-norm via an Edgeworth expansion of higher-order moments. The Kemeny covariance coefficient \\(τ_κ\\) is derived within a novel likelihood framework for pairwise comparison-continuous random variables, enabling direct inference on population-level correlation between ranked or weakly ordered datasets. Unlike existing approaches that focus on marginal or pairwise summaries, the proposed framework supports sample-observed weak orderings and accommodates ties without information loss. Drawing parallels with Thurstone's Case V latent ordering model, we derive a quasi-likelihood-based tie model with analytic standard errors, generalising classical U-statistics. The framework applies to general continuous and discrete random variables and establishes formal equivalence to Bradley-Terry and Thurstone models, yielding a uniquely identified linear representation with both analytic and likelihood-based estimators."}
{"id": "2512.24122", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24122", "abs": "https://arxiv.org/abs/2512.24122", "authors": ["Kristóf Benedek", "Géza Ódor"], "title": "The effect of HVDC lines in power-grids via Kuramoto modelling", "comment": null, "summary": "We present a numerical study on the synchronization and cascade failure behaviour by solving the adaptive second-order Kuramoto model on a large high voltage (HV) European power-grid. This non-perturbative analysis takes into account non-linear effects, which occur even when phase differences are large, when the system is away from the steady state, and even during a blackout cascade. Our dynamical simulations show that improvements in the phase synchronziation stabilization as well as the in the cascade sizes can be related to the finite size scaling behaviour of the second order Kuramoto on graphs with $d_s<4$ spectral dimensions. On the other hand drawbacks in the frequency spread and Braess effects also occur by varying the total transmitted power at large and small global couplings, presumably when the fluctuations are small, causing a freezing in the dynamics. We compare simulations of the fully AC model with those of static or adaptive High Voltage Direct Current (HVDC) line replacements. The adaptive (local frequency difference-based) HVDC lines are more efficient in the steady state, at the expense of very long relaxation times."}
{"id": "2512.23930", "categories": ["cond-mat.stat-mech", "cond-mat.mtrl-sci", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.23930", "abs": "https://arxiv.org/abs/2512.23930", "authors": ["Maximilian Schebek", "Jiajun He", "Emil Hoffmann", "Yuanqi Du", "Frank Noé", "Jutta Rogal"], "title": "Assessing generative modeling approaches for free energy estimates in condensed matter", "comment": null, "summary": "The accurate estimation of free energy differences between two states is a long-standing challenge in molecular simulations. Traditional approaches generally rely on sampling multiple intermediate states to ensure sufficient overlap in phase space and are, consequently, computationally expensive. Several generative-model-based methods have recently addressed this challenge by learning a direct bridge between distributions, bypassing the need for intermediate states. However, it remains unclear which approaches provide the best trade-off between efficiency, accuracy, and scalability. In this work, we systematically review these methods and benchmark selected approaches with a focus on condensed-matter systems. In particular, we investigate the performance of discrete and continuous normalizing flows in the context of targeted free energy perturbation as well as FEAT (Free energy Estimators with Adaptive Transport) together with the escorted Jarzynski equality, using coarse-grained monatomic ice and Lennard-Jones solids as benchmark systems. We evaluate accuracy, data efficiency, computational cost, and scalability with system size. Our results provide a quantitative framework for selecting effective free energy estimation strategies in condensed-phase systems."}
{"id": "2512.23776", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23776", "abs": "https://arxiv.org/abs/2512.23776", "authors": ["Dennis Delali Kwesi Wayo", "Rodrigo Alves Dias", "Leonardo Goliatt", "Sven Groppe"], "title": "DifGa: Differentiable Error Mitigation for Multi-Mode Gaussian and Non-Gaussian Noise in Quantum Photonic Circuits", "comment": null, "summary": "We introduce DifGa, a fully differentiable error-mitigation framework for continuous-variable (CV) quantum photonic circuits operating under Gaussian loss and weak non-Gaussian noise. The approach is demonstrated using analytic simulations with the default.gaussian backend of PennyLane, where quantum states are represented by first and second moments and optimized end-to-end via automatic differentiation. Gaussian loss is modeled as a beam splitter interaction with an environmental vacuum mode of transmissivity $η\\in [0.3,0.95]$, while non-Gaussian phase noise is incorporated through a differentiable Monte-Carlo mixture of random phase rotations with jitter amplitudes $δ\\in [0,0.7]$. The core architecture employs a multi-mode Gaussian circuit consisting of a signal, ancilla, and environment mode. Input states are prepared using squeezing and displacement operations with parameters $(r_s,\\varphi_s,α)=(0.60,0.30,0.80)$ and $(r_a,\\varphi_a)=(0.40,0.10)$, followed by an entangling beam splitter with angles $(θ,φ)=(0.70,0.20)$. Error mitigation is achieved by appending a six-parameter trainable Gaussian recovery layer comprising local phase rotations and displacements, optimized by minimizing a quadratic loss on the signal-mode quadratures $\\langle \\hat{x}_0\\rangle$ and $\\langle \\hat{p}_0\\rangle$ using gradient descent with fixed learning rate $0.06$ and identical initialization across experiments. Under pure Gaussian loss, the optimized recovery suppresses reconstruction error to near machine precision ($<10^{-30}$) for moderate loss ($η\\ge 0.5$). When non-Gaussian phase noise is present, noise-aware training using Monte Carlo averaging yields robust generalization, reducing error by more than an order of magnitude compared to Gaussian-trained recovery at large phase jitter. Runtime benchmarks confirm linear scaling with the number of Monte Carlo samples."}
{"id": "2512.24558", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24558", "abs": "https://arxiv.org/abs/2512.24558", "authors": ["Shuvro Chowdhury", "Jasper Pieterse", "Navid Anjum Aadit", "Johan H. Mentink", "Kerem Y. Camsari"], "title": "Probabilistic Computers for Neural Quantum States", "comment": null, "summary": "Neural quantum states efficiently represent many-body wavefunctions with neural networks, but the cost of Monte Carlo sampling limits their scaling to large system sizes. Here we address this challenge by combining sparse Boltzmann machine architectures with probabilistic computing hardware. We implement a probabilistic computer on field programmable gate arrays (FPGAs) and use it as a fast sampler for energy-based neural quantum states. For the two-dimensional transverse-field Ising model at criticality, we obtain accurate ground-state energies for lattices up to 80 $\\times$ 80 (6400 spins) using a custom multi-FPGA cluster. Furthermore, we introduce a dual-sampling algorithm to train deep Boltzmann machines, replacing intractable marginalization with conditional sampling over auxiliary layers. This enables the training of sparse deep models and improves parameter efficiency relative to shallow networks. Using this algorithm, we train deep Boltzmann machines for a system with 35 $\\times$ 35 (1225 spins). Together, these results demonstrate that probabilistic hardware can overcome the sampling bottleneck in variational simulation of quantum many-body systems, opening a path to larger system sizes and deeper variational architectures."}
{"id": "2512.24378", "categories": ["math.ST", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24378", "abs": "https://arxiv.org/abs/2512.24378", "authors": ["Konstantin Yakovlev", "Anna Markovich", "Nikita Puchkin"], "title": "Implicit score matching meets denoising score matching: improved rates of convergence and log-density Hessian estimation", "comment": "52 pages", "summary": "We study the problem of estimating the score function using both implicit score matching and denoising score matching. Assuming that the data distribution exhibiting a low-dimensional structure, we prove that implicit score matching is able not only to adapt to the intrinsic dimension, but also to achieve the same rates of convergence as denoising score matching in terms of the sample size. Furthermore, we demonstrate that both methods allow us to estimate log-density Hessians without the curse of dimensionality by simple differentiation. This justifies convergence of ODE-based samplers for generative diffusion models. Our approach is based on Gagliardo-Nirenberg-type inequalities relating weighted $L^2$-norms of smooth functions and their derivatives."}
{"id": "2512.24071", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.24071", "abs": "https://arxiv.org/abs/2512.24071", "authors": ["Jiajun Mo", "Leandro M. Chinellato", "Fletcher Williams", "Akiko Kikkawa", "Joseph A. M. Paddison", "Matthias D. Frontzek", "Gabriele Sala", "Chris Pasco", "Kipton Barros", "Taro Nakajima", "Taka-hisa Arima", "Yasujiro Taguchi", "Yoshinori Tokura", "Matthew B. Stone", "Andrew D. Christianson", "Cristian D. Batista", "Shang Gao"], "title": "Skyrmion and Meron Crystals in Intermetallic Gd$_3$Ru$_4$Al$_{12}$: Microscopic Model Insights into Chiral Phases", "comment": "28 pages, 24 figures", "summary": "Topological spin textures in frustrated intermetallics hold great promise for spintronics applications. However, understanding their origin and properties remains a significant challenge due to competing and often long-range interactions mediated by conduction electrons. Here, by combining neutron scattering experiments with theoretical modeling via unprecedented multi-target fits that further incorporate the ferromagnentic resonance data and magnetization curve, we construct a realistic microscopic model for the prototypical intermetallic skyrmion host \\text{Gd}$_3$\\text{Ru}$_4$\\text{Al}$_{12}$. Beyond magnetic frustration, we identify the competition between dipolar interactions and easy-plane single-ion anisotropy as a key ingredient for stabilizing the rich chiral magnetic phases observed in this compound -- including a hexagonal skyrmion crystal and two distinct meron crystals. Remarkably, the meron crystal in lower field is revealed to be commensurate with the underlying lattice, and its unique three-meron-one-antimeron spin texture is verified by the polarized x-ray diffraction data. At elevated temperatures, the short-range spin correlations in \\text{Gd}$_3$\\text{Ru}$_4$\\text{Al}$_{12}$ are well described by a codimension-two spiral spin-liquid. Perturbations from staggered Dzyaloshinskii-Moriya interactions give rise to chiral fluctuations that account for the temperature and field dependence of the anomalous Hall response. Our results highlight the unique power of neutron scattering, especially when combined with complementary experimental techniques, to unravel complex magnetic phase transitions and provide new insights into the rich variety of topological spin textures in frustrated systems."}
{"id": "2512.24291", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24291", "abs": "https://arxiv.org/abs/2512.24291", "authors": ["Xu Shi", "Yinglin Du", "Rufeng Xiao", "Rujun Jiang"], "title": "Adaptive Algorithms for Nonconvex Bilevel Optimization under PŁ Conditions", "comment": null, "summary": "Existing methods for nonconvex bilevel optimization (NBO) require prior knowledge of first- and second-order problem-specific parameters (e.g., Lipschitz constants and the Polyak-Łojasiewicz (PŁ) parameters) to set step sizes, a requirement that poses practical limitations when such parameters are unknown or computationally expensive. We introduce the Adaptive Fully First-order Bilevel Approximation (AF${}^2$BA) algorithm and its accelerated variant, A${}^2$F${}^2$BA, for solving NBO problems under the PŁ conditions. To our knowledge, these are the first methods to employ fully adaptive step size strategies, eliminating the need for any problem-specific parameters in NBO. We prove that both algorithms achieve $\\mathcal{O}(1/ε^2)$ iteration complexity for finding an $ε$-stationary point, matching the iteration complexity of existing well-tuned methods. Furthermore, we show that A${}^2$F${}^2$BA enjoys a near-optimal first-order oracle complexity of $\\tilde{\\mathcal{O}}(1/ε^2)$, matching the oracle complexity of existing well-tuned methods, and aligning with the complexity of gradient descent for smooth nonconvex single-level optimization when ignoring the logarithmic factors."}
{"id": "2512.24728", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24728", "abs": "https://arxiv.org/abs/2512.24728", "authors": ["Kota Okajima", "Koji Hukushima"], "title": "Phase transitions in time complexity of Brownian circuits", "comment": null, "summary": "Brownian circuits implement computation through stochastic transitions driven by thermal fluctuations. While the energetic costs of such fluctuation-driven computation have been extensively studied within stochastic thermodynamics, much less is known about its computational complexity, in particular how computation time scales with circuit size. Here, the computation time of explicitly designed Brownian circuits is investigated numerically via the first-passage time to a completed state. For arithmetic circuits such as adders, varying the forward transition rate induces a sharp change in the scaling behavior of the mean computation time, from linear to exponential in circuit size. This change can be interpreted as an easy-hard transition in computational time complexity. The transition suggests that, for meaningful computational tasks, achieving efficient polynomial-time computation generically requires a finite forward bias, corresponding to a nonzero energy input. As a counterexample, it is shown that arbitrary logical operations can be reduced to an effectively one-dimensional stochastic process, for which the zero-bias limit lines within the computationally efficient (easy) regime. However, realizing such a one-dimensional normal form unavoidably leads to an exponential increase in circuit size. These results reveal a fundamental trade-off between computation time, circuit size, and energy input in Brownian circuits, and demonstrate that phase transitions in time complexity provide a natural framework for characterizing the cost of fluctuation-driven computation."}
{"id": "2512.24127", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24127", "abs": "https://arxiv.org/abs/2512.24127", "authors": ["Alessia Lucca", "Michael Dumbser"], "title": "Structure-preserving schemes for nonlinear symmetric hyperbolic and thermodynamically compatible systems of partial differential equations", "comment": null, "summary": "This paper aims at developing exactly energy-conservative and structure-preserving finite volume schemes for the discretisation of first-order symmetric-hyperbolic and thermodynamically compatible (SHTC) systems of partial differential equations in continuum physics. Due to their thermodynamic compatibility the class of SHTC systems satisfies an additional conservation law for the total energy and many PDE in this class of equations also satisfy stationary differential constraints (involutions). First, we propose a simple semi-discrete cell-centered HTC finite volume scheme that employs collocated grids and that is compatible with the total energy conservation law, but which does not satisfy the involutions. Second, we develop a fully discrete semi-implicit finite volume scheme that conserves total energy and which can be proven to satisfy also the involution constraints exactly at the discrete level. This method is a vertex-based staggered semi-implicit scheme that preserves the basic vector calculus identities $\\nabla \\cdot \\nabla \\times A = 0$ and $\\nabla \\times \\nabla φ= 0$ for any vector and scalar field, respectively, exactly at the discrete level and which is also exactly totally energy conservative. The main key ingredient of the proposed implicit scheme is the fact that it uses a discrete version of the symmetric-hyperbolic Godunov-form of the governing PDE system. This leads naturally to sequences of symmetric and positive definite linear algebraic systems to be solved inside an iterative fixed-point method used in each time step. We apply our new schemes to three different SHTC systems. In particular, we consider the equations of nonlinear acoustics, the nonlinear Maxwell equations in the absence of charges and a nonlinear version of the Maxwell-GLM system. We also show some numerical results to provide evidence of the stated properties of the proposed schemes."}
{"id": "2512.24281", "categories": ["eess.SY", "cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.24281", "abs": "https://arxiv.org/abs/2512.24281", "authors": ["Spyridon Syntakas", "Kostas Vlachos"], "title": "Safe Sliding Mode Control for Marine Vessels Using High-Order Control Barrier Functions and Fast Projection", "comment": null, "summary": "This paper presents a novel safe control framework that integrates Sliding Mode Control (SMC), High-Order Control Barrier Functions (HOCBFs) with state-dependent adaptiveness and a lightweight projection for collision-free navigation of an over-actuated 3-DOF marine surface vessel subjected to strong environmental disturbances (wind, waves, and current). SMC provides robustness to matched disturbances common in marine operations, while HOCBFs enforce forward invariance of obstacle-avoidance constraints. A fast half-space projection method adjusts the SMC control only when needed, preserving robustness and minimizing chattering. The approach is evaluated on a nonlinear marine platform model that includes added mass, hydrodynamic damping, and full thruster allocation. Simulation results show robust navigation, guaranteed obstacle avoidance, and computational efficiency suitable for real-time embedded use. For small marine robots and surface vessels with limited onboard computational resources-where execution speed and computational efficiency are critical-the SMC-HOCBF framework constitutes a strong candidate for safety-critical control."}
{"id": "2512.24281", "categories": ["eess.SY", "cs.RO", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.24281", "abs": "https://arxiv.org/abs/2512.24281", "authors": ["Spyridon Syntakas", "Kostas Vlachos"], "title": "Safe Sliding Mode Control for Marine Vessels Using High-Order Control Barrier Functions and Fast Projection", "comment": null, "summary": "This paper presents a novel safe control framework that integrates Sliding Mode Control (SMC), High-Order Control Barrier Functions (HOCBFs) with state-dependent adaptiveness and a lightweight projection for collision-free navigation of an over-actuated 3-DOF marine surface vessel subjected to strong environmental disturbances (wind, waves, and current). SMC provides robustness to matched disturbances common in marine operations, while HOCBFs enforce forward invariance of obstacle-avoidance constraints. A fast half-space projection method adjusts the SMC control only when needed, preserving robustness and minimizing chattering. The approach is evaluated on a nonlinear marine platform model that includes added mass, hydrodynamic damping, and full thruster allocation. Simulation results show robust navigation, guaranteed obstacle avoidance, and computational efficiency suitable for real-time embedded use. For small marine robots and surface vessels with limited onboard computational resources-where execution speed and computational efficiency are critical-the SMC-HOCBF framework constitutes a strong candidate for safety-critical control."}
{"id": "2512.24222", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24222", "abs": "https://arxiv.org/abs/2512.24222", "authors": ["Tuhin Subhra Mahato", "Subhra Sankar Dhar"], "title": "A Robust Persistent Homology : Trimming Approach", "comment": null, "summary": "This article studies the robust version of persistent homology based on trimming methodology to capture the geometric feature through support of the data in presence of outliers. Precisely speaking, the proposed methodology works when the outliers lie outside the main data cloud as well as inside the data cloud. In the course of theoretical study, it is established that the Bottleneck distance between the proposed robust version of persistent homology and its population analogue can be made arbitrary small with a certain rate for a sufficiently large sample size. The practicability of the methodology is shown for various simulated data and bench mark real data associated with cellular biology."}
{"id": "2512.24558", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24558", "abs": "https://arxiv.org/abs/2512.24558", "authors": ["Shuvro Chowdhury", "Jasper Pieterse", "Navid Anjum Aadit", "Johan H. Mentink", "Kerem Y. Camsari"], "title": "Probabilistic Computers for Neural Quantum States", "comment": null, "summary": "Neural quantum states efficiently represent many-body wavefunctions with neural networks, but the cost of Monte Carlo sampling limits their scaling to large system sizes. Here we address this challenge by combining sparse Boltzmann machine architectures with probabilistic computing hardware. We implement a probabilistic computer on field programmable gate arrays (FPGAs) and use it as a fast sampler for energy-based neural quantum states. For the two-dimensional transverse-field Ising model at criticality, we obtain accurate ground-state energies for lattices up to 80 $\\times$ 80 (6400 spins) using a custom multi-FPGA cluster. Furthermore, we introduce a dual-sampling algorithm to train deep Boltzmann machines, replacing intractable marginalization with conditional sampling over auxiliary layers. This enables the training of sparse deep models and improves parameter efficiency relative to shallow networks. Using this algorithm, we train deep Boltzmann machines for a system with 35 $\\times$ 35 (1225 spins). Together, these results demonstrate that probabilistic hardware can overcome the sampling bottleneck in variational simulation of quantum many-body systems, opening a path to larger system sizes and deeper variational architectures."}
{"id": "2512.24440", "categories": ["physics.ao-ph", "cs.LG", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2512.24440", "abs": "https://arxiv.org/abs/2512.24440", "authors": ["Theodore MacMillan", "Nicholas T. Ouellette"], "title": "Towards mechanistic understanding in a data-driven weather model: internal activations reveal interpretable physical features", "comment": "18 pages, 13 figures", "summary": "Large data-driven physics models like DeepMind's weather model GraphCast have empirically succeeded in parameterizing time operators for complex dynamical systems with an accuracy reaching or in some cases exceeding that of traditional physics-based solvers. Unfortunately, how these data-driven models perform computations is largely unknown and whether their internal representations are interpretable or physically consistent is an open question. Here, we adapt tools from interpretability research in Large Language Models to analyze intermediate computational layers in GraphCast, leveraging sparse autoencoders to discover interpretable features in the neuron space of the model. We uncover distinct features on a wide range of length and time scales that correspond to tropical cyclones, atmospheric rivers, diurnal and seasonal behavior, large-scale precipitation patterns, specific geographical coding, and sea-ice extent, among others. We further demonstrate how the precise abstraction of these features can be probed via interventions on the prediction steps of the model. As a case study, we sparsely modify a feature corresponding to tropical cyclones in GraphCast and observe interpretable and physically consistent modifications to evolving hurricanes. Such methods offer a window into the black-box behavior of data-driven physics models and are a step towards realizing their potential as trustworthy predictors and scientifically valuable tools for discovery."}
{"id": "2512.23799", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23799", "abs": "https://arxiv.org/abs/2512.23799", "authors": ["Samyak Surti", "Lucas Daguerre", "Isaac H. Kim"], "title": "Efficient simulation of logical magic state preparation protocols", "comment": "19 pages, 15 figures + appendices", "summary": "Developing space- and time-efficient logical magic state preparation protocols will likely be an essential step towards building a large-scale fault-tolerant quantum computer. Motivated by this need, we introduce a scalable method for simulating logical magic state preparation protocols under the standard circuit-level noise model. When applied to protocols based on code switching, magic state cultivation, and magic state distillation, our method yields a complexity polynomial in (i) the number of qubits and (ii) the non-stabilizerness, e.g., stabilizer rank or Pauli rank, of the target encoded magic state. The efficiency of our simulation method is rooted in a curious fact: every circuit-level Pauli error in these protocols propagates to a Clifford error at the end. This property is satisfied by a large family of protocols, including those that repeatedly measure a transversal Clifford that squares to a Pauli. We provide a proof-of-principle numerical simulation that prepares a magic state using such logical Clifford measurements. Our work enables practical simulation of logical magic state preparation protocols without resorting to approximations or resource-intensive state-vector simulations."}
{"id": "2512.24527", "categories": ["math.ST", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.24527", "abs": "https://arxiv.org/abs/2512.24527", "authors": ["Matieyendou Lamboni"], "title": "Dimension-free estimators of gradients of functions with(out) non-independent variables", "comment": null, "summary": "This study proposes a unified stochastic framework for approximating and computing the gradient of every smooth function evaluated at non-independent variables, using $\\ell_p$-spherical distributions on $\\R^d$ with $d, p\\geq 1$. The upper-bounds of the bias of the gradient surrogates do not suffer from the curse of dimensionality for any $p\\geq 1$. Also, the mean squared errors (MSEs) of the gradient estimators are bounded by $K_0 N^{-1} d$ for any $p \\in [1, 2]$, and by $K_1 N^{-1} d^{2/p}$ when $2 \\leq p \\ll d$ with $N$ the sample size and $K_0, K_1$ some constants. Taking $\\max\\left\\{2, \\log(d) \\right\\} < p \\ll d$ allows for achieving dimension-free upper-bounds of MSEs. In the case where $d\\ll p< +\\infty$, the upper-bound $K_2 N^{-1} d^{2-2/p}/ (d+2)^2$ is reached with $K_2$ a constant. Such results lead to dimension-free MSEs of the proposed estimators, which boil down to estimators of the traditional gradient when the variables are independent. Numerical comparisons show the efficiency of the proposed approach."}
{"id": "2512.24076", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.24076", "abs": "https://arxiv.org/abs/2512.24076", "authors": ["João Augusto Sobral", "Pietro M. Bonetti", "Subrata Mandal", "Mathias S. Scheurer"], "title": "Exactly Solvable Models Hosting Altermagnetic Quantum Spin Liquids", "comment": "8+7 pages, 3+5 figures", "summary": "We construct spin-$3/2$ and spin-$7/2$ models on the square-octagon and checkerboard lattices that are exactly solvable with Majorana representations. They give rise to spin-liquid phases with full spin-rotation and lattice-translational symmetries but broken time-reversal symmetry. Although non-zero on elementary plaquettes, the net orbital magnetic moment is guaranteed to vanish as a result of point symmetries; due to the analogy to long-range ordered altermagnets, these types of phases were dubbed altermagnetic spin liquids in [Phys. Rev. Research 7, 023152 (2025)]. For the spin-$3/2$ model, we find that a $g$-wave altermagnetic spin liquid emerges as the unique ground state. In contrast, the spin-7/2 model exhibits a significantly richer phase diagram, involving different types of chiral spin liquids competing with a $d$-wave altermagnetic spin liquid. Finally, we identify and characterize the topological and non-topological excitations, illustrating the rich physics of altermagnetic spin liquids resulting from the interplay of non-trivial topological and symmetry aspects of this novel phase of matter."}
{"id": "2512.24295", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24295", "abs": "https://arxiv.org/abs/2512.24295", "authors": ["Jiatai Tong", "Yilin Zhu", "Thiago Serra", "Samuel Burer"], "title": "Optimization over Trained Neural Networks: Going Large with Gradient-Based Algorithms", "comment": null, "summary": "When optimizing a nonlinear objective, one can employ a neural network as a surrogate for the nonlinear function. However, the resulting optimization model can be time-consuming to solve globally with exact methods. As a result, local search that exploits the neural-network structure has been employed to find good solutions within a reasonable time limit. For such methods, a lower per-iteration cost is advantageous when solving larger models. The contribution of this paper is two-fold. First, we propose a gradient-based algorithm with lower per-iteration cost than existing methods. Second, we further adapt this algorithm to exploit the piecewise-linear structure of neural networks that use Rectified Linear Units (ReLUs). In line with prior research, our methods become competitive with -- and then dominant over -- other local search methods as the optimization models become larger."}
{"id": "2512.24877", "categories": ["cond-mat.stat-mech", "physics.bio-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2512.24877", "abs": "https://arxiv.org/abs/2512.24877", "authors": ["Doohyeong Cho", "Hawoong Jeong"], "title": "Exact Identity Linking Entropy Production and Mutual Information", "comment": "5 pages, 4 figures", "summary": "Linking entropy production (EP) to information is a key step toward data-driven nonequilibrium thermodynamics. We derive an exact identity for overdamped Langevin dynamics that equates the total EP rate to the mutual-information rate between an infinitesimal displacement and its time-symmetric midpoint, up to a bulk mean-flow contribution. This mapping elevates information theory to a thermodynamic calculus: the chain rule yields a canonical, nonnegative split into self and interaction EP, and leads to a tighter bound on learning rate with interaction EP as the necessary cost. As a proof of concept, applying the estimator to red-blood-cell flickering shows that interaction EP robustly exposes active signatures that conventional summaries can miss."}
{"id": "2512.24405", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24405", "abs": "https://arxiv.org/abs/2512.24405", "authors": ["Uria Mor"], "title": "Sufficient and Necessary Conditions for Eckart-Young-like Result for Tubal Tensors", "comment": null, "summary": "A valuable feature of the tubal tensor framework is that many familiar constructions from matrix algebra carry over to tensors, including SVD and notions of rank. Most importantly, it has been shown that for a specific family of tubal products, an Eckart-Young type theorem holds, i.e., the best low-rank approximation of a tensor under the Frobenius norm is obtained by truncating its tubal SVD. In this paper, we provide a complete characterization of the family of tubal products that yield an Eckart-Young type result. We demonstrate the practical implications of our theoretical findings by conducting experiments with video data and data-driven dynamical systems."}
{"id": "2512.24377", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.24377", "abs": "https://arxiv.org/abs/2512.24377", "authors": ["Brett T. Lopez"], "title": "New Insights into Cascaded Geometric Flight Control: From Performance Guarantees to Practical Pitfalls", "comment": "V1", "summary": "We present a new stability proof for cascaded geometric control used by aerial vehicles tracking time-varying position trajectories. Our approach uses sliding variables and a recently proposed quaternion-based sliding controller to demonstrate that exponentially convergent position trajectory tracking is theoretically possible. Notably, our analysis reveals new aspects of the control strategy, including how tracking error in the attitude loop influences the position loop, how model uncertainties affect the closed-loop system, and the practical pitfalls of the control architecture."}
{"id": "2512.24377", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.24377", "abs": "https://arxiv.org/abs/2512.24377", "authors": ["Brett T. Lopez"], "title": "New Insights into Cascaded Geometric Flight Control: From Performance Guarantees to Practical Pitfalls", "comment": "V1", "summary": "We present a new stability proof for cascaded geometric control used by aerial vehicles tracking time-varying position trajectories. Our approach uses sliding variables and a recently proposed quaternion-based sliding controller to demonstrate that exponentially convergent position trajectory tracking is theoretically possible. Notably, our analysis reveals new aspects of the control strategy, including how tracking error in the attitude loop influences the position loop, how model uncertainties affect the closed-loop system, and the practical pitfalls of the control architecture."}
{"id": "2512.24223", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24223", "abs": "https://arxiv.org/abs/2512.24223", "authors": ["Yuanhui Luo", "Xinzhou Guo", "Yuqi Gu"], "title": "Valid and Efficient Two-Stage Latent Subgroup Analysis with Observational Data", "comment": null, "summary": "Subgroup analysis evaluates treatment effects across multiple sub-populations. When subgroups are defined by latent memberships inferred from imperfect measurements, the analysis typically involves two inter-connected models, a latent class model and a subgroup outcome model. The classical one-stage framework, which models the joint distribution of the two models, may be infeasible with observational data containing many confounders. The two-stage framework, which first estimates the latent class model and then performs subgroup analysis using estimated latent memberships, can accommodate potential confounders but may suffer from bias issues due to misclassification of latent subgroup memberships. This paper focuses on latent subgroups inferred from binary item responses and addresses when and how a valid two-stage latent subgroup analysis can be made with observational data. We investigate the maximum misclassification rate that a valid two-stage framework can tolerate. Introducing a spectral method perspective, we propose a two-stage approach to achieve the desired misclassification rate with the blessing of many item responses. Our method accommodates high-dimensional confounders, is computationally efficient and robust to noninformative items. In observational studies, our methods lead to consistent estimation and valid inference on latent subgroup effects. We demonstrate its merit through simulation studies and an application to educational assessment data."}
{"id": "2512.23803", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23803", "abs": "https://arxiv.org/abs/2512.23803", "authors": ["Roman V. Buniy", "Thomas W. Kephart"], "title": "Mermin Devices for Generalized Dicke States", "comment": "12 pages, 1 figure", "summary": "We present here several new exact results for a number of entangled states: the W-state of three qubits and its generalization -- Dicke states for more than three qubits. We derive these results by bounding the expected values of the Bell-Mermin operators. We review the three qubit GHZ Mermin device, make its generalization to four qubits, and then construct analogous Mermin devices for the generalized Dicke states of three and four qubits. As a result of studying if their operations can be fully explained by Mermin's instructional sets, we show that the GHZ and Dicke states of three qubits and the GHZ state of four qubits do not allow such a description. However, among the two generalized Dicke states of four qubits, one does allow and the other does not allow such a description."}
{"id": "2512.24669", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.24669", "abs": "https://arxiv.org/abs/2512.24669", "authors": ["Wanteng Ma", "T. Tony Cai"], "title": "Nonparametric Bandits with Single-Index Rewards: Optimality and Adaptivity", "comment": null, "summary": "Contextual bandits are a central framework for sequential decision-making, with applications ranging from recommendation systems to clinical trials. While nonparametric methods can flexibly model complex reward structures, they suffer from the curse of dimensionality. We address this challenge using a single-index model, which projects high-dimensional covariates onto a one-dimensional subspace while preserving nonparametric flexibility.\n  We first develop a nonasymptotic theory for offline single-index regression for each arm, combining maximum rank correlation for index estimation with local polynomial regression. Building on this foundation, we propose a single-index bandit algorithm and establish its convergence rate. We further derive a matching lower bound, showing that the algorithm achieves minimax-optimal regret independent of the ambient dimension $d$, thereby overcoming the curse of dimensionality.\n  We also establish an impossibility result for adaptation: without additional assumptions, no policy can adapt to unknown smoothness levels. Under a standard self-similarity condition, however, we construct a policy that remains minimax-optimal while automatically adapting to the unknown smoothness. Finally, as the dimension $d$ increases, our algorithm continues to achieve minimax-optimal regret, revealing a phase transition that characterizes the fundamental limits of single-index bandit learning."}
{"id": "2512.24390", "categories": ["cond-mat.str-el", "hep-th", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24390", "abs": "https://arxiv.org/abs/2512.24390", "authors": ["Bram Vancraeynest-De Cuiper", "Weronika Wiesiolek", "Frank Verstraete"], "title": "Les Houches Lectures Notes on Tensor Networks", "comment": "Comments welcome", "summary": "Tensor networks provide a powerful new framework for classifying and simulating correlated and topological phases of quantum matter. Their central premise is that strongly correlated matter can only be understood by studying the underlying entanglement structure and its associated (generalised) symmetries. In essence, tensor networks provide a compressed, holographic description of the complicated vacuum fluctuations in strongly correlated systems, and as such they break down the infamous many-body exponential wall. These lecture notes provide a concise overview of the most important conceptual, computational and mathematical aspects of this theory."}
{"id": "2512.24302", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24302", "abs": "https://arxiv.org/abs/2512.24302", "authors": ["Hauke Brinkop", "Hua Chen", "Lin Chen", "Klaus Jansen", "Guochuan Zhang"], "title": "Approximation algorithms for integer programming with resource augmentation", "comment": null, "summary": "The classic algorithm [Papadimitriou, J.ACM '81] for IPs has a running time $n^{O(m)}(m\\cdot\\max\\{Δ,\\|\\textbf{b}\\|_{\\infty}\\})^{O(m^2)}$, where $m$ is the number of constraints, $n$ is the number of variables, and $Δ$ and $\\|\\textbf{b}\\|_{\\infty}$ are, respectively, the largest absolute values among the entries in the constraint matrix and the right-hand side vector of the constraint. The running time is exponential in $m$, and becomes pseudo-polynomial if $m$ is a constant. In recent years, there has been extensive research on FPT (fixed parameter tractable) algorithms for the so-called $n$-fold IPs, which may possess a large number of constraints, but the constraint matrix satisfies a specific block structure. It is remarkable that these FPT algorithms take as parameters $Δ$ and the number of rows and columns of some small submatrices. If $Δ$ is not treated as a parameter, then the running time becomes pseudo-polynomial even if all the other parameters are taken as constants.\n  This paper explores the trade-off between time and accuracy in solving an IP. We show that, for arbitrary small $\\varepsilon>0$, there exists an algorithm for IPs with $m$ constraints that runs in ${f(m,\\varepsilon)}\\cdot\\textnormal{poly}(|I|)$ time, and returns a near-feasible solution that violates the constraints by at most $\\varepsilonΔ$. Furthermore, for $n$-fold IPs, we establish a similar result -- our algorithm runs in time that depends on the number of rows and columns of small submatrices together with $1/\\varepsilon$, and returns a solution that slightly violates the constraints. Meanwhile, both solutions guarantee that their objective values are no worse than the corresponding optimal objective values satisfying the constraints. As applications, our results can be used to obtain additive approximation schemes for multidimensional knapsack as well as scheduling."}
{"id": "2512.24969", "categories": ["cond-mat.stat-mech", "cs.CL", "physics.bio-ph", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.24969", "abs": "https://arxiv.org/abs/2512.24969", "authors": ["Colin Scheibner", "Lindsay M. Smith", "William Bialek"], "title": "Large language models and the entropy of English", "comment": "8 pages, 6 figures", "summary": "We use large language models (LLMs) to uncover long-ranged structure in English texts from a variety of sources. The conditional entropy or code length in many cases continues to decrease with context length at least to $N\\sim 10^4$ characters, implying that there are direct dependencies or interactions across these distances. A corollary is that there are small but significant correlations between characters at these separations, as we show from the data independent of models. The distribution of code lengths reveals an emergent certainty about an increasing fraction of characters at large $N$. Over the course of model training, we observe different dynamics at long and short context lengths, suggesting that long-ranged structure is learned only gradually. Our results constrain efforts to build statistical physics models of LLMs or language itself."}
{"id": "2512.24456", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24456", "abs": "https://arxiv.org/abs/2512.24456", "authors": ["Gentian Zavalani"], "title": "Fast high-order spectral solvers for PDEs on triangulated surfaces with applications to deforming surfaces", "comment": "36 pages, 22 figures", "summary": "In this paper, we extend the classical quadrilateral based hierarchical Poincaré-Steklov (HPS) framework to triangulated geometries. Traditionally, the HPS method takes as input an unstructured, high-order quadrilateral mesh and relies on tensor-product spectral discretizations on each element. To overcome this restriction, we introduce two complementary high-order strategies for triangular elements: a reduced quadrilateralization approach which is straightforward to implement, and triangle based spectral element method based on Dubiner polynomials. We show numerically that these extensions preserve the spectral accuracy, efficiency, and fast direct-solver structure of the HPS framework. The method is further extended to time dependent and evolving surfaces, and its performance is demonstrated through numerical experiments on reaction-diffusion systems, and geometry driven surface evolution."}
{"id": "2512.24435", "categories": ["eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.24435", "abs": "https://arxiv.org/abs/2512.24435", "authors": ["Alexandre Rodrigues Mesquita"], "title": "Bayesian Subspace Identification in the MIMO Case", "comment": null, "summary": "This report investigates the extension of the Bayesian Subspace System Identification method proposed in our previous work to the Multiple-Input Multiple-Output (MIMO) case. We derive new equivariant priors and posterior distributions specifically suited for the MIMO framework. Numerical results utilizing the DAISY dataset are reported to validate the approach."}
{"id": "2512.24435", "categories": ["eess.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.24435", "abs": "https://arxiv.org/abs/2512.24435", "authors": ["Alexandre Rodrigues Mesquita"], "title": "Bayesian Subspace Identification in the MIMO Case", "comment": null, "summary": "This report investigates the extension of the Bayesian Subspace System Identification method proposed in our previous work to the Multiple-Input Multiple-Output (MIMO) case. We derive new equivariant priors and posterior distributions specifically suited for the MIMO framework. Numerical results utilizing the DAISY dataset are reported to validate the approach."}
{"id": "2512.24342", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24342", "abs": "https://arxiv.org/abs/2512.24342", "authors": ["Farimah Shamsi", "Andriy Derkach"], "title": "A Novel Approach for Data Integration with Multiple Heterogeneous Data Sources", "comment": null, "summary": "The integration of data from multiple sources is increasingly used to achieve larger sample sizes and enhance population diversity. Our previous work established that, under random sampling from the same underlying population, integrating large incomplete datasets with summary-level data produces unbiased parameter estimates. In this study, we develop a novel statistical framework that enables the integration of summary-level data with information from heterogeneous data sources by leveraging auxiliary information. The proposed approach estimates study-specific sampling weights using this auxiliary information and calibrates the estimating equations to obtain the full set of model parameters. We evaluate the performance of the proposed method through simulation studies under various sampling designs and illustrate its application by reanalyzing U.S. cancer registry data combined with summary-level odds ratio estimates for selected colorectal cancer (CRC) risk factors, while relaxing the random sampling assumption."}
{"id": "2512.23810", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2512.23810", "abs": "https://arxiv.org/abs/2512.23810", "authors": ["Dorit Aharonov", "Yosi Atia", "Eyal Bairey", "Zvika Brakerski", "Itsik Cohen", "Omri Golan", "Ilya Gurwich", "Netanel H. Lindner", "Maor Shutman"], "title": "Syndrome aware mitigation of logical errors", "comment": null, "summary": "Broad applications of quantum computers will require error correction (EC). However, quantum hardware roadmaps indicate that physical qubit numbers will remain limited in the foreseeable future, leading to residual logical errors that limit the size and accuracy of achievable computations. Recent work suggested logical error mitigation (LEM), which applies known error mitigation (EM) methods to logical errors, eliminating their effect at the cost of a runtime overhead. Improving the efficiency of LEM is crucial for increasing the logical circuit volumes it enables to execute.\n  We introduce syndrome-aware logical error mitigation (SALEM), which makes use of the syndrome data measured during error correction, when mitigating the logical errors. The runtime overhead of SALEM is exponentially lower than that of previously proposed LEM schemes, resulting in significantly increased circuit volumes that can be executed accurately. Notably, relative to the routinely used combination of error correction and syndrome rejection (post-selection), SALEM increases the size of reliably executable computations by orders of magnitude. In this practical setting in which space and time are both resources that need to be optimized, our work reveals a surprising phenomenon: SALEM, which tightly combines EC with EM, can outperform physical EM even above the standard fault-tolerance threshold. Thus, SALEM can make use of EC in regimes of physical error rates at which EC is commonly deemed useless."}
{"id": "2512.24701", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2512.24701", "abs": "https://arxiv.org/abs/2512.24701", "authors": ["Youngjo Lee"], "title": "Reformulating Confidence as Extended Likelihood", "comment": null, "summary": "Fisher's fiducial probability has recently received renewed attention under the name confidence. In this paper, we reformulate it within an extended-likelihood framework, a representation that helps to resolve many long-standing controversies. The proposed formulation accommodates multi-dimensional parameters and shows how higher-order approximations can be used to refine standard asymptotic confidence statements."}
{"id": "2512.24533", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.24533", "abs": "https://arxiv.org/abs/2512.24533", "authors": ["Hatem Barghathi", "Adrian Del Maestro"], "title": "Detection of a Rényi Index Dependent Transition in Entanglement Entropy Scaling", "comment": "11 pages, 5 figures. For associated data and code repository see: https://github.com/DelMaestroGroup/papers-code-EntanglementScalingTransition", "summary": "The scaling of entanglement with subsystem size encodes key information about phases and criticality, but the von Neumann entropy is costly to access in experiments and simulations, often requiring full state tomography. The second Rényi entropy is readily measured using two-copy protocols and is often used as a proxy for the von Neumann entanglement entropy, where it is assumed to track its asymptotic scaling. However, Sugino and Korepiny (Int. J. Mod. Phys. B 32, 1850306 (2018)) revealed that in the ground state of some spin models, the scaling of the von Neumann and second Rényi entropies varies from power law to logarithmic scaling as a function of the Rényi index. By constructing a number-conserving many-body state with only two local degrees of freedom, we obtain a Rényi-index-dependent change in the leading entanglement scaling: the second Rényi entropy remains logarithmic while the von Neumann entropy is parametrically larger. We then introduce a symmetry-aware lower bound on the von Neumann entropy built from charge-resolved second Rényi entropies and the subsystem charge distribution. Comparing this bound to the total second Rényi entropy provides a practical diagnostic for anomalous entanglement scaling from experimentally accessible data."}
{"id": "2512.24313", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24313", "abs": "https://arxiv.org/abs/2512.24313", "authors": ["Grégoire Lambrecht", "Mathieu Laurière"], "title": "Discrete-Time Mean Field Type Games: Probabilistic Setup", "comment": null, "summary": "We introduce a general probabilistic framework for discrete-time, infinite-horizon discounted Mean Field Type Games (MFTGs) with both global common noise and team-specific common noises. In our model, agents are allowed to use randomized actions, both at the individual level and at the team level. We formalize the concept of Mean Field Markov Games (MFMGs) and establish a connection between closed-loop policies in MFTGs and Markov policies in MFMGs through different layers of randomization. By leveraging recent results on infinite-horizon discounted games with infinite compact state-action spaces, we prove the existence of an optimal closed-loop policy for the original MFTG when the state spaces are at most countable and the action spaces are general Polish spaces. We also present an example satisfying our assumptions, called Mean Field Drift of Intentions, where the dynamics are strongly randomized, and we establish the existence of a Nash equilibrium using our theoretical results."}
{"id": "2512.25074", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25074", "abs": "https://arxiv.org/abs/2512.25074", "authors": ["Souradeep Ghosh", "Nicholas Hunter-Jones", "Joaquin F. Rodriguez-Nieva"], "title": "Randomization Times under Quantum Chaotic Hamiltonian Evolution", "comment": "5 pages, 4 figures", "summary": "Randomness generation through quantum-chaotic evolution underpins foundational questions in statistical mechanics and applications across quantum information science, including benchmarking, tomography, metrology, and demonstrations of quantum computational advantage. While statistical mechanics successfully captures the temporal averages of local observables, understanding randomness at the level of higher statistical moments remains a daunting challenge, with analytic progress largely confined to random quantum circuit models or fine-tuned systems exhibiting space-time duality. Here we study how much randomness can be dynamically generated by generic quantum-chaotic evolution under physical, non-random Hamiltonians. Combining theoretical insights with numerical simulations, we show that for broad classes of initially unentangled states, the dynamics become effectively Haar-random well before the system can ergodically explore the physically accessible Hilbert space. Both local and highly nonlocal observables, including entanglement measures, equilibrate to their Haar expectation values and fluctuations on polynomial timescales with remarkably high numerical precision, and with the fastest randomization occurring in regions of parameter space previously identified as maximally chaotic. Interestingly, this effective randomization can occur on timescales linear in system size, suggesting that the sub-ballistic growth of Renyi entropies typically observed in systems with conservation laws can be bypassed in non-random Hamiltonians with an appropriate choice of initial conditions."}
{"id": "2512.24523", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24523", "abs": "https://arxiv.org/abs/2512.24523", "authors": ["Kingsley Yeon", "Steven B. Damelin", "Michael Werman"], "title": "Exponential Convergence of Deep Composite Polynomial Approximation for Cusp-Type Functions", "comment": null, "summary": "We investigate deep composite polynomial approximations of continuous but non-differentiable functions with algebraic cusp singularities. The functions in focus consist of finitely many cusp terms of the form $|x-a_j|^{α_j}$ with rational exponents $α_j\\in(0,1)$ on a real-analytic background. We propose a constructive approximation scheme that combines a division-free polynomial iteration for fractional powers with an outer layer for the analytic polynomial fitting. Our main result shows that this composite structure achieves exponential convergence in the the number of scalar coefficients in the inner and outer polynomial layers. Specifically, the $L^p([-1,1])$ approximation error, decays exponentially with respect to the parameter budget, in contrast to the algebraic rates obtained by classical single-layer polynomial approximation for cusp-type functions. Numerical experiments for both single and multiple cusp configurations confirm the theoretical rates and demonstrate the parameter efficiency of deep composite polynomial constructions."}
{"id": "2512.24453", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.24453", "abs": "https://arxiv.org/abs/2512.24453", "authors": ["William Paul Heath", "Sayar Das", "Joaquin Carrasco"], "title": "Multipliers for forced Lurye systems with slope-restricted nonlinearities", "comment": "16 pages, 14 figures, submitted for review to IEEE Transactions on Automatic Control", "summary": "Dynamic multipliers can be used to guarantee the stability of Lurye systems with slope-restricted nonlinearities, but give no guarantee that the closed-loop system has finite incremental gain. We show that multipliers guarantee the closed-loop power gain to be bounded and quantifiable. Power may be measured about an appropriate steady state bias term, provided the multiplier does not require the nonlinearity to be odd. Hence dynamic multipliers can be used to guarantee such Lurye systems have low sensitivity to noise, provided other exogenous signals have constant steady state. For periodic excitation, the closed-loop response can apparently have a subharmonic or chaotic response. We revisit a class of multipliers that can guarantee a unique, attractive and period-preserving solution. We show the multipliers can be derived using classical tools and reconsider assumptions required for their application. Their phase limitations are inherited from those of discrete-time multipliers. The multipliers cannot be used at all frequencies unless the circle criterion can also be applied; this is consistent with known results about dynamic multipliers and incremental stability."}
{"id": "2512.24453", "categories": ["eess.SY", "math.DS"], "pdf": "https://arxiv.org/pdf/2512.24453", "abs": "https://arxiv.org/abs/2512.24453", "authors": ["William Paul Heath", "Sayar Das", "Joaquin Carrasco"], "title": "Multipliers for forced Lurye systems with slope-restricted nonlinearities", "comment": "16 pages, 14 figures, submitted for review to IEEE Transactions on Automatic Control", "summary": "Dynamic multipliers can be used to guarantee the stability of Lurye systems with slope-restricted nonlinearities, but give no guarantee that the closed-loop system has finite incremental gain. We show that multipliers guarantee the closed-loop power gain to be bounded and quantifiable. Power may be measured about an appropriate steady state bias term, provided the multiplier does not require the nonlinearity to be odd. Hence dynamic multipliers can be used to guarantee such Lurye systems have low sensitivity to noise, provided other exogenous signals have constant steady state. For periodic excitation, the closed-loop response can apparently have a subharmonic or chaotic response. We revisit a class of multipliers that can guarantee a unique, attractive and period-preserving solution. We show the multipliers can be derived using classical tools and reconsider assumptions required for their application. Their phase limitations are inherited from those of discrete-time multipliers. The multipliers cannot be used at all frequencies unless the circle criterion can also be applied; this is consistent with known results about dynamic multipliers and incremental stability."}
{"id": "2512.24356", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.24356", "abs": "https://arxiv.org/abs/2512.24356", "authors": ["Max Thannheimer", "Marco Oesting"], "title": "Bayesian inference for functional extreme events defined via partially unobserved processes", "comment": "18 pages, 1 figure, 1 table", "summary": "In order to describe the extremal behaviour of some stochastic process $X$, approaches from univariate extreme value theory are typically generalized to the spatial domain. In particular, generalized peaks-over-threshold approaches allow for the consideration of single extreme events. These can be flexibly defined as exceedances of a risk functional $r$, such as a spatial average, applied to $X$. Inference for the resulting limit process, the so-called $r$-Pareto process, requires the evaluation of $r(X)$ and thus the knowledge of the whole process $X$. In many practical applications, however, observations of $X$ are only available at scattered sites. To overcome this issue, we propose a two-step MCMC-algorithm in a Bayesian framework. In a first step, we sample from $X$ conditionally on the observations in order to evaluate which observations lead to $r$-exceedances. In a second step, we use these exceedances to sample from the posterior distribution of the parameters of the limiting $r$-Pareto process. Alternating these steps results in a full Bayesian model for the extremes of $X$. We show that, under appropriate assumptions, the probability of classifying an observation as $r$-exceedance in the first step converges to the desired probability. Furthermore, given the first step, the distribution of the Markov chain constructed in the second step converges to the posterior distribution of interest. The procedure is compared to the Bayesian version of the standard procedure in a simulation study."}
{"id": "2512.23817", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23817", "abs": "https://arxiv.org/abs/2512.23817", "authors": ["Seyed Mohamad Ali Tousi", "Adib Bazgir", "Yuwen Zhang", "G. N. DeSouza"], "title": "Quantum Error Mitigation with Attention Graph Transformers for Burgers Equation Solvers on NISQ Hardware", "comment": null, "summary": "We present a hybrid quantum-classical framework augmented with learned error mitigation for solving the viscous Burgers equation on noisy intermediate-scale quantum (NISQ) hardware. Using the Cole-Hopf transformation, the nonlinear Burgers equation is mapped to a diffusion equation, discretized on uniform grids, and encoded into a quantum state whose time evolution is approximated via Trotterized nearest-neighbor circuits implemented in Qiskit. Quantum simulations are executed on noisy Aer backends and IBM superconducting quantum devices and are benchmarked against high-accuracy classical solutions obtained using a Krylov-based solver applied to the corresponding discretized Hamiltonian. From measured quantum amplitudes, we reconstruct the velocity field and evaluate physical and numerical diagnostics, including the L2 error, shock location, and dissipation rate, both with and without zero-noise extrapolation (ZNE). To enable data-driven error mitigation, we construct a large parametric dataset by sweeping viscosity, time step, grid resolution, and boundary conditions, producing matched tuples of noisy, ZNE-corrected, hardware, and classical solutions together with detailed circuit metadata. Leveraging this dataset, we train an attention-based graph neural network that incorporates circuit structure, light-cone information, global circuit parameters, and noisy quantum outputs to predict error-mitigated solutions. Across a wide range of parameters, the learned model consistently reduces the discrepancy between quantum and classical solutions beyond what is achieved by ZNE alone. We discuss extensions of this approach to higher-dimensional Burgers systems and more general quantum partial differential equation solvers, highlighting learned error mitigation as a promising complement to physics-based noise reduction techniques on NISQ devices."}
{"id": "2512.24860", "categories": ["math.ST", "cs.CC", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.24860", "abs": "https://arxiv.org/abs/2512.24860", "authors": ["Deniz Akdemir"], "title": "Approximate Computation via Le Cam Simulability", "comment": null, "summary": "We propose a decision-theoretic framework for computational complexity, complementary to classical theory: moving from syntactic exactness (Turing / Shannon) to semantic simulability (Le Cam). While classical theory classifies problems by the cost of exact solution, modern computation often seeks only decision-valid approximations. We introduce a framework where \"computation\" is viewed as the efficient simulation of a target statistical experiment within a bounded risk distortion (Le Cam deficiency).\n  We formally define computational deficiency ($δ_{\\text{poly}}$) and use it to construct the complexity class LeCam-P (Decision-Robust Polynomial Time), characterizing problems that may be syntactically hard but semantically easy to approximate. We show that classical Karp reductions can be viewed as zero-deficiency simulations, and that approximate reductions correspond to bounded deficiency. Furthermore, we establish the No-Free-Transfer Inequality, showing that strictly invariant representations inevitably destroy decision-relevant information. This framework offers a statistical perspective on approximation theory, bridging the gap between algorithmic complexity and decision theory."}
{"id": "2512.24668", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2512.24668", "abs": "https://arxiv.org/abs/2512.24668", "authors": ["J. W. Park", "H. Kim", "H. W. Yeom"], "title": "Disentangle Intertwined Interactions in Correlated Charge Density Wave with Magnetic Impurities", "comment": "22 pages, 5 figures", "summary": "Magnetic impurities in strongly correlated electronic systems serve as sensitive probes to a wide range of many-body quantum phenomena. Broken symmetries in such a system can lead to inequivalent lattice sites, and magnetic impurities may interact selectively with particular orbitals or sublattices. However, the microscopic mechanisms behind such site-specific interactions have been poorly understood. Here, we explore the behavior of individual Fe adatoms on a cluster-Mott charge-density-wave (CDW) system of 1T-TaS2 utilizing scanning tunneling microscopy/spectroscopy (STM/STS) and density functional theory (DFT). Our measurements uncover pronounced site-dependent electronic states of CDW clusters with Fe adatoms, indicating distinct local coupling to cluster-Mott states. DFT calculations identify three distinct types of interactions; hybridization with localized correlated electrons, distorting the CDW cluster, and charge transfer. In particular, the hybridization of Fe 3d and half-filled Ta 5dz2 orbitals suppresses the Mott insulating state for an adatom at the center of a CDW cluster. While the results underscore a crucial role of the direct orbital hybridization and the limitation of the prevailing single-site Kondo impurity model, they suggest the possibility of controlling entangled interactions separately in a cluster Mott insulator."}
{"id": "2512.24335", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24335", "abs": "https://arxiv.org/abs/2512.24335", "authors": ["Manish Krishan Lal"], "title": "Backpropagation from KL Projections: Differential and Exact I-Projection Correspondences", "comment": null, "summary": "We establish two exact correspondences between reverse-mode automatic differentiation (backpropagation evaluated at a fixed forward pass) and compositions of projection maps in Kullback--Leibler (KL) geometry. In both settings, message passing defined by alternating KL projections enforces agreement and factorization constraints. In the first setting, backpropagation arises as the differential of a KL projection map on a delta-lifted factorization. In the second setting, on complete and decomposable sum--product networks, backpropagation coincides with exact probabilistic inference, and the backward values admit an interpretation as Lagrange multipliers of a KL I-projection problem."}
{"id": "2512.23840", "categories": ["physics.comp-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.23840", "abs": "https://arxiv.org/abs/2512.23840", "authors": ["Edoardo Monti", "Peter Yatsyshin", "Konstantinos Gkagkas", "Andrew B. Duncan"], "title": "Learning Density Functionals to Bridge Particle and Continuum Scales", "comment": null, "summary": "Predicting interfacial thermodynamics across molecular and continuum scales remains a central challenge in computational science. Classical density functional theory (cDFT) provides a first-principles route to connect microscopic interactions with macroscopic observables, but its predictive accuracy depends on approximate free-energy functionals that are difficult to generalize. Here we introduce a physics-informed learning framework that augments cDFT with neural corrections trained directly against molecular-dynamics data through adjoint optimization. Rather than replacing the theory with a black-box surrogate, we embed compact neural networks within the Helmholtz free-energy functional, learning local and nonlocal corrections that preserve thermodynamic consistency while capturing missing correlations. Applied to Lennard-Jones fluids, the resulting augmented excess free-energy functional quantitatively reproduces equilibrium density profiles, coexistence curves, and surface tensions across a broad temperature range, and accurately predicts contact angles and droplet shapes far beyond the training regime. This approach combines the interpretability of statistical mechanics with the adaptability of modern machine learning, establishing a general route to learned thermodynamic functionals that bridge molecular simulations and continuum-scale models."}
{"id": "2512.24567", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.24567", "abs": "https://arxiv.org/abs/2512.24567", "authors": ["Hannes Vandecasteele", "Nicholas Karris", "Alexander Cloninger", "Ioannis G. Kevrekidis"], "title": "Newton-Krylov Methods for Computing Steady States of Particle Timesteppers via Optimal Transport", "comment": null, "summary": "Timesteppers constitute a powerful tool in modern computational science and engineering. Although they are typically used to advance the system forward in time, they can also be viewed as nonlinear mappings that implicitly encode steady states and stability information. In this work, we present an extension of the matrix-free framework for calculating, via timesteppers, steady states of deterministic systems to stochastic particle simulations, where intrinsic randomness prevents direct steady state extraction. By formulating stochastic timesteppers in the language of optimal transport, we reinterpret them as operators acting on probability measures rather than on individual particle trajectories. This perspective enables the construction of smooth cumulative- and inverse-cumulative-distribution-function ((I)CDF) timesteppers that evolve distributions rather than particles. Combined with matrix-free Newton-Krylov solvers, these smooth timesteppers allow efficient computation of steady-state distributions even under high stochastic noise. We perform an error analysis quantifying how noise affects finite-difference Jacobian action approximations, and demonstrate that convergence can be obtained even in high noise regimes. Finally, we introduce higher-dimensional generalizations based on smooth CDF-related representations of particles and validate their performance on a non-trivial two-dimensional distribution. Together, these developments establish a unified variational framework for computing meaningful steady states of both deterministic and stochastic timesteppers."}
{"id": "2512.24484", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24484", "abs": "https://arxiv.org/abs/2512.24484", "authors": ["Sunjeev Venkateswaran", "Costas Kravaris"], "title": "Design of Linear Residual Generators for Combined Fault Detection and Estimation in Nonlinear Systems", "comment": null, "summary": "A systematic method for the design of linear residual generators for combined fault detection and estimation in nonlinear systems is developed. The proposed residual generator is a linear functional observer built for an extended system that incorporates the fault dynamics from a linear exo-system, and in addition possesses disturbance-decoupling properties. Necessary and sufficient conditions for the existence of such residual generators for nonlinear systems are derived. As long as these conditions are satisfied, we obtain explicit design formulas for the residual generator. The results are illustrated through a chemical reactor case study, which demonstrates the effectiveness of the proposed methodology."}
{"id": "2512.24484", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24484", "abs": "https://arxiv.org/abs/2512.24484", "authors": ["Sunjeev Venkateswaran", "Costas Kravaris"], "title": "Design of Linear Residual Generators for Combined Fault Detection and Estimation in Nonlinear Systems", "comment": null, "summary": "A systematic method for the design of linear residual generators for combined fault detection and estimation in nonlinear systems is developed. The proposed residual generator is a linear functional observer built for an extended system that incorporates the fault dynamics from a linear exo-system, and in addition possesses disturbance-decoupling properties. Necessary and sufficient conditions for the existence of such residual generators for nonlinear systems are derived. As long as these conditions are satisfied, we obtain explicit design formulas for the residual generator. The results are illustrated through a chemical reactor case study, which demonstrates the effectiveness of the proposed methodology."}
{"id": "2512.24392", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24392", "abs": "https://arxiv.org/abs/2512.24392", "authors": ["Jeongjin Lee", "Jennifer Wadsworth"], "title": "Geometric criteria for identifying extremal dependence and flexible modeling via additive mixtures", "comment": null, "summary": "The framework of geometric extremes is based on the convergence of scaled sample clouds onto a limit set, characterized by a gauge function, with the shape of the limit set determining extremal dependence structures. While it is known that a blunt limit set implies asymptotic independence, the absence of bluntness can be linked to both asymptotic dependence and independence. Focusing on the bivariate case, under a truncated gamma modeling assumption with bounded angular density, we show that a ``pointy'' limit set implies asymptotic dependence, thus offering practical geometric criteria for identifying extremal dependence classes. Suitable models for the gauge function offer the ability to capture asymptotically independent or dependent data structures, without requiring prior knowledge of the true extremal dependence structure. The geometric approach thus offers a simple alternative to various parametric copula models that have been developed for this purpose in recent years. We consider two types of additively mixed gauge functions that provide a smooth interpolation between asymptotic dependence and asymptotic independence. We derive their explicit forms, explore their properties, and establish connections to the developed geometric criteria. Through a simulation study, we evaluate the effectiveness of the geometric approach with additively mixed gauge functions, comparing its performance to existing methodologies that account for both asymptotic dependence and asymptotic independence. The methodology is computationally efficient and yields reliable performance across various extremal dependence scenarios."}
{"id": "2512.23867", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23867", "abs": "https://arxiv.org/abs/2512.23867", "authors": ["Francisco Figueiredo", "Itzhak Roditi"], "title": "Squeezed states for Frenkel-like two-fermion composite bosons", "comment": "8 pages, 3 figures", "summary": "We investigate squeezed states of composite bosons (cobosons) formed by pairs of spin-$1/2$ fermions, with emphasis on Frenkel-like cobosons. While squeezing for standard bosonic modes is well established, its extension to cobosons requires accounting for Pauli blocking and the resulting non-canonical commutation algebra. Building on earlier constructions of coboson coherent states, we define squeezed cobosons as eigenstates of a Bogoliubov transformed coboson operator and derive explicit expressions for the associated quadrature variances. We show that the underlying fermionic structure leads to state-dependent modifications of the Heisenberg--Robertson uncertainty bound, which may fall below the canonical bosonic limit without implying any violation of uncertainty principles. Numerical results based on finite-dimensional matrix representations illustrate how these effects constrain the attainable squeezing. Our framework is relevant to composite boson systems such as tightly bound electron-hole pairs and provides a physically transparent setting to probe compositeness through observable quadrature fluctuations."}
{"id": "2512.24999", "categories": ["math.ST", "cs.LG", "math.NA", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24999", "abs": "https://arxiv.org/abs/2512.24999", "authors": ["Seunghoon Paik", "Kangjie Zhou", "Matus Telgarsky", "Ryan J. Tibshirani"], "title": "Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis", "comment": "47 pages, 3 figures (7 subfigures)", "summary": "We introduce \\textit{basic inequalities} for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let $f$ denote the objective function to be optimized. Given a first-order iterative algorithm initialized at $θ_0$ with current iterate $θ_T$, the basic inequality upper bounds $f(θ_T)-f(z)$ for any reference point $z$ in terms of the accumulated step sizes and the distances between $θ_0$, $θ_T$, and $z$. The bound translates the number of iterations into an effective regularization coefficient in the loss function. We demonstrate this framework through analyses of training dynamics and prediction risk bounds. In addition to revisiting and refining known results on gradient descent, we provide new results for mirror descent with Bregman divergence projection, for generalized linear models trained by gradient descent and exponentiated gradient descent, and for randomized predictors. We illustrate and supplement these theoretical findings with experiments on generalized linear models."}
{"id": "2512.24709", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "math-ph", "math.AT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24709", "abs": "https://arxiv.org/abs/2512.24709", "authors": ["Hisham Sati", "Urs Schreiber"], "title": "Fragile Topological Phases and Topological Order of 2D Crystalline Chern Insulators", "comment": "15 pages, 8 figures", "summary": "We apply methods of equivariant homotopy theory, which may not previously have found due attention in condensed matter physics, to classify first the fragile/unstable topological phases of 2D crystalline Chern insulator materials, and second the possible topological order of their fractional cousins. We highlight that the phases are given by the equivariant 2-Cohomotopy of the Brillouin torus of crystal momenta (with respect to wallpaper point group actions) -- which, despite the attention devoted to crystalline Chern insulators, seems not to have been considered before. Arguing then that any topological order must be reflected in the adiabatic monodromy of gapped quantum ground states over the covariantized space of these band topologies, we compute the latter in examples where this group is non-abelian, showing that any potential FQAH anyons must be localized in momentum space. We close with an outlook on the relevance for the search for topological quantum computing hardware. Mathematical details are spelled out in a supplement."}
{"id": "2512.24483", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24483", "abs": "https://arxiv.org/abs/2512.24483", "authors": ["Liyuan Liang", "Yilong Song", "Kun Yuan"], "title": "Decentralized Optimization over Time-Varying Row-Stochastic Digraphs", "comment": null, "summary": "Decentralized optimization over directed graphs is essential for applications such as robotic swarms, sensor networks, and distributed learning. In many practical scenarios, the underlying network is a Time-Varying Broadcast Network (TVBN), where only row-stochastic mixing matrices can be constructed due to inaccessible out-degree information. Achieving exact convergence over TVBNs has remained a long-standing open question, as the limiting distribution of time-varying row-stochastic mixing matrices depends on unpredictable future graph realizations, rendering standard bias-correction techniques infeasible.\n  This paper resolves this open question by developing the first algorithm that achieves exact convergence using only time-varying row-stochastic matrices. We propose PULM (Pull-with-Memory), a gossip protocol that attains average consensus with exponential convergence by alternating between row-stochastic mixing and local adjustment. Building on PULM, we develop PULM-DGD, which converges to a stationary solution at $\\mathcal{O}(\\ln(T)/T)$ for smooth nonconvex objectives. Our results significantly extend decentralized optimization to highly dynamic communication environments."}
{"id": "2512.24122", "categories": ["physics.soc-ph", "cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24122", "abs": "https://arxiv.org/abs/2512.24122", "authors": ["Kristóf Benedek", "Géza Ódor"], "title": "The effect of HVDC lines in power-grids via Kuramoto modelling", "comment": null, "summary": "We present a numerical study on the synchronization and cascade failure behaviour by solving the adaptive second-order Kuramoto model on a large high voltage (HV) European power-grid. This non-perturbative analysis takes into account non-linear effects, which occur even when phase differences are large, when the system is away from the steady state, and even during a blackout cascade. Our dynamical simulations show that improvements in the phase synchronziation stabilization as well as the in the cascade sizes can be related to the finite size scaling behaviour of the second order Kuramoto on graphs with $d_s<4$ spectral dimensions. On the other hand drawbacks in the frequency spread and Braess effects also occur by varying the total transmitted power at large and small global couplings, presumably when the fluctuations are small, causing a freezing in the dynamics. We compare simulations of the fully AC model with those of static or adaptive High Voltage Direct Current (HVDC) line replacements. The adaptive (local frequency difference-based) HVDC lines are more efficient in the steady state, at the expense of very long relaxation times."}
{"id": "2512.24647", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24647", "abs": "https://arxiv.org/abs/2512.24647", "authors": ["Qiling Gu", "Wenlong Zhang", "Zhidong Zhang"], "title": "Solving the inverse Source Problems for wave equation with final time measurements by a data driven approach", "comment": null, "summary": "This paper develops a discrete data-driven approach for solving the inverse source problem of the wave equation with final time measurements. Focusing on the $L^2$-Tikhonov regularization method, we analyze its convergence under two different noise models, using noisy discrete spatial observations. By exploiting the spectral decomposition of the forward operator and introducing a noise separation technique into the variational framework, we establish error bounds for the reconstructed solution $u$ and the source term $f$ without requiring classical source conditions. Moreover, an expected convergence rate for the source error is derived in a weaker topology. We also extend the analysis to the fully discrete case with finite element discretization, showing that the overall error depends only on the noise level, regularization parameter, time step size, and spatial mesh size. These estimates provide a basis for selecting the optimal regularization parameter in a data-driven manner, without a priori information. Numerical experiments validate the theoretical results and demonstrate the efficiency of the proposed algorithm."}
{"id": "2512.24493", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.24493", "abs": "https://arxiv.org/abs/2512.24493", "authors": ["Chi Ho Leung", "Philip E. Paré"], "title": "Energy-Aware Bayesian Control Barrier Functions for Physics-Informed Gaussian Process Dynamics", "comment": null, "summary": "We study safe control for dynamical systems whose continuous-time dynamics are learned with Gaussian processes (GPs), focusing on mechanical and port-Hamiltonian systems where safety is naturally expressed via energy constraints. The availability of a GP Hamiltonian posterior naturally raises the question of how to systematically exploit this structure to design an energy-aware control barrier function with high-probability safety guarantees. We address this problem by developing a Bayesian-CBF framework and instantiating it with energy-aware Bayesian-CBFs (EB-CBFs) that construct conservative energy-based barriers directly from the Hamiltonian and vector-field posteriors, yielding safety filters that minimally modify a nominal controller while providing probabilistic energy safety guarantees. Numerical simulations on a mass-spring system demonstrate that the proposed EB-CBFs achieve high-probability safety under noisy sampled GP-learned dynamics."}
{"id": "2512.24493", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.24493", "abs": "https://arxiv.org/abs/2512.24493", "authors": ["Chi Ho Leung", "Philip E. Paré"], "title": "Energy-Aware Bayesian Control Barrier Functions for Physics-Informed Gaussian Process Dynamics", "comment": null, "summary": "We study safe control for dynamical systems whose continuous-time dynamics are learned with Gaussian processes (GPs), focusing on mechanical and port-Hamiltonian systems where safety is naturally expressed via energy constraints. The availability of a GP Hamiltonian posterior naturally raises the question of how to systematically exploit this structure to design an energy-aware control barrier function with high-probability safety guarantees. We address this problem by developing a Bayesian-CBF framework and instantiating it with energy-aware Bayesian-CBFs (EB-CBFs) that construct conservative energy-based barriers directly from the Hamiltonian and vector-field posteriors, yielding safety filters that minimally modify a nominal controller while providing probabilistic energy safety guarantees. Numerical simulations on a mass-spring system demonstrate that the proposed EB-CBFs achieve high-probability safety under noisy sampled GP-learned dynamics."}
{"id": "2512.24413", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24413", "abs": "https://arxiv.org/abs/2512.24413", "authors": ["Grace V. Ringlein", "Trang Quynh Nguyen", "Peter P. Zandi", "Elizabeth A. Stuart", "Harsh Parikh"], "title": "Demystifying Proximal Causal Inference", "comment": "32 pages, 5 figures", "summary": "Proximal causal inference (PCI) has emerged as a promising framework for identifying and estimating causal effects in the presence of unobserved confounders. While many traditional causal inference methods rely on the assumption of no unobserved confounding, this assumption is likely often violated. PCI mitigates this challenge by relying on an alternative set of assumptions regarding the relationships between treatment, outcome, and auxiliary variables that serve as proxies for unmeasured confounders. We review existing identification results, discuss the assumptions necessary for valid causal effect estimation via PCI, and compare different PCI estimation methods. We offer practical guidance on operationalizing PCI, with a focus on selecting and evaluating proxy variables using domain knowledge, measurement error perspectives, and negative control analogies. Through conceptual examples, we demonstrate tensions in proxy selection and discuss the importance of clearly defining the unobserved confounding mechanism. By bridging formal results with applied considerations, this work aims to demystify PCI, encourage thoughtful use in practice, and identify open directions for methodological development and empirical research."}
{"id": "2512.23917", "categories": ["quant-ph", "cond-mat.str-el", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23917", "abs": "https://arxiv.org/abs/2512.23917", "authors": ["Rong-Yang Sun", "Tomonori Shirakawa", "Hidehiko Kohshiro", "D. N. Sheng", "Seiji Yunoki"], "title": "Tensor Computing Interface: An Application-Oriented, Lightweight Interface for Portable High-Performance Tensor Network Applications", "comment": "34 pages, 10 figures", "summary": "Tensor networks (TNs) are a central computational tool in quantum science and artificial intelligence. However, the lack of unified software interface across tensor-computing frameworks severely limits the portability of TN applications, coupling algorithmic development to specific hardware and software back ends. To address this challenge, we introduce the Tensor Computing Interface (TCI) -- an application-oriented, lightweight application programming interface designed to enable framework-independent, high-performance TN applications. TCI provides a well-defined type system that abstracts tensor objects together with a minimal yet expressive set of core functions covering essential tensor manipulations and tensor linear-algebra operations. Through numerical demonstrations on representative tensor-network applications, we show that codes written against TCI can be migrated seamlessly across heterogeneous hardware and software platforms while achieving performance comparable to native framework implementations. We further release an open-source implementation of TCI based on \\textit{Cytnx}, demonstrating its practicality and ease of integration with existing tensor-computing frameworks."}
{"id": "2512.23772", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.23772", "abs": "https://arxiv.org/abs/2512.23772", "authors": ["Amélie Artis", "Achmad Choiruddin", "Jean-François Coeurjolly", "Frédérique Letué"], "title": "Marked point processes intensity estimation using sparse group Lasso method applied to locations of lucrative and cooperative banks in mainland France", "comment": null, "summary": "In this paper, we model the locations of five major banks in mainland France, two lucrative and three cooperative institutions based on socio-economic considerations. Locations of banks are collected using web scrapping and constitute a bivariate spatial point process for which we estimate nonparametrically summary functions (intensity, Ripley and cross-Ripley's K functions). This shows that the pattern is highly inhomogenenous and exhibits a clustering effect especially at small scales, and thus a significant departure to the bivariate (inhomogeneous) Poisson point process is pointed out. We also collect socio-economic datasets (at the living area level) from INSEE and propose a parametric modelling of the intensity function using these covariates. We propose a group-penalized bivariate composite likelihood method to estimate the model parameters, and we establish its asymptotic properties. The application of the methodology to the banking dataset provides new insights into the specificity of the cooperative model within the sector, particularly in relation to the theories of institutional isomorphism."}
{"id": "2512.24758", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.24758", "abs": "https://arxiv.org/abs/2512.24758", "authors": ["Mohit Kumar", "Sayan Ghosh", "Gourab Roy", "Ekta Kushwaha", "Vincent Caignaert", "Wilfrid Prellier", "Subham Majumdar", "Vincent Hardy", "Tathamay Basu"], "title": "Intriguing Magnetocaloric Effect in 6H-perovskite Ba3RRu2O9 (R=Ho, Gd, Tb, Nd) with Strong 4d-4f Correlations", "comment": null, "summary": "Here we demonstrate the magnetocaloric effect (MCE) of a 4d-4f correlated system, namely Ba3RRu2O9 (R= Ho, Gd, Tb, Nd). The compound Ba3HoRu2O9 antiferromagnetically orders at 50 K where both the Ho and Ru-moments order, followed by another phase transition ~ 10 K. Whereas, the compound Ba3GdRu2O9 and Ba3TbRu2O9 orders at 14.5 and 10.5 K respectively, where the ordering of both R and Ru moments are speculated. Our results reveal robust MCE around low-T magnetic phase transition for all the heavy rare-earth members (Ho, Gd, Tb) in this family. The heavy rare-earth members exhibit an intriguing MCE behavior switching from conventional to non-conventional MCE. Interestingly, the light R-member, Ba3NdRu2O9, orders ferromagnetically below 24 K where Nd-moments order, followed by Ru-ordering below 18 K, exhibits a positive MCE below and above FM-ordering. The compelling MCE are attributed to temperature dependent complex spin-reorientations for different R-members and anisotropy."}
{"id": "2512.24623", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24623", "abs": "https://arxiv.org/abs/2512.24623", "authors": ["Naoki Ito"], "title": "A Study on the Algorithm and Implementation of SDPT3", "comment": "34 pages", "summary": "This technical report presents a comprehensive study of SDPT3, a widely used open-source MATLAB solver for semidefinite-quadratic-linear programming, which is based on the interior-point method. It includes a self-contained and consistent description of the algorithm, with mathematical notation carefully aligned with the implementation. The aim is to offer a clear and structured reference for researchers and developers seeking to understand or build upon the implementation of SDPT3."}
{"id": "2512.24418", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.24418", "abs": "https://arxiv.org/abs/2512.24418", "authors": ["Yevgeny Bar Lev", "Jad C. Halimeh", "Achilleas Lazarides"], "title": "Dissipation-Stabilized Quantum Revivals in a Non-Hermitian Lattice Gauge Theory", "comment": "$9$ pages, $4$ figures", "summary": "With the advent of quantum simulation experiments of lattice gauge theories (LGTs), an open question is the effect of non-Hermiticity on their rich physics. The well-known PXP model, a U$(1)$ LGT with a two-level electric field in one spatial dimension, has become a paradigm of exotic physics in and out of equilibrium. Here, we introduce a non-Hermitian version in which the spin-flip rate differs between the two spin directions. While the naive expectation is that non-Hermiticity might suppress coherent phenomena such as quantum many-body scars, we find that when the facilitating direction of the spin is disfavored, the oscillations are instead \\emph{enhanced}, decaying much slower than in the PXP limit. We demonstrate that this can be understood through a similarity transformation that maps our model to the standard PXP model, revealing that the oscillations are enhanced versions of the PXP scars. Our work provides an analytically tractable and conceptually simple example where non-Hermiticity enhances the stability of dynamically non-trivial coherent many-body modes."}
{"id": "2512.24714", "categories": ["math.NA", "math.PR", "q-fin.CP"], "pdf": "https://arxiv.org/pdf/2512.24714", "abs": "https://arxiv.org/abs/2512.24714", "authors": ["Xiang Gao", "Cody Hyndman"], "title": "Boundary error control for numerical solution of BSDEs by the convolution-FFT method", "comment": "15 pages, 3 figures, 1 table", "summary": "We first review the convolution fast-Fourier-transform (CFFT) approach for the numerical solution of backward stochastic differential equations (BSDEs) introduced in (Hyndman and Oyono Ngou, 2017). We then propose a method for improving the boundary errors obtained when valuing options using this approach. We modify the damping and shifting schemes used in the original formulation, which transforms the target function into a bounded periodic function so that Fourier transforms can be applied successfully. Time-dependent shifting reduces boundary error significantly. We present numerical results for our implementation and provide a detailed error analysis showing the improved accuracy and convergence of the modified convolution method."}
{"id": "2512.24542", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24542", "abs": "https://arxiv.org/abs/2512.24542", "authors": ["Bo Li", "Zijun Chen", "Haiwang Zhong", "Di Cao", "Guangchun Ruan"], "title": "A Graph Neural Network with Auxiliary Task Learning for Missing PMU Data Reconstruction", "comment": null, "summary": "In wide-area measurement systems (WAMS), phasor measurement unit (PMU) measurement is prone to data missingness due to hardware failures, communication delays, and cyber-attacks. Existing data-driven methods are limited by inadaptability to concept drift in power systems, poor robustness under high missing rates, and reliance on the unrealistic assumption of full system observability. Thus, this paper proposes an auxiliary task learning (ATL) method for reconstructing missing PMU data. First, a K-hop graph neural network (GNN) is proposed to enable direct learning on the subgraph consisting of PMU nodes, overcoming the limitation of the incompletely observable system. Then, an auxiliary learning framework consisting of two complementary graph networks is designed for accurate reconstruction: a spatial-temporal GNN extracts spatial-temporal dependencies from PMU data to reconstruct missing values, and another auxiliary GNN utilizes the low-rank property of PMU data to achieve unsupervised online learning. In this way, the low-rank properties of the PMU data are dynamically leveraged across the architecture to ensure robustness and self-adaptation. Numerical results demonstrate the superior offline and online performance of the proposed method under high missing rates and incomplete observability."}
{"id": "2512.24542", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24542", "abs": "https://arxiv.org/abs/2512.24542", "authors": ["Bo Li", "Zijun Chen", "Haiwang Zhong", "Di Cao", "Guangchun Ruan"], "title": "A Graph Neural Network with Auxiliary Task Learning for Missing PMU Data Reconstruction", "comment": null, "summary": "In wide-area measurement systems (WAMS), phasor measurement unit (PMU) measurement is prone to data missingness due to hardware failures, communication delays, and cyber-attacks. Existing data-driven methods are limited by inadaptability to concept drift in power systems, poor robustness under high missing rates, and reliance on the unrealistic assumption of full system observability. Thus, this paper proposes an auxiliary task learning (ATL) method for reconstructing missing PMU data. First, a K-hop graph neural network (GNN) is proposed to enable direct learning on the subgraph consisting of PMU nodes, overcoming the limitation of the incompletely observable system. Then, an auxiliary learning framework consisting of two complementary graph networks is designed for accurate reconstruction: a spatial-temporal GNN extracts spatial-temporal dependencies from PMU data to reconstruct missing values, and another auxiliary GNN utilizes the low-rank property of PMU data to achieve unsupervised online learning. In this way, the low-rank properties of the PMU data are dynamically leveraged across the architecture to ensure robustness and self-adaptation. Numerical results demonstrate the superior offline and online performance of the proposed method under high missing rates and incomplete observability."}
{"id": "2512.24414", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.24414", "abs": "https://arxiv.org/abs/2512.24414", "authors": ["Ramsés H. Mena", "Christos Merkatas", "Theodoros Nicoleris", "Carlos E. Rodríguez"], "title": "Exact finite mixture representations for species sampling processes", "comment": "27 pages, 4 figures", "summary": "Random probability measures, together with their constructions, representations, and associated algorithms, play a central role in modern Bayesian inference. A key class is that of proper species sampling processes, which offer a relatively simple yet versatile framework that extends naturally to non-exchangeable settings. We revisit this class from a computational perspective and show that they admit exact finite mixture representations. In particular, we prove that any proper species sampling process can be written, at the prior level, as a finite mixture with a latent truncation variable and reweighted atoms, while preserving its distributional features exactly. These finite formulations can be used as drop-in replacements in Bayesian mixture models, recasting posterior computation in terms of familiar finite-mixture machinery. This yields straightforward MCMC implementations and tractable expressions, while avoiding ad hoc truncations and model-specific constructions. The resulting representation preserves the full generality of the original infinite-dimensional priors while enabling practical gains in algorithm design and implementation."}
{"id": "2512.23923", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.23923", "abs": "https://arxiv.org/abs/2512.23923", "authors": ["Eren Volkan Küçük"], "title": "Geometric View of One-Dimensional Quantum Mechanics", "comment": null, "summary": "We apply De Haro's Geometric View of Theories to one of the simplest quantum systems: a spinless particle on a line and on a circle. The classical phase space M = T*Q is taken as the base of a trivial Hilbert bundle E ~ M x H, and the familiar position and momentum representations are realised as different global trivialisations of this bundle. The Fourier transform appears as a fibrewise unitary transition function, so that the standard position-momentum duality is made precise as a change of coordinates on a single geometric object. For the circle, we also discuss twisted boundary conditions and show how a twist parameter can be incorporated either as a fixed boundary condition or as a base coordinate, in which case it gives rise to a flat U(H)-connection with nontrivial holonomy. These examples provide a concrete illustration of how the Geometric View organises quantum-mechanical representations and dualities in geometric terms."}
{"id": "2512.23993", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.23993", "abs": "https://arxiv.org/abs/2512.23993", "authors": ["Landon Hurley"], "title": "Completing and studentising Spearman's correlation in the presence of ties", "comment": null, "summary": "Non-parametric correlation coefficients have been widely used for analysing arbitrary random variables upon common populations, when requiring an explicit error distribution to be known is an unacceptable assumption. We examine an \\(\\ell_{2}\\) representation of a correlation coefficient (Emond and Mason, 2002) from the perspective of a statistical estimator upon random variables, and verify a number of interesting and highly desirable mathematical properties, mathematically similar to the Whitney embedding of a Hilbert space into the \\(\\ell_{2}\\)-norm space. In particular, we show here that, in comparison to the traditional Spearman (1904) \\(ρ\\), the proposed Kemeny \\(ρ_κ\\) correlation coefficient satisfies Gauss-Markov conditions in the presence or absence of ties, thereby allowing both discrete and continuous marginal random variables. We also prove under standard regularity conditions a number of desirable scenarios, including the construction of a null hypothesis distribution which is Student-t distributed, parallel to standard practice with Pearson's r, but without requiring either continuous random variables nor particular Gaussian errors. Simulations in particular focus upon highly kurtotic data, with highly nominal empirical coverage consistent with theoretical expectation."}
{"id": "2512.24778", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24778", "abs": "https://arxiv.org/abs/2512.24778", "authors": ["Gourab Roy", "Ekta Kushwaha", "Mohit Kumar", "Sayan Ghosh", "Fabio Orlandi", "Duc Le", "Matthew B. Stone", "Jhuma Sannigrahi", "Devashibhai T. Adroja", "Tathamay Basu"], "title": "Quasiparticle Dynamics in the 4d-4f Ising-like Double Perovskite Ba2DyRuO6 Probed by Neutron Scattering and Machine-Learning Framework", "comment": null, "summary": "Double perovskites containing 4d--4f interactions provide a platform to study complex magnetic phenomena in correlated systems. Here, we investigate the magnetic ground state and quasiparticle excitations of the fascinating double perovskite system, Ba$_2$DyRuO$_6$, through Time of flight (TOF) neutron diffraction (TOF), inelastic neutron scattering (INS), and theoretical modelling. The compound Ba$_2$DyRuO$_6$ is reported to exhibit a single magnetic transition, in sharp contrast to most of the other rare-earth (R) members in this family, A$_2$RRuO$_6$ (A = Ca/Sr/Ba), which typically show magnetic ordering of the Ru ions, followed by R-ion ordering. Our neutron diffraction results confirm that long-range antiferromagnetic order emerges at $T_\\mathrm{N} \\approx 47$~K, primarily driven by 4d--4f Ru$^{5+}$--Dy$^{3+}$ exchange interactions, where both Dy and Ru moments start to order simultaneously. The ordered ground state is a collinear antiferromagnet with Ising character, carrying ordered moments of $μ_{\\mathrm{Ru}} = 1.6(1)~μ_\\mathrm{B}$ and $μ_{\\mathrm{Dy}} = 5.1(1)~μ_\\mathrm{B}$ at 1.5~K. Low-temperature INS reveals well-defined magnon excitations below 10~meV. SpinW modelling of the INS spectra evidences complex exchange interactions and the presence of magnetic anisotropy, which governs the Ising ground state and accounts for the observed magnon spectrum. Combined INS and Raman spectroscopy reveal crystal-electric-field (CEF) excitations of Dy$^{3+}$ at 46.5 and 71.8~meV in the paramagnetic region. The observed CEF levels are reproduced by point-charge calculations consistent with the $O_h$ symmetry of Dy$^{3+}$. A complementary machine-learning approach is used to analyse the phonon spectrum and compare with INS data. Together, these results clarify the origin of phonon and magnon excitations and their role in the ground-state magnetism of Ba$_2$DyRuO$_6$."}
{"id": "2512.24640", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24640", "abs": "https://arxiv.org/abs/2512.24640", "authors": ["Xiaochi Wu"], "title": "A Differential Game with Symmetric Incomplete Information on Probabilistic Initial Condition and with Signal Revelation", "comment": null, "summary": "In this paper, we investigate the existence and characterization of the value for a two-player zero-sum differential game with symmetric incomplete information on a continuum of initial positions and with signal revelation. Before the game starts, the initial position is chosen randomly according to a probability measure with compact support, and neither player is informed of the chosen initial position. However, they observe a public signal revealing the current state as soon as the trajectory of the dynamics hits a target set. We prove that, under a suitable notion of signal-dependent strategies, the value of the game exists, and the extended value function of the game is the unique viscosity solution of an associated Hamilton-Jacobi-Isaacs equation that satisfies a boundary condition."}
{"id": "2512.24495", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24495", "abs": "https://arxiv.org/abs/2512.24495", "authors": ["Foster Thompson", "Daniel K. J. Boneß", "Mark Dykman", "Alex Kamenev"], "title": "Spectroscopy of Quantum Phase Slips: Visualizing Complex Real-Time Instantons", "comment": null, "summary": "Parametrically driven oscillators can emerge as a basis for the next generation of qubits. Classically, these systems exhibit two stable oscillatory states with opposite phases. Upon quantization, these states turn into a pair of closely spaced Floquet states, which can serve as the logical basis for a qubit. However, interaction with the environment induces phase-slip events which set a limit on qubit coherence. Such phase slips persist even at zero temperature due to a mechanism known as quantum activation \\cite{QuantumActivation}. In contrast to conventional tunneling, the quantum activation is described by a {\\em real-time} instanton trajectory in the complexified phase space of the system. In this work, we show that the phase-slip rate is exponentially sensitive to weak AC perturbations. The spectrum of the system's response -- captured by the so-called logarithmic susceptibility (LS) -- enables a direct observation of characteristic features of real-time instantons. Studying this spectrum suggests new means of efficient qubit control."}
{"id": "2512.24875", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24875", "abs": "https://arxiv.org/abs/2512.24875", "authors": ["Weizhu Bao", "Yifei Li", "Wenjun Ying", "Yulin Zhang"], "title": "A structure-preserving parametric approximation for anisotropic geometric flows via an $α$-surface energy matrix", "comment": null, "summary": "We propose a structure-preserving parametric approximation for geometric flows with general anisotropic effects. By introducing a hyperparameter $α$, we construct a unified surface energy matrix $\\hat{\\boldsymbol{G}}_k^α(θ)$ that encompasses all existing formulations of surface energy matrices, and apply it to anisotropic curvature flow. We prove that $α=-1$ is the unique choice achieving optimal energy stability under the necessary and sufficient condition $3\\hatγ(θ)\\geq\\hatγ(θ-π)$, while all other $α\\neq-1$ require strictly stronger conditions. The framework extends naturally to general anisotropic geometric flows through a unified velocity discretization that ensures energy stability. Numerical experiments validate the theoretical optimality of $α=-1$ and demonstrate the effectiveness and robustness."}
{"id": "2512.24619", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24619", "abs": "https://arxiv.org/abs/2512.24619", "authors": ["Yunian Pan", "Jun Li", "Lifan Xu", "Shunqiao Sun", "Quanyan Zhu"], "title": "Decentralized No-Regret Frequency-Time Scheduling for FMCW Radar Interference Avoidance", "comment": null, "summary": "Automotive FMCW radars are indispensable to modern ADAS and autonomous-driving systems, but their increasing density has intensified the risk of mutual interference. Existing mitigation techniques, including reactive receiver-side suppression, proactive waveform design, and cooperative scheduling, often face limitations in scalability, reliance on side-channel communication, or degradation of range-Doppler resolution. Building on our earlier work on decentralized Frequency-Domain No-Regret hopping, this paper introduces a unified time-frequency game-theoretic framework that enables radars to adapt across both spectral and temporal resources. We formulate the interference-avoidance problem as a repeated anti-coordination game, in which each radar autonomously updates a mixed strategy over frequency subbands and chirp-level time offsets using regret-minimization dynamics. We show that the proposed Time-Frequency No-Regret Hopping algorithm achieves vanishing external and swap regret, and that the induced empirical play converges to an $\\varepsilon$-coarse correlated equilibrium or a correlated equilibrium. Theoretical analysis provides regret bounds in the joint domain, revealing how temporal adaptation implicitly regularizes frequency selection and enhances robustness against asynchronous interference. Numerical experiments with multi-radar scenarios demonstrate substantial improvements in SINR, collision rate, and range-Doppler quality compared with time-frequency random hopping and centralized Nash-based benchmarks."}
{"id": "2512.24619", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24619", "abs": "https://arxiv.org/abs/2512.24619", "authors": ["Yunian Pan", "Jun Li", "Lifan Xu", "Shunqiao Sun", "Quanyan Zhu"], "title": "Decentralized No-Regret Frequency-Time Scheduling for FMCW Radar Interference Avoidance", "comment": null, "summary": "Automotive FMCW radars are indispensable to modern ADAS and autonomous-driving systems, but their increasing density has intensified the risk of mutual interference. Existing mitigation techniques, including reactive receiver-side suppression, proactive waveform design, and cooperative scheduling, often face limitations in scalability, reliance on side-channel communication, or degradation of range-Doppler resolution. Building on our earlier work on decentralized Frequency-Domain No-Regret hopping, this paper introduces a unified time-frequency game-theoretic framework that enables radars to adapt across both spectral and temporal resources. We formulate the interference-avoidance problem as a repeated anti-coordination game, in which each radar autonomously updates a mixed strategy over frequency subbands and chirp-level time offsets using regret-minimization dynamics. We show that the proposed Time-Frequency No-Regret Hopping algorithm achieves vanishing external and swap regret, and that the induced empirical play converges to an $\\varepsilon$-coarse correlated equilibrium or a correlated equilibrium. Theoretical analysis provides regret bounds in the joint domain, revealing how temporal adaptation implicitly regularizes frequency selection and enhances robustness against asynchronous interference. Numerical experiments with multi-radar scenarios demonstrate substantial improvements in SINR, collision rate, and range-Doppler quality compared with time-frequency random hopping and centralized Nash-based benchmarks."}
{"id": "2512.24442", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24442", "abs": "https://arxiv.org/abs/2512.24442", "authors": ["Lindsey E. Turner", "Carolyn T. Bramante", "Thomas A. Murray"], "title": "Model-Assisted Bayesian Estimators of Transparent Population Level Summary Measures for Ordinal Outcomes in Randomized Controlled Trials", "comment": "28 pages, 7 figures", "summary": "In randomized controlled trials, ordinal outcomes typically improve statistical efficiency over binary outcomes. The treatment effect on an ordinal outcome is usually described by the odds ratio from a proportional odds model, but this summary measure lacks transparency with respect to its emphasis on the components of the ordinal outcome when proportional odds is violated. We propose various summary measures for ordinal outcomes that are fully transparent in this regard, including 'weighted geometric mean' odds ratios and relative risks, and 'weighted mean' risk differences. We also develop and evaluate efficient model-assisted Bayesian estimators for these population level summary measures based on non-proportional odds models that facilitate covariate adjustment with marginalization via the Bayesian bootstrap. We propose a weighting scheme that engenders appealing invariance properties, including to whether the ordinal outcome is ordered from best to worst versus worst to best. Using computer simulation, we show that comparative testing based on the proposed population level summary measures performs well relative to the conventional proportional odds approach. We also report an analysis of the COVID-OUT trial, which exhibits evidence of non-proportional odds."}
{"id": "2512.23991", "categories": ["quant-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2512.23991", "abs": "https://arxiv.org/abs/2512.23991", "authors": ["Wael Itani", "Katepalli R. Sreenivasan"], "title": "Towards Quantum Machine Learning of Lattice Boltzmann Collision Operators for Fluid Dynamic Simulations", "comment": null, "summary": "We attempt the use of a unitary operator to approximate the lattice Boltzmann collision operator. We use a modified amplitude encoding to bypass the renormalization that would have required classical processing at every step (thus eroding any quantum advantage to be had). We describe the hard-wiring of the lattice Boltzmann symmetries into the quantum circuit and show that, for the specific case of the cavity flow, approximating the nonlinear system is limited to low velocities. These findings may help us understand better the possibilities of nonlinear simulations on a quantum computer, and also pave the way for a discussion on how quantum machine learning might be harnessed to address more complex problems."}
{"id": "2512.24009", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.24009", "abs": "https://arxiv.org/abs/2512.24009", "authors": ["Landon Hurley"], "title": "An exact unbiased semi-parametric maximum quasi-likelihood framework which is complete in the presence of ties", "comment": null, "summary": "This paper introduces a novel quasi-likelihood extension of the generalised Kendall \\(τ_{a}\\) estimator, together with an extension of the Kemeny metric and its associated covariance and correlation forms. The central contribution is to show that the U-statistic structure of the proposed coefficient \\(τ_κ\\) naturally induces a quasi-maximum likelihood estimation (QMLE) framework, yielding consistent Wald and likelihood ratio test statistics. The development builds on the uncentred correlation inner-product (Hilbert space) formulation of Emond and Mason (2002) and resolves the associated sub-Gaussian likelihood optimisation problem under the \\(\\ell_{2}\\)-norm via an Edgeworth expansion of higher-order moments. The Kemeny covariance coefficient \\(τ_κ\\) is derived within a novel likelihood framework for pairwise comparison-continuous random variables, enabling direct inference on population-level correlation between ranked or weakly ordered datasets. Unlike existing approaches that focus on marginal or pairwise summaries, the proposed framework supports sample-observed weak orderings and accommodates ties without information loss. Drawing parallels with Thurstone's Case V latent ordering model, we derive a quasi-likelihood-based tie model with analytic standard errors, generalising classical U-statistics. The framework applies to general continuous and discrete random variables and establishes formal equivalence to Bradley-Terry and Thurstone models, yielding a uniquely identified linear representation with both analytic and likelihood-based estimators."}
{"id": "2512.25011", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25011", "abs": "https://arxiv.org/abs/2512.25011", "authors": ["Ashirbad Padhan", "Harsh Nigam"], "title": "Parity order as a fundamental driver of bosonic topology", "comment": null, "summary": "Symmetry-protected topological (SPT) phases in interacting bosonic systems have been extensively studied, yet most realizations rely on fine-tuned interactions or enlarged symmetries. Here we show that a qualitatively different mechanism--parity order coupled to bond dimerization--acts as a fundamental driver of bosonic topology. Using density matrix renormalization group simulations, we identify two distinct topological phases absent in the purely dimerized model: an SPT phase at half filling stabilized by positive parity coupling, and a topological phase at unit filling stabilized by negative coupling that can be adiabatically connected to a trivial phase without breaking any symmetry. Our results establish parity order as a new organizing principle for correlation-driven bosonic topology."}
{"id": "2512.24676", "categories": ["math.OC", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24676", "abs": "https://arxiv.org/abs/2512.24676", "authors": ["Kuangyu Ding", "Marie Maros", "Gesualdo Scutari"], "title": "A New Decomposition Paradigm for Graph-structured Nonlinear Programs via Message Passing", "comment": "55 pages, 14 figures", "summary": "We study finite-sum nonlinear programs whose decision variables interact locally according to a graph or hypergraph. We propose MP-Jacobi (Message Passing-Jacobi), a graph-compliant decentralized framework that couples min-sum message passing with Jacobi block updates. The (hyper)graph is partitioned into tree clusters. At each iteration, agents update in parallel by solving a cluster subproblem whose objective decomposes into (i) an intra-cluster term evaluated by a single min-sum sweep on the cluster tree (cost-to-go messages) and (ii) inter-cluster couplings handled via a Jacobi correction using neighbors' latest iterates. This design uses only single-hop communication and yields a convergent message-passing method on loopy graphs.\n  For strongly convex objectives we establish global linear convergence and explicit rates that quantify how curvature, coupling strength, and the chosen partition affect scalability and provide guidance for clustering. To mitigate the computation and communication cost of exact message updates, we develop graph-compliant surrogates that preserve convergence while reducing per-iteration complexity. We further extend MP-Jacobi to hypergraphs; in heavily overlapping regimes, a surrogate-based hyperedge-splitting scheme restores finite-time intra-cluster message updates and maintains convergence. Experiments validate the theory and show consistent improvements over decentralized gradient baselines."}
{"id": "2512.25011", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25011", "abs": "https://arxiv.org/abs/2512.25011", "authors": ["Ashirbad Padhan", "Harsh Nigam"], "title": "Parity order as a fundamental driver of bosonic topology", "comment": null, "summary": "Symmetry-protected topological (SPT) phases in interacting bosonic systems have been extensively studied, yet most realizations rely on fine-tuned interactions or enlarged symmetries. Here we show that a qualitatively different mechanism--parity order coupled to bond dimerization--acts as a fundamental driver of bosonic topology. Using density matrix renormalization group simulations, we identify two distinct topological phases absent in the purely dimerized model: an SPT phase at half filling stabilized by positive parity coupling, and a topological phase at unit filling stabilized by negative coupling that can be adiabatically connected to a trivial phase without breaking any symmetry. Our results establish parity order as a new organizing principle for correlation-driven bosonic topology."}
{"id": "2512.24879", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.24879", "abs": "https://arxiv.org/abs/2512.24879", "authors": ["Maria Lukacova-Medvidova", "Simon Schneider"], "title": "Random compressible Euler flows", "comment": null, "summary": "We propose a finite volume stochastic collocation method for the random Euler system. We rigorously prove the convergence of random finite volume solutions under the assumption that the discrete differential quotients remain bounded in probability. Convergence analysis combines results on the convergence of a deterministic FV method with stochastic compactness arguments due to Skorokhod and Gyöngy-Krylov."}
{"id": "2512.24658", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24658", "abs": "https://arxiv.org/abs/2512.24658", "authors": ["Donghyeon Song", "Yeongjun Jang", "Joowon Lee", "Junsoo Kim"], "title": "Taking Advantage of Rational Canonical Form for Faster Ring-LWE based Encrypted Controller with Recursive Multiplication", "comment": "8 pages, 1 figures, presented at 2025 IEEE Conference on Decision and Control", "summary": "This paper aims to provide an efficient implementation of encrypted linear dynamic controllers that perform recursive multiplications on a Ring-Learning With Errors (Ring-LWE) based cryptosystem. By adopting a system-theoretical approach, we significantly reduce both time and space complexities, particularly the number of homomorphic operations required for recursive multiplications. Rather than encrypting the entire state matrix of a given controller, the state matrix is transformed into its rational canonical form, whose sparse and circulant structure enables that encryption and computation are required only on its nontrivial columns. Furthermore, we propose a novel method to ``pack'' each of the input and the output matrices into a single polynomial, thereby reducing the number of homomorphic operations. Simulation results demonstrate that the proposed design enables a remarkably fast implementation of encrypted controllers."}
{"id": "2512.24658", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24658", "abs": "https://arxiv.org/abs/2512.24658", "authors": ["Donghyeon Song", "Yeongjun Jang", "Joowon Lee", "Junsoo Kim"], "title": "Taking Advantage of Rational Canonical Form for Faster Ring-LWE based Encrypted Controller with Recursive Multiplication", "comment": "8 pages, 1 figures, presented at 2025 IEEE Conference on Decision and Control", "summary": "This paper aims to provide an efficient implementation of encrypted linear dynamic controllers that perform recursive multiplications on a Ring-Learning With Errors (Ring-LWE) based cryptosystem. By adopting a system-theoretical approach, we significantly reduce both time and space complexities, particularly the number of homomorphic operations required for recursive multiplications. Rather than encrypting the entire state matrix of a given controller, the state matrix is transformed into its rational canonical form, whose sparse and circulant structure enables that encryption and computation are required only on its nontrivial columns. Furthermore, we propose a novel method to ``pack'' each of the input and the output matrices into a single polynomial, thereby reducing the number of homomorphic operations. Simulation results demonstrate that the proposed design enables a remarkably fast implementation of encrypted controllers."}
{"id": "2512.24450", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.24450", "abs": "https://arxiv.org/abs/2512.24450", "authors": ["The Tien Mai"], "title": "Robust reduced rank regression under heavy-tailed noise and missing data via non-convex penalization", "comment": null, "summary": "Reduced rank regression (RRR) is a fundamental tool for modeling multiple responses through low-dimensional latent structures, offering both interpretability and strong predictive performance in high-dimensional settings. Classical RRR methods, however, typically rely on squared loss and Gaussian noise assumptions, rendering them sensitive to heavy-tailed errors, outliers, and data contamination. Moreover, the presence of missing data--common in modern applications--further complicates reliable low-rank estimation. In this paper, we propose a robust reduced rank regression framework that simultaneously addresses heavy-tailed noise, outliers, and missing data. Our approach combines a robust Huber loss with nonconvex spectral regularization, specifically the minimax concave penalty (MCP) and smoothly clipped absolute deviation (SCAD). Unlike convex nuclear-norm regularization, the proposed nonconvex penalties alleviate excessive shrinkage and enable more accurate recovery of the underlying low-rank structure. The method also accommodates missing data in the response matrix without requiring imputation. We develop an efficient proximal gradient algorithm based on alternating updates and tailored spectral thresholding. Extensive simulation studies demonstrate that the proposed methods substantially outperform nuclear-norm-based and non-robust alternatives under heavy-tailed noise and contamination. An application to cancer cell line data set further illustrates the practical advantages of the proposed robust RRR framework.\n  Our method is implemented in the R package rrpackrobust available at https://github.com/tienmt/rrpackrobust."}
{"id": "2512.24019", "categories": ["quant-ph", "cs.CV"], "pdf": "https://arxiv.org/pdf/2512.24019", "abs": "https://arxiv.org/abs/2512.24019", "authors": ["Haijian Shao", "Wei Liu", "Xing Deng", "Yingtao Jiang"], "title": "One-Shot Structured Pruning of Quantum Neural Networks via $q$-Group Engineering and Quantum Geometric Metrics", "comment": "10 pages, 2 figures", "summary": "Quantum neural networks (QNNs) suffer from severe gate-level redundancy, which hinders their deployment on noisy intermediate-scale quantum (NISQ) devices. In this work, we propose q-iPrune, a one-shot structured pruning framework grounded in the algebraic structure of $q$-deformed groups and task-conditioned quantum geometry.\n  Unlike prior heuristic or gradient-based pruning methods, q-iPrune formulates redundancy directly at the gate level. Each gate is compared within an algebraically consistent subgroup using a task-conditioned $q$-overlap distance, which measures functional similarity through state overlaps on a task-relevant ensemble. A gate is removed only when its replacement by a subgroup representative provably induces a bounded deviation on all task observables.\n  We establish three rigorous theoretical guarantees. First, we prove completeness of redundancy pruning: no gate that violates the prescribed similarity threshold is removed. Second, we show that the pruned circuit is functionally equivalent up to an explicit, task-conditioned error bound, with a closed-form dependence on the redundancy tolerance and the number of replaced gates. Third, we prove that the pruning procedure is computationally feasible, requiring only polynomial-time comparisons and avoiding exponential enumeration over the Hilbert space.\n  To adapt pruning decisions to hardware imperfections, we introduce a noise-calibrated deformation parameter $λ$ that modulates the $q$-geometry and redundancy tolerance. Experiments on standard quantum machine learning benchmarks demonstrate that q-iPrune achieves substantial gate reduction while maintaining bounded task performance degradation, consistent with our theoretical guarantees."}
{"id": "2512.24414", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2512.24414", "abs": "https://arxiv.org/abs/2512.24414", "authors": ["Ramsés H. Mena", "Christos Merkatas", "Theodoros Nicoleris", "Carlos E. Rodríguez"], "title": "Exact finite mixture representations for species sampling processes", "comment": "27 pages, 4 figures", "summary": "Random probability measures, together with their constructions, representations, and associated algorithms, play a central role in modern Bayesian inference. A key class is that of proper species sampling processes, which offer a relatively simple yet versatile framework that extends naturally to non-exchangeable settings. We revisit this class from a computational perspective and show that they admit exact finite mixture representations. In particular, we prove that any proper species sampling process can be written, at the prior level, as a finite mixture with a latent truncation variable and reweighted atoms, while preserving its distributional features exactly. These finite formulations can be used as drop-in replacements in Bayesian mixture models, recasting posterior computation in terms of familiar finite-mixture machinery. This yields straightforward MCMC implementations and tractable expressions, while avoiding ad hoc truncations and model-specific constructions. The resulting representation preserves the full generality of the original infinite-dimensional priors while enabling practical gains in algorithm design and implementation."}
{"id": "2512.25036", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.25036", "abs": "https://arxiv.org/abs/2512.25036", "authors": ["Yiming Wang", "Shouvik Sur", "Chia-Chuan Liu", "Qimiao Si"], "title": "Perturbative Kondo destruction and global phase diagram of heavy fermion metals", "comment": "6+12 pages, 5+5 figures", "summary": "Strange metals represent a foundational problem in quantum condensed matter physics, and heavy fermion systems provide a canonical setting to advance a general understanding. The concept of a Kondo destruction quantum critical point is widely invoked to describe the competition of the Kondo effect and the local-moment magnetism. Here, we develop a unified field-theoretic approach, analyzing this competition from a rare approach that is anchored by the magnetically ordered side. Our analysis reveals, for the first time within a renormalization group framework, a quantum critical point across which the Kondo effect goes from being destroyed to dominating. Our findings elucidate not only the Kondo destruction quantum criticality but also an accompanying global phase diagram of heavy fermion metals."}
{"id": "2512.24717", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24717", "abs": "https://arxiv.org/abs/2512.24717", "authors": ["Nguyen Van Tuyen", "Minh N. Dao", "Tran Van Nghi"], "title": "A proximal subgradient algorithm for constrained multiobjective DC-type optimization", "comment": null, "summary": "In this paper, we consider a class of constrained multiobjective optimization problems, where each objective function can be expressed by adding a possibly nonsmooth nonconvex function and a differentiable function with Lipschitz continuous gradient, then subtracting a weakly convex function. This encompasses multiobjective optimization problems involving difference-of-convex (DC) functions, which are prevalent in various applications due to their ability to model nonconvex problems. We first establish necessary and sufficient optimality conditions for these problems, providing a theoretical foundation for algorithm development. Building on these conditions, we propose a proximal subgradient algorithm tailored to the structure of the objectives. Under mild assumptions, the sequence generated by the proposed algorithm is bounded and each of its cluster points is a stationary solution."}
{"id": "2512.25054", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.25054", "abs": "https://arxiv.org/abs/2512.25054", "authors": ["Yin Tang", "Cristian Voinea", "Liangdong Hu", "Zlatko Papić", "W. Zhu"], "title": "Emergence of 3D Superconformal Ising Criticality on the Fuzzy Sphere", "comment": "6+8 pages, 6 figures", "summary": "Supersymmetric conformal field theories (SCFTs) form a unique subset of quantum field theories which provide powerful insights into strongly coupled critical phenomena. Here, we present a microscopic and non-perturbative realization of the three-dimensional $\\mathcal{N}=1$ superconformal Ising critical point, based on a Yukawa-type coupling between a 3D Ising CFT and a gauged Majorana fermion. Using the recently developed fuzzy sphere regularization, we directly extract the scaling dimensions of low-lying operators via the state-operator correspondence. At the critical point, we demonstrate conformal multiplet structure together with the hallmark of emergent spacetime supersymmetry through characteristic relations between fermionic and bosonic operators. Moreover, by tuning the Yukawa coupling, we explicitly track the evolution of operator spectra from the decoupled Ising-Majorana fixed point to the interacting superconformal fixed point, revealing renormalization-group flow at the operator level. Our results establish a controlled, non-perturbative microscopic route to 3D SCFTs."}
{"id": "2512.24928", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2512.24928", "abs": "https://arxiv.org/abs/2512.24928", "authors": ["Dominik Stantejsky"], "title": "A finite element approach for minimizing line and surface energies arising in the study of singularities in liquid crystals", "comment": "26 pages, 20 figures", "summary": "Motivated by a problem originating in the study of defect structures in nematic liquid crystals, we describe and study a numerical algorithm for the resolution of a Plateau-like problem. The energy contains the area of a two-dimensional surface $T$ and the length of its boundary $\\partial T$ reduced by a prescribed curve to make our problem non-trivial. We additionally include an obstacle $E$ for $T$ and pose a surface energy on $E$. We present an algorithm based on the Alternating Direction Method of Multipliers that minimizes a discretized version of the energy using finite elements, generalizing existing TV-minimization methods. We study different inclusion shapes demonstrating the rich structure of minimizing configurations and provide physical interpretation of our findings for colloidal particles in nematic liquid crystal."}
{"id": "2512.24683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24683", "abs": "https://arxiv.org/abs/2512.24683", "authors": ["Qi He", "Chunyu Qu"], "title": "Waste-to-Energy-Coupled AI Data Centers: Cooling Efficiency and Grid Resilience", "comment": null, "summary": "AI data-center expansion is increasingly constrained by the coupled availability of deliverable electricity and heat-rejection (cooling) capacity. We propose and evaluate an integrated Waste-to-Energy-AI Data Center configuration that treats cooling as a first-class energy service rather than an unavoidable electricity burden. The coupled system is modeled as an input-output 'black box' with transparent boundaries and a standalone benchmark in which mechanical chilling is powered by grid electricity. The central mechanism is energy-grade matching: low-grade WtE thermal output drives absorption cooling to deliver chilled service, thereby displacing baseline cooling electricity. We show that thermoeconomic superiority is governed by three first-order determinants, (i) cooling coverage of IT heat load, (ii) parasitic electricity for transport and auxiliaries, and (iii) distance-driven delivery decay, yielding a break-even corridor beyond which net benefits vanish. Comparative statics characterize sensitivity to IT utilization, feedstock quality (waste LHV and throughput), climate parameterization, and corridor distance. We translate these accounting gains into decision language through a computable prototype for Levelized Cost of Computing (LCOC) and an ESG valuation channel grounded in measurable mechanisms, without re-deriving full lifecycle inventories. The framework provides siting-ready feasibility conditions for WtE-AIDC coupling in urban AI corridors under grid stress."}
{"id": "2512.24683", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24683", "abs": "https://arxiv.org/abs/2512.24683", "authors": ["Qi He", "Chunyu Qu"], "title": "Waste-to-Energy-Coupled AI Data Centers: Cooling Efficiency and Grid Resilience", "comment": null, "summary": "AI data-center expansion is increasingly constrained by the coupled availability of deliverable electricity and heat-rejection (cooling) capacity. We propose and evaluate an integrated Waste-to-Energy-AI Data Center configuration that treats cooling as a first-class energy service rather than an unavoidable electricity burden. The coupled system is modeled as an input-output 'black box' with transparent boundaries and a standalone benchmark in which mechanical chilling is powered by grid electricity. The central mechanism is energy-grade matching: low-grade WtE thermal output drives absorption cooling to deliver chilled service, thereby displacing baseline cooling electricity. We show that thermoeconomic superiority is governed by three first-order determinants, (i) cooling coverage of IT heat load, (ii) parasitic electricity for transport and auxiliaries, and (iii) distance-driven delivery decay, yielding a break-even corridor beyond which net benefits vanish. Comparative statics characterize sensitivity to IT utilization, feedstock quality (waste LHV and throughput), climate parameterization, and corridor distance. We translate these accounting gains into decision language through a computable prototype for Levelized Cost of Computing (LCOC) and an ESG valuation channel grounded in measurable mechanisms, without re-deriving full lifecycle inventories. The framework provides siting-ready feasibility conditions for WtE-AIDC coupling in urban AI corridors under grid stress."}
{"id": "2512.24521", "categories": ["stat.ME", "cs.HC", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.24521", "abs": "https://arxiv.org/abs/2512.24521", "authors": ["Ron Kohavi", "Jakub Linowski", "Lukas Vermeer", "Fabrice Boisseranc", "Joachim Furuseth", "Andrew Gelman", "Guido Imbens", "Ravikiran Rajagopal"], "title": "Power Analysis is Essential: High-Powered Tests Suggest Minimal to No Effect of Rounded Shapes on Click-Through Rates", "comment": "41 pages, 9 figures", "summary": "Underpowered studies (below 50%) suffer from the winner's curse: a statistically significant result must exaggerate the true treatment effect to meet the significance threshold. A study by Dipayan Biswas, Annika Abell, and Roger Chacko published in the Journal of Consumer Research (2023) reported that in an A/B test simply rounding the corners of square buttons increased the online click-through rate by 55% (p-value 0.037)$\\unicode{x2014}$a striking finding with potentially wide-ranging implications for the digital industry that is seeking to enhance consumer engagement. Drawing on our experience with tens of thousands of A/B tests, many involving similar user interface modifications, we found this dramatic claim implausibly large. To evaluate the claim, we conducted three high-powered A/B tests, each involving over two thousand times more users than the original study. All three experiments yielded effect size estimates that were approximately two orders of magnitude smaller than initially reported, with 95% confidence intervals that include zero, that is, not statistically significant at the 0.05 level. Two additional independent replications by Evidoo found similarly small effects. These findings underscore the critical importance of power analysis and experimental design to increase trust and reproducibility of results."}
{"id": "2512.24053", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24053", "abs": "https://arxiv.org/abs/2512.24053", "authors": ["Nathan A. Harper", "Ayantika Sengupta", "Emily Y. Hwang", "Scott K. Cushing"], "title": "Entangled photon triplets using lithium niobate nanophotonics", "comment": "Main text: 11 pages, 3 figures; Supplementary Material: 11 pages, 8 figures", "summary": "Multiphoton states are needed for quantum communication and computation. Multiphoton states are significantly more difficult to generate than one- and two-photon states because two individual down-conversion processes must be cascaded. Only efficiencies of $<100$ Hz/mW have been reported to date. We integrate two down-converters on the same thin-film lithium niobate waveguide, significantly enhancing the cascaded process efficiency to $237 \\pm 36$ kHz/mW. The measured $4.4\\times10^{-5}$ probability of the second down-converter, which sets the limit on detectable triplet rates, exceeds those of previous triplet sources by an order of magnitude and demonstrates a path towards MHz rates of triplets for quantum applications."}
{"id": "2512.25025", "categories": ["stat.ME", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.25025", "abs": "https://arxiv.org/abs/2512.25025", "authors": ["Elynn Chen", "Yuefeng Han", "Jiayu Li", "Ke Xu"], "title": "Modewise Additive Factor Model for Matrix Time Series", "comment": null, "summary": "We introduce a Modewise Additive Factor Model (MAFM) for matrix-valued time series that captures row-specific and column-specific latent effects through an additive structure, offering greater flexibility than multiplicative frameworks such as Tucker and CP factor models. In MAFM, each observation decomposes into a row-factor component, a column-factor component, and noise, allowing distinct sources of variation along different modes to be modeled separately. We develop a computationally efficient two-stage estimation procedure: Modewise Inner-product Eigendecomposition (MINE) for initialization, followed by Complement-Projected Alternating Subspace Estimation (COMPAS) for iterative refinement. The key methodological innovation is that orthogonal complement projections completely eliminate cross-modal interference when estimating each loading space. We establish convergence rates for the estimated factor loading matrices under proper conditions. We further derive asymptotic distributions for the loading matrix estimators and develop consistent covariance estimators, yielding a data-driven inference framework that enables confidence interval construction and hypothesis testing. As a technical contribution of independent interest, we establish matrix Bernstein inequalities for quadratic forms of dependent matrix time series. Numerical experiments on synthetic and real data demonstrate the advantages of the proposed method over existing approaches."}
{"id": "2512.25054", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.25054", "abs": "https://arxiv.org/abs/2512.25054", "authors": ["Yin Tang", "Cristian Voinea", "Liangdong Hu", "Zlatko Papić", "W. Zhu"], "title": "Emergence of 3D Superconformal Ising Criticality on the Fuzzy Sphere", "comment": "6+8 pages, 6 figures", "summary": "Supersymmetric conformal field theories (SCFTs) form a unique subset of quantum field theories which provide powerful insights into strongly coupled critical phenomena. Here, we present a microscopic and non-perturbative realization of the three-dimensional $\\mathcal{N}=1$ superconformal Ising critical point, based on a Yukawa-type coupling between a 3D Ising CFT and a gauged Majorana fermion. Using the recently developed fuzzy sphere regularization, we directly extract the scaling dimensions of low-lying operators via the state-operator correspondence. At the critical point, we demonstrate conformal multiplet structure together with the hallmark of emergent spacetime supersymmetry through characteristic relations between fermionic and bosonic operators. Moreover, by tuning the Yukawa coupling, we explicitly track the evolution of operator spectra from the decoupled Ising-Majorana fixed point to the interacting superconformal fixed point, revealing renormalization-group flow at the operator level. Our results establish a controlled, non-perturbative microscopic route to 3D SCFTs."}
{"id": "2512.24736", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24736", "abs": "https://arxiv.org/abs/2512.24736", "authors": ["Zhaolin Hu"], "title": "Some Studies on Stochastic Optimization based Quantitative Risk Management", "comment": null, "summary": "Risk management often plays an important role in decision making under uncertainty. In quantitative risk management, assessing and optimizing risk metrics requires efficient computing techniques and reliable theoretical guarantees. In this paper, we introduce several topics on quantitative risk management and review some of the recent studies and advancements on the topics. We consider several risk metrics and study decision models that involve the metrics, with a main focus on the related computing techniques and theoretical properties. We show that stochastic optimization, as a powerful tool, can be leveraged to effectively address these problems."}
{"id": "2512.24964", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.24964", "abs": "https://arxiv.org/abs/2512.24964", "authors": ["Alessia andò", "Giusy Bosco", "Dimitri Breda", "Davide Liessi"], "title": "Approximating evolution operators of linear delay equations: a general framework for the convergence analysis", "comment": null, "summary": "We consider the problem of discretizing evolution operators of linear delay equations with the aim of approximating their spectra, which is useful in investigating the stability properties of (nonlinear) equations via the principle of linearized stability. We develop a general convergence analysis based on a reformulation of the operators by means of a fixed-point equation, providing a list of hypotheses related to the regularization properties of the equation and the convergence of the chosen approximation techniques on suitable subspaces. This framework unifies the proofs for some methods based on pseudospectral discretization, which we present here in this new form. To exemplify the generality of the framework, we also apply it to a method of weighted residuals found in the literature, which was previously lacking a formal convergence analysis."}
{"id": "2512.24700", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24700", "abs": "https://arxiv.org/abs/2512.24700", "authors": ["Evagoras Makridis", "Gabriele Oliva", "Apostolos I. Rikos", "Themistoklis Charalambous"], "title": "Average Consensus with Dynamic Quantization Framing and Finite-Time Termination over Limited-Bandwidth Directed Networks", "comment": "arXiv admin note: substantial text overlap with arXiv:2508.06893", "summary": "This paper proposes a deterministic distributed algorithm, referred to as PP-ACDC, that achieves exact average consensus over possibly unbalanced directed graphs using only a fixed and a priori specified number of quantization bits. The method integrates Push-Pull (surplus) consensus dynamics with a dynamic quantization framing scheme combining zooming and midpoint shifting, enabling agents to preserve the true global average while progressively refining their quantization precision. We establish a rigorous convergence theory showing that PP-ACDC achieves asymptotic (exact) average consensus on any strongly connected digraph under appropriately chosen quantization parameters. Moreover, we develop a fully distributed and synchronized finite-time termination mechanism, and we provide a formal proof on the detection of $ε$-convergence to the average within a finite number of iterations. Numerical simulations corroborate the theoretical results and demonstrate that PP-ACDC achieves reliable, communication-efficient, and precise average consensus even under very tight bit budgets, underscoring its suitability for large-scale and resource-constrained multi-agent systems operating over directed networks."}
{"id": "2512.24700", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24700", "abs": "https://arxiv.org/abs/2512.24700", "authors": ["Evagoras Makridis", "Gabriele Oliva", "Apostolos I. Rikos", "Themistoklis Charalambous"], "title": "Average Consensus with Dynamic Quantization Framing and Finite-Time Termination over Limited-Bandwidth Directed Networks", "comment": "arXiv admin note: substantial text overlap with arXiv:2508.06893", "summary": "This paper proposes a deterministic distributed algorithm, referred to as PP-ACDC, that achieves exact average consensus over possibly unbalanced directed graphs using only a fixed and a priori specified number of quantization bits. The method integrates Push-Pull (surplus) consensus dynamics with a dynamic quantization framing scheme combining zooming and midpoint shifting, enabling agents to preserve the true global average while progressively refining their quantization precision. We establish a rigorous convergence theory showing that PP-ACDC achieves asymptotic (exact) average consensus on any strongly connected digraph under appropriately chosen quantization parameters. Moreover, we develop a fully distributed and synchronized finite-time termination mechanism, and we provide a formal proof on the detection of $ε$-convergence to the average within a finite number of iterations. Numerical simulations corroborate the theoretical results and demonstrate that PP-ACDC achieves reliable, communication-efficient, and precise average consensus even under very tight bit budgets, underscoring its suitability for large-scale and resource-constrained multi-agent systems operating over directed networks."}
{"id": "2512.24588", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24588", "abs": "https://arxiv.org/abs/2512.24588", "authors": ["Kwangok Seo", "Johan Lim", "Hyungwon Choi", "Jaesik Jeong"], "title": "Multiple Testing of One-Sided Hypotheses with Conservative $p$-values", "comment": null, "summary": "We study a large-scale one-sided multiple testing problem in which test statistics follow normal distributions with unit variance, and the goal is to identify signals with positive mean effects. A common approach is to compute $p$-values under the assumption that all null means are exactly zero and then apply standard multiple testing procedures such as the Benjamini--Hochberg (BH) or Storey--BH method. However, because the null hypothesis is composite, some null means may be strictly negative. In this case, the resulting $p$-values are conservative, leading to a substantial loss of power. Existing methods address this issue by modifying the multiple testing procedure itself, for example through conditioning strategies or discarding rules. In contrast, we focus on correcting the $p$-values so that they are exact under the null. Specifically, we estimate the marginal null distribution of the test statistics within an empirical Bayes framework and construct refined $p$-values based on this estimated distribution. These refined $p$-values can then be directly used in standard multiple testing procedures without modification. Extensive simulation studies show that the proposed method substantially improves power when $p$-values are conservative, while achieving comparable performance to existing methods when $p$-values are exact. An application to phosphorylation data further demonstrates the practical effectiveness of our approach."}
{"id": "2512.24057", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24057", "abs": "https://arxiv.org/abs/2512.24057", "authors": ["Dong-Ping Xuan", "Zhong-Xi Shen", "Wen Zhou", "Zhi-Xi Wang", "Shao-Ming Fei"], "title": "A new entanglement measure based on the total concurrence", "comment": "19pages, 12 figures", "summary": "Quantum entanglement is a crucial resource in quantum information processing, advancing quantum technologies. The greater the uncertainty in subsystems' pure states, the stronger the quantum entanglement between them. From the dual form of $q$-concurrence ($q\\geq 2$) we introduce the total concurrence. A bona fide measure of quantum entanglement is introduced, the $\\mathcal{C}^{t}_q$-concurrence ($q \\geq 2$), which is based on the total concurrence. Analytical lower bounds for the $\\mathcal{C}^{t}_q$-concurrence are derived. In addition, an analytical expression is derived for the $\\mathcal{C}^{t}_q$-concurrence in the cases of isotropic and Werner states. Furthermore, the monogamy relations that the $\\mathcal{C}^{t}_q$-concurrence satisfies for qubit systems are examined. Additionally, based on the parameterized $α$-concurrence and its complementary dual, the $\\mathcal{C}^{t}_α$-concurrence $(0\\leqα\\leq\\frac{1}{2})$ is also proposed."}
{"id": "2512.25069", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2512.25069", "abs": "https://arxiv.org/abs/2512.25069", "authors": ["Shang-Qiang Ning", "Xing-Yu Ren", "Qing-Rui Wang", "Yang Qi", "Zheng-Cheng Gu"], "title": "Classification of Interacting Topological Crystalline Superconductors in Three Dimensions and Beyond", "comment": "38 pages, 15 figures, 6 tables, all comments and suggestions are welcome", "summary": "Although classification for free-fermion topological superconductors (TSC) is established, systematically understanding the classification of 3D interacting TSCs remains difficult, especially those protected by crystalline symmetries like the 230 space groups. We build up a general framework for systematically classifying 3D interacting TSCs protected by crystalline symmetries together with discrete internal symmetries. We first establish a complete classification for fermionic symmetry protected topological phases (FSPT) with purely discrete internal symmetries, which determines the crystalline case via the crystalline equivalence principle. Using domain wall decoration, we obtain classification data and formulas for generic FSPTs, what are suitable for systematic computation. The four layers of decoration data $(n_1, n_2, n_3, ν_4)$ characterize a 3D FSPT with symmetry $G_b\\times_{ω_2}Z_2^f$, corresponding to $p+ip$, Kitaev chain, complex fermion, and bosonic SPT layers. Inspired by previous works, a crucial aspect is the $p+ip$ layer, where classification involves two possibilities: anti-unitary and infinite-order symmetries (e.g., translation). We show the former maps to some mirror FSPT classification with the mirror plane decorated by a $p+ip$ superconductor, while the latter is determined by the free part of $H^1(G_b, Z_T)$, corresponding to weak TSCs. Another key point is the Kitaev chain decoration for the anti-unitary symmetries, which differs essentially from unitary ones. We explicitly obtain formulas for all three layers of decoration $(n_2, n_3, ν_4)$, which are amenable to automatic computation. As an application, we classify the 230 space-group topological crystalline superconductors in interacting electronic systems."}
{"id": "2512.24785", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24785", "abs": "https://arxiv.org/abs/2512.24785", "authors": ["Roberto Baldacci", "Fabio Ciccarelli", "Stefano Coniglio", "Valerio Dose", "Fabio Furini"], "title": "A first approximation algorithm for the Bin Packing Problem with Setups", "comment": null, "summary": "We study constant-factor approximation algorithms for the Bin Packing Problem with Setups (BPPS). First, we show that adaptations of classical BPP heuristics can have arbitrarily poor worst-case performance on BPPS instances. Then, we propose a two-phase heuristic for the BPPS that applies an α-approximation algorithm for the BPP to the items of each class and then performs a merging phase on the open bins. We prove that this heuristic is a 2 α-approximation algorithm for the BPPS."}
{"id": "2512.25012", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2512.25012", "abs": "https://arxiv.org/abs/2512.25012", "authors": ["Nilima Nigam"], "title": "At the intersection of Numerical Analysis and Spectral Geometry", "comment": "20 pages, 5 figures, for Proceedings of the ICM, 2026", "summary": "How do the geometric properties of a domain impact the spectrum of an operator defined on it? How do we compute accurate and reliable approximations of these spectra? The former question is studied in spectral geometry, and the latter is a central concern in numerical analysis. In this short expository survey we revisit the process of eigenvalue approximation, from the perspective of computational spectral geometry. Over the years a multitude of methods -- for discretizing the operator and for the resultant discrete system -- have been developed and analyzed in the field of numerical analysis. High-accuracy and provably convergent discretization approaches can be used to examine the interplay between the spectrum of an operator and the geometric properties of the spatial domain or manifold it is defined on. While computations have been used to guide conjectures in spectral geometry, in recent years approximation-theoretic tools and validated computations are also being used as part of proof strategies in spectral geometry.\n  Given a particular spectral feature of interest, should we discretize the original problem, or seek a reformulation? Of the many possible approximation strategies, which should we choose? These choices are inextricably linked to the objective: on the one hand, rapid, specialized methods are often ideal for conjecture formulation (prioritizing efficiency and accuracy), whereas schemes with guaranteed, computable error bounds are needed when computation is incorporated into a proof strategy. We also review instances where the demanding requirements of spectral geometry -- the need for rigorous error control or the robust calculation of higher eigenvalues -- motivate new developments in numerical analysis."}
{"id": "2512.24735", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24735", "abs": "https://arxiv.org/abs/2512.24735", "authors": ["Qin Fang", "Mamadou Diagne", "Yang Zhu"], "title": "Exact compensation of communication delays for discrete-time heterogeneous multi-agent linear systems with applications to SIR epidemic model", "comment": null, "summary": "This paper investigates the output synchronization problem for discrete-time heterogeneous multi-agent systems (MASs) subject to distinct communication delays. The presence of such delays prevents the instantaneous delivery of information from neighboring nodes, thereby severely degrading the performance of standard distributed control schemes. To overcome this, we propose a prediction-based framework for exact delay compensation. Specifically, we introduce predictors combined with a mechanism of distributed predictors, which enables the recursive reconstruction of future state information across the communication network. Building upon these predictors, we construct prediction-based distributed observers and formulate both prediction-based distributed state-feedback and dynamic output-feedback controllers. Theoretical analysis confirms that the proposed strategy eliminates the impact of delays after a finite number of steps, ensuring output synchronization. The effectiveness of the methods is validated through a numerical example and a Koopman operator-based linear Susceptible-Infected-Recovered (SIR) epidemic model. Notably, for a population of 4 million, the proposed delay compensation strategy achieves a reduction of over 200,000 infected individuals at the peak, underscoring its potential significance in epidemic mitigation."}
{"id": "2512.24735", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24735", "abs": "https://arxiv.org/abs/2512.24735", "authors": ["Qin Fang", "Mamadou Diagne", "Yang Zhu"], "title": "Exact compensation of communication delays for discrete-time heterogeneous multi-agent linear systems with applications to SIR epidemic model", "comment": null, "summary": "This paper investigates the output synchronization problem for discrete-time heterogeneous multi-agent systems (MASs) subject to distinct communication delays. The presence of such delays prevents the instantaneous delivery of information from neighboring nodes, thereby severely degrading the performance of standard distributed control schemes. To overcome this, we propose a prediction-based framework for exact delay compensation. Specifically, we introduce predictors combined with a mechanism of distributed predictors, which enables the recursive reconstruction of future state information across the communication network. Building upon these predictors, we construct prediction-based distributed observers and formulate both prediction-based distributed state-feedback and dynamic output-feedback controllers. Theoretical analysis confirms that the proposed strategy eliminates the impact of delays after a finite number of steps, ensuring output synchronization. The effectiveness of the methods is validated through a numerical example and a Koopman operator-based linear Susceptible-Infected-Recovered (SIR) epidemic model. Notably, for a population of 4 million, the proposed delay compensation strategy achieves a reduction of over 200,000 infected individuals at the peak, underscoring its potential significance in epidemic mitigation."}
{"id": "2512.24611", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.24611", "abs": "https://arxiv.org/abs/2512.24611", "authors": ["Kwangok Seo", "Johan Lim", "Kaiwen Wang", "Dohwan Park", "Shota Katayama", "Xinlei Wang"], "title": "Empirical Bayes Method for Large Scale Multiple Testing with Heteroscedastic Errors", "comment": null, "summary": "In this paper, we address the normal mean inference problem, which involves testing multiple means of normal random variables with heteroscedastic variances. Most existing empirical Bayes methods for this setting are developed under restrictive assumptions, such as the scaled inverse-chi-squared prior for variances and unimodality for the non-null mean distribution. However, when either of these assumptions is violated, these methods often fail to control the false discovery rate (FDR) at the target level or suffer from a substantial loss of power. To overcome these limitations, we propose a new empirical Bayes method, gg-Mix, which assumes only independence between the normal means and variances, without imposing any structural restrictions on their distributions. We thoroughly evaluate the FDR control and power of gg-Mix through extensive numerical studies and demonstrate its superior performance compared to existing methods. Finally, we apply gg-Mix to three real data examples to further illustrate the practical advantages of our approach."}
{"id": "2512.24070", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24070", "abs": "https://arxiv.org/abs/2512.24070", "authors": ["Dong-Ping Xuan", "Zhi-Xi Wang", "Shao-Ming Fei"], "title": "Quantum Speed Limits Based on the Sharma-Mittal Entropy", "comment": "17 pages, 23 figures", "summary": "Quantum speed limits (QSLs) establish intrinsic bounds on the minimum time required for the evolution of quantum systems. We present a class of QSLs formulated in terms of the two-parameter Sharma-Mittal entropy (SME), applicable to finite-dimensional systems evolving under general nonunitary dynamics. In the single-qubit case, the QSLs for both quantum channels and non-Hermitian dynamics are analyzed in detail. For many-body systems, we explore the role of SME-based bounds in characterizing the reduced dynamics and apply the results to the XXZ spin chain model. These entropy-based QSLs characterize fundamental limits on quantum evolution speeds and may be employed in contexts including entropic uncertainty relations, quantum metrology, coherent control and quantum sensing."}
{"id": "2512.23917", "categories": ["quant-ph", "cond-mat.str-el", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23917", "abs": "https://arxiv.org/abs/2512.23917", "authors": ["Rong-Yang Sun", "Tomonori Shirakawa", "Hidehiko Kohshiro", "D. N. Sheng", "Seiji Yunoki"], "title": "Tensor Computing Interface: An Application-Oriented, Lightweight Interface for Portable High-Performance Tensor Network Applications", "comment": "34 pages, 10 figures", "summary": "Tensor networks (TNs) are a central computational tool in quantum science and artificial intelligence. However, the lack of unified software interface across tensor-computing frameworks severely limits the portability of TN applications, coupling algorithmic development to specific hardware and software back ends. To address this challenge, we introduce the Tensor Computing Interface (TCI) -- an application-oriented, lightweight application programming interface designed to enable framework-independent, high-performance TN applications. TCI provides a well-defined type system that abstracts tensor objects together with a minimal yet expressive set of core functions covering essential tensor manipulations and tensor linear-algebra operations. Through numerical demonstrations on representative tensor-network applications, we show that codes written against TCI can be migrated seamlessly across heterogeneous hardware and software platforms while achieving performance comparable to native framework implementations. We further release an open-source implementation of TCI based on \\textit{Cytnx}, demonstrating its practicality and ease of integration with existing tensor-computing frameworks."}
{"id": "2512.24872", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24872", "abs": "https://arxiv.org/abs/2512.24872", "authors": ["Haibin Chen", "Yixuan Chen", "Chunyan Wang", "Qi Fan"], "title": "Tensor Based Proximal Alternating Minimization Method for A Kind of Inhomogeneous Quartic Optimization Problem", "comment": null, "summary": "In this paper, we propose an efficient numerical approach for solving a specific type of quartic inhomogeneous polynomial optimization problem inspired by practical applications. The primary contribution of this work lies in establishing an inherent equivalence between the quartic inhomogeneous polynomial optimization problem and a multilinear optimization problem (MOP). This result extends the equivalence between fourth-order homogeneous polynomial optimization and multilinear optimization in the existing literature to the equivalence between fourth-order inhomogeneous polynomial optimization and multilinear optimization. By leveraging the multi-block structure embedded within the MOP, a tensor-based proximal alternating minimization algorithm is proposed to approximate the optimal value of the quartic problem. Under mild assumptions, the convergence of the algorithm is rigorously proven. Finally, the effectiveness of the proposed algorithm is demonstrated through preliminary computational results obtained using synthetic datasets."}
{"id": "2512.25017", "categories": ["math.NA", "cs.LG", "q-fin.CP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.25017", "abs": "https://arxiv.org/abs/2512.25017", "authors": ["Chenguang Liu", "Antonis Papapantoleon", "Jasper Rou"], "title": "Convergence of the generalization error for deep gradient flow methods for PDEs", "comment": "28 pages", "summary": "The aim of this article is to provide a firm mathematical foundation for the application of deep gradient flow methods (DGFMs) for the solution of (high-dimensional) partial differential equations (PDEs). We decompose the generalization error of DGFMs into an approximation and a training error. We first show that the solution of PDEs that satisfy reasonable and verifiable assumptions can be approximated by neural networks, thus the approximation error tends to zero as the number of neurons tends to infinity. Then, we derive the gradient flow that the training process follows in the ``wide network limit'' and analyze the limit of this flow as the training time tends to infinity. These results combined show that the generalization error of DGFMs tends to zero as the number of neurons and the training time tend to infinity."}
{"id": "2512.24755", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24755", "abs": "https://arxiv.org/abs/2512.24755", "authors": ["Sungwoo Kang"], "title": "Trustworthy Equipment Monitoring via Cascaded Anomaly Detection and Thermal Localization", "comment": null, "summary": "Predictive maintenance demands accurate anomaly detection and trustable explanations. Although multimodal fusion of sensor time-series and thermal imagery shows promise, we demonstrate that naive fusion strategies can paradoxically degrade performance. This paper introduces a Cascaded Anomaly Detection framework that decouples detection and localization. Stage 1 employs an LSTM-based sensor encoder with temporal attention for high-accuracy detection, while Stage 2 activates a CNN-based thermal encoder for post-detection fault localization. Our results reveal that sensor-only detection outperforms full fusion by 8.3 percentage points (93.08% vs. 84.79% F1-score), challenging the assumption that additional modalities invariably improve performance. We further contribute an explainability pipeline integrating SHAP, temporal/spatial attention, and gate weight analysis. This analysis uncovers a \"modality bias\" where fusion models assign 65-87% weight to the weaker thermal modality. Validated on a real-world bearing dataset (78,397 samples), our cascaded approach achieves state-of-the-art accuracy while providing actionable diagnostics for maintenance decision-making."}
{"id": "2512.24755", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24755", "abs": "https://arxiv.org/abs/2512.24755", "authors": ["Sungwoo Kang"], "title": "Trustworthy Equipment Monitoring via Cascaded Anomaly Detection and Thermal Localization", "comment": null, "summary": "Predictive maintenance demands accurate anomaly detection and trustable explanations. Although multimodal fusion of sensor time-series and thermal imagery shows promise, we demonstrate that naive fusion strategies can paradoxically degrade performance. This paper introduces a Cascaded Anomaly Detection framework that decouples detection and localization. Stage 1 employs an LSTM-based sensor encoder with temporal attention for high-accuracy detection, while Stage 2 activates a CNN-based thermal encoder for post-detection fault localization. Our results reveal that sensor-only detection outperforms full fusion by 8.3 percentage points (93.08% vs. 84.79% F1-score), challenging the assumption that additional modalities invariably improve performance. We further contribute an explainability pipeline integrating SHAP, temporal/spatial attention, and gate weight analysis. This analysis uncovers a \"modality bias\" where fusion models assign 65-87% weight to the weaker thermal modality. Validated on a real-world bearing dataset (78,397 samples), our cascaded approach achieves state-of-the-art accuracy while providing actionable diagnostics for maintenance decision-making."}
{"id": "2512.24748", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2512.24748", "abs": "https://arxiv.org/abs/2512.24748", "authors": ["Zhijian Wang", "Xingbai Xu", "Tuo Liu"], "title": "Quasi-Maximum Likelihood Estimation for a Genuinely Unbalanced Dynamic Network Panel Data Model", "comment": null, "summary": "This paper develops a quasi-maximum likelihood estimator for genuinely unbalanced dynamic network panel data models with individual fixed effects. We propose a model that accommodates contemporaneous and lagged network spillovers, temporal dependence, and a listing effect that activates upon a unit's first appearance in the panel. We establish the consistency of the QMLE as both $N$ and $T$ go to infinity, derive its asymptotic distribution, and identify an asymptotic bias arising from incidental parameters when $N$ is asymptotically large relative to $T$. Based on the asymptotic bias expression, we propose a bias-corrected estimator that is asymptotically unbiased and normally distributed under appropriate regularity conditions. Monte Carlo experiments examine the finite sample performance of the bias-corrected estimator across different criteria, including bias, RMSE, coverage probability, and the normality of the estimator. The empirical application to Airbnb listings from New Zealand and New York City reveals region-specific patterns in spatial and temporal price transmission, illustrating the importance of modeling genuine unbalancedness in dynamic network settings."}
{"id": "2512.24081", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24081", "abs": "https://arxiv.org/abs/2512.24081", "authors": ["Sijin Li", "Wei Wang"], "title": "Parametric amplification of continuous variable entangled state for loss-tolerant multi-phase estimation", "comment": null, "summary": "Quantum parameter estimation exploits quantum states to achieve estimation sensitivity beyond classical limit. In continuous variable (CV) regime, squeezed state has been exploited to implement deterministic phase estimation. It is however, often restricted by fragility of quantum states. The quantum phase estimation sensitivity of squeezed state is significantly affected by loss or detection inefficiency, which restrict its applications. This issue can be solved by using a method of parametric amplification of squeezed state \\cite{OPA}. In this work, we implement multi-phase estimation with optical parametric amplification of entanglement generated from squeezed states. We find multi-phase estimation sensitivity is robust against loss or detection inefficiency, where we use two-mode Einstein-Podolsky-Rosen entangled state and four-mode cluster state for analysis. Our work provides a method for realizing large-scale quantum metrology in real-world applications against loss or detection inefficiency."}
{"id": "2512.24418", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.24418", "abs": "https://arxiv.org/abs/2512.24418", "authors": ["Yevgeny Bar Lev", "Jad C. Halimeh", "Achilleas Lazarides"], "title": "Dissipation-Stabilized Quantum Revivals in a Non-Hermitian Lattice Gauge Theory", "comment": "$9$ pages, $4$ figures", "summary": "With the advent of quantum simulation experiments of lattice gauge theories (LGTs), an open question is the effect of non-Hermiticity on their rich physics. The well-known PXP model, a U$(1)$ LGT with a two-level electric field in one spatial dimension, has become a paradigm of exotic physics in and out of equilibrium. Here, we introduce a non-Hermitian version in which the spin-flip rate differs between the two spin directions. While the naive expectation is that non-Hermiticity might suppress coherent phenomena such as quantum many-body scars, we find that when the facilitating direction of the spin is disfavored, the oscillations are instead \\emph{enhanced}, decaying much slower than in the PXP limit. We demonstrate that this can be understood through a similarity transformation that maps our model to the standard PXP model, revealing that the oscillations are enhanced versions of the PXP scars. Our work provides an analytically tractable and conceptually simple example where non-Hermiticity enhances the stability of dynamically non-trivial coherent many-body modes."}
{"id": "2512.24889", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24889", "abs": "https://arxiv.org/abs/2512.24889", "authors": ["Yifan He", "Griffin Kearney", "Makan Fardad"], "title": "Adaptive Clutter Suppression via Convex Optimization", "comment": null, "summary": "Passive and bistatic radar systems are often limited by strong clutter and direct-path interference that mask weak moving targets. Conventional cancellation methods such as the extensive cancellation algorithm require careful tuning and can distort the delay-Doppler response. This paper introduces a convex optimization framework that adaptively synthesizes per-cell delay-Doppler filters to suppress clutter while preserving the canonical cross-ambiguity function (CAF). The approach formulates a quadratic program that minimizes distortion of the CAF surface subject to linear clutter-suppression constraints, eliminating the need for a separate cancellation stage. Monte Carlo simulations using common communication waveforms demonstrate strong clutter suppression, accurate CFAR calibration, and major detection-rate gains over the classical CAF. The results highlight a scalable, CAF-faithful method for adaptive clutter mitigation in passive radar."}
{"id": "2512.23804", "categories": ["math.OC", "math.AP", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23804", "abs": "https://arxiv.org/abs/2512.23804", "authors": ["Zhendong Li", "Akwum Onwunta", "Bedřich Sousedík"], "title": "Stochastic Galerkin Method and Hierarchical Preconditioning for PDE-constrained Optimization", "comment": null, "summary": "We develop efficient hierarchical preconditioners for optimal control problems governed by partial differential equations with uncertain coefficients. Adopting a discretize-then-optimize framework that integrates finite element discretization, stochastic Galerkin approximation, and advanced time-discretization schemes, the approach addresses the challenge of large-scale, ill-conditioned linear systems arising in uncertainty quantification. By exploiting the sparsity inherent in generalized polynomial chaos expansions, we derive hierarchical preconditioners based on truncated stochastic expansion that strike an effective balance between computational cost and preconditioning quality. Numerical experiments demonstrate that the proposed preconditioners significantly accelerate the convergence of iterative solvers compared to existing methods, providing robust and efficient solvers for both steady-state and time-dependent optimal control applications under uncertainty."}
{"id": "2512.24886", "categories": ["eess.SY", "cs.MA", "math.AT"], "pdf": "https://arxiv.org/pdf/2512.24886", "abs": "https://arxiv.org/abs/2512.24886", "authors": ["Tyler Hanks", "Cristian F. Nino", "Joana Bou Barcelo", "Austin Copeland", "Warren Dixon", "James Fairbanks"], "title": "Heterogeneous Multi-Agent Multi-Target Tracking using Cellular Sheaves", "comment": "8 pages", "summary": "Multi-agent target tracking in the presence of nonlinear dynamics and agent heterogeneity, where state-space dimensions may differ, is a challenging problem that traditional graph Laplacian methods cannot easily address. This work leverages the framework of cellular sheaves, a mathematical generalization of graph theory, to natively model such heterogeneous systems. While existing coordination sheaf frameworks focus on cooperative problems like consensus, this work extends them to the non-cooperative target-tracking problem. The tracking of multiple, unknown targets is formulated as a harmonic extension problem on a cellular sheaf, accommodating nonlinear dynamics and external disturbances for all agents. A decentralized control law is developed using the sheaf Laplacian, and a corresponding Lyapunov-based stability analysis is provided to guarantee tracking error convergence, with results validated by simulation."}
{"id": "2512.24886", "categories": ["eess.SY", "cs.MA", "math.AT"], "pdf": "https://arxiv.org/pdf/2512.24886", "abs": "https://arxiv.org/abs/2512.24886", "authors": ["Tyler Hanks", "Cristian F. Nino", "Joana Bou Barcelo", "Austin Copeland", "Warren Dixon", "James Fairbanks"], "title": "Heterogeneous Multi-Agent Multi-Target Tracking using Cellular Sheaves", "comment": "8 pages", "summary": "Multi-agent target tracking in the presence of nonlinear dynamics and agent heterogeneity, where state-space dimensions may differ, is a challenging problem that traditional graph Laplacian methods cannot easily address. This work leverages the framework of cellular sheaves, a mathematical generalization of graph theory, to natively model such heterogeneous systems. While existing coordination sheaf frameworks focus on cooperative problems like consensus, this work extends them to the non-cooperative target-tracking problem. The tracking of multiple, unknown targets is formulated as a harmonic extension problem on a cellular sheaf, accommodating nonlinear dynamics and external disturbances for all agents. A decentralized control law is developed using the sheaf Laplacian, and a corresponding Lyapunov-based stability analysis is provided to guarantee tracking error convergence, with results validated by simulation."}
{"id": "2512.25025", "categories": ["stat.ME", "econ.EM", "math.ST"], "pdf": "https://arxiv.org/pdf/2512.25025", "abs": "https://arxiv.org/abs/2512.25025", "authors": ["Elynn Chen", "Yuefeng Han", "Jiayu Li", "Ke Xu"], "title": "Modewise Additive Factor Model for Matrix Time Series", "comment": null, "summary": "We introduce a Modewise Additive Factor Model (MAFM) for matrix-valued time series that captures row-specific and column-specific latent effects through an additive structure, offering greater flexibility than multiplicative frameworks such as Tucker and CP factor models. In MAFM, each observation decomposes into a row-factor component, a column-factor component, and noise, allowing distinct sources of variation along different modes to be modeled separately. We develop a computationally efficient two-stage estimation procedure: Modewise Inner-product Eigendecomposition (MINE) for initialization, followed by Complement-Projected Alternating Subspace Estimation (COMPAS) for iterative refinement. The key methodological innovation is that orthogonal complement projections completely eliminate cross-modal interference when estimating each loading space. We establish convergence rates for the estimated factor loading matrices under proper conditions. We further derive asymptotic distributions for the loading matrix estimators and develop consistent covariance estimators, yielding a data-driven inference framework that enables confidence interval construction and hypothesis testing. As a technical contribution of independent interest, we establish matrix Bernstein inequalities for quadratic forms of dependent matrix time series. Numerical experiments on synthetic and real data demonstrate the advantages of the proposed method over existing approaches."}
{"id": "2512.24094", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.24094", "abs": "https://arxiv.org/abs/2512.24094", "authors": ["Guo-Wei Zhang", "Sheng-Teng Zheng", "You Xiao", "Fang-Xiang Wang", "Wen-Jing Ding", "Dianpeng Wang", "Penglei Hao", "Li Zhang", "Jia-Lin Chen", "Yu-Yang Ding", "Shuang Wang", "De-Yong He", "Zhen-Qiang Yin", "Zheng Zhou", "Hao Li", "Lixing You", "Guang-Can Guo", "Wei Chen", "Zheng-Fu Han"], "title": "5-GHz chip-based quantum key distribution with 1Mbps secure key rate over 150 km", "comment": "4 figures and comments are welcome", "summary": "Quantum key distribution (QKD) enables secure communication by harnessing the fundamental principles of quantum physics, which inherently guarantee information-theoretic security and intrinsic resistance to quantum computing attacks. However, the secure key rate of QKD typically decreases exponentially with increasing channel distance. In this work, by developing a novel polarization-state preparation method, an ultra-low time-jitter laser source and superconducting nanowire single-photon detectors, we demonstrate a 5-GHz integrated QKD system featuring ultra-low quantum bit error rates (QBERs). The system achieves secure key rates of 1.076 Mbps at 150 km and 105 kbps at 200 km over standard single-mode fiber channels, respectively. Our system substantially enhances the secure key rate, enabling high-resolution video calls with one-time-pad encryption over intercity backbone QKD links. This work represents a significant step forward in the development of high-performance practical QKD systems."}
{"id": "2512.24589", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.24589", "abs": "https://arxiv.org/abs/2512.24589", "authors": ["Grant Davis", "James K. Freericks"], "title": "Hidden rotation symmetry of the Jordan-Wigner transformation and its application to measurement in quantum computation", "comment": "Submitted to Symmetry", "summary": "Using a global rotation by theta about the z-axis in the spin sector of the Jordan-Wigner transformation rotates Pauli matrices X and Y in the x-y-plane, while it adds a global complex phase to fermionic quantum states that have a fixed number of particles. With the right choice of angles, this relates expectation values of Pauli strings containing products of X and Y to different products, which can be employed to reduce the number of measurements needed when simulating fermionic systems on a quantum computer. Here, we derive this symmetry and show how it can be applied to systems in Physics and Chemistry that involve Hamiltonians with only single-particle (hopping) and two-particle (interaction) terms. We also discuss the consequences of this for finding efficient measurement circuits in variational ground state preparation."}
{"id": "2512.24897", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.24897", "abs": "https://arxiv.org/abs/2512.24897", "authors": ["Wuzhe Xu", "Jiequn Han", "Rongjie Lai"], "title": "Self-Supervised Amortized Neural Operators for Optimal Control: Scaling Laws and Applications", "comment": null, "summary": "Optimal control provides a principled framework for transforming dynamical system models into intelligent decision-making, yet classical computational approaches are often too expensive for real-time deployment in dynamic or uncertain environments. In this work, we propose a method based on self-supervised neural operators for open-loop optimal control problems. It offers a new paradigm by directly approximating the mapping from system conditions to optimal control strategies, enabling instantaneous inference across diverse scenarios once trained. We further extend this framework to more complex settings, including dynamic or partially observed environments, by integrating the learned solution operator with Model Predictive Control (MPC). This yields a solution-operator learning method for closed-loop control, in which the learned operator supplies rapid predictions that replace the potentially time-consuming optimization step in conventional MPC. This acceleration comes with a quantifiable price to pay. Theoretically, we derive scaling laws that relate generalization error and sample/model complexity to the intrinsic dimension of the problem and the regularity of the optimal control function. Numerically, case studies show efficient, accurate real-time performance in low-intrinsic-dimension regimes, while accuracy degrades as problem complexity increases. Together, these results provide a balanced perspective: neural operators are a powerful novel tool for high-performance control when hidden low-dimensional structure can be exploited, yet they remain fundamentally constrained by the intrinsic dimensional complexity in more challenging settings."}
{"id": "2512.23843", "categories": ["math.OC", "math.DS", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.23843", "abs": "https://arxiv.org/abs/2512.23843", "authors": ["Manish Krishan Lal"], "title": "The Flow-Limit of Reflect-Reflect-Relax: Existence, Stability, and Discrete-Time Behavior", "comment": null, "summary": "We study the Reflect-Reflect-Relax (RRR) algorithm in its small-step (flow-limit) regime. In the smooth transversal setting, we show that the transverse dynamics form a hyperbolic sink, yielding exponential decay of a natural gap measure. Under uniform geometric assumptions, we construct a tubular neighborhood of the feasible manifold on which the squared gap defines a strict Lyapunov function, excluding recurrent dynamics and chaotic behavior within this basin.\n  In the discrete setting, the induced flow is piecewise constant on W-domains and supports Filippov sliding along convergent boundaries, leading to finite-time capture into a solution domain. We prove that small-step RRR is a forward-Euler discretization of this flow, so that solution times measured in rescaled units converge to a finite limit while iteration counts diverge, explaining the emergence of iteration-optimal relaxation parameters. Finally, we introduce a heuristic mesoscopic framework based on percolation and renormalization group to organize performance deterioration near the Douglas-Rachford limit."}
{"id": "2512.24905", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24905", "abs": "https://arxiv.org/abs/2512.24905", "authors": ["Yufan Lin", "Xavier Guidetti", "Yannick Nagel", "Efe C. Balta", "John Lygeros"], "title": "One-Shot Camera-Based Extrusion Optimization for High Speed Fused Filament Fabrication", "comment": null, "summary": "Off-the-shelf fused filament fabrication 3D printers are widely accessible and convenient, yet they exhibit quality loss at high speeds due to dynamic mis-synchronization between printhead motion and material extrusion systems, notably corner over-extrusion. Existing methods require specialized hardware, extensive calibration, or firmware modifications that are inaccessible to most users. This work presents a practical, end-to-end optimization framework that enhances high-speed printing using only standard 3D printers and a phone camera, without requiring additional complex setup. The method employs a one-shot calibration approach in which two simple printed patterns, captured by a phone camera, enable identification of extrusion dynamics and cornering behavior. The identified systems enable a model-based constrained optimal control strategy that generates optimized G-code, synchronizing motion and extrusion. Experiments show reduced width tracking error, mitigated corner defects, and lower surface roughness, achieving surface quality at 3600 mm/min comparable to conventional printing at 1600 mm/min, effectively doubling production speed while maintaining print quality. This accessible, hardware-minimal approach enables a wide range of fused filament fabrication users to achieve high-quality, high-speed additive manufacturing."}
{"id": "2512.24905", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24905", "abs": "https://arxiv.org/abs/2512.24905", "authors": ["Yufan Lin", "Xavier Guidetti", "Yannick Nagel", "Efe C. Balta", "John Lygeros"], "title": "One-Shot Camera-Based Extrusion Optimization for High Speed Fused Filament Fabrication", "comment": null, "summary": "Off-the-shelf fused filament fabrication 3D printers are widely accessible and convenient, yet they exhibit quality loss at high speeds due to dynamic mis-synchronization between printhead motion and material extrusion systems, notably corner over-extrusion. Existing methods require specialized hardware, extensive calibration, or firmware modifications that are inaccessible to most users. This work presents a practical, end-to-end optimization framework that enhances high-speed printing using only standard 3D printers and a phone camera, without requiring additional complex setup. The method employs a one-shot calibration approach in which two simple printed patterns, captured by a phone camera, enable identification of extrusion dynamics and cornering behavior. The identified systems enable a model-based constrained optimal control strategy that generates optimized G-code, synchronizing motion and extrusion. Experiments show reduced width tracking error, mitigated corner defects, and lower surface roughness, achieving surface quality at 3600 mm/min comparable to conventional printing at 1600 mm/min, effectively doubling production speed while maintaining print quality. This accessible, hardware-minimal approach enables a wide range of fused filament fabrication users to achieve high-quality, high-speed additive manufacturing."}
{"id": "2512.25045", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.25045", "abs": "https://arxiv.org/abs/2512.25045", "authors": ["Christopher M. Hans", "Ningyi Liu"], "title": "Bayesian Elastic Net Regression with Structured Prior Dependence", "comment": null, "summary": "Many regularization priors for Bayesian regression assume the regression coefficients are a priori independent. In particular this is the case for standard Bayesian treatments of the lasso and the elastic net. While independence may be reasonable in some data-analytic settings, incorporating dependence in these prior distributions provides greater modeling flexibility. This paper introduces the orthant normal distribution in its general form and shows how it can be used to structure prior dependence in the Bayesian elastic net regression model. An L1-regularized version of Zellner's g prior is introduced as a special case, creating a new link between the literature on penalized optimization and an important class of regression priors. Computation is challenging due to an intractable normalizing constant in the prior. We avoid this issue by modifying slightly a standard prior of convenience for the hyperparameters in such a way to enable simple and fast Gibbs sampling of the posterior distribution. The benefit of including structured prior dependence in the Bayesian elastic net regression model is demonstrated through simulation and a near-infrared spectroscopy data example."}
{"id": "2512.24135", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2512.24135", "abs": "https://arxiv.org/abs/2512.24135", "authors": ["Dario Fasone", "Shreyasi Mukherjee", "Mauro Paternostro", "Elisabetta Paladino", "Luigi Giannelli", "Giuseppe A. Falci"], "title": "Testing Noise Correlations by an AI-Assisted Two-Qubit Quantum Sensor", "comment": "6 pages, 1 figure", "summary": "We introduce and validate a machine learning-assisted protocol to classify time and space correlations of classical noise acting on a quantum system, using two interacting qubits as probe. We consider different classes of noise, according to their Markovianity and spatial correlations. Leveraging the sensitivity of a coherent population transfer protocol under three distinct driving conditions, the various noises are discriminated by only measuring the final transfer efficiencies. This approach reaches around 90% accuracy with a minimal experimental overhead."}
{"id": "2512.24836", "categories": ["hep-lat", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.24836", "abs": "https://arxiv.org/abs/2512.24836", "authors": ["Sandip Maiti", "Debasish Banerjee", "Shailesh Chandrasekharan", "Marina K. Marinkovic"], "title": "Symmetric mass generation as a multicritical point with enhanced symmetry", "comment": "6 pages, 4 figures", "summary": "We explore the phase diagram of a lattice fermion model that exhibits three distinct phases: a massless fermion (MF) phase; a massive fermion phase with spontaneous symmetry breaking (SSB) induced by a fermion bilinear condensate; and a massive fermion phase with symmetric mass generation (SMG). Using the fermion-bag Monte Carlo method on large cubical lattices, we find evidence for traditional second-order critical points separating the first two and the latter two phases. Remarkably, these critical points appear to merge at a multicritical point with enhanced symmetry when the symmetry breaking parameter is tuned to zero, giving rise to the recently discovered direct second-order transition between the massless and symmetric massive fermion phases."}
{"id": "2512.24916", "categories": ["math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.24916", "abs": "https://arxiv.org/abs/2512.24916", "authors": ["Christian Bayer", "Saifeddine Ben naamia", "Erik von Schwerin", "Raul Tempone"], "title": "A Pontryagin Maximum Principle on the Belief Space for Continuous-Time Optimal Control with Discrete Observations", "comment": null, "summary": "We study a continuous time stochastic optimal control problem under partial observations that are available only at discrete time instants. This hybrid setting, with continuous dynamics and intermittent noisy measurements, arises in applications ranging from robotic exploration and target tracking to epidemic control. We formulate the problem on the space of beliefs (information states), treating the controller's posterior distribution of the state as the state variable for decision making. On this belief space we derive a Pontryagin maximum principle that provides necessary conditions for optimality. The analysis carefully tracks both the continuous evolution of the state between observation times and the Bayesian jump updates of the belief at observation instants.\n  A key insight is a relationship between the adjoint process in our maximum principle and the gradient of the value functional on the belief space, which links the optimality conditions to the dynamic programming approach on the space of probability measures. The resulting optimality system has a prediction and update structure that is closely related to the unnormalised Zakai equation and the normalised Kushner-Stratonovich equation in nonlinear filtering.\n  Building on this analysis, we design a particle based numerical scheme to approximate the coupled forward (filter) and backward (adjoint) system. The scheme uses particle filtering to represent the evolving belief and regression techniques to approximate the adjoint, which yields a practical algorithm for computing near optimal controls under partial information. The effectiveness of the approach is illustrated on both linear and nonlinear examples and highlights in particular the benefits of actively controlling the observation process."}
{"id": "2512.24999", "categories": ["math.ST", "cs.LG", "math.NA", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24999", "abs": "https://arxiv.org/abs/2512.24999", "authors": ["Seunghoon Paik", "Kangjie Zhou", "Matus Telgarsky", "Ryan J. Tibshirani"], "title": "Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis", "comment": "47 pages, 3 figures (7 subfigures)", "summary": "We introduce \\textit{basic inequalities} for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let $f$ denote the objective function to be optimized. Given a first-order iterative algorithm initialized at $θ_0$ with current iterate $θ_T$, the basic inequality upper bounds $f(θ_T)-f(z)$ for any reference point $z$ in terms of the accumulated step sizes and the distances between $θ_0$, $θ_T$, and $z$. The bound translates the number of iterations into an effective regularization coefficient in the loss function. We demonstrate this framework through analyses of training dynamics and prediction risk bounds. In addition to revisiting and refining known results on gradient descent, we provide new results for mirror descent with Bregman divergence projection, for generalized linear models trained by gradient descent and exponentiated gradient descent, and for randomized predictors. We illustrate and supplement these theoretical findings with experiments on generalized linear models."}
{"id": "2512.25056", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2512.25056", "abs": "https://arxiv.org/abs/2512.25056", "authors": ["Liliang Wang", "Alex Gorodetsky"], "title": "Sequential Bayesian parameter-state estimation in dynamical systems with noisy and incomplete observations via a variational framework", "comment": "31 pages, 8 figures", "summary": "Online joint estimation of unknown parameters and states in a dynamical system with uncertainty quantification is crucial in many applications. For example, digital twins dynamically update their knowledge of model parameters and states to support prediction and decision-making. Reliability and computational speed are vital for DTs. Online parameter-state estimation ensures computational efficiency, while uncertainty quantification is essential for making reliable predictions and decisions. In parameter-state estimation, the joint distribution of the state and model parameters conditioned on the data, termed the joint posterior, provides accurate uncertainty quantification. Because the joint posterior is generally intractable to compute, this paper presents an online variational inference framework to compute its approximation at each time step. The approximation is factorized into a marginal distribution over the model parameters and a state distribution conditioned on the parameters. This factorization enables recursive updates through a two-stage procedure: first, the parameter posterior is approximated via variational inference; second, the state distribution conditioned on the parameters is computed using Gaussian filtering based on the estimated parameter posterior. The algorithmic design is supported by a theorem establishing upper bounds on the joint posterior approximation error. Numerical experiments demonstrate that the proposed method (i) matches the performance of the joint particle filter in low-dimensional problems, accurately inferring both unobserved states and unknown parameters of dynamical and observation models; (ii) remains robust under noisy, partial observations and model discrepancies in a chaotic Lorenz 96 system; and (iii) scales effectively to a high-dimensional convection-diffusion system, where it outperforms the joint ensemble Kalman filter."}
{"id": "2512.24173", "categories": ["quant-ph", "cs.GR", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.24173", "abs": "https://arxiv.org/abs/2512.24173", "authors": ["Jui-Ting Lu", "Henrique Ennes", "Chih-Kang Huang", "Ali Abbassi"], "title": "Variational Quantum Brushes", "comment": null, "summary": "Quantum brushes are computational arts software introduced by Ferreira et al (2025) that leverage quantum behavior to generate novel artistic effects. In this outreach paper, we introduce the mathematical framework and describe the implementation of two quantum brushes based on variational quantum algorithms, Steerable and Chemical. While Steerable uses quantum geometric control theory to merge two works of art, Chemical mimics variational eigensolvers for estimating molecular ground energies to evolve colors on an underlying canvas. The implementation of both brushes is available open-source at https://github.com/moth-quantum/QuantumBrush and is fully compatible with the original quantum brushes."}
{"id": "2512.25018", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2512.25018", "abs": "https://arxiv.org/abs/2512.25018", "authors": ["Lacy M. Greening", "Santanu S. Dey", "Alan L. Erera"], "title": "Strengthening Dual Bounds for Multicommodity Capacitated Network Design with Unsplittable Flow Constraints", "comment": null, "summary": "Multicommodity capacitated network design (MCND) models can be used to optimize the consolidation of shipments within e-commerce fulfillment networks. In practice, fulfillment networks require that shipments with the same origin and destination follow the same transfer path. This unsplittable flow requirement complicates the MCND problem, requiring integer programming (IP) formulations in which binary variables replace continuous flow variables. To enhance the solvability of this variant of the MCND problem for large-scale logistics networks, this work focuses on strengthening dual bounds. We investigate the polyhedra of arc-set relaxations, and we introduce two new classes of valid inequalities that can be implemented within solution approaches. We develop one approach that dynamically adds valid inequalities to the root node of a reformulation of the MCND IP with additional valid metric inequalities. We show the effectiveness of our ideas with a comprehensive computational study using path-based fulfillment instances, constructed from data provided by a large U.S.-based e-commerce company, and the well-known arc-based Canad instances. Experiments show that our best solution approach for a practical path-based model reduces the IP gap by an average of 26.5% and 22.5% for the two largest instance groups, compared to solving the reformulation alone, demonstrating its effectiveness in improving the dual bound. In addition, experiments using only the arc-based relaxation highlight the strength of our new valid inequalities relative to the linear programming relaxation (LPR), yielding an IP-gap reduction of more than 85%."}
{"id": "2512.24198", "categories": ["quant-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2512.24198", "abs": "https://arxiv.org/abs/2512.24198", "authors": ["Krzysztof Sienicki"], "title": "A short technical comment on Bub's There is No Quantum World (arXiv:2512.18400v2) and a brief remark on related Grangier's reply (arXiv:2512.22965v1)", "comment": "5 pages, 10 references. Comments on arXiv:2512.18400v2 and rXiv:2512.22965v1", "summary": "This note is a friendly technical check of Jeffrey Bub's There is No Quantum World (arXiv:2512.18400v2). I flag one unambiguous mathematical slip (a cardinality identity that implicitly assumes the Continuum Hypothesis) and then point out a few places where the discussion of infinite tensor products, ``sectorization,'' and measurement updates would benefit from sharper wording. Nothing here is meant as a critique of Bub's interpretive goals; the aim is simply to separate what is mathematically forced from what depends on choices of algebra, representation, or philosophical stance. I end with a short remark on Philippe Grangier's reply (arXiv:2512.22965v1)."}
{"id": "2512.24173", "categories": ["quant-ph", "cs.GR", "cs.LG", "math.OC"], "pdf": "https://arxiv.org/pdf/2512.24173", "abs": "https://arxiv.org/abs/2512.24173", "authors": ["Jui-Ting Lu", "Henrique Ennes", "Chih-Kang Huang", "Ali Abbassi"], "title": "Variational Quantum Brushes", "comment": null, "summary": "Quantum brushes are computational arts software introduced by Ferreira et al (2025) that leverage quantum behavior to generate novel artistic effects. In this outreach paper, we introduce the mathematical framework and describe the implementation of two quantum brushes based on variational quantum algorithms, Steerable and Chemical. While Steerable uses quantum geometric control theory to merge two works of art, Chemical mimics variational eigensolvers for estimating molecular ground energies to evolve colors on an underlying canvas. The implementation of both brushes is available open-source at https://github.com/moth-quantum/QuantumBrush and is fully compatible with the original quantum brushes."}
{"id": "2512.24245", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24245", "abs": "https://arxiv.org/abs/2512.24245", "authors": ["Miao-Miao Yi", "L. X. Cui", "Y -M Du", "C. P. Sun"], "title": "Capacity-time Trade-off in Highly Reliable Quantum Memory", "comment": null, "summary": "Reliable optical quantum memory is limited by real-world imperfections such as disordered coupling and detuning. Existing studies mostly address these factors separately, while in practice their correlated effects set a fundamental limit on storage performance. We develop a comprehensive model that simultaneously incorporates disordered coupling and detuning. It is shown that these disorders induce a random Berry's phase in the stored states, while decoherence from disordered coupling stems from correlations with detuning rather than individual imperfections. This mechanism imposes a fundamental trade-off among storage capacity, storage time, and driving time, setting a universal limit for reliable storage. Extending the analysis to memory based devices operating with multiple storage processes shows that enhancing parameter independence improves their reliability. We further provide a more precise relation for measuring and correcting global detuning, which is directly relevant to current experimental protocols."}
{"id": "2512.24527", "categories": ["math.ST", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2512.24527", "abs": "https://arxiv.org/abs/2512.24527", "authors": ["Matieyendou Lamboni"], "title": "Dimension-free estimators of gradients of functions with(out) non-independent variables", "comment": null, "summary": "This study proposes a unified stochastic framework for approximating and computing the gradient of every smooth function evaluated at non-independent variables, using $\\ell_p$-spherical distributions on $\\R^d$ with $d, p\\geq 1$. The upper-bounds of the bias of the gradient surrogates do not suffer from the curse of dimensionality for any $p\\geq 1$. Also, the mean squared errors (MSEs) of the gradient estimators are bounded by $K_0 N^{-1} d$ for any $p \\in [1, 2]$, and by $K_1 N^{-1} d^{2/p}$ when $2 \\leq p \\ll d$ with $N$ the sample size and $K_0, K_1$ some constants. Taking $\\max\\left\\{2, \\log(d) \\right\\} < p \\ll d$ allows for achieving dimension-free upper-bounds of MSEs. In the case where $d\\ll p< +\\infty$, the upper-bound $K_2 N^{-1} d^{2-2/p}/ (d+2)^2$ is reached with $K_2$ a constant. Such results lead to dimension-free MSEs of the proposed estimators, which boil down to estimators of the traditional gradient when the variables are independent. Numerical comparisons show the efficiency of the proposed approach."}
{"id": "2512.24273", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.24273", "abs": "https://arxiv.org/abs/2512.24273", "authors": ["Valts Krumins", "Ivars Krastins", "Oskars Rudzitis", "Reinis Lazda", "Florian Gahbauer", "Marcis Auzinsh"], "title": "Using NV centers in diamond to detect DC to very-low frequency magnetic fields", "comment": null, "summary": "In this work we present a compact and portable tabletop magnetometer that utilizes negatively charged nitrogen-vacancy (NV) centers in diamond. The magnetometer is operated using a dual microwave resonance detection approach in combination with an optically detected magnetic resonance (ODMR) technique (mitigating drifts in results due to changes of the diamond temperature), capable of simultaneously exciting and registering two ODMR transitions. The experimentally measured magnetic field noise-floor is $\\approx 2.3~\\textrm{nT}\\sqrt{\\textrm{Hz}}$ while the calculated shot-noise-limited magnetic field sensitivity is $\\approx 585~\\textrm{pT}\\sqrt{\\textrm{Hz}}$ when excited with a continuous wave laser at 0.5~W.\n  These results pave the way for realizing a simple set-up magnetometer for precise single axis magnetic field measurements for example for accurate electric current measurements for stabilization purposes and magnetic communication applications."}
{"id": "2512.24999", "categories": ["math.ST", "cs.LG", "math.NA", "math.OC", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.24999", "abs": "https://arxiv.org/abs/2512.24999", "authors": ["Seunghoon Paik", "Kangjie Zhou", "Matus Telgarsky", "Ryan J. Tibshirani"], "title": "Basic Inequalities for First-Order Optimization with Applications to Statistical Risk Analysis", "comment": "47 pages, 3 figures (7 subfigures)", "summary": "We introduce \\textit{basic inequalities} for first-order iterative optimization algorithms, forming a simple and versatile framework that connects implicit and explicit regularization. While related inequalities appear in the literature, we isolate and highlight a specific form and develop it as a well-rounded tool for statistical analysis. Let $f$ denote the objective function to be optimized. Given a first-order iterative algorithm initialized at $θ_0$ with current iterate $θ_T$, the basic inequality upper bounds $f(θ_T)-f(z)$ for any reference point $z$ in terms of the accumulated step sizes and the distances between $θ_0$, $θ_T$, and $z$. The bound translates the number of iterations into an effective regularization coefficient in the loss function. We demonstrate this framework through analyses of training dynamics and prediction risk bounds. In addition to revisiting and refining known results on gradient descent, we provide new results for mirror descent with Bregman divergence projection, for generalized linear models trained by gradient descent and exponentiated gradient descent, and for randomized predictors. We illustrate and supplement these theoretical findings with experiments on generalized linear models."}
{"id": "2512.24274", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24274", "abs": "https://arxiv.org/abs/2512.24274", "authors": ["Souvik Chatterjee", "Prasenjit Deb", "Chandan Datta", "Pankaj Agrawal"], "title": "Deterministic distribution of W-class states in quantum networks", "comment": null, "summary": "Multipartite entangled states possess a number of non-intuitive properties, making them a useful resource for various quantum information-processing tasks. The three-qubit W-state is one such example where every state is robust to single-qubit loss. However, this state is not suitable for deterministic distribution, and deterministic communication protocols. Here, we focus on the distribution of a non-symmetric version of such states, namely $W_{\\mathrm{mod}}$ states. These states belong to the W-class, and have one ebit of entanglement across a specific bipartition, enabling deterministic teleportation and superdense coding. In particular, we describe a few protocols through which these multipartite entangled states can be distributed {\\it deterministically} in a quantum network by first preparing them locally in a central node and then transmitting individual qubits to the end nodes. We analyse the performance of these protocols based on the fidelity of the final distributed state, considering all types of noises that can act during the distribution. Finally, we compare the performance of the protocols to the case where the distribution is performed without any central node."}
{"id": "2512.24282", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24282", "abs": "https://arxiv.org/abs/2512.24282", "authors": ["Attila Portik", "Orsolya Kálmán", "Tamás Kiss"], "title": "Ergodic dynamics in iterated quantum protocols", "comment": "13 pages, 12 figures", "summary": "We study measurement-induced nonlinear dynamics generated by an iterated quantum protocol combining an entangling gate, a single-qubit rotation, and post-selection. For pure single-qubit inputs, a particular choice of the single-qubit unitary yields globally chaotic, strongly mixing dynamics that explores the entire Bloch sphere, providing a physical realization of ergodic behavior in a complex map. We extend the analysis to realistic, noisy preparation by considering mixed initial states and the induced nonlinear evolution inside the Bloch sphere. Numerical results show that the maximally mixed state is an attractor for mixed inputs, although many trajectories exhibit transient increases in purity before ultimately converging. To quantify robustness against noise, we introduce a practical notion of quasi-ergodicity: ensembles prepared in a small angular patch at fixed purity rapidly spread to cover all directions, while the purity gradually decreases toward its minimal value. By varying the final single-qubit gate, we identify a broad family of protocols that remain ergodic-like for pure states, supported by consistent diagnostics including the absence of attracting cycles, agreement of time and ensemble statistics, rapid spreading from localized regions, and exponential sensitivity to initial conditions. Away from the special globally mixing case, the mixed-state dynamics can change qualitatively: for most ergodic-like parameters, a finite subset of noisy inputs is driven toward purification rather than complete mixing, demonstrating the coexistence of statistical mixing and purification within a single iterated protocol."}
{"id": "2512.24296", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24296", "abs": "https://arxiv.org/abs/2512.24296", "authors": ["Camille L Latune"], "title": "Quantum Thermodynamics and Quantum Perspectives", "comment": "in French language, Contribution to the celebration of the 200 years of Sadi Carnot's book \"Reflections on the Motive Power of Fire\", in French and part of the book \"Chaleur, énergie, thermodynamique: le message de Carnot aujourd'hui... 200 ans après\", direction G. Bertrand, Ed. Univ. de Dijon (2025). https://eud.ube.fr/sciences/891-chaleur-energie-thermodynamique-9782364415829.html?search_query=carnot&results=3", "summary": "After a brief historical perspective, we introduce the key notions of work and heat for quantum systems, to then apply them to quantum engines operating on quantum Otto and Carnot cycles. The irreversible and dissipative character of the quantum Otto cycle is briefly analyzed, contrasting with the energetic optimality of the quantum Carnot cycle. The central question of quantum effects is also addressed and illustrated with several examples. Finally, the last part strives to explain the role that quantum thermodynamics plays for quantum applications and quantum technologies, particularly in relation to energy optimization and the trade-off between performances and energy costs."}
{"id": "2512.24304", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24304", "abs": "https://arxiv.org/abs/2512.24304", "authors": ["Antoni Wójcik", "Jan Wójcik"], "title": "In defense of temporal Tsirelson bound", "comment": null, "summary": "In a recent paper, Chatterjee et al. [Phys. Rev. Lett 135, 220202 (2025)] analyze and experimentally implement a specific unitary evolution of a simple quantum system. The authors refer to this type of dynamics as a \"superposition of unitary time evolutions.\" They claim that such an evolution enables a violation of the temporal Tsirelson bound in the Leggett-Garg scenario, a claim that is supported by their experimental results. In this work, we show that the proposed evolution can be understood within a more conventional framework, without invoking a superposition of evolutions. Furthermore, we demonstrate that the apparent violation of the bound arises because the measured quantities are not consistent with the assumptions of the Leggett-Garg scenario. This is a slightly extended version of the Comment submitted for publication in Phys. Rev. Lett."}
{"id": "2512.24308", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24308", "abs": "https://arxiv.org/abs/2512.24308", "authors": ["Omer Gurevich", "Maor Matityahu", "Tal Mor"], "title": "Quantum Computing, Ising Formulation, and the Traveling Salesman Problem", "comment": "19 pages, 9 figures", "summary": "Ising formulation is important for many NP problems (Lucas, 2014). This formulation enables implementing novel quantum computing methods including Quantum Approximate Optimization Algorithm and Variational Quantum Eigensolver (VQE). Here, we investigate closely the traveling salesman problem (TSP).\n  First, we present some non-trivial issues related to Ising model view versus a realistic salesman.\n  Then, focusing on VQE we discuss and clarify the use of: a.-- Conventional VQE and how it is relevant as a novel SAT-solver; b.-- Qubit efficiency and its importance in the Noisy Intermediate Scale Quantum-era; and c.-- the relevance and importance of a novel approach named Discrete Quantum Exhaustive Search (Alfassi, Meirom, and Mor, 2024), for enhancing VQE and other methods using mutually unbiased bases.\n  The approach we present here in details can potentially be extended for analyzing approximating and solving various other NP complete problems. Our approach can also be extended beyond the Ising model and beyond the class NP, for example to the class Quantum Merlin Arthur (QMA) of problems, relevant for quantum chemistry and for general spin problems."}
{"id": "2512.24312", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2512.24312", "abs": "https://arxiv.org/abs/2512.24312", "authors": ["Julia Tokarska", "Andrzej Dragan"], "title": "Gravitationally Induced Entanglement Between Particles in Harmonic Traps: Limits for Gaussian States", "comment": "7 pages, 2 figures", "summary": "Gravitationally induced entanglement has been proposed as a probe of the quantum nature of gravity. This work analyzes a system of two particles in harmonic traps interacting only through gravity, considering thermal and two-mode squeezed initial states. For thermal states, a maximum temperature is identified above which entanglement cannot be generated, and for fixed system parameters an optimal trap frequency that maximizes the logarithmic negativity is found. Squeezing the initial state does not further enhance the entanglement generation, but increases the temperature range over which it can be observed. Extending the analysis to general Gaussian states, an upper bound on the achievable entanglement is derived and shown to be saturated, for example, by ground and squeezed states. The results show that the amount of entanglement generated in this setup is extremely small, highlighting the experimental challenges of observing gravitationally induced quantum effects."}
{"id": "2512.24341", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.24341", "abs": "https://arxiv.org/abs/2512.24341", "authors": ["Andre G. Campos", "Karen Z. Hatsagortsyan", "Christoph H. Keitel"], "title": "Relativistic Lindblad description of the electron's radiative dynamics", "comment": null, "summary": "An effective model for describing the relativistic quantum dynamics of a radiating electron is developed via a relativistic generalization of the Lindblad master equation. By incorporating both radiation reaction and vacuum fluctuations into the Dirac equation within an open quantum system framework, our approach captures the Zitterbewegung of the electron, ensuing noncommutativity of its effective spatial coordinates, and provides the quantum analogue of the Landau-Lifshitz (LL) classical equation of motion with radiation reaction. We develop the corresponding phase-space representation via the relativistic Wigner function and derive the semiclassical limit through a Foldy-Wouthuysen transformation. The latter elucidates the signature of quantum vacuum fluctuations in the LL equation, and shows its relationship with the corrected Sokolov equation. Our results offer a robust framework for investigating quantum radiation reaction effects in ultrastrong laser fields."}
{"id": "2512.24387", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24387", "abs": "https://arxiv.org/abs/2512.24387", "authors": ["Lukas Eisemann", "Ömer Bayraktar", "Stefan Richter", "Kevin Jaksch", "Hüseyin Vural", "Christoph Marquardt"], "title": "Increased-Efficiency Multiple-Decoding-Attempts Error Correction for Continuous-Variable Quantum Key Distribution", "comment": "8 pages, 8 figures;", "summary": "In continuous-variable quantum key distribution (CV-QKD), the performance of the information reconciliation (IR) step is critical for the achievable secret key rate (SKR) and transmission distance. We show how to improve on the recently introduced implementation of an IR-protocol involving multiple decoding attempts (MDA) and validate the method on simulated data in different application scenarios. Throughout, we demonstrate meaningful SKR-gains compared to both the standard protocol of a single decoding attempt and to the original MDA-implementation, even at given decoding complexity."}
{"id": "2512.24389", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24389", "abs": "https://arxiv.org/abs/2512.24389", "authors": ["Dariusz Chruściński", "Vivek Pandey", "Sohail"], "title": "Diagonal Unitary Covariant Superchannels", "comment": "32 pages, no figures", "summary": "We present a complete characterization of diagonal unitary covariant (DU-covariant) superchannels, i.e. higher-order transformations transforming quantum channels into themselves. Necessary and sufficient conditions for complete positivity and trace preservation are derived and the canonical decomposition describing DU-covariant superchannels is provided. The presented framework unifies and extends known families of covariant quantum channels and enables explicit analysis of their action on physically relevant examples, including amplitude-damping, bit-flip, and Pauli channels. Our results provide a practical toolbox for symmetry-restricted higher-order quantum processes and offer a setting for exploring open problems such as the PPT$^2$ conjecture."}
{"id": "2512.24393", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24393", "abs": "https://arxiv.org/abs/2512.24393", "authors": ["Riccardo Cantone", "Shreyasi Mukherjee", "Luigi Giannelli", "Elisabetta Paladino", "Giuseppe A. Falci"], "title": "Machine Learning-Aided Optimal Control of a Qubit Subjected to External Noise", "comment": null, "summary": "We apply a machine-learning-enhanced greybox framework to a quantum optimal control protocol for open quantum systems. Combining a whitebox physical model with a neural-network blackbox trained on synthetic data, the method captures non-Markovian noise effects and achieves gate fidelities above 90% under Random Telegraph and Ornstein-Uhlenbeck noise. Critical issues of the approach are discussed."}
{"id": "2512.24406", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24406", "abs": "https://arxiv.org/abs/2512.24406", "authors": ["Vladimir M. Stojanovic", "Tommaso Calarco", "Andrea Muratori"], "title": "Harnessing subspace controllability: Time-optimal Dicke-state generation in Heisenberg-coupled qubit arrays with a single local control", "comment": "16 pages, 12 figures", "summary": "We explore the feasibility of realizing Dicke states in qubit arrays with always-on isotropic Heisenberg coupling between adjacent qubits, assuming a single Zeeman-type control acting in the $z$ direction on an actuator qubit. The Lie-algebraic criteria of controllability imply that such an array is not completely controllable, but satisfies the conditions for subspace controllability on any subspace with a fixed number of excitations. Therefore, a qubit array described by the model under consideration is state-to-state controllable for an arbitrary choice of initial and final states that have the same Hamming weight. This limited controllability is exploited here for the time-optimal dynamical generation of an $a$-excitation Dicke state $|D^{N}_{a}\\rangle$ ($a=1,2,\\ldots, N-1$) in a linear array with $N$ qubits starting from a generic Hamming-weight-$a$ product state. To dynamically generate the desired Dicke states -- including $W$ states $|W_{N}\\rangle$ as their special ($a=1$) case -- in the shortest possible time with a single local $Z$ control, we employ an optimal-control scheme based on the dressed Chopped RAndom Basis (dCRAB) algorithm. We optimize the target-state fidelity over the expansion coefficients of smoothly-varying control fields in a truncated random Fourier basis; this is done by combining Nelder-Mead-type local optimizations with the multistart-based clustering algorithm that facilitates searches for global extrema. In this manner, we obtain the optimal control fields for Dicke-state preparation in arrays with up to $N=9$ qubits. Based on our numerical results, we find that the shortest possible state-preparation times scale quadratically with $N$. Finally, we demonstrate the robustness of our control scheme against small control-field deviations from the optimal values."}
{"id": "2512.24418", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech", "cond-mat.str-el", "hep-lat"], "pdf": "https://arxiv.org/pdf/2512.24418", "abs": "https://arxiv.org/abs/2512.24418", "authors": ["Yevgeny Bar Lev", "Jad C. Halimeh", "Achilleas Lazarides"], "title": "Dissipation-Stabilized Quantum Revivals in a Non-Hermitian Lattice Gauge Theory", "comment": "$9$ pages, $4$ figures", "summary": "With the advent of quantum simulation experiments of lattice gauge theories (LGTs), an open question is the effect of non-Hermiticity on their rich physics. The well-known PXP model, a U$(1)$ LGT with a two-level electric field in one spatial dimension, has become a paradigm of exotic physics in and out of equilibrium. Here, we introduce a non-Hermitian version in which the spin-flip rate differs between the two spin directions. While the naive expectation is that non-Hermiticity might suppress coherent phenomena such as quantum many-body scars, we find that when the facilitating direction of the spin is disfavored, the oscillations are instead \\emph{enhanced}, decaying much slower than in the PXP limit. We demonstrate that this can be understood through a similarity transformation that maps our model to the standard PXP model, revealing that the oscillations are enhanced versions of the PXP scars. Our work provides an analytically tractable and conceptually simple example where non-Hermiticity enhances the stability of dynamically non-trivial coherent many-body modes."}
{"id": "2512.24423", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24423", "abs": "https://arxiv.org/abs/2512.24423", "authors": ["Innes L. Maxwell", "Stefan N. van den Hoven", "Jelmer J. Renema"], "title": "A Quantum-Inspired Algorithm for Graph Isomorphism", "comment": "12 pages", "summary": "The Noisy Intermediate-Scale Quantum (NISQ) era of technology in which we currently find ourselves is defined by non-universality, susceptibility to errors and noise, and a search for useful applications. While demonstrations of practical quantum advantage remain elusive in this era, it provides space to develop and analyze the advantages and limitations of systems and their ability to solve problems. In this work, we critically assess a proposed quantum algorithm for the graph isomorphism problem, implemented on a photonic quantum device. Inspired by the nature of this quantum algorithm, we formulate a necessary condition for the isomorphism of graphs encoded in Gaussian boson samplers and a classical algorithm to test for it. Our classical algorithm makes use of efficiently computable statistical properties of a quantum sampling system to show a pair of graphs fail to meet our necessary condition and thus cannot be isomorphic. We analyze our algorithm in the context of the inspiring, sampler-based quantum algorithm of Bràdler et. al., the classical color refinement algorithm, and the state-of-the-art quasi-polynomial Babai algorithm."}
{"id": "2512.24424", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24424", "abs": "https://arxiv.org/abs/2512.24424", "authors": ["Patryk Michalski", "Andrzej Dragan"], "title": "Detection of quantum entanglement across the event horizon", "comment": "8 pages, 6 figures", "summary": "We investigate the problem of distinguishing between separable and entangled states of two quantum wave packets, one of which falls into a black hole. Intuitively, one might expect the two scenarios to be indistinguishable, since the information carried by one wave packet is hidden beyond the event horizon. We show, however, that fundamental limitations on the localizability of quantum states render the two scenarios, in principle, distinguishable. Employing tools from quantum state discrimination theory, we analyze a concrete realization and discuss the configurations that maximize the probability of successfully distinguishing between the two cases."}
{"id": "2512.24437", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24437", "abs": "https://arxiv.org/abs/2512.24437", "authors": ["Yanet Alvarez", "Mariela Portesi", "Romina Ramirez", "Marta Reboiro"], "title": "Uncertainty inequalities in a non-Hermitian scenario: the problem of the metric", "comment": "12 pages, 12 figures", "summary": "We investigate uncertainty relations for quantum observables evolving under non-Hermitian Hamiltonians, with particular emphasis on the role of metric operators. By constructing appropriate metrics in each dynamical regime, namely the unbroken-symmetry phase, the broken-symmetry phase, and at exceptional points, we provide a consistent definition of expectation values, variances, and time evolution within a Krein-space framework. Within this approach, we derive a generalized Heisenberg-Robertson uncertainty inequality which is valid across all spectral regimes. As an application, we analyze a two level model with parity-time reversal symmetry and show that, while the uncertainty measure exhibits oscillatory behavior in the unbroken phase, it evolves toward a minimum-uncertainty steady state in the broken symmetry phase and at exceptional points. We further compare our metric-based description with a Lindblad master-equation approach and show their agreement in the steady state. Our results highlight the necessity of incorporating appropriate metric structures to extract physically meaningful predictions from non-Hermitian quantum dynamics."}
{"id": "2512.24448", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24448", "abs": "https://arxiv.org/abs/2512.24448", "authors": ["Ghazi Khan", "Thomas E. Roth"], "title": "Incorporating multi-qubit exchange coupling effects between transmon qubits in Maxwell-Schrödinger numerical methods", "comment": "17 pages, 12 figures", "summary": "Superconducting qubits have emerged as a leading platform for realizing quantum computers. Accurate modeling of these devices is essential for predicting performance, improving design, and optimizing control. Many modeling approaches currently rely on lumped circuit approximations or other simplified treatments that can be limited in resolving the interplay between the qubit dynamics and the electromagnetic circuitry, leading to significant experimental deviations from numerical predictions at times. To address many of these limitations, methods that self-consistently solve the Schrödinger equation for qubit dynamics with the classical Maxwell's equations have been developed and shown to accurately predict a wide range of effects related to superconducting qubit control and readout. Despite these successes, these methods have not been able to consider multi-qubit effects that give rise to qubit-qubit entanglement. Here, we address this by rigorously deriving how multi-qubit coupling effects between transmon qubits can be embedded into Maxwell-Schrödinger methods. To support this, we build on earlier first-principles derivations of Maxwell-Schrödinger methods for the specific case of two transmon qubits coupled together through a common electromagnetic system in the dispersive regime. To aid in validating aspects of the Maxwell-Schrödinger framework, we also provide a new interpretation of Maxwell-Schrödinger methods as an efficient simulation strategy to capture the class of non-Markovian open quantum system dynamics. Our results demonstrate that these effects can give rise to strong classical crosstalk that can significantly alter multi-qubit dynamics, which we demonstrate for the cross-resonance gate. These classical crosstalk effects have been noted in cross-resonance experiments, but previous quantum theory and device analysis could not explain their origin."}
{"id": "2512.24454", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24454", "abs": "https://arxiv.org/abs/2512.24454", "authors": ["E. K. Berinyuy", "P. Djorwé", "J. -X. Peng", "A. Sohail", "J. Ghosh", "A. -H. Abdel-Aty", "S. G. N. Engo", "S. K. Singh"], "title": "Quantum phase synchronisation enhanced via Coulomb interaction in an optomechanical system", "comment": null, "summary": "In this work, we investigate the dynamics of quantum synchronization in a four-mode optomechanical system, focusing on the influence of the Coulomb interaction between two mechanical resonators. We analyze the effect of the Coulomb coupling on three distinct synchronization regimes, i.e., complete quantum synchronization, $φ$-synchronization, and quantum phase synchronization. Our results show that while the Coulomb interaction plays a pivotal role in significantly enhancing quantum phase synchronization by facilitating energy exchange and phase coherence, it has little impact on complete and $φ$-synchronization. This indicates that amplitude and frequency locking are primarily determined by the optical driving, whereas phase alignment depends critically on inter-resonator coupling. We also demonstrate that the oscillations of the two optical cavities, which are indirectly coupled via the mechanical resonators, can become aligned over time, resulting in classical synchronization. These findings provide a robust mechanism for controlling collective quantum dynamics and offer a foundation for applications in quantum communication, precision sensing, and the development of synchronized quantum networks."}
{"id": "2512.24466", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24466", "abs": "https://arxiv.org/abs/2512.24466", "authors": ["Mustafa Bakr"], "title": "A Boundary Condition Perspective on Circuit QED Dispersive Readout", "comment": null, "summary": "Boundary conditions in confined geometries and measurement interactions in quantum mechanics share a common structural role: both select a preferred basis by determining which states are compatible with the imposed constraint. This paper develops this perspective for circuit QED dispersive readout through a first-principles derivation starting from the circuit Lagrangian. The transmon qubit terminating a transmission line resonator provides a frequency-dependent boundary condition whose pole structure encodes the qubit's transition frequencies; different qubit states yield different resonator frequencies. Two approximations, linear response and a pole-dominated expansion valid near resonance, reduce the boundary function to a rational form in the Sturm-Liouville eigenparameter. The extended Hilbert space of the Fulton-Walter spectral theory then provides a framework for the dressed-mode eigenvalue problem conditional on the qubit state. The dispersive shift and vacuum Rabi splitting emerge from the transcendental eigenvalue equation, with the residues determined by matching to the splitting: $δ_{ge} = 2Lg^2ω_q^2/v^4$, where $g$ is the vacuum Rabi coupling. A level repulsion theorem guarantees that no dressed mode frequency coincides with a transmon transition. For two qubits with matched dispersive shifts, odd-parity states become frequency-degenerate; true parity-only measurement requires engineered suppression of linear dispersive terms."}
{"id": "2512.24472", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24472", "abs": "https://arxiv.org/abs/2512.24472", "authors": ["Chon-Fai Kam"], "title": "Three-Axis Spin Squeezed States Associated with Excited-State Quantum Phase Transitions", "comment": null, "summary": "Spin squeezing in collective atomic ensembles enables quantum-enhanced metrology by reducing noise below the standard quantum limit through nonlinear interactions. Extending the one-axis and two-axis twisting paradigms of Kitagawa and Ueda, we introduce a general class of three-axis spin squeezed states within the anisotropic Lipkin-Meshkov-Glick model. The model features direction-dependent quadratic couplings that interpolate between uniaxial and biaxial regimes and can be interpreted as an asymmetric quantum rotor. Using semiclassical dynamics, Majorana representations, and Husimi-Q distributions, we analyze the structure and metrological properties of the resulting states. The three-axis framework reproduces the known N^(-2/3) scaling of one-axis twisting and the Heisenberg-limited N^(-1) scaling of two-axis twisting, while allowing additional tunability and enhanced entanglement generation in low-spin systems. We further show that tuning the anisotropy parameters induces ground-state and excited-state quantum phase transitions, including a second-order transition associated with level clustering and critical dynamics. These results unify spin squeezing, quantum criticality, and rotor analogies, and suggest implementations in Rydberg arrays and cavity-QED platforms for precision sensing and quantum simulation."}
{"id": "2512.24495", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2512.24495", "abs": "https://arxiv.org/abs/2512.24495", "authors": ["Foster Thompson", "Daniel K. J. Boneß", "Mark Dykman", "Alex Kamenev"], "title": "Spectroscopy of Quantum Phase Slips: Visualizing Complex Real-Time Instantons", "comment": null, "summary": "Parametrically driven oscillators can emerge as a basis for the next generation of qubits. Classically, these systems exhibit two stable oscillatory states with opposite phases. Upon quantization, these states turn into a pair of closely spaced Floquet states, which can serve as the logical basis for a qubit. However, interaction with the environment induces phase-slip events which set a limit on qubit coherence. Such phase slips persist even at zero temperature due to a mechanism known as quantum activation \\cite{QuantumActivation}. In contrast to conventional tunneling, the quantum activation is described by a {\\em real-time} instanton trajectory in the complexified phase space of the system. In this work, we show that the phase-slip rate is exponentially sensitive to weak AC perturbations. The spectrum of the system's response -- captured by the so-called logarithmic susceptibility (LS) -- enables a direct observation of characteristic features of real-time instantons. Studying this spectrum suggests new means of efficient qubit control."}
{"id": "2512.24509", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2512.24509", "abs": "https://arxiv.org/abs/2512.24509", "authors": ["A. Bagci"], "title": "Multidimensional derivative-free optimization. A case study on minimization of Hartree-Fock-Roothaan energy functionals", "comment": null, "summary": "This study presents an evaluation of derivative-free optimization algorithms for the direct minimization of Hartree-Fock-Roothaan energy functionals involving nonlinear orbital parameters and quantum numbers with noninteger order. The analysis focuses on atomic calculations employing noninteger Slater-type orbitals. Analytic derivatives of the energy functional are not readily available for these orbitals. Four methods are investigated under identical numerical conditions: Powell's conjugate-direction method, the Nelder-Mead simplex algorithm, coordinate-based pattern search, and a model-based algorithm utilizing radial basis functions for surrogate-model construction. Performance benchmarking is first performed using the Powell singular function, a well-established test case exhibiting challenging properties including Hessian singularity at the global minimum. The algorithms are then applied to Hartree-Fock-Roothaan self-consistent-field energy functionals, which define a highly non-convex optimization landscape due to the nonlinear coupling of orbital parameters. Illustrative examples are provided for closed$-$shell atomic configurations, specifically the He, Be isoelectronic series, with calculations performed for energy functionals involving up to eight nonlinear parameters."}
{"id": "2512.24528", "categories": ["quant-ph", "hep-th", "nucl-th"], "pdf": "https://arxiv.org/pdf/2512.24528", "abs": "https://arxiv.org/abs/2512.24528", "authors": ["Okuto Morikawa", "Shoya Ogawa", "Soma Onoda"], "title": "Geometric phase of exceptional point as quantum resonance in complex scaling method", "comment": "18 pages, 5 figures", "summary": "Non-Hermitian operators and exceptional points (EPs) are now routinely realized in few-mode systems such as optical resonators and superconducting qubits. However, their foundations in genuine scattering problems with unbounded Hamiltonians remain much less clear. In this work, we address how the geometric phase associated with encircling an EP should be formulated when the underlying eigenstates are quantum resonances within a one-dimensional scattering model. To do this, we employ the complex scaling method, where resonance poles of the S-matrix are realized as discrete eigenvalues of the non-Hermitian dilated Hamiltonian, to construct situations in which resonant and scattering states coalesce into an EP in the complex energy plane, that is, the resonance pole is embedded into the continuum spectrum. We analyze the self-orthogonality in the vicinity of an EP and the Berry phase. Our results provide a bridge between non-Hermitian spectral theory and the traditional theory of quantum resonances."}
{"id": "2512.24539", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2512.24539", "abs": "https://arxiv.org/abs/2512.24539", "authors": ["Cyril Metzger", "Alec L. Emser", "Brendon C. Rose", "Konrad W. Lehnert"], "title": "TLS-induced thermal nonlinearity in a micro-mechanical resonator", "comment": "45 pages, 16 figures, main paper followed by appendices and supplemental materials", "summary": "We present experimental evidence of a thermally-driven amplitude-frequency nonlinearity in a thin-film quartz phononic crystal resonator at millikelvin temperatures. The nonlinear response arises from the coupling of the mechanical mode to an ensemble of microscopic two-level system defects driven out of equilibrium by a microwave drive. In contrast to the conventional Duffing oscillator, the observed nonlinearity exhibits a mixed reactive-dissipative character. Notably, the reactive effect can manifest as either a softening or hardening of the mechanical resonance, depending on the ratio of thermal to phonon energy. By combining the standard TLS theory with a thermal conductance model, the measured power-dependent response is quantitatively reproduced and readout-enhanced relaxation damping from off-resonant TLSs is identified as the primary mechanism limiting mechanical coherence. Within this framework, we delineate the conditions under which similar systems will realize this nonlinearity."}
{"id": "2512.24558", "categories": ["quant-ph", "cond-mat.dis-nn", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24558", "abs": "https://arxiv.org/abs/2512.24558", "authors": ["Shuvro Chowdhury", "Jasper Pieterse", "Navid Anjum Aadit", "Johan H. Mentink", "Kerem Y. Camsari"], "title": "Probabilistic Computers for Neural Quantum States", "comment": null, "summary": "Neural quantum states efficiently represent many-body wavefunctions with neural networks, but the cost of Monte Carlo sampling limits their scaling to large system sizes. Here we address this challenge by combining sparse Boltzmann machine architectures with probabilistic computing hardware. We implement a probabilistic computer on field programmable gate arrays (FPGAs) and use it as a fast sampler for energy-based neural quantum states. For the two-dimensional transverse-field Ising model at criticality, we obtain accurate ground-state energies for lattices up to 80 $\\times$ 80 (6400 spins) using a custom multi-FPGA cluster. Furthermore, we introduce a dual-sampling algorithm to train deep Boltzmann machines, replacing intractable marginalization with conditional sampling over auxiliary layers. This enables the training of sparse deep models and improves parameter efficiency relative to shallow networks. Using this algorithm, we train deep Boltzmann machines for a system with 35 $\\times$ 35 (1225 spins). Together, these results demonstrate that probabilistic hardware can overcome the sampling bottleneck in variational simulation of quantum many-body systems, opening a path to larger system sizes and deeper variational architectures."}
{"id": "2512.24577", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24577", "abs": "https://arxiv.org/abs/2512.24577", "authors": ["Rui Mao", "Pei Yuan", "Jonathan Allcock", "Shengyu Zhang"], "title": "QAOA-MaxCut has barren plateaus for almost all graphs", "comment": null, "summary": "The QAOA has been the subject of intense study over recent years, yet the corresponding Dynamical Lie Algebra (DLA)--a key indicator of the expressivity and trainability of VQAs--remains poorly understood beyond highly symmetric instances. An exponentially scaling DLA dimension is associated with the presence of so-called barren plateaus (BP) in the optimization landscape, which renders training intractable. In this work, we investigate the DLA of QAOA applied to the canonical MaxCut, for both weighted and unweighted graphs. For weighted graphs, we show that when the weights are drawn from a continuous distribution, the DLA dimension grows as $Θ(4^n)$ almost surely for all connected graphs except paths and cycles. In the more common unweighted setting, we show that asymptotically all but an exponentially vanishing fraction of graphs have $Θ(4^n)$ large DLA dimension. The entire simple Lie algebra decomposition of the corresponding DLAs is also identified, from which we prove that the variance of the loss function is $O(1/2^n)$, implying that QAOA on these weighted and unweighted graphs all suffers from BP. Moreover, we give explicit constructions for families of graphs whose DLAs have exponential dimension, including cases whose MaxCut is in $\\mathsf P$. Our proof of the unweighted case is based on a number of splitting lemmas and DLA-freeness conditions that allow one to convert prohibitively complicated Lie algebraic problems into amenable graph theoretic problems. These form the basis for a new algorithm that computes such DLAs orders of magnitude faster than previous methods, reducing runtimes from days to seconds on standard hardware. We apply this algorithm to MQLib, a classical MaxCut benchmark suite covering over 3,500 instances with up to 53,130 vertices, and find that, ignoring edge weights, at least 75% of the instances possess a DLA of dimension at least $2^{128}$."}
{"id": "2512.24589", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2512.24589", "abs": "https://arxiv.org/abs/2512.24589", "authors": ["Grant Davis", "James K. Freericks"], "title": "Hidden rotation symmetry of the Jordan-Wigner transformation and its application to measurement in quantum computation", "comment": "Submitted to Symmetry", "summary": "Using a global rotation by theta about the z-axis in the spin sector of the Jordan-Wigner transformation rotates Pauli matrices X and Y in the x-y-plane, while it adds a global complex phase to fermionic quantum states that have a fixed number of particles. With the right choice of angles, this relates expectation values of Pauli strings containing products of X and Y to different products, which can be employed to reduce the number of measurements needed when simulating fermionic systems on a quantum computer. Here, we derive this symmetry and show how it can be applied to systems in Physics and Chemistry that involve Hamiltonians with only single-particle (hopping) and two-particle (interaction) terms. We also discuss the consequences of this for finding efficient measurement circuits in variational ground state preparation."}
{"id": "2512.24596", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.24596", "abs": "https://arxiv.org/abs/2512.24596", "authors": ["Wenxuan Xie", "John C. Schotland"], "title": "Band Structure and Dynamics of Single Photons in Atomic Lattices", "comment": null, "summary": "We present a framework to investigate the collective properties of atomic lattices in one, two, and three dimensions. We analyze the single-photon band structure and associated atomic decay rates, revealing a fundamental dependence on dimensionality. One- and two-dimensional arrays are shown to be inherently radiative, exhibiting band gaps and decay rates that oscillate between superradiant and subradiant regimes, as a function of lattice spacing. In contrast, three-dimensional lattices are found to be fundamentally non-radiative due to the inhibition of spontaneous emission, with decay only at discrete Bragg resonances. Furthermore, we demonstrate that this structural difference dictates the system dynamics, which crosses over from dissipative decay in lower dimensions to coherent transport in three dimensions. Our results provide insight into cooperative effects in atomic arrays at the single-photon level."}
{"id": "2512.24626", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2512.24626", "abs": "https://arxiv.org/abs/2512.24626", "authors": ["Dong-Qi Ma", "Qing-Xuan Jie", "Ya-Dong Hu", "Wen-Yi Zhu", "Yi-Chen Zhang", "Hong-Jie Fan", "Xiao-Kang Zhong", "Guang-Jie Chen", "Yan-Lei Zhang", "Tian-Yang Zhang", "Xi-Feng Ren", "Liang Chen", "Zhu-Bo Wang", "Guang-Can Guo", "Chang-Ling Zou"], "title": "Volcano Architecture for Scalable Quantum Processor Units", "comment": "Accepted to Science China Physics, Mechanics & Astronomy. 12 pages, 6 figures", "summary": "Quantum information processing platforms based on array of matter qubits, such as neutral atoms, trapped ions, and quantum dots, face significant challenges in scalable addressing and readout as system sizes increase. Here, we propose the \"Volcano\" architecture that establishes a new quantum processing unit implementation method based on optical channel mapping on a arbitrarily arranged static qubit array. To support the feasibility of Volcano architecture, we show a proof-of-principle demonstration by employing a photonic chip that leverages custom-designed three-dimensional waveguide structures to transform one-dimensional beam arrays into arbitrary two-dimensional output patterns matching qubit array geometries. We demonstrate parallel and independent control of 49-channel with negligible crosstalk and high uniformity. This architecture addresses the challenges in scaling up quantum processors, including both the classical link for parallel qubit control and the quantum link for efficient photon collection, and holds the potential for interfacing with neutral atom arrays and trapped ion crystals, as well as networking of heterogeneous quantum systems."}
{"id": "2512.24664", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24664", "abs": "https://arxiv.org/abs/2512.24664", "authors": ["Weixiang Ye"], "title": "Variance Decomposition in Bohmian Mechanics with Weak Actual Value Field and Quantum Potential", "comment": null, "summary": "We introduce a trajectory-based decomposition of quantum variances within Bohmian mechanics. By extending the weak actual value to a field on configuration space, we prove, under strong regularity conditions for stationary bound states, that the standard quantum variance splits into two non-negative terms: the ensemble variance of weak actual value and a quantum termarising from phase-amplitude coupling. For momentum, linking variance-level fluctuations to the average quantum potential. The decomposition fails to provide a physical interpretation for spin, reinforcing the Bohmian tenet that only position is fundamental. The work provides a formal tool for analyzing quantum fluctuations and clarifies the interpretative limits of such a trajectory-based approach."}
{"id": "2512.24685", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24685", "abs": "https://arxiv.org/abs/2512.24685", "authors": ["Xuyang Huang", "Han-Ze Li", "Jian-Xin Zhong"], "title": "A fast and exact algorithm for stabilizer Rényi entropy via XOR-FWHT", "comment": null, "summary": "Quantum advantage is widely understood to rely on key quantum resources beyond entanglement, among which nonstabilizerness (quantum ``magic'') plays a central role in enabling universal quantum computation. However, a direct brute-force enumeration of all Pauli strings and the corresponding expectation values from a length-$2^N$ state vector, where $N$ is the system size, yields an overall computational cost scaling as $O(8^N)$, which quickly becomes infeasible as the system size grows. Here we reformulate the second-order stabilizer Rényi entropy in a bitstring language, expose an underlying XOR-convolution structure on $\\mathbb Z_2^N$, and reduce the computation to $2^N$ fast Walsh-Hadamard transforms of length, together with pointwise operations, yielding a deterministic and exact XOR fast Walsh-Hadamard transforms algorithm with runtime scaling $O(N4^N)$ and natural parallelism. This algorithm enables high-precision, medium-scale exact calculations for generic state vectors. It provides a practical tool for probing the scaling, phase diagnostics, and dynamical fine structure of quantum magic in many-body systems."}
{"id": "2512.24687", "categories": ["quant-ph", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.24687", "abs": "https://arxiv.org/abs/2512.24687", "authors": ["Wenbo Qiao", "Peng Zhang", "Qinghua Hu"], "title": "Quantum Visual Word Sense Disambiguation: Unraveling Ambiguities Through Quantum Inference Model", "comment": null, "summary": "Visual word sense disambiguation focuses on polysemous words, where candidate images can be easily confused. Traditional methods use classical probability to calculate the likelihood of an image matching each gloss of the target word, summing these to form a posterior probability. However, due to the challenge of semantic uncertainty, glosses from different sources inevitably carry semantic biases, which can lead to biased disambiguation results. Inspired by quantum superposition in modeling uncertainty, this paper proposes a Quantum Inference Model for Unsupervised Visual Word Sense Disambiguation (Q-VWSD). It encodes multiple glosses of the target word into a superposition state to mitigate semantic biases. Then, the quantum circuit is executed, and the results are observed. By formalizing our method, we find that Q-VWSD is a quantum generalization of the method based on classical probability. Building on this, we further designed a heuristic version of Q-VWSD that can run more efficiently on classical computing. The experiments demonstrate that our method outperforms state-of-the-art classical methods, particularly by effectively leveraging non-specialized glosses from large language models, which further enhances performance. Our approach showcases the potential of quantum machine learning in practical applications and provides a case for leveraging quantum modeling advantages on classical computers while quantum hardware remains immature."}
{"id": "2512.24705", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24705", "abs": "https://arxiv.org/abs/2512.24705", "authors": ["Monika Schleier-Smith"], "title": "Interfacing Atomic Spins with Photons for Quantum Metrology, Simulation and Computation", "comment": "This manuscript has been submitted to appear in the Proceedings of the Course 214 \"Quantum Computers and Simulators with Atoms\" of the International School of Physics \"Enrico Fermi\" (Varenna, July 2024)", "summary": "These lecture notes discuss applications of atom-light interactions in cavities to quantum metrology, simulation, and computation. A focus is on nonlocally interacting spin systems realized by coupling many atoms to a delocalized mode of light. We will build up from the fundamentals: understanding how a cavity enables light to coherently imprint information on atoms and atoms to imprint information on the light, enabling quantum non-demolition measurements that constitute a powerful means of engineering nonclassical states. By extension, letting the intracavity light act back on the atoms enables coherent photon-mediated interactions. I start by discussing collective spin models, emphasizing applications in entanglement-enhanced metrology, before proceeding to richer many-body physics enabled by incorporating spatiotemporal control or employing multiple cavity modes. I will highlight opportunities for leveraging these tools for quantum simulations inspired by problems in condensed matter and quantum gravity. Along the way, I provide a pedagogical introduction to criteria for strong atom-light coupling, illustrate how the corresponding figure of merit -- the cooperativity -- sets fundamental limits on the coherence of atom-light interactions, and discuss prospects for harnessing high-cooperativity cavity QED in quantum simulation and computation."}
{"id": "2512.24718", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24718", "abs": "https://arxiv.org/abs/2512.24718", "authors": ["Hai Zhong", "Qianqian Hu", "Zhiyue Zuo", "Zhipeng Wang", "Duan Huang", "Ying Guo"], "title": "Continuous-variable quantum key distribution network based on entangled states of optical frequency combs", "comment": null, "summary": "Continuous-variable quantum key distribution (CVQKD) features a high key rate and compatibility with classical optical communication. Developing expandable and efficient CVQKD networks will promote the deployment of large-scale quantum communication networks in the future. This paper proposes a CVQKD network based on the entangled states of an optical frequency comb. This scheme generates Einstein-Podolsky-Rosen entangled states with a frequency comb structure through the process of a type-II optical parametric oscillator. By combining with the scheme of entanglement in the middle, a fully connected CVQKD network capable of distributing secret keys simultaneously can be formed. We analyze the security of the system in the asymptotic case. Simulation results show that under commendable controlling of system loss and noise, the proposed scheme is feasible for deploying a short-distance fully connected CVQKD network. Loss will be the main factor limiting the system's performance. The proposed scheme provides new ideas for a multi-user fully connected CVQKD network."}
{"id": "2512.24744", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24744", "abs": "https://arxiv.org/abs/2512.24744", "authors": ["Debankan Sannamoth", "Kristine Boone", "Arnaud Carignan-Dugas", "Akel Hashim", "Irfan Siddiqi", "Karl Mayer", "Joseph Emerson"], "title": "Easier randomizing gates provide more accurate fidelity estimation", "comment": "15 pages, 7 figures. Comments are welcome", "summary": "Accurate benchmarking of quantum gates is crucial for understanding and enhancing the performance of quantum hardware. A standard method for this is interleaved benchmarking, a technique which estimates the error on an interleaved target gate by comparing cumulative error rates of randomized sequences implemented with the interleaved gate and without it. In this work, we show both numerically and experimentally that the standard approach of interleaved randomized benchmarking (IRB), which uses the multi-qubit Clifford group for randomization, can produce highly inaccurate and even physically impossible estimates for the error on the interleaved gate in the presence of coherent errors. Fortunately we also show that interleaved benchmarking performed with cycle benchmarking, which randomizes with single qubit Pauli gates, provides dramatically reduced systematic uncertainty relative to standard IRB, and further provides as host of additional benefits including data reusability. We support our conclusions with a theoretical framework for bounding systematic errors, extensive numerical results comparing a range of interleaved protocols under fixed resource costs, and experimental demonstrations on three quantum computing platforms."}
{"id": "2512.24759", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24759", "abs": "https://arxiv.org/abs/2512.24759", "authors": ["Sascha Mücke", "Thore Gerlach", "Nico Piatkowski"], "title": "Quadratic Continuous Quantum Optimization", "comment": "Presented at the Seventh Data Science Meets Optimization (DSO) Workshop at ECML PKDD 2025 in Porto", "summary": "Quantum annealers can solve QUBO problems efficiently but struggle with continuous optimization tasks like regression due to their discrete nature. We introduce Quadratic Continuous Quantum Optimization (QCQO), an anytime algorithm that approximates solutions to unconstrained quadratic programs via a sequence of QUBO instances. Rather than encoding real variables as binary vectors, QCQO implicitly represents them using continuous QUBO weights and iteratively refines the solution by summing sampled vectors. This allows flexible control over the number of binary variables and adapts well to hardware constraints. We prove convergence properties, introduce a step size adaptation scheme, and validate the method on linear regression. Experiments with simulated and real quantum annealers show that QCQO achieves accurate results with fewer qubits, though convergence slows on noisy hardware. Our approach enables quantum annealing to address a wider class of continuous problems."}
{"id": "2512.24790", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24790", "abs": "https://arxiv.org/abs/2512.24790", "authors": ["Arseny Pantsialei"], "title": "Harmonic rigidity at fixed spectral gap in one dimension", "comment": "22 pages, 1 figure", "summary": "We solve the static isoperimetric problem underlying the Mandelstam-Tamm bound. Among one-dimensional confining potentials with a fixed spectral gap, we prove that the harmonic trap is the unique maximizer of the ground-state position variance. As a consequence, we obtain a sharp geometric quantum speed-limit bound on the position-position component of the quantum metric, and we give a necessary-and-sufficient condition for when the bound is saturated. Beyond the exact extremum, we establish quantitative rigidity. We control the Thomas-Reiche-Kuhn spectral tail and provide square-integrable structural stability for potentials that nearly saturate the bound. We further extend the analysis to magnetic settings, deriving a longitudinal necessary-and-sufficient characterization and transverse bounds expressed in terms of guiding-center structure. Finally, we outline applications to bounds on static polarizability, limits on the quantum metric, and benchmarking of trapping potentials."}
{"id": "2512.24798", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2512.24798", "abs": "https://arxiv.org/abs/2512.24798", "authors": ["J. Dai", "A. Molochkov", "A. J. Niemi", "J. Westerholm"], "title": "Non-Abelian Geometric Phases in Triangular Structures And Universal SU(2) Control in Shape Space", "comment": "2 figures", "summary": "We construct holonomic quantum gates for qubits that are encoded in the near-degenerate vibrational $E$-doublet of a deformable three-body system. Using Kendall's shape theory, we derive the Wilczek--Zee connection governing adiabatic transport within the $E$-manifold. We show that its restricted holonomy group is $\\mathrm{SU}(2)$, implying universal single-qubit control by closed loops in shape space. We provide explicit loops implementing a $π/2$ phase gate and a Hadamard-type gate. For two-qubit operations, we outline how linked holonomic cycles in arrays generate a controlled Chern--Simons phase, enabling an entangling controlled-$X$ (CNOT) gate. We present a Ramsey/echo interferometric protocol that measures the Wilson loop trace of the Wilczek--Zee connection for a control cycle, providing a gauge-invariant signature of the non-Abelian holonomy. As a physically realizable demonstrator, we propose bond-length modulations of a Cs($6s$)--Cs($6s$)--Cs($nd_{3/2}$)\n  Rydberg trimer in optical tweezers and specify operating conditions that suppress leakage out of the $E$-manifold."}
{"id": "2512.24801", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24801", "abs": "https://arxiv.org/abs/2512.24801", "authors": ["Sabrina Herbst", "Ivona Brandić", "Adrián Pérez-Salinas"], "title": "Limits of quantum generative models with classical sampling hardness", "comment": "29 pages, 9 figures", "summary": "Sampling tasks have been successful in establishing quantum advantages both in theory and experiments. This has fueled the use of quantum computers for generative modeling to create samples following the probability distribution underlying a given dataset. In particular, the potential to build generative models on classically hard distributions would immediately preclude classical simulability, due to theoretical separations. In this work, we study quantum generative models from the perspective of output distributions, showing that models that anticoncentrate are not trainable on average, including those exhibiting quantum advantage. In contrast, models outputting data from sparse distributions can be trained. We consider special cases to enhance trainability, and observe that this opens the path for classical algorithms for surrogate sampling. This observed trade-off is linked to verification of quantum processes. We conclude that quantum advantage can still be found in generative models, although its source must be distinct from anticoncentration."}
{"id": "2512.24806", "categories": ["quant-ph", "gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2512.24806", "abs": "https://arxiv.org/abs/2512.24806", "authors": ["Michele Arzano", "Goffredo Chirco"], "title": "Operator Entanglement from Non-Commutative Symmetries", "comment": "7 pages, 2 figures", "summary": "We argue that Hopf-algebra deformations of symmetries -- as encountered in non-commutative models of quantum spacetime -- carry an intrinsic content of $operator$ $entanglement$ that is enforced by the coproduct-defined notion of composite generators. As a minimal and exactly solvable example, we analyze the $U_q(\\mathfrak{su}(2))$ quantum group and a two-qubit realization obtained from the coproduct of a $q$-deformed single-spin Hamiltonian. Although the deformation is invisible on a single qubit, it resurfaces in the two-qubit sector through the non-cocommutative coproduct, yielding a family of intrinsically nonlocal unitaries. We compute their operator entanglement in closed form and show that, for Haar-uniform product inputs, their entangling power is fully determined by the latter. This provides a concrete mechanism by which non-commutative symmetries enforce a baseline of entanglement at the algebraic level, with implications for information dynamics in quantum-spacetime settings and quantum information processing."}
{"id": "2512.24822", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2512.24822", "abs": "https://arxiv.org/abs/2512.24822", "authors": ["Chen-Yang Wang", "Jing-Ping Xu", "Ce Wang", "Ya-Ping Yang"], "title": "Unsupervised Topological Phase Discovery in Periodically Driven Systems via Floquet-Bloch State", "comment": null, "summary": "Floquet engineering offers an unparalleled platform for realizing novel non-equilibrium topological phases. However, the unique structure of Floquet systems, which includes multiple quasienergy gaps, poses a significant challenge to classification using conventional analytical methods. We propose a novel unsupervised machine learning framework that employs a kernel defined in momentum-time ($\\boldsymbol{k},t$) space, constructed directly from Floquet-Bloch eigenstates. This approach is intrinsically data-driven and requires no prior knowledge of the underlying topological invariants, providing a fundamental advantage over prior methods that rely on abstract concepts like the micromotion operator or homotopic transformations. Crucially, this work successfully reveals the intrinsic topological characteristics encoded within the Floquet eigenstates themselves. We demonstrate that our method robustly and simultaneously identifies the topological invariants associated with both the $0$-gap and the $π$-gap across various symmetry classes (1D AIII, 1D D, and 2D A), establishing a robust methodology for the systematic classification and discovery of complex non-equilibrium topological matter."}
{"id": "2512.24839", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24839", "abs": "https://arxiv.org/abs/2512.24839", "authors": ["Arunabha Das", "Paranjoy Chaki", "Priya Ghosh", "Ujjwal Sen"], "title": "Role reversal in quantum Mpemba effect", "comment": "13 pages, 4 figures", "summary": "We investigate the quantum Mpemba effect in a dissipative Dicke model, which consists of a spin-1/2 ensemble coupled to a bosonic mode, which in turn is coupled to a bosonic bath. We derive a sufficient criterion for occurrence of the quantum Mpemba effect, characterized by quantum coherence, in this model. We introduce the phenomenon of role reversal in the Mpemba effect, wherein changes in the system parameters invert the relaxation ordering of a given pair of initial states that exhibit the Mpemba effect, causing the faster-relaxing state to become slower and vice versa. We find the existence of role reversal in Mpemba effect for this Dicke model using different relaxation measures, including differential quantum coherence and entanglement, and trace distance, between the time-evolved and steady states."}
{"id": "2512.24857", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.24857", "abs": "https://arxiv.org/abs/2512.24857", "authors": ["Qin-Qin Wang", "Xiao-Ye Xu", "Yong-Jian Han", "Chuan-Feng Li", "Guang-Can Guo"], "title": "Measuring Mixed-State Topological Invariant in Open Photonic Quantum Walk", "comment": "6 pages, 3 figures", "summary": "Pure-state manifestations of geometric phase are well established and have found applications across essentially all branches of physics, yet their generalization to mixed-state regimes remains largely unexplored experimentally. The Uhlmann geometric phase offers a natural extension of pure-state paradigms and can exhibit a topological character. However, observation of this invariant is impeded by the incompatibility between Uhlmann parallel transport and Hamiltonian dynamics, as well as the difficulty of preparing topologically nontrivial mixed states. To address this challenge, we report an experimentally accessible protocol for directly measuring the mixed-state topological invariant. By engineering controlled nonunitary dynamics in a photonic quantum walk, we prepare topologically nontrivial mixed states from a trivial initial state. Furthermore, by machine-learning the full density matrix in momentum space, we directly extract the quantized geometric phase of the nontrivial mixed states. These results highlight a geometric phase framework that naturally extends to open quantum systems both in and out of thermal equilibrium."}
{"id": "2512.24878", "categories": ["quant-ph", "physics.ins-det", "physics.optics"], "pdf": "https://arxiv.org/pdf/2512.24878", "abs": "https://arxiv.org/abs/2512.24878", "authors": ["David McFadden", "Rainer Heintzmann"], "title": "Image-Plane Detection of Spatially Entangled Photon Pairs with a CMOS Camera", "comment": "10 pages, 3 figures", "summary": "Spatially entangled photon pairs (biphotons) generated by spontaneous parametric down-conversion offer unique opportunities for quantum imaging, but image-plane biphoton correlations are difficult to observe with camera-based detectors. Previous camera-based biphoton imaging experiments have relied on photon-counting detection, which necessitates operation deep in the photon-sparse regime and requires extremely low dark rates.\n  Here, we demonstrate the detection of spatial biphoton joint probability distributions in both the image plane and the pupil plane (also termed \"near-field plane\" and \"far-field plane\" respectively) using a conventional scientific CMOS camera operated in linear mode. We work at mesoscopic intensity levels, corresponding to a photon flux approximately four orders of magnitude higher than typical photon-counting approaches. From the measured image- and pupil plane correlations, we observe position and momentum correlations consistent with an EPR-type entanglement witness.\n  A tailored correlation analysis suited for image plane imaging suppresses detector artifacts and intensity fluctuations, enabling acquisition with significantly fewer frames. Our results demonstrate that spatially entangled-light imaging can be performed efficiently with standard imaging hardware, extending quantum imaging techniques beyond the photon-counting regime."}
{"id": "2512.24883", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24883", "abs": "https://arxiv.org/abs/2512.24883", "authors": ["H. B. Crispin", "N. Talebi"], "title": "Probing quantum-coherent dynamics with free electrons", "comment": "11 pages (6 main text + 5 supplementary), 3 figures (3 main text). Comments are welcome", "summary": "Recent advances in time-resolved cathodoluminescence have enabled ultrafast studies of single emitters in quantum materials with femtosecond temporal resolution. Here, we develop a quantum theory modeling the dynamics of free electrons interacting with quantum emitters in arbitrary initial states. Our analysis reveals that a free electron can induce transient coherent oscillations in the populations when the system is initially prepared in a coherent superposition of its states. Moreover, the electron energy spectrum exhibits a clear signature of the quantum coherence and sensitivity to the transition frequency of the emitter. These coherence effects manifest themselves as oscillations in the zero-loss peak of the spectral energy-loss probability. Our findings pave the way for characterization of quantum-coherent dynamics of individual quantum emitters by electron-probes."}
{"id": "2512.24884", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24884", "abs": "https://arxiv.org/abs/2512.24884", "authors": ["M. Abdellaoui", "N. -E. Abouelkhir", "A. Slaoui", "R. Ahl Laamara", "S. Haddadi"], "title": "Quantumness of hybrid systems under quantum noise", "comment": "9 pages, 2 figures", "summary": "We investigate the quantum correlations in an axially symmetric hybrid qubit-qutrit system subjected to different noisy environments. We first introduce a physical model and analyze its Hamiltonian structure, emphasizing the role of hybrid dimensionality and axial symmetry. The effects of decoherence are then examined under two local noise mechanisms, namely dephasing and phase-flip channels, acting on the qubit and qutrit subsystems in both symmetric and asymmetric configurations. Quantum correlations are quantified using negativity to capture entanglement and quantum discord based on linear entropy to characterize more general nonclassical correlations. Our results show that both thermal fluctuations and phase noise lead to a monotonic degradation of quantum correlations, with increasing temperature accelerating coherence loss and inducing entanglement sudden death at finite temperatures. While negativity vanishes abruptly under sufficiently strong noise, quantum discord persists beyond the entanglement threshold, revealing residual quantum correlations in mixed states. We further demonstrate that asymmetric noise configurations significantly enhance the robustness of both entanglement and discord by partially shielding coherence in the less affected subsystem. A comparative analysis reveals that phase-flip noise is more destructive than pure dephasing, leading to faster suppression of quantum correlations."}
{"id": "2512.24902", "categories": ["quant-ph", "cs.DC"], "pdf": "https://arxiv.org/pdf/2512.24902", "abs": "https://arxiv.org/abs/2512.24902", "authors": ["Kuan-Cheng Chen", "Felix Burt", "Nitish K. Panigrahy", "Kin K. Leung"], "title": "Adaptive Resource Orchestration for Distributed Quantum Computing Systems", "comment": null, "summary": "Scaling quantum computing beyond a single device requires networking many quantum processing units (QPUs) into a coherent quantum-HPC system. We propose the Modular Entanglement Hub (ModEn-Hub) architecture: a hub-and-spoke photonic interconnect paired with a real-time quantum network orchestrator. ModEn-Hub centralizes entanglement sources and shared quantum memory to deliver on-demand, high-fidelity Bell pairs across heterogeneous QPUs, while the control plane schedules teleportation-based non-local gates, launches parallel entanglement attempts, and maintains a small ebit cache. To quantify benefits, we implement a lightweight, reproducible Monte Carlo study under realistic loss and tight round budgets, comparing a naive sequential baseline to an orchestrated policy with logarithmically scaled parallelism and opportunistic caching. Across 1-128 QPUs and 2,500 trials per point, ModEn-Hub-style orchestration sustains about 90% teleportation success while the baseline degrades toward about 30%, at the cost of higher average entanglement attempts (about 10-12 versus about 3). These results provide clear, high-level evidence that adaptive resource orchestration in the ModEn-Hub enables scalable and efficient quantum-HPC operation on near-term hardware."}
{"id": "2512.24926", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24926", "abs": "https://arxiv.org/abs/2512.24926", "authors": ["Hongwei Huang", "Jie Zhou", "Weizhou Cai", "Weiting Wang", "Yilong Zhou", "Yunlai Zhu", "Ziyue Hua", "Yifang Xu", "Lida Sun", "Juan Song", "Tang Su", "Ming Li", "Haifeng Yu", "Chang-Ling Zou", "Luyan Sun"], "title": "High-performance quantum interconnect between bosonic modules beyond transmission loss constraints", "comment": null, "summary": "Distributed quantum computing architectures require high-performance quantum interconnects between quantum information processing units, while previous implementations have been fundamentally limited by transmission line losses. Here, we demonstrate a low-loss interconnect between two superconducting modules using an aluminum coaxial cable, achieving a bus mode quality factor of 1.7e6. By employing SNAIL as couplers, we realize inter-modular state transfer in 0.8 μs via a three-wave mixing process. The state transfer fidelity reaches 98.2% for quantum states encoded in the first two energy levels, achieving a Bell state fidelity of 92.5%. Furthermore, we show the capability to transfer high-dimensional states by successfully transmitting binomially encoded logical states. Systematic characterization reveals that performance constraints have shifted from transmission line losses (contributing merely 0.2% infidelity) to module-channel interface effects and local Kerr nonlinearities. Our work advances the realization of quantum interconnects approaching fundamental capacity limits, paving the way for scalable distributed quantum computing and efficient quantum communications."}
{"id": "2512.24942", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24942", "abs": "https://arxiv.org/abs/2512.24942", "authors": ["Ivan Ahumada", "Max Badcott", "James P. Edwards", "Craig McNeile", "Filippo Ricchetti", "Federico Grasselli", "Guido Goldoni", "Olindo Corradini", "Marco Palomino"], "title": "Multi-particle quantum systems within the Worldline Monte Carlo formalism", "comment": "23 pages (with 3 appendices), 14 figures", "summary": "We extend the Worldline Monte Carlo approach to computationally simulating the Feynman path integral of non-relativistic multi-particle quantum-mechanical systems. We show how to generate an arbitrary number of worldlines distributed according to the (free) kinetic part of the multi-particle quantum dynamics and how to simulate interactions between worldlines in the ensemble. We test this formalism with two- and three-particle quantum mechanical systems, with both long range Coulomb-like interactions between the particles and external fields acting separately on the particles, in various spatial dimensionality. We extract accurate estimations of the ground state energy of these systems using the late-time behaviour of the propagator, validating our approach with numerically exact solutions obtained via straightforward diagonalisation of the Hamiltonian. Systematic benchmarking of the new approach, presented here for the first time, shows that the computational complexity of Wordline Monte Carlo scales more favourably with respect to standard numerical alternatives. The method, which is general, numerically exact, and computationally not intensive, can easily be generalised to relativistic systems."}
{"id": "2512.24950", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24950", "abs": "https://arxiv.org/abs/2512.24950", "authors": ["Minyi Huang"], "title": "The uncertainty constants: A unified framework of two, three and four observables", "comment": "4 pages", "summary": "Uncertainty is a fundamental and important concept in quantum mechanics. Recent works have revealed both the product and sum forms of uncertainty constants for three observables. Such a result is intimately to the properties of Pauli operators. In this work, using the technique in matrix theory, we give an alternative proof for the case of three observables, and generalize the result to the case of four measurements. Comparing with the original proof, such a derivation is simplified. Moreover, the discussions can deal with the summation form of uncertainty relation for two, three and four observables in a unified way."}
{"id": "2512.24951", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24951", "abs": "https://arxiv.org/abs/2512.24951", "authors": ["J. M. Wollenberg", "F. Perona", "A. Palaci", "H. Wenzel", "H. Christopher", "A. Knigge", "W. Knolle", "J. M. Bopp", "T. Schröder"], "title": "Laser intracavity absorption magnetometry for optical quantum sensing", "comment": "8 pages, 5 figures", "summary": "Intracavity absorption spectroscopy (ICAS) is a well-established technique for detecting weak absorption signals with ultrahigh sensitivity. Here, we extend this concept to magnetometry using nitrogen-vacancy (NV) centers in diamond. We introduce laser intracavity absorption magnetometry (LICAM), a concept that is in principle applicable to a broader class of optical quantum sensors, including optically pumped magnetometers. Using an electrically driven, edge-emitting diode laser that operates self-sustainably, we show that LICAM enables highly sensitive magnetometers operating under ambient conditions. Near the lasing threshold, we achieve a 475-fold enhancement in optical contrast and a 180-fold improvement in magnetic sensitivity compared with a conventional single-pass geometry. The experimental results are accurately described by a rate-equation model for single-mode diode lasers. From our measurements, we determine a projected shot-noise-limited sensitivity in the $\\mathrm{pT}\\,\\mathrm{Hz}^{-1/2}$ range and show that, with realistic device improvements, sensitivities down to the $\\mathrm{fT}\\,\\mathrm{Hz}^{-1/2}$ scale are attainable."}
{"id": "2512.24956", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24956", "abs": "https://arxiv.org/abs/2512.24956", "authors": ["Domingos S. P. Salazar"], "title": "Matrix Thermodynamic Uncertainty Relation for Non-Abelian Charge Transport", "comment": null, "summary": "Thermodynamic uncertainty relations (TURs) bound the precision of currents by entropy production, but quantum transport of noncommuting (non-Abelian) charges challenges standard formulations because different charge components cannot be monitored within a single classical frame. We derive a process-level matrix TUR starting from the operational entropy production $Σ= D(ρ'_{SE}\\|ρ'_S\\!\\otimes\\!ρ_E)$. Isolating the experimentally accessible bath divergence $D_{\\mathrm{bath}}=D(ρ'_E\\|ρ_E)$, we prove a fully nonlinear, saturable lower bound valid for arbitrary current vectors $Δq$: $D_{\\mathrm{bath}} \\ge B(Δq,V,V')$, where the bound depends only on the transported-charge signal $Δq$ and the pre/post collision covariance matrices $V$ and $V'$. In the small-fluctuation regime $D_{\\mathrm{bath}}\\geq\\frac12\\,Δq^{\\mathsf T}V^{-1}Δq+O(\\|Δq\\|^4)$, while beyond linear response it remains accurate. Numerical strong-coupling qubit collisions illustrate the bound and demonstrate near-saturation across broad parameter ranges using only local measurements on the bath probe."}
{"id": "2512.24973", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24973", "abs": "https://arxiv.org/abs/2512.24973", "authors": ["Rafał Potempa", "Michał Kordasz", "Józef P. Cyran", "Kamil Wereszczyński", "Krzysztof Simiński"], "title": "GEQIE Framework for Rapid Quantum Image Encoding", "comment": null, "summary": "This work presents a Python framework named after the General Equation of Quantum Image Encoding (GEQIE). The framework creates the image-encoding state using a unitary gate, which can later be transpiled to target quantum backends. The benchmarking results, simulated with different noise levels, demonstrate the correctness of the already implemented encoding methods and the usability of the framework for more sophisticated research tasks based on quantum image encodings. Additionally, we present a showcase example of Cosmic Web dark-matter density snapshot encoding and high-accuracy retrieval (PCC = 0.995) to demonstrate the extendability of the GEQIE framework to multidimensional data and its applicability to other fields of research."}
{"id": "2512.24981", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24981", "abs": "https://arxiv.org/abs/2512.24981", "authors": ["Yuma Nakanishi", "Tomohiro Sasamoto"], "title": "Lindbladian PT phase transitions", "comment": null, "summary": "A parity-time (PT) transition is a spectral transition characteristic of non-Hermitian generators; it typically occurs at an exceptional point, where multiple eigenvectors coalesce. The concept of a PT transition has been extended to Markovian open quantum systems, which are described by the GKSL equation. Interestingly, the PT transition in many-body Markovian open quantum systems, the so-called \\textit{Lindbladian PT (L-PT) phase transition}, is closely related to two classes of exotic nonequilibrium many-body phenomena: \\textit{continuous-time crystals} and \\textit{non-reciprocal phase transitions}. In this review, we describe the recent advances in the study of L-PT phase transitions. First, we define PT symmetry in three distinct contexts: non-Hermitian systems, nonlinear dynamical systems, and Markovian open quantum systems, highlighting the interconnections between these frameworks. Second, we develop mean-field theories of L-PT phase transitions for collective-spin systems and for bipartite bosonic systems with particle-number conservation. Within these classes of models, we show that L-PT symmetry can induce a breaking of continuous time-translation symmetry down to a discrete one, leading to persistent periodic dynamics. We further demonstrate that the L-PT phase transition point is typically \\textit{a critical exceptional point}, where multiple collective excitation modes with zero excitation spectrum coalesce. These findings establish an explicit connection to continuous-time crystals and non-reciprocal phase transitions. Third, going beyond the mean-field theory, we analyze statistical and quantum properties, such as purity and quantum entanglement indicators of time-independent steady states for several specific models with the L-PT symmetry. Finally, we discuss future research directions for L-PT phase transitions."}
{"id": "2512.24982", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24982", "abs": "https://arxiv.org/abs/2512.24982", "authors": ["Isaac H. Kim", "Tuomas Laakkonen"], "title": "Any Clifford+T circuit can be controlled with constant T-depth overhead", "comment": "14 pages", "summary": "Since an n-qubit circuit consisting of CNOT gates can have up to $Ω(n^2/\\log{n})$ CNOT gates, it is natural to expect that $Ω(n^2/\\log{n})$ Toffoli gates are needed to apply a controlled version of such a circuit. We show that the Toffoli count can be reduced to at most n. The Toffoli depth can also be reduced to O(1), at the cost of 2n Toffoli gates, even without using any ancilla or measurement. In fact, using a measurement-based uncomputation, the Toffoli depth can be further reduced to 1. From this, we give two corollaries: any controlled Clifford circuit can be implemented with O(1) T-depth, and any Clifford+T circuit with T-depth D can be controlled with T-depth O(D), even without ancillas. As an application, we show how to catalyze a rotation by any angle up to precision $ε$ in T-depth exactly 1 using a universal $\\lceil\\log_2(8/ε)\\rceil$-qubit catalyst state."}
{"id": "2512.24992", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24992", "abs": "https://arxiv.org/abs/2512.24992", "authors": ["Yi-Han Yu", "Xin-Yi Li", "Kai Xu", "Heng Fan"], "title": "Mathieu Control of the Effective Coupling in Superconducting Qubits", "comment": "11 pages, 2 figures", "summary": "A common challenge in superconducting quantum circuits is the trade-off between strong coupling and computational subspace integrity. We present Mathieu control, which uses a non-resonant two-photon drive to create a selective nonlinear frequency shift. This shift modifies interactions while preserving qubit states, enabling continuous tuning of the ZZ coupling, including full suppression, and integrating single- and two-qubit gates with low leakage. For a qubit-coupler-qubit device, it allows independent ZZ control, facilitating a programmable Heisenberg (XXZ) Hamiltonian. Extended to a five-qubit chain, the system can be reconfigured to simulate dynamics of quantum magnetic phases. Mathieu control thus provides a framework for high-fidelity quantum logic and programmable simulation."}
{"id": "2512.25004", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25004", "abs": "https://arxiv.org/abs/2512.25004", "authors": ["Jonas Stadelmann", "Julian Übelher", "Mafalda Ramôa", "Bharath Sambasivam", "Edwin Barnes", "Sophia E. Economou"], "title": "Strategies for Overcoming Gradient Troughs in the ADAPT-VQE Algorithm", "comment": null, "summary": "The adaptive derivative-assembled problem-tailored variational quantum eigensolver (ADAPT-VQE) provides a promising approach for simulating highly correlated quantum systems on quantum devices, as it strikes a balance between hardware efficiency, trainability, and accuracy. Although ADAPT-VQE avoids many of the shortcomings of other VQEs, it is sometimes hindered by a phenomenon known as gradient troughs. This refers to a non-monotonic convergence of the gradients, which may become very small even though the minimum energy has not been reached. This results in difficulties finding the right operators to add to the ansatz, due to the limited number of shots and statistical uncertainties, leading to stagnation in the circuit structure optimization. In this paper, we propose ways to detect and mitigate this phenomenon. Leveraging the non-commutative algebra of the ansatz, we develop heuristics for determining where to insert new operators into the circuit. We find that gradient troughs are more likely to arise when the same locations are used repeatedly for new operator insertions. Our novel protocols, which add new operators in different ansatz positions, allow us to escape gradient troughs and thereby lower the measurement cost of the algorithm. This approach achieves an effective balance between cost and efficiency, leading to faster convergence without compromising the low circuit depth and gate count of ADAPT-VQE."}
{"id": "2512.25068", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25068", "abs": "https://arxiv.org/abs/2512.25068", "authors": ["Pawel Cieslinski", "Lukas Knips", "Harald Weinfurter", "Wieslaw Laskowski"], "title": "No-cost Bell Nonlocality Certification from Quantum Tomography and Its Applications in Quantum Magic Witnessing", "comment": "11 pages, 3 figures", "summary": "Tomographic measurements are the standard tool for characterizing quantum states, yet they are usually regarded only as means for state reconstruction or fidelity measurement. Here, we show that the same Pauli-basis measurements (X, Y, Z) can be directly employed for the certification of nonlocality at no additional experimental cost. Our framework allows any tomographic data - including archival datasets -- to be reinterpreted in terms of fundamental nonlocality tests. We introduce a generic, constructive method to generate tailored Bell inequalities and showcase their applicability to certify the non-locality of states in realistic experimental scenarios. Recognizing the stabilizer nature of the considered operators, we analyze our inequalities in the context of witnessing quantum magic - a crucial resource for quantum computing. Our approach requires Pauli measurements only and tests the quantum magic solely through the resources present in the state. Our results establish a universal standard that unifies state tomography with nonlocality certification and its application to quantum magic witnessing, thereby streamlining both fundamental studies and practical applications."}
{"id": "2512.23721", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.23721", "abs": "https://arxiv.org/abs/2512.23721", "authors": ["Mikołaj Sienicki", "Krzysztof Sienicki"], "title": "Notes on Crowther and the \"Interpretation\" of Quantum Mechanics (arXiv:2512.14315)", "comment": "13 pages, many references, notes on arXiv:2512.14315", "summary": "We read Karen Crowther's \\emph{Another 100 Years of Quantum Interpretation?} with two practical goals. First, we spell out what she means by interpretation'': an attempt to provide understanding (not just predictions), which may be representationalist or non-representationalist, and which she contrasts with deeper \\emph{reductive} (inter-theoretic) explanation -- especially in the quantum-gravity setting. Second, we list twelve points where the paper's physics-facing wording could be sharpened. In our view, several claims are directionally well-motivated but stated more strongly than the underlying physics supports, or they run together distinct notions (e.g.\\ degrees of freedom,'' singularity,'' and different senses of locality'') that need careful separation. We end by suggesting that the philosophical question is genuinely worthwhile, but the physics should be phrased more cautiously so that heuristic motivation is not mistaken for strict implication."}
{"id": "2512.24390", "categories": ["cond-mat.str-el", "hep-th", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24390", "abs": "https://arxiv.org/abs/2512.24390", "authors": ["Bram Vancraeynest-De Cuiper", "Weronika Wiesiolek", "Frank Verstraete"], "title": "Les Houches Lectures Notes on Tensor Networks", "comment": "Comments welcome", "summary": "Tensor networks provide a powerful new framework for classifying and simulating correlated and topological phases of quantum matter. Their central premise is that strongly correlated matter can only be understood by studying the underlying entanglement structure and its associated (generalised) symmetries. In essence, tensor networks provide a compressed, holographic description of the complicated vacuum fluctuations in strongly correlated systems, and as such they break down the infamous many-body exponential wall. These lecture notes provide a concise overview of the most important conceptual, computational and mathematical aspects of this theory."}
{"id": "2512.24709", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "math-ph", "math.AT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24709", "abs": "https://arxiv.org/abs/2512.24709", "authors": ["Hisham Sati", "Urs Schreiber"], "title": "Fragile Topological Phases and Topological Order of 2D Crystalline Chern Insulators", "comment": "15 pages, 8 figures", "summary": "We apply methods of equivariant homotopy theory, which may not previously have found due attention in condensed matter physics, to classify first the fragile/unstable topological phases of 2D crystalline Chern insulator materials, and second the possible topological order of their fractional cousins. We highlight that the phases are given by the equivariant 2-Cohomotopy of the Brillouin torus of crystal momenta (with respect to wallpaper point group actions) -- which, despite the attention devoted to crystalline Chern insulators, seems not to have been considered before. Arguing then that any topological order must be reflected in the adiabatic monodromy of gapped quantum ground states over the covariantized space of these band topologies, we compute the latter in examples where this group is non-abelian, showing that any potential FQAH anyons must be localized in momentum space. We close with an outlook on the relevance for the search for topological quantum computing hardware. Mathematical details are spelled out in a supplement."}
{"id": "2512.24778", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24778", "abs": "https://arxiv.org/abs/2512.24778", "authors": ["Gourab Roy", "Ekta Kushwaha", "Mohit Kumar", "Sayan Ghosh", "Fabio Orlandi", "Duc Le", "Matthew B. Stone", "Jhuma Sannigrahi", "Devashibhai T. Adroja", "Tathamay Basu"], "title": "Quasiparticle Dynamics in the 4d-4f Ising-like Double Perovskite Ba2DyRuO6 Probed by Neutron Scattering and Machine-Learning Framework", "comment": null, "summary": "Double perovskites containing 4d--4f interactions provide a platform to study complex magnetic phenomena in correlated systems. Here, we investigate the magnetic ground state and quasiparticle excitations of the fascinating double perovskite system, Ba$_2$DyRuO$_6$, through Time of flight (TOF) neutron diffraction (TOF), inelastic neutron scattering (INS), and theoretical modelling. The compound Ba$_2$DyRuO$_6$ is reported to exhibit a single magnetic transition, in sharp contrast to most of the other rare-earth (R) members in this family, A$_2$RRuO$_6$ (A = Ca/Sr/Ba), which typically show magnetic ordering of the Ru ions, followed by R-ion ordering. Our neutron diffraction results confirm that long-range antiferromagnetic order emerges at $T_\\mathrm{N} \\approx 47$~K, primarily driven by 4d--4f Ru$^{5+}$--Dy$^{3+}$ exchange interactions, where both Dy and Ru moments start to order simultaneously. The ordered ground state is a collinear antiferromagnet with Ising character, carrying ordered moments of $μ_{\\mathrm{Ru}} = 1.6(1)~μ_\\mathrm{B}$ and $μ_{\\mathrm{Dy}} = 5.1(1)~μ_\\mathrm{B}$ at 1.5~K. Low-temperature INS reveals well-defined magnon excitations below 10~meV. SpinW modelling of the INS spectra evidences complex exchange interactions and the presence of magnetic anisotropy, which governs the Ising ground state and accounts for the observed magnon spectrum. Combined INS and Raman spectroscopy reveal crystal-electric-field (CEF) excitations of Dy$^{3+}$ at 46.5 and 71.8~meV in the paramagnetic region. The observed CEF levels are reproduced by point-charge calculations consistent with the $O_h$ symmetry of Dy$^{3+}$. A complementary machine-learning approach is used to analyse the phonon spectrum and compare with INS data. Together, these results clarify the origin of phonon and magnon excitations and their role in the ground-state magnetism of Ba$_2$DyRuO$_6$."}
{"id": "2512.25011", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25011", "abs": "https://arxiv.org/abs/2512.25011", "authors": ["Ashirbad Padhan", "Harsh Nigam"], "title": "Parity order as a fundamental driver of bosonic topology", "comment": null, "summary": "Symmetry-protected topological (SPT) phases in interacting bosonic systems have been extensively studied, yet most realizations rely on fine-tuned interactions or enlarged symmetries. Here we show that a qualitatively different mechanism--parity order coupled to bond dimerization--acts as a fundamental driver of bosonic topology. Using density matrix renormalization group simulations, we identify two distinct topological phases absent in the purely dimerized model: an SPT phase at half filling stabilized by positive parity coupling, and a topological phase at unit filling stabilized by negative coupling that can be adiabatically connected to a trivial phase without breaking any symmetry. Our results establish parity order as a new organizing principle for correlation-driven bosonic topology."}
{"id": "2512.25074", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.25074", "abs": "https://arxiv.org/abs/2512.25074", "authors": ["Souradeep Ghosh", "Nicholas Hunter-Jones", "Joaquin F. Rodriguez-Nieva"], "title": "Randomization Times under Quantum Chaotic Hamiltonian Evolution", "comment": "5 pages, 4 figures", "summary": "Randomness generation through quantum-chaotic evolution underpins foundational questions in statistical mechanics and applications across quantum information science, including benchmarking, tomography, metrology, and demonstrations of quantum computational advantage. While statistical mechanics successfully captures the temporal averages of local observables, understanding randomness at the level of higher statistical moments remains a daunting challenge, with analytic progress largely confined to random quantum circuit models or fine-tuned systems exhibiting space-time duality. Here we study how much randomness can be dynamically generated by generic quantum-chaotic evolution under physical, non-random Hamiltonians. Combining theoretical insights with numerical simulations, we show that for broad classes of initially unentangled states, the dynamics become effectively Haar-random well before the system can ergodically explore the physically accessible Hilbert space. Both local and highly nonlocal observables, including entanglement measures, equilibrate to their Haar expectation values and fluctuations on polynomial timescales with remarkably high numerical precision, and with the fastest randomization occurring in regions of parameter space previously identified as maximally chaotic. Interestingly, this effective randomization can occur on timescales linear in system size, suggesting that the sub-ballistic growth of Renyi entropies typically observed in systems with conservation laws can be bypassed in non-random Hamiltonians with an appropriate choice of initial conditions."}
