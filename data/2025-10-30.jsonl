{"id": "2510.24948", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.24948", "abs": "https://arxiv.org/abs/2510.24948", "authors": ["Hanxuan Ye", "Zachary Qian", "Hongzhe Li"], "title": "Differential Density Analysis in Single-Cell Genomics Using Specially Designed Exponential Families", "comment": "29 pages, 5 figures", "summary": "Recent advances in high-resolution sequencing have paved the way for\npopulation-scale analysis in single-cell RNA-sequencing (scRNA-seq) data.\nscRNA-seq data, in particular, have proven to be extremely powerful in\nprofiling a variety of outcomes such as disease and aging. The abundance of\nscRNA-seq data makes it possible to model each individual's gene expression as\na probability density across cells, offering a richer representation than\nsummary statistics such as means or variances, and allowing for more nuanced\ngroup comparisons. To this end, we propose a model-agnostic framework for\ndensity estimation and inference based on specially designed exponential\nfamilies~(SEF), which accommodates diverse underlying models without requiring\nprior specifications. The proposed method enables estimation and visualization\nfor both individual-specific and group-level gene expression densities, as well\nas conducting formal hypothesis testing for expression density difference\nacross groups of interest. It relies on relaxed assumptions with established\nasymptotic properties and a consistent covariance estimator for valid\ninference. Through simulation under various scenarios, the SEF-based approach\ndemonstrates good error control and improved statistical power over competing\nmethods,including pseudo-bulk tests and moment estimators. Application to a\npopulation-scale scRNA-seq dataset from patients with systemic lupus\nerythematosus identified genes and gene sets that are missed from pseudo-bulk\nbased tests."}
{"id": "2510.24969", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.24969", "abs": "https://arxiv.org/abs/2510.24969", "authors": ["Jooyeon Lee", "M. S.", "Evan Kwiatkowski", "Ph. D"], "title": "Bayesian Spatial Point Process Modeling for Cluster Randomized Trials", "comment": "7 figures, 4 tables", "summary": "Cluster randomized trials (CRTs) offer a practical alternative for addressing\nlogistical challenges and ensuring feasibility in community health, education,\nand prevention studies, even though randomized controlled trials are considered\nthe gold standard in evaluating therapeutic interventions. Despite their\nutility, CRTs are often criticized for limited precision and complex modeling\nrequirements. Advances in robust Bayesian methods and the incorporation of\nspatial correlation into CRT design and analysis remain relatively\nunderdeveloped. This paper introduces a Bayesian spatial point process\nframework that models individuals nested within geographic clusters while\nexplicitly accounting for spatial dependence. We demonstrate that conventional\nnon-spatial models consistently underestimate uncertainty and lead to\nmisleading inferences, whereas our spatial approach improves estimation\nstability, controls type I error, and enhances statistical power. Our results\nunderscore the value and need for wider adoption of spatial methods in CRT."}
{"id": "2510.25036", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.25036", "abs": "https://arxiv.org/abs/2510.25036", "authors": ["Kellin N. Rumsey", "Devin Francom", "Graham C. Gibson", "J. Derek Tucker", "Gabriel Huerta"], "title": "Bayesian Adaptive Polynomial Chaos Expansions", "comment": null, "summary": "Polynomial chaos expansions (PCE) are widely used for uncertainty\nquantification (UQ) tasks, particularly in the applied mathematics community.\nHowever, PCE has received comparatively less attention in the statistics\nliterature, and fully Bayesian formulations remain rare, especially with\nimplementations in R. Motivated by the success of adaptive Bayesian machine\nlearning models such as BART, BASS, and BPPR, we develop a new fully Bayesian\nadaptive PCE method with an efficient and accessible R implementation: khaos.\nOur approach includes a novel proposal distribution that enables data-driven\ninteraction selection, and supports a modified g-prior tailored to PCE\nstructure. Through simulation studies and real-world UQ applications, we\ndemonstrate that Bayesian adaptive PCE provides competitive performance for\nsurrogate modeling, global sensitivity analysis, and ordinal regression tasks."}
{"id": "2510.25052", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25052", "abs": "https://arxiv.org/abs/2510.25052", "authors": ["Valerie Odeh-Couvertier", "Gabriel Zayas-Caban", "Brian Patterson", "Amy Cochran"], "title": "Designing a quasi-experiment to study the clinical impact of adaptive risk prediction models", "comment": null, "summary": "Clinical risk prediction is a valuable tool for guiding healthcare\ninterventions toward those most likely to benefit. Yet, evaluating the pairing\nof a risk prediction model with an intervention using randomized controlled\ntrials (RCTs) presents substantial challenges to today's healthcare systems.\nThis makes quasi-experimental designs, which can offer nearly the same level of\nevidence as an RCT, an attractive alternative. However, existing\nquasi-experimental designs do not allow models and thresholds to adapt. As a\nresult, they struggle to serve new populations, meet emerging trends, and\naddress practical issues. To address this gap, we introduce regression\ndiscontinuity designs for evaluating risk prediction models paired with\nspecific interventions in a modern healthcare system. In our designs, treatment\nis assigned when predicted risk crosses a defined threshold, with the design\nexplicitly accommodating adaptations in both the model and threshold. We\naccount for the interference that arises from these adaptations to estimate the\nlocal average treatment effect in a valid and efficient way. To that end, we\ncharacterize interference and provide sufficient conditions for identification.\nEstimators are introduced, and their performance is evaluated in a simulation\nthat emulates how cardiovascular risk calculators could guide interventions in\nprimary care settings."}
{"id": "2510.24747", "categories": ["physics.comp-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.24747", "abs": "https://arxiv.org/abs/2510.24747", "authors": ["Arefeh Abbasi", "Maurizio Ricci", "Pietro Carrara", "Moritz Flaschel", "Siddhant Kumar", "Sonia Marfia", "Laura De Lorenzis"], "title": "Discovery of Hyperelastic Constitutive Laws from Experimental Data with EUCLID", "comment": null, "summary": "We assess the performance of EUCLID, Efficient Unsupervised Constitutive Law\nIdentification and Discovery, a recently proposed framework for automated\ndiscovery of constitutive laws, on experimental data. Mechanical tests are\nperformed on natural rubber specimens spanning simple to complex geometries,\nfrom which we collect both global, force elongation, and local, full-field\ndisplacement, measurements. Using these data, we obtain constitutive laws via\ntwo routes, the conventional identification of unknown parameters in a priori\nselected material models, and EUCLID, which automates model selection and\nparameter identification within a unified model-discovery pipeline. We compare\nthe two methodologies using global versus local data, analyze predictive\naccuracy, and examine generalization to unseen geometries. Moreover, we\nquantify the experimental noise, investigate the coverage of the material state\nspace achieved by each approach and discuss the relative performance of\ndifferent datasets and different a priori chosen models versus EUCLID."}
{"id": "2510.24867", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24867", "abs": "https://arxiv.org/abs/2510.24867", "authors": ["Viviana Gómez", "Gabriel Téllez", "Fernando J. Gómez-Ruiz"], "title": "Spin Glass Dynamics on Complex Hardware Topologies: A Bond-Correlated Percolation Approach", "comment": null, "summary": "Understanding how frustration and disorder shape relaxation in complex\nsystems is a central problem in statistical physics and quantum annealing.\nSpin-glass models provide a natural framework to explore this connection, as\ntheir energy landscapes are governed by competing interactions and constrained\ntopologies. We investigate the non-exponential relaxation behavior of spin\nglasses on network architectures relevant to quantum annealing hardware -- such\nas finite size Chimera, Pegasus, and Zephyr graphs -- where embedding\nconstraints and finite connectivity strongly modulate the distribution of\nbarriers and metastable states. This slow relaxation arises from the combined\neffects of frustration and disorder, which persist even beyond the conventional\nspin-glass transition. Within the Fortuin-Kasteleyn-Coniglio-Klein (FKCK)\ncluster formalism, the appearance of unfrustrated cluster regions gives rise to\nmultiple relaxation scales, as distinct domains follow different dynamical\npathways across a rugged energy landscape. This framework enables a more\ncomprehensive characterization of spin-glass energy landscapes and offers\nvaluable insight into how topological constraints and disorder jointly govern\nrelaxation dynamics, providing quantitative benchmarks for evaluating the\nperformance and limitations of quantum annealing architectures."}
{"id": "2510.24863", "categories": ["math.ST", "math.AG", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.24863", "abs": "https://arxiv.org/abs/2510.24863", "authors": ["Pooja Yadav", "Tanuja Srivastava"], "title": "Maximum Likelihood Estimation of Multivariate and Matrix Variate Symmetric Laplace Distributions Through Group Actions", "comment": null, "summary": "In this paper, we study the maximum likelihood estimation of the parameters\nof the multivariate and matrix variate symmetric Laplace distributions through\ngroup actions. The multivariate and matrix variate symmetric Laplace\ndistributions are not in the exponential family of distributions. We relate the\nmaximum likelihood estimation problems of these distributions to norm\nminimization over a group and build a correspondence between stability of data\nwith respect to the group action and the properties of the likelihood function."}
{"id": "2510.24723", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24723", "abs": "https://arxiv.org/abs/2510.24723", "authors": ["Sehyun Ryu", "Hyun Jong Yang"], "title": "Blockage-Aware Multi-RIS WSR Maximization via Per-RIS Indexed Synchronization Sequences and Closed-Form Riemannian Updates", "comment": null, "summary": "Millimeter-wave (mmWave) multi-user MIMO systems are highly vulnerable to\nblockage, and reconfigurable intelligent surfaces (RIS) have been proposed as a\nremedy. However, RIS links may themselves be blocked, while most prior works\nassume ideal RIS availability. We propose an end-to-end blockage-aware\nmulti-RIS weighted sum-rate (WSR) optimization framework. The BS transmits\nshort per-RIS indexed synchronization signals, enabling each user to identify\nblocked panels through a simple energy detection test. Based on the detected\nfeasible sets, we jointly optimize the BS precoder and RIS phases via a\nClosed-form Riemannian Phase Alignment (CRPA) algorithm. CRPA provides\nunit-modulus-preserving closed-form updates, requiring no projection or line\nsearch, and ensures monotone ascent. Simulations validate reliable blockage\ndetection and notable WSR and convergence gains over existing baselines."}
{"id": "2510.25050", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.25050", "abs": "https://arxiv.org/abs/2510.25050", "authors": ["Shereen Ismail", "Eman Hammad", "William Hatcher", "Salah Dandan", "Ammar Alomari", "Michael Spratt"], "title": "Merit Network Telescope: Processing and Initial Insights from Nearly 20 Years of Darknet Traffic for Cybersecurity Research", "comment": null, "summary": "This paper presents an initial longitudinal analysis of unsolicited Internet\ntraffic collected between 2005 and 2025 by one of the largest and most\npersistent network telescopes in the United States, operated by Merit Network.\nThe dataset provides a unique view into global threat activity as observed\nthrough scanning and backscatter traffic, key indicators of large-scale probing\nbehavior, data outages, and ongoing denial-of-service (DoS) campaigns. To\nprocess this extensive archive, coarse-to-fine methodology is adopted in which\ngeneral insights are first extracted through a resource-efficient metadata\nsub-pipeline, followed by a more detailed packet header sub-pipeline for\nfiner-grained analysis. The methodology establishes two sub-pipelines to enable\nscalable processing of nearly two decades of telescope data and supports\nmulti-level exploration of traffic dynamics. Initial insights highlight\nlong-term trends and recurring traffic spikes, some attributable to\nInternet-wide scanning events and others likely linked to DoS activities.We\npresent general observations spanning 2006-2024, with a focused analysis of\ntraffic characteristics during 2024."}
{"id": "2510.25040", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.25040", "abs": "https://arxiv.org/abs/2510.25040", "authors": ["Madhav Vadlamani", "Dyutimoy Chakraborty", "Jianwei Jia", "Halid Mulaosmanovic", "Stefan Duenkel", "Sven Beyer", "Suman Datta", "Shimeng Yu"], "title": "Cryogenic Characterization of Ferroelectric Non-volatile Capacitors", "comment": null, "summary": "Ferroelectric-based capacitive crossbar arrays have been proposed for\nenergy-efficient in-memory computing in the charge domain. They combat the\nchallenges like sneak paths and high static power faced by resistive crossbar\narrays but are susceptible to thermal noise limiting the effective number of\nbits (ENOB) for the weighted sum. A direct way to reduce this thermal noise is\nby lowering the temperature as thermal noise is proportional to temperature. In\nthis work, we first characterize the non-volatile capacitors (nvCaps) on a\nfoundry 28 nm platform at cryogenic temperatures to evaluate the memory window,\nON state retention as a function of temperature down to 77K, and then use the\ncalibrated device models to simulate the capacitive crossbar arrays in SPICE at\nlower temperatures to demonstrate higher ENOB (~5 bits) for 128x128\nmultiple-and-accumulate (MAC) operations."}
{"id": "2510.24723", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24723", "abs": "https://arxiv.org/abs/2510.24723", "authors": ["Sehyun Ryu", "Hyun Jong Yang"], "title": "Blockage-Aware Multi-RIS WSR Maximization via Per-RIS Indexed Synchronization Sequences and Closed-Form Riemannian Updates", "comment": null, "summary": "Millimeter-wave (mmWave) multi-user MIMO systems are highly vulnerable to\nblockage, and reconfigurable intelligent surfaces (RIS) have been proposed as a\nremedy. However, RIS links may themselves be blocked, while most prior works\nassume ideal RIS availability. We propose an end-to-end blockage-aware\nmulti-RIS weighted sum-rate (WSR) optimization framework. The BS transmits\nshort per-RIS indexed synchronization signals, enabling each user to identify\nblocked panels through a simple energy detection test. Based on the detected\nfeasible sets, we jointly optimize the BS precoder and RIS phases via a\nClosed-form Riemannian Phase Alignment (CRPA) algorithm. CRPA provides\nunit-modulus-preserving closed-form updates, requiring no projection or line\nsearch, and ensures monotone ascent. Simulations validate reliable blockage\ndetection and notable WSR and convergence gains over existing baselines."}
{"id": "2510.24875", "categories": ["hep-lat", "hep-th", "nucl-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24875", "abs": "https://arxiv.org/abs/2510.24875", "authors": ["Navya Gupta", "Christopher David White", "Zohreh Davoudi"], "title": "A Euclidean Monte-Carlo-informed route to ground-state preparation for quantum simulation of scalar field theory", "comment": "Prepared for the proceedings of the 41st International Symposium on\n  Lattice Field Theory at the University of Liverpool, United Kingdom", "summary": "Quantum simulators hold great promise for studying real-time (Minkowski)\ndynamics of quantum field theories. Nonetheless, preparing non-trivial initial\nstates remains a major obstacle. Euclidean-time Monte-Carlo methods yield\nground-state spectra and static correlation functions that can, in principle,\nguide state preparation. In this work, we exploit this classical information to\nbridge Euclidean and Minkowski descriptions for a (1+1)-dimensional interacting\nscalar field theory. We propose variational ansatz families which achieve\ncomparable ground-state energies, yet exhibit distinct correlations and local\nnon-Gaussianity. By optimizing selected wavefunction moments with Monte-Carlo\ndata, we obtain ansatzes that can be efficiently translated into quantum\ncircuits. Our algorithmic cost analysis shows these circuits' gate complexity\nscales polynomially in system size. Our work paves the way for systematically\nleveraging classically-computed information to prepare initial states in\nquantum field theories of interest in nature."}
{"id": "2510.24755", "categories": ["math.OC", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.24755", "abs": "https://arxiv.org/abs/2510.24755", "authors": ["Baptiste Chevalier", "Shimpei Yamaguchi", "Wojciech Roga", "Masahiro Takeoka"], "title": "A Compressive Sensing Inspired Monte-Carlo Method for Combinatorial Optimization", "comment": "29 pages, 4 figures", "summary": "In this paper, we present the Monte-Carlo Compressive Optimization algorithm,\na new method to solve a combinatorial optimization problem that is assumed\ncompressible. The method relies on random queries to the objective function in\norder to estimate generalized moments. Next, a greedy algorithm from\ncompressive sensing is repurposed to find the global optimum when not\noverfitting to samples. We provide numerical results giving evidences that our\nmethods overcome state-of-the-art dual annealing. Moreover, we also give\ntheoretical justification of the algorithm success and analyze its properties.\nThe practicality of our algorithm is enhanced by the ability to tune heuristic\nparameters to available computational resources."}
{"id": "2510.25011", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.25011", "abs": "https://arxiv.org/abs/2510.25011", "authors": ["Edward C. Wolff", "James S. Goodnight", "Leanne Blind-Doskocil", "Elijah M. Conklin", "Evan T. Gustafson", "Joseph E. Trujillo-Falcón"], "title": "Reflecting on a Decade of Formalized Tornado Emergencies", "comment": "This article has been submitted to the Bulletin of the American\n  Meteorological Society. Copyright in this article may be transferred without\n  further notice", "summary": "In 1999 the NWS began using the phrase \"tornado emergency\" to denote tornado\nwarnings for storms with the potential to cause rare, catastrophic damage.\nAfter years of informal usage, tornado emergencies were formally introduced to\n46 weather forecasting offices in 2014 as part of the impact-based warning\n(IBW) program, with a nationwide rollout occurring over the following years. In\nconcert with the new tiered warning approach, the Warning Decision Training\nDivision (WDTD) also introduced suggested criteria for when forecasters should\nconsider upgrading a tornado warning to a tornado emergency, which includes\nthresholds of rotational velocity (VROT) and significant tornado parameter\n(STP). Although significant research has studied both tornado forecasting and\ntornado warning dissemination in the decade since, relatively little work has\nexamined the effectiveness of the tornado emergency specifically. Our analysis\nof all 89 IBW tornado emergencies issued from 2014-2023 found that forecasters\ndo not appear to follow suggested criteria for issuance in the majority of\ncases, with only two tornado emergencies meeting both VROT and STP thresholds.\nRegardless, 70% of tornado emergencies were issued for EF-3+ tornadoes and\ntornado emergencies covered 55% of all EF-4 tornadoes as well as 41% of all\ntornadoes resulting in 3 or more fatalities. Based on these results, we propose\nseveral updates to the current NWS training materials for impact-based tornado\nwarnings."}
{"id": "2510.24742", "categories": ["nlin.CD", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.24742", "abs": "https://arxiv.org/abs/2510.24742", "authors": ["Adam J. Czarnecki", "Andrzej Czarnecki", "Raquel Secrist", "Julia Willsey"], "title": "Shock Wave in the Beirut Explosion: Theory and Video Analysis", "comment": "5 pages, 4 figures. Submitted to the American Journal of Physics", "summary": "Videos of the 2020 Beirut explosion offer a rare opportunity to see a shock\nwave. We summarize the non-linear theory of a weak shock, derive the\nLandau-Whitham formula for the thickness of the overpressure layer and, using\nframe-by-frame video analysis, we demonstrate a semi-quantitative agreement of\ndata and theory."}
{"id": "2510.24905", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2510.24905", "abs": "https://arxiv.org/abs/2510.24905", "authors": ["Bianca Y. S. Ishikawa", "José F. Fontanari"], "title": "Finite Population Dynamics Resolve the Central Paradox of the Inspection Game", "comment": null, "summary": "The Inspection Game is the canonical model for the strategic conflict between\nlaw enforcement (inspectors) and citizens (potential criminals), but its\nclassical analysis is crippled by a paradox: the equilibrium crime rate is\nfound to be independent of both the penalty size ($p$) and the crime gain\n($g$). This result severely undermines the policy relevance of the static\nmodel, suggesting fines are futile. To resolve this paradox, we employ\nevolutionary game theory and analyze the long-term fixation probabilities of\nstrategies using finite population dynamics. Our results fundamentally\ndemonstrate that high absolute penalties $p$ are highly effective at\nsuppressing crime by driving the system toward the criminal extinction\nabsorbing state, thereby restoring the intuitive role of $p$. Furthermore, we\nreveal a U-shaped policy landscape where both high penalties and light\npenalties (where $p \\approx g$) are successful suppressors, maximizing criminal\nrisk at intermediate deterrence levels. Most critically, we analyze the\nrealistic asymptotic limit of extreme population asymmetry, where inspectors\nare exceedingly rare. In this limit, the system's dynamic outcome is entirely\ndecoupled from the citizen payoff parameters $p$ and $g$, and is instead\ndetermined by the initial frequency of crime ($x_0$) relative to the deterrence\nthreshold (the ratio of inspection cost to reward for catching a criminal). We\nfind the highly counter-intuitive result of the dominance of the initially rare\nstrategy: crime becomes fixed if $x_0$ is below this threshold, but goes\nextinct if $x_0$ is above it. These findings highlight the need to move beyond\ndeterministic predictions and emphasize that effective deterrence requires\nmanaging demographic noise and initial conditions."}
{"id": "2510.25022", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.25022", "abs": "https://arxiv.org/abs/2510.25022", "authors": ["Changkai Zhang", "Jan von Delft"], "title": "Finite-Temperature Study of the Hubbard Model via Enhanced Exponential Tensor Renormalization Group", "comment": "10 pages, 5 figures for numerical results", "summary": "The two-dimensional (2D) Hubbard model has long attracted interest for its\nrich phase diagram and its relevance to high-$T_c$ superconductivity. However,\nreliable finite-temperature studies remain challenging due to the exponential\ncomplexity of many-body interactions. Here, we introduce an enhanced\n$1\\text{s}^+$ eXponential Tensor Renormalization Group algorithm that enables\nefficient finite-temperature simulations of the 2D Hubbard model. By exploring\nan expanded space, our approach achieves two-site update accuracy at the\ncomputational cost of a one-site update, and delivers up to 50% acceleration\nfor Hubbard-like systems, which enables simulations down to\n$T\\!\\approx\\!0.004t$. This advance permits a direct investigation of\nsuperconducting order over a wide temperature range and facilitates a\ncomparison with zero-temperature infinite Projected Entangled Pair State\nsimulations. Finally, we compile a comprehensive dataset of snapshots spanning\nthe relevant region of the phase diagram, providing a valuable reference for\nArtificial Intelligence-driven analyses of the Hubbard model and a comparison\nwith cold-atom experiments."}
{"id": "2510.24903", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.24903", "abs": "https://arxiv.org/abs/2510.24903", "authors": ["Alejandro de Haro García", "Joaquín J. Torres"], "title": "Emergence of Chimeras States in One-dimensional Ising model with Long-Range Diffusion", "comment": "26 pages, 8 figures", "summary": "In this work, we examine the conditions for the emergence of chimera-like\nstates in Ising systems. We study an Ising chain with periodic boundaries in\ncontact with a thermal bath at temperature T, that induces stochastic changes\nin spin variables. To capture the non-locality needed for chimera formation, we\nintroduce a model setup with non-local diffusion of spin values through the\nwhole system. More precisely, diffusion is modeled through spin-exchange\ninteractions between units up to a distance R, using Kawasaki dynamics. This\nsetup mimics, e.g., neural media, as the brain, in the presence of electrical\n(diffusive) interactions. We explored the influence of such non-local dynamics\non the emergence of complex spatiotemporal synchronization patterns of\nactivity. Depending on system parameters we report here for the first time\nchimera-like states in the Ising model, characterized by relatively stable\nmoving domains of spins with different local magnetization. We analyzed the\nsystem at T=0, both analytically and via simulations and computed the system's\nphase diagram, revealing rich behavior: regions with only chimeras, coexistence\nof chimeras and stable domains, and metastable chimeras that decay into uniform\nstable domains. This study offers fundamental insights into how coherent and\nincoherent synchronization patterns can arise in complex networked systems as\nit is, e.g., the brain."}
{"id": "2510.24905", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2510.24905", "abs": "https://arxiv.org/abs/2510.24905", "authors": ["Bianca Y. S. Ishikawa", "José F. Fontanari"], "title": "Finite Population Dynamics Resolve the Central Paradox of the Inspection Game", "comment": null, "summary": "The Inspection Game is the canonical model for the strategic conflict between\nlaw enforcement (inspectors) and citizens (potential criminals), but its\nclassical analysis is crippled by a paradox: the equilibrium crime rate is\nfound to be independent of both the penalty size ($p$) and the crime gain\n($g$). This result severely undermines the policy relevance of the static\nmodel, suggesting fines are futile. To resolve this paradox, we employ\nevolutionary game theory and analyze the long-term fixation probabilities of\nstrategies using finite population dynamics. Our results fundamentally\ndemonstrate that high absolute penalties $p$ are highly effective at\nsuppressing crime by driving the system toward the criminal extinction\nabsorbing state, thereby restoring the intuitive role of $p$. Furthermore, we\nreveal a U-shaped policy landscape where both high penalties and light\npenalties (where $p \\approx g$) are successful suppressors, maximizing criminal\nrisk at intermediate deterrence levels. Most critically, we analyze the\nrealistic asymptotic limit of extreme population asymmetry, where inspectors\nare exceedingly rare. In this limit, the system's dynamic outcome is entirely\ndecoupled from the citizen payoff parameters $p$ and $g$, and is instead\ndetermined by the initial frequency of crime ($x_0$) relative to the deterrence\nthreshold (the ratio of inspection cost to reward for catching a criminal). We\nfind the highly counter-intuitive result of the dominance of the initially rare\nstrategy: crime becomes fixed if $x_0$ is below this threshold, but goes\nextinct if $x_0$ is above it. These findings highlight the need to move beyond\ndeterministic predictions and emphasize that effective deterrence requires\nmanaging demographic noise and initial conditions."}
{"id": "2510.24861", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "physics.plasm-ph", "65M70, 65F30, 35Q83, 65Y20, 82D10"], "pdf": "https://arxiv.org/pdf/2510.24861", "abs": "https://arxiv.org/abs/2510.24861", "authors": ["Nanyi Zheng", "William A. Sands", "Daniel Hayes", "Andrew J. Christlieb", "Jing-Mei Qiu"], "title": "A Semi-Lagrangian Adaptive Rank (SLAR) Method for High-Dimensional Vlasov Dynamics", "comment": "24 pages, 10 figures, 2 algorithms", "summary": "We extend our previous work on a semi-Lagrangian adaptive rank (SLAR)\nintegrator, in the finite difference framework for nonlinear Vlasov-Poisson\nsystems, to the general high-order tensor setting. The proposed scheme retains\nthe high-order accuracy of semi-Lagrangian methods, ensuring stability for\nlarge time steps and avoiding dimensional splitting errors. The primary\ncontribution of this paper is the novel extension of the algorithm from the\nmatrix to the high-dimensional tensor setting, which enables the simulation of\nVlasov models in up to six dimensions. The key technical components include (1)\na third-order high-dimensional polynomial reconstruction that scales as\n$O(d^2)$, providing a point-wise approximation of the solution at the foot of\ncharacteristics in a semi-Lagrangian scheme; (2) a recursive hierarchical\nadaptive cross approximation of high-order tensors in a hierarchical Tucker\nformat, characterized by a tensor tree; (3) a low-complexity Poisson solver in\nthe hierarchical Tucker format that leverages the FFT for efficiency. The\ncomputed adaptive rank kinetic solutions exhibit low-rank structures within\nbranches of the tensor tree resulting in substantial computational savings in\nboth storage and time. The resulting algorithm achieves a computational\ncomplexity of $O(d^4 N r^{3+\\lceil\\log_2d\\rceil})$, where $N$ is the number of\ngrid points per dimension, $d$ is the problem dimension, and $r$ is the maximum\nrank in the tensor tree, overcoming the curse of dimensionality. Through\nextensive numerical tests, we demonstrate the efficiency of the proposed\nalgorithm and highlight its ability to capture complex solution structures\nwhile maintaining a computational complexity that scales linearly with $N$."}
{"id": "2510.24727", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24727", "abs": "https://arxiv.org/abs/2510.24727", "authors": ["Weiman Yan", "Yi-Chia Chang", "Wanyu Zhao"], "title": "Stiff Circuit System Modeling via Transformer", "comment": null, "summary": "Accurate and efficient circuit behavior modeling is a cornerstone of modern\nelectronic design automation. Among different types of circuits, stiff circuits\nare challenging to model using previous frameworks. In this work, we propose a\nnew approach using Crossformer, which is a current state-of-the-art Transformer\nmodel for time-series prediction tasks, combined with Kolmogorov-Arnold\nNetworks (KANs), to model stiff circuit transient behavior. By leveraging the\nCrossformer's temporal representation capabilities and the enhanced feature\nextraction of KANs, our method achieves improved fidelity in predicting circuit\nresponses to a wide range of input conditions. Experimental evaluations on\ndatasets generated through SPICE simulations of analog-to-digital converter\n(ADC) circuits demonstrate the effectiveness of our approach, with significant\nreductions in training time and error rates."}
{"id": "2510.24743", "categories": ["physics.geo-ph", "astro-ph.EP"], "pdf": "https://arxiv.org/pdf/2510.24743", "abs": "https://arxiv.org/abs/2510.24743", "authors": ["Eugenia Hyung", "Emma Levy", "Loralei Cook", "Stein B. Jacobsen", "Abraham Loeb", "Jayden Squire", "Juraj Farkas"], "title": "Comparison of Australasian tektites with Australasian microtektites and BeLaU spherules recovered from the ocean", "comment": "Accepted for publication in RNAAS, October 2025", "summary": "The Australasian strewn field covers more than 15% of Earth's surface,\nconsisting of tektites and microtektites. Australasian tektites from Southeast\nAsia and Australia, as well as microtektites recovered from deep sea sediments\nand Antarctica, are established to be derived from upper continental crust\nsediments. An expedition to retrieve remnants of bolide CNEOS 2014 January 8\n(IM1), held in the Pacific Ocean, was in proximity to the known extent of the\nAustralasian strewn field, and yielded \"BeLaU\"-spherules, whose compositions\ndid not match most well-studied solar system material. We therefore report\nprecise and comprehensive elemental data for Australasian tektites to compare\ntheir elemental abundances to those of microtektites from deep sea sediments,\nand BeLaU. Our findings corroborate previous studies that Australasian tektites\nand microtektites closely resemble the elemental abundance patterns of the\nupper continental crust. Meanwhile, the elemental patterns of the\nBeLaU-spherules are distinct from the Australasian tektite/microtektite\ncompositions."}
{"id": "2510.25153", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25153", "abs": "https://arxiv.org/abs/2510.25153", "authors": ["Hannah Comiskey", "Niamh Cahill", "Leontine Alkema", "David Fraizer", "Worapree Maneesoonthorn"], "title": "Bayesian probabilistic projections of proportions with limited data: An application to subnational contraceptive method supply shares", "comment": null, "summary": "Engaging the private sector in contraceptive method supply is critical for\ncreating equitable, sustainable, and accessible healthcare systems. To achieve\nthis, it is essential to understand where women obtain their modern\ncontraceptives. While national-level estimates provide valuable insights into\noverall trends in contraceptive supply, they often obscure variation within and\nacross subnational regions. Addressing localized needs has become increasingly\nimportant as countries adopt decentralized models for family planning services.\nDecentralization has also underscored the need for reliable subnational\nestimates of key family planning indicators. The absence of regularly collected\nsubnational data has hindered effective monitoring and decision-making. To\nbridge this gap, we propose a novel approach that leverages latent attributes\nin Demographic and Health Survey (DHS) data to produce Bayesian probabilistic\nprojections of contraceptive method supply shares (the proportions of modern\ncontraceptive methods supplied by public and private sectors) with limited\ndata. Our modeling framework is built on Bayesian hierarchical models. Using\npenalized splines to track public and private supply shares over time, we\nleverage the spatial nature of the data and incorporate a correlation structure\nbetween recent supply share observations at national and subnational levels.\nThis framework contributes to the domain of subnational estimation of\nproportions in data-sparse settings, outperforming comparable and previous\napproaches. As decentralization continues to reshape family planning services,\nproducing reliable subnational estimates of key indicators is increasingly\nvital for researchers and policymakers."}
{"id": "2510.24979", "categories": ["physics.comp-ph", "physics.bio-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2510.24979", "abs": "https://arxiv.org/abs/2510.24979", "authors": ["Chenyu Tang", "Mayank Prakash Pandey", "Cheng Giuseppe Chen", "Alberto Megías", "François Dehez", "Christophe Chipot"], "title": "Breaking the Timescale Barrier: Generative Discovery of Conformational Free-Energy Landscapes and Transition Pathways", "comment": "17 pages, 4 figures", "summary": "Molecular transitions -- such as protein folding, allostery, and membrane\ntransport -- are central to biology yet remain notoriously difficult to\nsimulate. Their intrinsic rarity pushes them beyond reach of standard molecular\ndynamics, while enhanced-sampling methods are costly and often depend on\narbitrary variables that bias outcomes. We introduce Gen-COMPAS, a generative\ncommittor-guided path sampling framework that reconstructs transition pathways\nwithout predefined variables and at a fraction of the cost. Gen-COMPAS couples\na generative diffusion model, which produces physically realistic\nintermediates, with committor-based filtering to pinpoint transition states.\nShort unbiased simulations from these intermediates rapidly yield full\ntransition-path ensembles that converge within nanoseconds, where conventional\nmethods require orders of magnitude more sampling. Applied to systems from a\nminiprotein to a ribose-binding protein to a mitochondrial carrier, Gen-COMPAS\nretrieves committors, transition states, and free-energy landscapes\nefficiently, uniting machine learning and molecular dynamics for broad\nmechanistic and practical insight."}
{"id": "2510.25071", "categories": ["cond-mat.stat-mech", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2510.25071", "abs": "https://arxiv.org/abs/2510.25071", "authors": ["Ravi Kiran", "A. Taraphder"], "title": "Phonon dynamics and chiral modes in the two-dimensional square-octagon lattice", "comment": "15 pages, 21 figures", "summary": "Chiral phonons, originally identified in two-dimensional hexagonal lattices\nand later extended to kagome, square, and other lattices, have been extensively\nstudied as manifestations of broken inversion and time-reversal symmetries in\nvibrational dynamics. In this work, we investigate the vibrational dynamics of\nthe two-dimensional square-octagon lattice using a spring-mass model with\ncentral-force interactions. The model incorporates mass contrast and variable\ncoupling strengths among nearest, next-nearest, and third-nearest neighbors.\nFrom the dynamical matrix, we obtain the phonon dispersion relations and\nidentify tunable phononic band gaps governed by both mass and spring-constant\nratios. The angular dependence of phase and group velocities is analyzed to\nreveal the pronounced anisotropy inherent to this lattice geometry. We also\nexamine the distinctive features of the square-octagon geometry, including\nflat-band anomalies in the density of states and anisotropic sound propagation\ninduced by longer-range couplings. In addition, we explore the emergence of\nchiral phonons by introducing a time reversal symmetry-breaking term in the\ndynamical matrix, and to elucidate their optical signatures, we construct a\nminimal model to study infrared circular dichroism arising from chiral phonon\nmodes."}
{"id": "2510.25287", "categories": ["math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25287", "abs": "https://arxiv.org/abs/2510.25287", "authors": ["Ferdinand Genans", "Antoine Godichon-Baggioni", "François-Xavier Vialard", "Olivier Wintenberger"], "title": "Stochastic Optimization in Semi-Discrete Optimal Transport: Convergence Analysis and Minimax Rate", "comment": null, "summary": "We investigate the semi-discrete Optimal Transport (OT) problem, where a\ncontinuous source measure $\\mu$ is transported to a discrete target measure\n$\\nu$, with particular attention to the OT map approximation. In this setting,\nStochastic Gradient Descent (SGD) based solvers have demonstrated strong\nempirical performance in recent machine learning applications, yet their\ntheoretical guarantee to approximate the OT map is an open question. In this\nwork, we answer it positively by providing both computational and statistical\nconvergence guarantees of SGD. Specifically, we show that SGD methods can\nestimate the OT map with a minimax convergence rate of\n$\\mathcal{O}(1/\\sqrt{n})$, where $n$ is the number of samples drawn from $\\mu$.\nTo establish this result, we study the averaged projected SGD algorithm, and\nidentify a suitable projection set that contains a minimizer of the objective,\neven when the source measure is not compactly supported. Our analysis holds\nunder mild assumptions on the source measure and applies to MTW cost\nfunctions,whic include $\\|\\cdot\\|^p$ for $p \\in (1, \\infty)$. We finally\nprovide numerical evidence for our theoretical results."}
{"id": "2510.24730", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24730", "abs": "https://arxiv.org/abs/2510.24730", "authors": ["Jaehong Oh"], "title": "Constructive Lyapunov Functions via Topology-Preserving Neural Networks", "comment": "54pages, 14 figures", "summary": "We prove that ONN achieves order-optimal performance on convergence rate\n($\\mu \\propto \\lambda_2$), edge efficiency ($E = N$ for minimal connectivity $k\n= 2$), and computational complexity ($O(N d^2)$). Empirical validation on\n3M-node semantic networks demonstrates 99.75\\% improvement over baseline\nmethods, confirming exponential convergence ($\\mu = 3.2 \\times 10^{-4}$) and\ntopology preservation. ORTSF integration into transformers achieves 14.7\\%\nperplexity reduction and 2.3 faster convergence on WikiText-103. We establish\ndeep connections to optimal control (Hamilton-Jacobi-Bellman), information\ngeometry (Fisher-efficient natural gradient), topological data analysis\n(persistent homology computation in $O(KN)$), discrete geometry (Ricci flow),\nand category theory (adjoint functors). This work transforms Massera's abstract\nexistence theorem into a concrete, scalable algorithm with provable guarantees,\nopening pathways for constructive stability analysis in neural networks,\nrobotics, and distributed systems."}
{"id": "2510.25120", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.25120", "abs": "https://arxiv.org/abs/2510.25120", "authors": ["Wenyan Xu", "Dawei Xiang", "Tianqi Ding", "Weihai Lu"], "title": "MMM-Fact: A Multimodal, Multi-Domain Fact-Checking Dataset with Multi-Level Retrieval Difficulty", "comment": "Dataset link: https://huggingface.co/datasets/Wenyan0110/MMM-Fact", "summary": "Misinformation and disinformation demand fact checking that goes beyond\nsimple evidence-based reasoning. Existing benchmarks fall short: they are\nlargely single modality (text-only), span short time horizons, use shallow\nevidence, cover domains unevenly, and often omit full articles -- obscuring\nmodels' real-world capability. We present MMM-Fact, a large-scale benchmark of\n125,449 fact-checked statements (1995--2025) across multiple domains, each\npaired with the full fact-check article and multimodal evidence (text, images,\nvideos, tables) from four fact-checking sites and one news outlet. To reflect\nverification effort, each statement is tagged with a retrieval-difficulty tier\n-- Basic (1--5 sources), Intermediate (6--10), and Advanced (>10) -- supporting\nfairness-aware evaluation for multi-step, cross-modal reasoning. The dataset\nadopts a three-class veracity scheme (true/false/not enough information) and\nenables tasks in veracity prediction, explainable fact-checking, complex\nevidence aggregation, and longitudinal analysis. Baselines with mainstream LLMs\nshow MMM-Fact is markedly harder than prior resources, with performance\ndegrading as evidence complexity rises. MMM-Fact offers a realistic, scalable\nbenchmark for transparent, reliable, multimodal fact-checking."}
{"id": "2510.25676", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2510.25676", "abs": "https://arxiv.org/abs/2510.25676", "authors": ["Teena tom Dieck", "Lukas Brand", "Sebastian Lotter", "Kathrin Castiglione", "Robert Schober", "Maximilian Schäfer"], "title": "Modulation Schemes for Functionalized Vesicle-based MC Transmitters", "comment": "7 pages, 8 figures. Submitted to IEEE International Conference on\n  Communications (ICC) 2026", "summary": "Molecular communication (MC) enables information exchange through the\ntransmission of signaling molecules (SMs) and holds promise for many innovative\napplications. However, most existing MC studies rely on simplified transmitter\n(TX) models that do not account for the physical and biochemical limitations of\nrealistic biological hardware. This work extends previous efforts toward\ndeveloping models for practical MC systems by proposing a more realistic TX\nmodel that incorporates the delay in SM release and TX noise introduced by\nbiological components. Building on this more realistic, functionalized\nvesicle-based TX model, we propose two novel modulation schemes specifically\ndesigned for this TX to mitigate TX-induced memory effects that arise from\ndelayed and imperfectly controllable SM release. The proposed modulation\nschemes enable low-complexity receiver designs by mitigating memory effects\ndirectly at the TX. Numerical evaluations demonstrate that the proposed schemes\nimprove communication reliability under realistic biochemical constraints,\noffering an important step toward physically realizable MC systems."}
{"id": "2510.24730", "categories": ["eess.SY", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24730", "abs": "https://arxiv.org/abs/2510.24730", "authors": ["Jaehong Oh"], "title": "Constructive Lyapunov Functions via Topology-Preserving Neural Networks", "comment": "54pages, 14 figures", "summary": "We prove that ONN achieves order-optimal performance on convergence rate\n($\\mu \\propto \\lambda_2$), edge efficiency ($E = N$ for minimal connectivity $k\n= 2$), and computational complexity ($O(N d^2)$). Empirical validation on\n3M-node semantic networks demonstrates 99.75\\% improvement over baseline\nmethods, confirming exponential convergence ($\\mu = 3.2 \\times 10^{-4}$) and\ntopology preservation. ORTSF integration into transformers achieves 14.7\\%\nperplexity reduction and 2.3 faster convergence on WikiText-103. We establish\ndeep connections to optimal control (Hamilton-Jacobi-Bellman), information\ngeometry (Fisher-efficient natural gradient), topological data analysis\n(persistent homology computation in $O(KN)$), discrete geometry (Ricci flow),\nand category theory (adjoint functors). This work transforms Massera's abstract\nexistence theorem into a concrete, scalable algorithm with provable guarantees,\nopening pathways for constructive stability analysis in neural networks,\nrobotics, and distributed systems."}
{"id": "2510.24894", "categories": ["hep-lat", "hep-ph", "hep-th", "nucl-th"], "pdf": "https://arxiv.org/pdf/2510.24894", "abs": "https://arxiv.org/abs/2510.24894", "authors": ["Raúl A. Briceño", "Maxwell T. Hansen", "Andrew W. Jackura", "Robert G. Edwards", "Christopher E. Thomas"], "title": "Isotensor $πππ$ scattering with a $ρ$ resonant subsystem from QCD", "comment": "26 pages, 10 figures", "summary": "This work presents a lattice quantum chromodynamics (QCD) determination of\n$\\pi\\pi\\pi$ scattering amplitudes for the isospin-2 channel with angular\nmomentum and parity $J^{P} = 1^+$. The calculation is performed using\nunphysically heavy light-quark masses, corresponding to a pion mass of $m_{\\pi}\n\\approx 400$~MeV, for which the $\\rho$ meson manifests as a narrow resonance.\nThe analysis employs a previously developed formalism that non-perturbatively\nrelates the finite-volume spectra of two- and three-pion systems to their\ninfinite-volume scattering amplitudes. We combine earlier lattice QCD results\nfor $\\pi\\pi$ systems with isospins 1 and 2 with new determinations of the\nisospin-2 three-pion finite-volume spectrum, obtained for three cubic, periodic\nlattice volumes with box length ranging from $\\approx 4/m_\\pi$ to $6/m_\\pi$.\nThese combined data constrain the low-lying partial waves of the\ninfinite-volume three-pion K matrix, from which we solve a set of coupled\nintegral equations to extract the corresponding scattering amplitudes."}
{"id": "2510.24876", "categories": ["math.OC", "cs.NA", "math.AP", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.24876", "abs": "https://arxiv.org/abs/2510.24876", "authors": ["Abhishek Chaudhary"], "title": "Convergence analysis for an implementable scheme to solve the linear-quadratic stochastic optimal control problem with stochastic wave equation", "comment": "37 pages, 16 figures", "summary": "We study an optimal control problem for the stochastic wave equation driven\nby affine multiplicative noise, formulated as a stochastic linear-quadratic\n(SLQ) problem. By applying a stochastic Pontryagin's maximum principle, we\ncharacterize the optimal state-control pair via a coupled forward-backward SPDE\nsystem. We propose an implementable discretization using conforming finite\nelements in space and an implicit midpoint rule in time. By a new technical\napproach we obtain strong convergence rates for the discrete state-control pair\nwithout relying on Malliavin calculus. For the practical computation we develop\na gradient-descent algorithm based on artificial iterates that employs an exact\ncomputation for the arising conditional expectations, thereby eliminating\ncostly Monte Carlo sampling. Consequently, each iteration has a computational\ncost that is proportional to the number of spatial degrees of freedom,\nproducing a scalable method that preserves the established strong convergence\nrates. Numerical results validate its efficiency."}
{"id": "2510.25045", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.25045", "abs": "https://arxiv.org/abs/2510.25045", "authors": ["Nicholas Loveday", "Tracy Hertneky"], "title": "Evaluating Extreme Precipitation Forecasts: A Threshold-Weighted, Spatial Verification Approach for Comparing an AI Weather Prediction Model Against a High-Resolution NWP Model", "comment": null, "summary": "Recent advances in AI-based weather prediction have led to the development of\nartificial intelligence weather prediction (AIWP) models with competitive\nforecast skill compared to traditional NWP models, but with substantially\nreduced computational cost. There is a strong need for appropriate methods to\nevaluate their ability to predict extreme weather events, particularly when\nspatial coherence is important, and grid resolutions differ between models.\n  We introduce a verification framework that combines spatial verification\nmethods and proper scoring rules. Specifically, the framework extends the\nHigh-Resolution Assessment (HiRA) approach with threshold-weighted scoring\nrules. It enables user-oriented evaluation consistent with how forecasts may be\ninterpreted by operational meteorologists or used in simple post-processing\nsystems. The method supports targeted evaluation of extreme events by allowing\nflexible weighting of the relative importance of different decision thresholds.\nWe demonstrate this framework by evaluating 32 months of precipitation\nforecasts from an AIWP model and a high-resolution NWP model. Our results show\nthat model rankings are sensitive to the choice of neighbourhood size.\nIncreasing the neighbourhood size has a greater impact on scores evaluating\nextreme-event performance for the high-resolution NWP model than for the AIWP\nmodel. At equivalent neighbourhood sizes, the high-resolution NWP model only\noutperformed the AIWP model in predicting extreme precipitation events at short\nlead times. We also demonstrate how this approach can be extended to evaluate\ndiscrimination ability in predicting heavy precipitation. We find that the\nhigh-resolution NWP model had superior discrimination ability at short lead\ntimes, while the AIWP model had slightly better discrimination ability from a\nlead time of 24-hours onwards."}
{"id": "2510.25307", "categories": ["nlin.CD", "math-ph", "math.AP", "math.DS", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.25307", "abs": "https://arxiv.org/abs/2510.25307", "authors": ["Frédéric Faure"], "title": "Can quantum dynamics emerge from classical chaos?", "comment": "20 pages", "summary": "Anosov geodesic flows are among the simplest mathematical models of\ndeterministic chaos. In this survey we explain how, quite unexpectedly, quantum\ndynamics emerges from purely classical correlation functions. The underlying\nmechanism is the discrete Pollicott Ruelle spectrum of the geodesic flow,\nrevealed through microlocal analysis. This spectrum naturally arranges into\nvertical bands; when the rightmost band is separated from the rest by a gap, it\ngoverns an effective dynamics that mirrors quantum evolution."}
{"id": "2510.25155", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.25155", "abs": "https://arxiv.org/abs/2510.25155", "authors": ["Yatao Zhang", "Ye Hong", "Song Gao", "Martin Raubal"], "title": "Bidirectional yet asymmetric causality between urban systems and traffic dynamics in 30 cities worldwide", "comment": null, "summary": "Understanding how urban systems and traffic dynamics co-evolve is crucial for\nadvancing sustainable and resilient cities. However, their bidirectional causal\nrelationships remain underexplored due to challenges of simultaneously\ninferring spatial heterogeneity, temporal variation, and feedback mechanisms.\nTo address this gap, we propose a novel spatio-temporal causality framework\nthat bridges correlation and causation by integrating spatio-temporal weighted\nregression with a newly developed spatio-temporal convergent cross-mapping\napproach. Characterizing cities through urban structure, form, and function,\nthe framework uncovers bidirectional causal patterns between urban systems and\ntraffic dynamics across 30 cities on six continents. Our findings reveal\nasymmetric bidirectional causality, with urban systems exerting stronger\ninfluences on traffic dynamics than the reverse in most cities. Urban form and\nfunction shape mobility more profoundly than structure, even though structure\noften exhibits higher correlations, as observed in cities such as Singapore,\nNew Delhi, London, Chicago, and Moscow. This does not preclude the reversed\ncausal direction, whereby long-established mobility patterns can also reshape\nthe built environment over time. Finally, we identify three distinct causal\narchetypes: tightly coupled, pattern-heterogeneous, and workday-attenuated,\nwhich map pathways from causal diagnosis to intervention. This typology\nsupports city-to-city learning and lays a foundation for context-sensitive\nstrategies in sustainable urban and transport planning."}
{"id": "2510.25169", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.25169", "abs": "https://arxiv.org/abs/2510.25169", "authors": ["Shinji Watanabe", "Tsunetomo Yamada", "Hiroyuki Takakura", "Nobuhisa Fujita"], "title": "Monte Carlo study on critical exponents of the classical Heisenberg model in ferromagnetic icosahedral quasicrystal", "comment": "14 pages, 17 figures, 3 tables", "summary": "Quasicrystals (QCs) lack three-dimensional periodicity of atomic arrangement\nbut possess long-range structural order, which are distinct from periodic\ncrystals and random systems. Here, we show how the ferromagnetic (FM) order\narises in the icosahedral QC (i-QC) on the basis of the Monte Carlo simulation\nof the Heisenberg model on the Yb lattice of Cd$_{5.7}$Yb composed of regular\nicosahedrons. By finite-size scaling of the Monte Carlo data, we identified the\ncritical exponents of the magnetization, magnetic susceptibility, and spin\ncorrelation length, $\\beta=0.508(30)$, $\\gamma=1.361(59)$, and $\\nu=0.792(17)$,\nrespectively. We confirmed that our data satisfy the hyperscaling relation and\nestimated the other critical exponents $\\alpha=-0.376(51)$, $\\delta=3.68(23)$,\nand $\\eta=0.282(65)$. These results show a new universality class inherent in\nthe i-QC, which is different from those in periodic magnets and spin glasses.\nIn the i-QC, each Yb site at vertices of the regular icosahedrons is classified\ninto 8 classes with respect to the coordination numbers of the nearest-neighbor\nand next-nearest-neighbor bonds. We revealed the FM-transition mechanism by\nshowing that the difference in the local environment of each site is governed\nby cooperative evolution of spin correlations upon cooling, giving rise to the\ncritical phenomena."}
{"id": "2510.25553", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.25553", "abs": "https://arxiv.org/abs/2510.25553", "authors": ["Gorka Peraza Coppola", "Moritz Helias", "Zohar Ringel"], "title": "Renormalization group for deep neural networks: Universality of learning and scaling laws", "comment": null, "summary": "Self-similarity, where observables at different length scales exhibit similar\nbehavior, is ubiquitous in natural systems. Such systems are typically\ncharacterized by power-law correlations and universality, and are studied using\nthe powerful framework of the renormalization group (RG). Intriguingly, power\nlaws and weak forms of universality also pervade real-world datasets and deep\nlearning models, motivating the application of RG ideas to the analysis of deep\nlearning. In this work, we develop an RG framework to analyze self-similarity\nand its breakdown in learning curves for a class of weakly non-linear\n(non-lazy) neural networks trained on power-law distributed data. Features\noften neglected in standard treatments -- such as spectrum discreteness and\nlack of translation invariance -- lead to both quantitative and qualitative\ndepartures from conventional perturbative RG. In particular, we find that the\nconcept of scaling intervals naturally replaces that of scaling dimensions.\nDespite these differences, the framework retains key RG features: it enables\nthe classification of perturbations as relevant or irrelevant, and reveals a\nform of universality at large data limits, governed by a Gaussian Process--like\nUV fixed point."}
{"id": "2510.24944", "categories": ["math.NA", "cs.NA", "35Q30, 65M32, 76D05, 93E10"], "pdf": "https://arxiv.org/pdf/2510.24944", "abs": "https://arxiv.org/abs/2510.24944", "authors": ["Tong Wu", "Humberto Godinez", "Vitaliy Gyrya", "James M. Hyman"], "title": "Interpolated Discrepancy Data Assimilation for PDEs with Sparse Observations", "comment": "25 pages, 6 figures, submitted to SIAM Journal on Scientific\n  Computing (SISC)", "summary": "Sparse sensor networks in weather and ocean modeling observe only a small\nfraction of the system state, which destabilizes standard nudging-based data\nassimilation. We introduce Interpolated Discrepancy Data Assimilation (IDDA),\nwhich modifies how discrepancies enter the governing equations. Rather than\nadding observations as a forcing term alone, IDDA also adjusts the nonlinear\noperator using interpolated observational information. This structural change\nsuppresses error amplification when nonlinear effects dominate. We prove\nexponential convergence under explicit conditions linking error decay to\nobservation spacing, nudging strength, and diffusion coefficient. The key\nrequirement establishes bounds on nudging strength relative to observation\nspacing and diffusion, giving practitioners a clear operating window. When\nobservations resolve the relevant scales, error decays at a user-specified\nrate. Critically, the error bound scales with the square of observation spacing\nrather than through hard-to-estimate nonlinear growth rates. We validate IDDA\non Burgers flow, Kuramoto-Sivashinsky dynamics, and two-dimensional\nNavier-Stokes turbulence. Across these tests, IDDA reaches target accuracy\nfaster than standard interpolated nudging, remains stable in chaotic regimes,\navoids non-monotone transients, and requires minimal parameter tuning. Because\nIDDA uses standard explicit time integration, it fits readily into existing\nsimulation pipelines without specialized solvers. These properties make IDDA a\npractical upgrade for operational systems constrained by sparse sensor\ncoverage."}
{"id": "2510.25038", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.25038", "abs": "https://arxiv.org/abs/2510.25038", "authors": ["G. Robalo Rei", "C. P. Schmidt", "J. Nitzler", "M. Dinkel", "W. A. Wall"], "title": "A Black Box Variational Inference Scheme for Inverse Problems with Demanding Physics-Based Models", "comment": null, "summary": "Bayesian methods are particularly effective for addressing inverse problems\ndue to their ability to manage uncertainties inherent in the inference process.\nHowever, employing these methods with costly forward models poses significant\nchallenges, especially in the context of non-differentiable models, where the\nabsence of likelihood model gradient information can result in high\ncomputational costs. To tackle this issue, we develop a novel Bayesian\ninference approach based on black box variational inference, utilizing\nimportance sampling to reuse existing simulation model calls in the variational\nobjective gradient estimation, without relying on forward model gradients. The\nnovelty lies in a new batch-sequential sampling procedure, which only requires\nnew model evaluations if the currently available model evaluations fail to\nyield a suitable approximation of the objective gradient. The resulting\napproach reduces computational costs by leading to variational parameter\nupdates without requiring new model evaluations when possible, while adaptively\nincreasing the number of model calls per iteration as needed. In combination\nwith its black box nature, this new approach is suitable for inverse problems\ninvolving demanding physics-based models that lack model gradients. We\ndemonstrate the efficiency gains of the proposed method compared to its\nbaseline version, sequential Monte Carlo, and Markov-Chain Monte Carlo in\ndiverse benchmarks, ranging from density matching to the Bayesian calibration\nof a nonlinear electro-chemo-mechanical model for solid-state batteries."}
{"id": "2510.25099", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.25099", "abs": "https://arxiv.org/abs/2510.25099", "authors": ["Liangjun Wu"], "title": "Discovery of Late Triassic volcanic ash layers in the deep-water zone of the Nanpanjiang Basin (South China) and the possibility of Carnian Pluvial Episode correlation", "comment": null, "summary": "This study presents new geochronological constraints for the Niluo Member\nwithin the slope-basin facies of the Late Triassic Nanpanjiang Basin, eastern\nTethys. The basin underwent a significant marine-to-continental transition\nduring this period. Previous biostratigraphic studies on platform facies were\nhindered by inconclusive conodont zonation, leaving the chronology of\nslope-basin deposits poorly resolved. To address this, we identified volcanic\nash layers within the Niluo Member in the Wangmo area. Zircon U-Pb dating of\nthese ashes yielded weighted mean ages of 229.9 Ma and 229.0 Ma, establishing a\nCarnian depositional age. This result is significantly younger than previous\nestimates and coincides with the CPE. The Niluo Member is interpreted as a\nperiod of slow, oxygen-deficient sedimentation, contrasting with the rapid\nturbidite deposition of the enclosing formations. This depositional hiatus\nlikely facilitated the preservation of the datable ash layers. The Carnian age\nand unique lithology suggest the Niluo Member may record the CPE in the slope\nenvironment, potentially linked to increased terrigenous input that suppressed\ncarbonate production. Concurrent conodont sampling was unsuccessful, validating\nthe documented difficulties in applying biostratigraphy in these deep-water\nsettings. These new radiometric ages provide a crucial anchor point for Late\nTriassic stratigraphy in South China, demonstrate the potential for preserving\nCPE records in slope facies, and offer a new basis for regional and global\ncorrelation."}
{"id": "2510.25154", "categories": ["stat.ME", "stat.CO", "stat.ML", "62F15"], "pdf": "https://arxiv.org/pdf/2510.25154", "abs": "https://arxiv.org/abs/2510.25154", "authors": ["Kenyon Ng", "Edwin Fong", "David T. Frazier", "Jeremias Knoblauch", "Susan Wei"], "title": "TabMGP: Martingale Posterior with TabPFN", "comment": "11 pages (+3 reference, +22 appendix). Extra plots in\n  https://drive.google.com/drive/folders/1ct_effOoTEGpiWUf0_1xI3VqLWHtJY16", "summary": "Bayesian inference provides principled uncertainty quantification but is\noften limited by challenges of prior elicitation, likelihood misspecification,\nand computational burden. The martingale posterior (MGP, Fong et al., 2023)\noffers an alternative, replacing prior-likelihood elicitation with a predictive\nrule - namely, a sequence of one-step-ahead predictive distributions - for\nforward data generation. The utility of MGPs depends on the choice of\npredictive rule, yet the literature has offered few compelling examples.\nFoundation transformers are well-suited here, as their autoregressive\ngeneration mirrors this forward simulation and their general-purpose design\nenables rich predictive modeling. We introduce TabMGP, an MGP built on TabPFN,\na transformer foundation model that is currently state-of-the-art for tabular\ndata. TabMGP produces credible sets with near-nominal coverage and often\noutperforms both existing MGP constructions and standard Bayes."}
{"id": "2510.25088", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.25088", "abs": "https://arxiv.org/abs/2510.25088", "authors": ["Wencai Yan", "Wanming Hao", "Yajun Fan", "Yabo Guo", "Qingqing Wu", "Xingwang Li"], "title": "Six-Dimensional Movable Antenna Enabled Wideband THz Communications", "comment": null, "summary": "In this paper, we investigate a six-dimensional movable antenna\n(6DMA)-enabled wideband terahertz (THz) communication system with sub-connected\nhybrid beamforming architecture at the base station (BS). In particular, the\nthree-dimensional (3D) position and 3D rotation of each 6DMA surface can be\nflexibly reconfigured to mitigate the beam squint effects instead of\nintroducing costly true-time-delay devices. We first analyze the normalized\narray gain in the 6DMA-enabled wideband THz systems based on the beam squint\neffects. Then, we formulate a sum-rate maximization problem via jointly\noptimizing 3D positions, 3D rotations, and hybrid analog/digital beamforming.\nTo solve the non-convex problem, an alternating optimization algorithm is\ndeveloped that decomposes the original problem into three subproblems, which\nare solved alternately. Specifically, given the positions and rotations of 6DMA\nsurfaces, we first reformulate the objective function and design a semidefinite\nrelaxation-based alternating minimization scheme to obtain the hybrid\nanalog/digital beamforming. Then, the positions and rotations of the 6DMA\nsurfaces are further optimized through a feasible gradient descent procedure.\nThe final solutions are obtained by repeating the above procedure until\nconvergence. Numerical results demonstrate the superior performance of the\nproposed scheme compared with conventional fixed-position antenna\narchitectures."}
{"id": "2510.25359", "categories": ["cond-mat.stat-mech", "q-bio.SC"], "pdf": "https://arxiv.org/pdf/2510.25359", "abs": "https://arxiv.org/abs/2510.25359", "authors": ["Roger D. Jones", "Achille Giacometti", "Alan M. Jones"], "title": "Thermodynamics of Biological Switches", "comment": "One figure. Proceedings of Wivace2025. 10 pages", "summary": "We derive a formulation of the First Law of nonequilibrium thermodynamics for\nbiological information-processing systems by partitioning entropy in the Second\nLaw into microscopic and mesoscopic components and by assuming that natural\nselection promotes optimal information processing and transmission. The\nresulting framework demonstrates how mesoscopic information-based subsystems\ncan attain nonequilibrium steady states (NESS) sustained by external energy and\nentropy fluxes, such as those generated by ATP/ADP imbalances in vivo.\nMoreover, mesoscopic systems may reach NESS before microscopic subsystems,\nleading to ordered structures in entropy flow analogous to eddies in a moving\nstream."}
{"id": "2510.25400", "categories": ["math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25400", "abs": "https://arxiv.org/abs/2510.25400", "authors": ["Sirine Louati"], "title": "Estimation of discrete distributions with high probability under $χ^2$-divergence", "comment": "22 pages", "summary": "We investigate the high-probability estimation of discrete distributions from\nan \\iid sample under $\\chi^2$-divergence loss. Although the minimax risk in\nexpectation is well understood, its high-probability counterpart remains\nlargely unexplored. We provide sharp upper and lower bounds for the classical\nLaplace estimator, showing that it achieves optimal performance among\nestimators that do not rely on the confidence level. We further characterize\nthe minimax high-probability risk for any estimator and demonstrate that it can\nbe attained through a simple smoothing strategy. Our analysis highlights an\nintrinsic separation between asymptotic and non-asymptotic guarantees, with the\nlatter suffering from an unavoidable overhead. This work sharpens existing\nguarantees and advances the theoretical understanding of divergence-based\nestimation."}
{"id": "2510.24756", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24756", "abs": "https://arxiv.org/abs/2510.24756", "authors": ["Jithu Paul", "Karel N. van Dalen", "Andrei B. Faragau", "Rens J. van Leijden", "Biagio Carboni", "Andrei V. Metrikine"], "title": "Principal and Combination Parametric Resonances of an Electromagnetically Suspended Vehicle subject to Base Excitation", "comment": null, "summary": "This paper investigates the dynamic stability of an electromagnetically\nsuspended vehicle, encountered in Hyperloop and Maglev systems, subject to\nperiodic excitations caused by surface irregularities or vibration of the\nsupport induced by external noise. The narrow clearance between the vehicle and\nthe support can make it highly sensitive to small oscillations, since the\nadmissible amplitudes of the vehicle oscillations can be comparable to external\nexcitation amplitude. The vehicle is modelled as a three-degree-of-freedom\nmodel where the vehicle is suspended via two identical electromagnetic\nactuators from a rigid support that oscillates. The governing equations are\nderived using force and torque balances, incorporating nonlinear\nelectromagnetic forces, and Kirchhoffs law for the electromagnets with PD\ncontrol strategy on the airgap. The equations of motion are linearized around\nthe steady state induced by the surface oscillation, yielding a system with\ntime-periodic coefficients. We analytically explore both principal and\ncombination parametric resonances using an extended Hills method, and Floquet\ntheory is used for numerical validation. The stability boundaries are obtained\nas ellipses in control gain parameter space, and the influence of system\nparameters on these boundaries is characterized. For the principal parametric\nresonance, the ratio of the sizes of the two obtained ellipses is three to one,\nwhereas for the combination parametric resonance, the ratio is fourteen to one.\nWhen all ellipses are simultaneously present, one of the ellipses associated\nwith the combination parametric resonance is the largest."}
{"id": "2510.25204", "categories": ["cs.SI", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.25204", "abs": "https://arxiv.org/abs/2510.25204", "authors": ["Qianyun Wu", "Orr Levy", "Yoed N. Kenett", "Yukie Sano", "Hideki Takayasu", "Shlomo Havlin", "Misako Takayasu"], "title": "Stable Emotional Co-occurrence Patterns Revealed by Network Analysis of Social Media", "comment": null, "summary": "Examining emotion interactions as an emotion network in social media offers\nkey insights into human psychology, yet few studies have explored how\nfluctuations in such emotion network evolve during crises and normal times.\nThis study proposes a novel computational approach grounded in network theory,\nleveraging large-scale Japanese social media data spanning varied crisis events\n(earthquakes and COVID-19 vaccination) and non-crisis periods over the past\ndecade. Our analysis identifies and evaluates links between emotions through\nthe co-occurrence of emotion-related concepts (words), revealing a stable\nstructure of emotion network across situations and over time at the population\nlevel. We find that some emotion links (represented as link strength) such as\nemotion links associated with Tension are significantly strengthened during\nearthquake and pre-vaccination periods. However, the rank of emotion links\nremains highly intact. These findings challenge the assumption that emotion\nco-occurrence is context-based and offer a deeper understanding of emotions'\nintrinsic structure. Moreover, our network-based framework offers a systematic,\nscalable method for analyzing emotion co-occurrence dynamics, opening new\navenues for psychological research using large-scale textual data."}
{"id": "2510.24756", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24756", "abs": "https://arxiv.org/abs/2510.24756", "authors": ["Jithu Paul", "Karel N. van Dalen", "Andrei B. Faragau", "Rens J. van Leijden", "Biagio Carboni", "Andrei V. Metrikine"], "title": "Principal and Combination Parametric Resonances of an Electromagnetically Suspended Vehicle subject to Base Excitation", "comment": null, "summary": "This paper investigates the dynamic stability of an electromagnetically\nsuspended vehicle, encountered in Hyperloop and Maglev systems, subject to\nperiodic excitations caused by surface irregularities or vibration of the\nsupport induced by external noise. The narrow clearance between the vehicle and\nthe support can make it highly sensitive to small oscillations, since the\nadmissible amplitudes of the vehicle oscillations can be comparable to external\nexcitation amplitude. The vehicle is modelled as a three-degree-of-freedom\nmodel where the vehicle is suspended via two identical electromagnetic\nactuators from a rigid support that oscillates. The governing equations are\nderived using force and torque balances, incorporating nonlinear\nelectromagnetic forces, and Kirchhoffs law for the electromagnets with PD\ncontrol strategy on the airgap. The equations of motion are linearized around\nthe steady state induced by the surface oscillation, yielding a system with\ntime-periodic coefficients. We analytically explore both principal and\ncombination parametric resonances using an extended Hills method, and Floquet\ntheory is used for numerical validation. The stability boundaries are obtained\nas ellipses in control gain parameter space, and the influence of system\nparameters on these boundaries is characterized. For the principal parametric\nresonance, the ratio of the sizes of the two obtained ellipses is three to one,\nwhereas for the combination parametric resonance, the ratio is fourteen to one.\nWhen all ellipses are simultaneously present, one of the ellipses associated\nwith the combination parametric resonance is the largest."}
{"id": "2510.25644", "categories": ["hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.25644", "abs": "https://arxiv.org/abs/2510.25644", "authors": ["Claudio Bonanno", "Margarita García Pérez", "Antonio González-Arroyo", "Ken-Ichi Ishikawa", "Masanori Okawa", "Dario Panfalone"], "title": "Universal Features of Chiral Symmetry Breaking in Large-$N$ QCD", "comment": "30 pages, 7 figures", "summary": "We investigate the universal features of chiral symmetry breaking in\nlarge-$N$ QCD by comparing non-perturbative determinations of the low-lying\nDirac spectrum with chiral Random Matrix Theory (RMT) predictions. Our\nnumerical Monte Carlo calculations are based on a chiral lattice discretization\nof the Dirac operator, and exploit twisted volume reduction to reach $N$ as\nlarge as 841. Matching lattice data with RMT analytic results, we are able to\nextract the large-$N$ chiral condensate, which is compared with a recent\ndetermination obtained with non-chiral Wilson quarks from twisted\nvolume-reduced models."}
{"id": "2510.24929", "categories": ["math.OC", "90C15, 90C30, 65K05", "G.1.6; G.3"], "pdf": "https://arxiv.org/pdf/2510.24929", "abs": "https://arxiv.org/abs/2510.24929", "authors": ["Yuya Hikima", "Akiko Takeda"], "title": "Zeroth-order gradient estimators for stochastic problems with decision-dependent distributions", "comment": "Author's HP: https://yuya-hikima.github.io/", "summary": "Stochastic optimization problems with unknown decision-dependent\ndistributions have attracted increasing attention in recent years due to its\nimportance in applications. Since the gradient of the objective function is\ninaccessible as a result of the unknown distribution, various zeroth-order\nmethods have been developed to solve the problem. However, it remains unclear\nwhich search direction to construct a gradient estimator is more appropriate\nand how to set the algorithmic parameters. In this paper, we conduct a unified\nsample complexity analysis of zeroth-order methods across gradient estimators\nwith different search directions. As a result, we show that gradient estimators\nthat average over multiple directions, either uniformly from the unit sphere or\nfrom a Gaussian distribution, achieve the lowest sample complexity. The\nattained sample complexities improve those of existing zeroth-order methods in\nthe problem setting that allows nonconvexity and unboundedness of the objective\nfunction. Moreover, by simulation experiments on multiple products pricing and\nstrategic classification applications, we show practical performance of\nzeroth-order methods with various gradient estimators."}
{"id": "2510.25444", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.25444", "abs": "https://arxiv.org/abs/2510.25444", "authors": ["E. McKinnon-Gray", "D. Shipley", "J. Methven", "T. H. A. Frame", "C. Sanchez", "A. McCabe", "N. M. Roberts"], "title": "The representation of Convectively Coupled Equatorial Waves and upscale energy transfer in models with explicit and parametrized convection", "comment": "This article has been submitted to Journal of the Atmospheric\n  Sciences. Copyright in this article may be transferred without further notice", "summary": "Convectively Coupled Equatorial Waves (CCEWs) dominate atmospheric\nvariability on timescales of 2--30 days in the Tropics, bringing episodes of\nwidespread heavy precipitation. This study compares the representation of CCEWs\nand their connection to upscale energy transfer in two Met Office Unified Model\nsimulations of the full tropical channel with identical km-scale resolution.\nThe principal difference between the simulations is that one parametrizes\nconvection (GAL), while the other (RAL) is convection permitting. This means\nGAL acts to remove vertical instability without explicitly representing the\nresolved-scale circulation associated with convective plumes. We present the\nfirst quantitative diagnosis of interscale energy transfer and its relation to\nCCEWs. This diagnosis is important because upscale energy transfer between\nconvection and large-scale waves may influence accurate simulation and\npredictability of tropical weather systems. The average upper-tropospheric\nupscale transfer simulated by RAL is approximately 50\\% higher than GAL. CCEWs\nare more coherent in RAL, with an average phase-speed variability 80\\% higher\nthan observations, compared with 166\\% higher in GAL. RAL also simulates\ngreater upscale energy transfer within waves than GAL, with a stronger\ncorrelation between the interscale energy transfer rate and equatorial wave\nwinds. Simulated Kelvin and Rossby waves are associated with upscale energy\ntransfer from scales 2--8 times smaller than the dominant wavelength, related\nto active deep convection within a particular sector of the wave phase. Our\nfindings show that the explicit representation of convective motions has a\nsignificant impact on the simulation of upscale energy transfer, and is\ntherefore very likely to be a significant factor in the faithful simulation of\nthe convective coupling within CCEWs."}
{"id": "2510.25645", "categories": ["physics.soc-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2510.25645", "abs": "https://arxiv.org/abs/2510.25645", "authors": ["Ferran Larroya", "Isabelle Bonhoure", "Femke Min", "Josep Perelló"], "title": "Citizen science dataset on residents' urban heat perception in outdoor public spaces of climate-vulnerable neighborhoods", "comment": null, "summary": "We present a dataset generated to investigate urban heat and thermal\nperception across five neighborhoods in the Barcelona metropolitan area. In\ncollaboration with 14 non-academic partner organizations, we conducted a series\nof citizen science campaigns involving 439 residents as co-researchers engaged\nthroughout all stages of the research process. Participants, residents of areas\nclassified as highly or very highly climate-vulnerable, identified 210 public\noutdoor sites relevant to their daily lives. These locations were subsequently\ncharacterized using a range of spatial and environmental indicators pertinent\nto urban heat island effects, urban health, and climate resilience. Over the\ncourse of 48 thermal walks, participants carried portable, low-cost sensors\nthat continuously recorded air temperature, relative humidity, and geolocation,\nresulting in 296,286 processed microclimatic data points. At pre-defined sites,\nindividuals completed standardized surveys to report their Thermal Sensation\nVotes and Thermal Comfort Votes, yielding 5,169 self-reported entries.\nSociodemographic data were also collected to further contextualize\nparticipants' responses. The resulting dataset integrates objective\nenvironmental measurements with subjective perceptions of heat, enabling\npoint-by-point analysis of thermal experience within the urban fabric. It\noffers a novel, multi-dimensional resource to support research on heat, thermal\ninequality, and the experiential dimensions of climate vulnerability, and is\nintended to inform evidence-based decision-making in urban planning, public\nhealth, and climate adaptation."}
{"id": "2510.25194", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.25194", "abs": "https://arxiv.org/abs/2510.25194", "authors": ["A. E. Petrova", "S. Yu. Gavrilkin", "V. A. Stepanov", "S. S. Khasanov", "Dirk Mensel", "S. M. Stishov"], "title": "Linear and isotropic magnetoresistance of Co$_{1-x}$Fe$_x$Si at x=0.2; 0.4; 0.65", "comment": "5 pages, 10 figures", "summary": "We studied the magnetoresistance (MR) of well-characterized samples of\nCo$_{1-x}$Fe$_x$Si at x=0.2, 0.4, and 0.65 at temperatures between 1.8 and\n100~K and magnetic fields of 9~T. The quasilinear dependence of MR on the\nmagnetic field at low temperatures and the practically isotropic properties of\nMR in these compounds are tentatively attributed to the specifics of Weyl\nelectron spectra and general disorder of the materials."}
{"id": "2510.25539", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.25539", "abs": "https://arxiv.org/abs/2510.25539", "authors": ["Marcus V. Marinho", "Eric C. Andrade"], "title": "Quantum Spin Liquids Stabilized by Disorder in Non-Kramers Pyrochlores", "comment": "9 pages, 6 figures. Contribution to the Annalen der Physik,\n  Collection: Advances in Strongly Correlated Systems", "summary": "This study investigates the emergence of quantum spin liquid phases in\npyrochlore oxides with non-Kramers ions, driven by structural randomness that\neffectively acts as a transverse field, introducing quantum fluctuations on top\nof the spin ice manifold. This is contrary to the naive expectation that\ndisorder favors phases with short-range entanglement by adjusting the spins\nwith their local environment. Given this unusual situation, it is essential to\nassess the stability of the spin-liquid phase with respect to the disorder. To\nperform this study, a minimal model for disordered quantum spin ice, the\ntransverse-field Ising model, is analyzed using a formulation of gauge\nmean-field theory (GMFT) directly in real space. This approach allows the\ninclusion of disorder effects exactly and provides access to non-perturbative\neffects. The analysis shows that the quantum spin ice remains remarkably stable\nwith respect to disorder up to the transition to the polarized phase at high\nfields, indicating that it can occur in real materials. Moreover, the Griffiths\nregion of enhanced disorder-induced fluctuations appears tiny and restricted to\nthe immediate vicinity of this transition due to the uniqueness of the\nlow-energy excitations of the problem. For most of the phase diagram, an\naverage description of the disorder captures the physical behavior well,\nindicating that the inhomogeneous quantum spin ice behaves closely to its\nhomogeneous counterpart."}
{"id": "2510.24984", "categories": ["math.NA", "cs.NA", "65R20 (Primary) 45E05, 65E05 (Secondary)"], "pdf": "https://arxiv.org/pdf/2510.24984", "abs": "https://arxiv.org/abs/2510.24984", "authors": ["Maria Capcelea", "Titu Capcelea"], "title": "The B-spline collocation method for solving Cauchy singular integral equations with piecewise Holder continuous coefficients", "comment": "Preprint, 21 pages, submitted to Mathematics of Computation", "summary": "In this paper, we propose a numerical method for approximating the solution\nof a Cauchy singular integral equation defined on a closed, smooth contour in\nthe complex plane. The coefficients and the right-hand side of the equation are\npiecewise Holder continuous functions that may have a finite number of jump\ndiscontinuities, and are given numerically at a finite set of points on the\ncontour. We introduce an efficient approximation scheme for piecewise Holder\ncontinuous functions based on linear combinations of B-spline functions and\nHeaviside step functions, which serves as the foundation for the proposed\ncollocation algorithm. We then establish the convergence of the sequence of the\nconstructed approximations to the exact solution of the equation in the norm of\npiecewise Holder spaces and derive estimates for the convergence rate of the\nmethod."}
{"id": "2510.25201", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.25201", "abs": "https://arxiv.org/abs/2510.25201", "authors": ["Vishal Patil", "Kavya Bhand", "Kaustubh Mukdam", "Kavya Sharma", "Manas Kawtikwar", "Prajwal Kavhar", "Hridayansh Kaware"], "title": "Enhancing Financial Decision-Making: Machine Learning and AI-Powered Predictions and Analysis", "comment": null, "summary": "The proposed system aims to use various machine learning algorithms to\nenhance financial prediction and generate highly accurate analyses. It\nintroduces an AI-driven platform which offers inflation-analysis, stock market\nprediction, and E-learning module powered by a chatbot. It has achieved high\naccuracy where the Inflation Analysis depicts 0.8% MAE, 1.2% RMSE and the Stock\nPrediction shows 98% and 96% accuracy for Apple and Google stock prices\nrespectively. Key features include historical price trends, inflation rates,\nshort-term future stock prediction, where the data has been extracted using\nreal-world financial datasets. Additionally, the E-learning feature contributes\nto bridging financial gaps and promoting informed decisions. We have\nimplemented algorithms like linear regression, ARIMA, LSTM where the accuracy\nhas been evaluated using metrics such as MAE, RMSE and the like."}
{"id": "2510.25447", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.25447", "abs": "https://arxiv.org/abs/2510.25447", "authors": ["Yohei Sawada", "Masashi Minamide", "Yuyue Yan", "Kazumune Hashimoto", "Le Duc"], "title": "Data-driven Exploration of Tropical Cyclone's Controllability", "comment": "22 pages, 6 figures", "summary": "Although the chaotic nature of the atmosphere may enable efficient control of\ntropical cyclones (TCs) via small-scale perturbations, few studies have\nproposed data-driven optimization methods to identify such perturbations. Here,\nwe apply the recently proposed Ensemble Kalman Control (EnKC) to a TC\nsimulation. We show that EnKC finds small-scale perturbations that mitigate TC.\nAn EnKC-estimated reduction in surface water vapor, located approximately 250km\nfrom the TC center, suppresses convective activity and latent heat release in\nthe eye wall, leading to a reduction of TC intensity. To advance the discovery\nof feasible TC mitigation strategies, we discuss the potential of this\ndata-driven method for leveraging chaos, as well as its remaining challenges."}
{"id": "2510.25236", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25236", "abs": "https://arxiv.org/abs/2510.25236", "authors": ["Yuchang Lin", "Qianqian Zhu", "Guodong Li"], "title": "Improving time series estimation and prediction via transfer learning", "comment": null, "summary": "There are many time series in the literature with high dimension yet limited\nsample sizes, such as macroeconomic variables, and it is almost impossible to\nobtain efficient estimation and accurate prediction by using the corresponding\ndatasets themselves. This paper fills the gap by introducing a novel\nrepresentation-based transfer learning framework for vector autoregressive\nmodels, and information from related source datasets with rich observations can\nbe leveraged to enhance estimation efficiency through representation learning.\nA two-stage regularized estimation procedure is proposed with well established\nnon-asymptotic properties, and algorithms with alternating updates are\nsuggested to search for the estimates. Our transfer learning framework can\nhandle time series with varying sample sizes and asynchronous starting and/or\nending time points, thereby offering remarkable flexibility in integrating\ninformation from diverse datasets. Simulation experiments are conducted to\nevaluate the finite-sample performance of the proposed methodology, and its\nusefulness is demonstrated by an empirical analysis on 20 macroeconomic\nvariables from Japan and another nine countries."}
{"id": "2510.25654", "categories": ["physics.comp-ph", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2510.25654", "abs": "https://arxiv.org/abs/2510.25654", "authors": ["Steffen Schultze", "Helmut Grubmüller"], "title": "Bayesian MINFLUX localization microscopy", "comment": "5 pages, 5 figures", "summary": "MINFLUX microscopy allows for localization of fluorophores with nanometer\nprecision using targeted scanning with an illumination profile with a minimum.\nHowever, current scanning patterns and the overall procedure are based on\nheuristics, and may therefore be suboptimal. Here we present a rigorous\nBayesian that offers maximal resolutions from either minimal detected photons\nor minimal exposures. We estimate using simulated localization runs that this\napproach should reduce the number of photons required for 1 nm resolution by a\nfactor of about four."}
{"id": "2510.25377", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2510.25377", "abs": "https://arxiv.org/abs/2510.25377", "authors": ["Charlotte Myin", "Benoît Mahault"], "title": "Flocking in weakly nonreciprocal mixtures", "comment": null, "summary": "We show that weakly nonreciprocal alignment leads to large-scale structure\nformation in flocking mixtures. By combining numerical simulations of a binary\nVicsek model and the analysis of coarse-grained continuum equations, we\ndemonstrate that nonreciprocity destabilizes the ordered phase formed by\nmutually aligning or anti-aligning species in a large part of the phase\ndiagram. For aligning populations, this instability results in one species\ncondensing in a single band that travels within a homogeneous liquid of the\nother species. When interactions are anti-aligning, both species self-assemble\ninto polar clusters with large-scale chaotic dynamics. In both cases, the\nemergence of structures is accompanied by the demixing of the two species,\ndespite the absence of repulsive interactions. Our theoretical analysis allows\nus to elucidate the origin of the instability, and show that it is generic to\nnonreciprocal flocks."}
{"id": "2510.25408", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25408", "abs": "https://arxiv.org/abs/2510.25408", "authors": ["Fabian Mies"], "title": "Empirical Orlicz norms", "comment": null, "summary": "The empirical Orlicz norm based on a random sample is defined as a natural\nestimator of the Orlicz norm of a univariate probability distribution. A law of\nlarge numbers is derived under minimal assumptions. The latter extends readily\nto a linear and a nonparametric regression model. Secondly, sufficient\nconditions for a central limit theorem with a standard rate of convergence are\nsupplied. The conditions for the CLT exclude certain canonical examples, such\nas the empirical sub-Gaussian norm of normally distributed random variables.\nFor the latter, we discover a nonstandard rate of $n^{1/4} \\log(n)^{-3/8}$,\nwith a heavy-tailed, stable limit distribution. It is shown that in general,\nthe empirical Orlicz norm does not admit any uniform rate of convergence for\nthe class of distributions with bounded Orlicz norm."}
{"id": "2510.24757", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24757", "abs": "https://arxiv.org/abs/2510.24757", "authors": ["Ahmet Eren Sertbaş", "Tufan Kumbasar"], "title": "Stable-by-Design Neural Network-Based LPV State-Space Models for System Identification", "comment": "In the 12th International Conference of Image Processing, Wavelet and\n  Applications on Real World Problems, 2025", "summary": "Accurate modeling of nonlinear systems is essential for reliable control, yet\nconventional identification methods often struggle to capture latent dynamics\nwhile maintaining stability. We propose a \\textit{stable-by-design LPV neural\nnetwork-based state-space} (NN-SS) model that simultaneously learns latent\nstates and internal scheduling variables directly from data. The\nstate-transition matrix, generated by a neural network using the learned\nscheduling variables, is guaranteed to be stable through a Schur-based\nparameterization. The architecture combines an encoder for initial state\nestimation with a state-space representer network that constructs the full set\nof scheduling-dependent system matrices. For training the NN-SS, we develop a\nframework that integrates multi-step prediction losses with a state-consistency\nregularization term, ensuring robustness against drift and improving\nlong-horizon prediction accuracy. The proposed NN-SS is evaluated on benchmark\nnonlinear systems, and the results demonstrate that the model consistently\nmatches or surpasses classical subspace identification methods and recent\ngradient-based approaches. These findings highlight the potential of\nstability-constrained neural LPV identification as a scalable and reliable\nframework for modeling complex nonlinear systems."}
{"id": "2510.25289", "categories": ["cs.SI", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25289", "abs": "https://arxiv.org/abs/2510.25289", "authors": ["Dong Huang", "Pengkun Yang"], "title": "Testing Correlation in Graphs by Counting Bounded Degree Motifs", "comment": "44 pages, 9 figures", "summary": "Correlation analysis is a fundamental step for extracting meaningful insights\nfrom complex datasets. In this paper, we investigate the problem of detecting\ncorrelation between two Erd\\H{o}s-R\\'enyi graphs $G(n,p)$, formulated as a\nhypothesis testing problem: under the null hypothesis, the two graphs are\nindependent, while under the alternative hypothesis, they are correlated. We\ndevelop a polynomial-time test by counting bounded degree motifs and prove its\neffectiveness for any constant correlation coefficient $\\rho$ when the edge\nconnecting probability satisfies $p\\ge n^{-2/3}$. Our results overcome the\nlimitation requiring $\\rho \\ge \\sqrt{\\alpha}$, where $\\alpha\\approx 0.338$ is\nthe Otter's constant, extending it to any constant $\\rho$. Methodologically,\nbounded degree motifs -- ubiquitous in real networks -- make the proposed\nstatistic both natural and scalable. We also validate our method on synthetic\nand real co-citation networks, further confirming that this simple motif family\neffectively captures correlation signals and exhibits strong empirical\nperformance."}
{"id": "2510.24757", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24757", "abs": "https://arxiv.org/abs/2510.24757", "authors": ["Ahmet Eren Sertbaş", "Tufan Kumbasar"], "title": "Stable-by-Design Neural Network-Based LPV State-Space Models for System Identification", "comment": "In the 12th International Conference of Image Processing, Wavelet and\n  Applications on Real World Problems, 2025", "summary": "Accurate modeling of nonlinear systems is essential for reliable control, yet\nconventional identification methods often struggle to capture latent dynamics\nwhile maintaining stability. We propose a \\textit{stable-by-design LPV neural\nnetwork-based state-space} (NN-SS) model that simultaneously learns latent\nstates and internal scheduling variables directly from data. The\nstate-transition matrix, generated by a neural network using the learned\nscheduling variables, is guaranteed to be stable through a Schur-based\nparameterization. The architecture combines an encoder for initial state\nestimation with a state-space representer network that constructs the full set\nof scheduling-dependent system matrices. For training the NN-SS, we develop a\nframework that integrates multi-step prediction losses with a state-consistency\nregularization term, ensuring robustness against drift and improving\nlong-horizon prediction accuracy. The proposed NN-SS is evaluated on benchmark\nnonlinear systems, and the results demonstrate that the model consistently\nmatches or surpasses classical subspace identification methods and recent\ngradient-based approaches. These findings highlight the potential of\nstability-constrained neural LPV identification as a scalable and reliable\nframework for modeling complex nonlinear systems."}
{"id": "2510.25704", "categories": ["hep-lat", "cond-mat.stat-mech", "cs.LG", "hep-ph"], "pdf": "https://arxiv.org/pdf/2510.25704", "abs": "https://arxiv.org/abs/2510.25704", "authors": ["Claudio Bonanno", "Andrea Bulgarelli", "Elia Cellini", "Alessandro Nada", "Dario Panfalone", "Davide Vadacchino", "Lorenzo Verzichelli"], "title": "Scaling flow-based approaches for topology sampling in $\\mathrm{SU}(3)$ gauge theory", "comment": "1+39 pages, 14 figures", "summary": "We develop a methodology based on out-of-equilibrium simulations to mitigate\ntopological freezing when approaching the continuum limit of lattice gauge\ntheories. We reduce the autocorrelation of the topological charge employing\nopen boundary conditions, while removing exactly their unphysical effects using\na non-equilibrium Monte Carlo approach in which periodic boundary conditions\nare gradually switched on. We perform a detailed analysis of the computational\ncosts of this strategy in the case of the four-dimensional $\\mathrm{SU}(3)$\nYang-Mills theory. After achieving full control of the scaling, we outline a\nclear strategy to sample topology efficiently in the continuum limit, which we\ncheck at lattice spacings as small as $0.045$ fm. We also generalize this\napproach by designing a customized Stochastic Normalizing Flow for evolutions\nin the boundary conditions, obtaining superior performances with respect to the\npurely stochastic non-equilibrium approach, and paving the way for more\nefficient future flow-based solutions."}
{"id": "2510.24967", "categories": ["math.OC", "cs.NA", "math.NA", "90C30, 90C25, 49M15, 65K05"], "pdf": "https://arxiv.org/pdf/2510.24967", "abs": "https://arxiv.org/abs/2510.24967", "authors": ["Nick Tsipinakis", "Panos Parpas", "Matthias Voigt"], "title": "Adaptive Multilevel Newton: A Quadratically Convergent Optimization Method", "comment": "35 pages, 29 figures", "summary": "Newton's method may exhibit slower convergence than vanilla Gradient Descent\nin its initial phase on strongly convex problems. Classical Newton-type\nmultilevel methods mitigate this but, like Gradient Descent, achieve only\nlinear convergence near the minimizer. We introduce an adaptive multilevel\nNewton-type method with a principled automatic switch to full Newton once its\nquadratic phase is reached. The local quadratic convergence for strongly convex\nfunctions with Lipschitz continuous Hessians and for self-concordant functions\nis established and confirmed empirically. Although per-iteration cost can\nexceed that of classical multilevel schemes, the method is efficient and\nconsistently outperforms Newton's method, Gradient Descent, and the multilevel\nNewton method, indicating that second-order methods can outperform first-order\nmethods even when Newton's method is initially slow."}
{"id": "2510.25481", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.25481", "abs": "https://arxiv.org/abs/2510.25481", "authors": ["Nils Melsom Kristensen", "Kristian Mogensen", "Sarah-Jane Lock", "Øyvind Breivik"], "title": "Diagnostic vs dynamic representation of the inverse barometer effect in a global ocean model and its potential for probabilistic storm surge forecasting", "comment": null, "summary": "The global ocean model NEMO is run in a series of stand-alone configurations\n(2015-2022) to investigate the potential for improving global medium-range\nstorm surge forecasts by including the inverse barometer effect. Here, we\ncompare a control experiment, where the inverse barometer effect was not\nincluded, against a run dynamically forced with mean sea level pressure. In the\ncontrol experiment, the inverse barometer effect was then calculated\ndiagnostically and added to the ocean model sea surface elevation, resulting in\na total of three experiments to investigate. We compare against the global\nGESLA3 water level data set and find that the inclusion of the inverse\nbarometer effect reduces the root-mean-square error by $\\sim 1~cm$ on average.\nWhen we mask out all data where the observed storm surge is less than $\\pm1$ or\n$\\pm2$ standard deviations, including the inverse barometer effect reduces the\nRMS error by $4-5$ cm. While both methods reduce water level errors, there are\nregional differences in their performance. The run with dynamical pressure\nforcing is seen to perform slightly better than diagnostically adding the\ninverse barometer effect in enclosed basins such as the Baltic Sea. Finally, an\nensemble forecast experiment with the Integrated Forecast System of the\nEuropean Centre for Medium-range Weather Forecasts demonstrates that when the\ndiagnostic inverse barometer effect is included for a severe storm surge event\nin the North Sea (Storm Xaver, December 2013), the ensemble spread of water\nlevel provides a stronger and earlier indication of the observed maximum surge\nlevel than the when the effect is excluded."}
{"id": "2510.25349", "categories": ["cond-mat.str-el", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.25349", "abs": "https://arxiv.org/abs/2510.25349", "authors": ["M. Bayer", "M. Vieweg", "K. P. Schmidt"], "title": "Immobile and mobile excitations of three-spin interactions on the diamond chain", "comment": "19 pages, 4 figures", "summary": "We present a solvable one-dimensional spin-1/2 model on the diamond chain\nfeaturing three-spin interactions, which displays both, mobile excitations\ndriving a second-order phase transition between an ordered and a\n$\\mathbb{Z}_2$-symmetry broken phase, as well as non-trivial fully immobile\nexcitations. The model is motivated by the physics of fracton excitations,\nwhich only possess mobility in a reduced dimension compared to the full model.\nWe provide an exact mapping of this model to an arbitrary number of independent\ntransverse-field Ising chain segments with open boundary conditions. The number\nand lengths of these segments correspond directly to the number of immobile\nexcitations and their respective distances from one another. Furthermore, we\ndemonstrate that multiple immobile excitations exhibit Casimir-like forces\nbetween them, resulting in a non-trivial spectrum."}
{"id": "2510.25034", "categories": ["math.NA", "cs.NA", "math-ph", "math.AP", "math.MP", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.25034", "abs": "https://arxiv.org/abs/2510.25034", "authors": ["Benedict Leimkuhler", "René Lohmann", "Grigorios A. Pavliotis", "Peter A. Whalley"], "title": "Cluster Formation in Diffusive Systems", "comment": "51 pages, 29 Figures", "summary": "In this paper, we study the formation of clusters for stochastic interacting\nparticle systems (SIPS) that interact through short-range attractive potentials\nin a periodic domain. We consider kinetic (underdamped) Langevin dynamics and\nfocus on the low-friction regime. Employing a linear stability analysis for the\nkinetic McKean-Vlasov equation, we show that, at sufficiently low temperatures,\nand for sufficiently short-ranged interactions, the particles form clusters\nthat correspond to metastable states of the mean-field dynamics. We derive the\nfriction and particle-count dependent cluster-formation time and numerically\nmeasure the friction-dependent times to reach a stationary state (given by a\nstate in which all particles are bound in a single cluster). By providing both\ntheory and numerical methods in the inertial stochastic setting, this work acts\nas a bridge between cluster formation studies in overdamped Langevin dynamics\nand the Hamiltonian (microcanonical) limit."}
{"id": "2510.25697", "categories": ["cs.CE", "I.6.3, J.2, I.2.1"], "pdf": "https://arxiv.org/pdf/2510.25697", "abs": "https://arxiv.org/abs/2510.25697", "authors": ["Edgard Moreira Minete", "Mathis Immertreu", "Fabian Teichmann", "Sebastian Müller"], "title": "Fourier Neural Operators for Two-Phase, 2D Mold-Filling Problems Related to Metal Casting", "comment": "21 pages, 7 figures, 5 tables, 63 references", "summary": "This work reframes mold filling in metal casting as a simplified 2D operator\nlearning surrogate to avoid costly transient CFD simulations. The method\ncombines a graph based encoder that aggregates neighborhood information on an\nunstructured input mesh to encode geometry and boundary data, a Fourier\nspectral core that operates on a regular latent grid to capture global\ninteractions, and a graph based decoder that maps latent fields back to a\ntarget mesh. The model jointly predicts velocities, pressure, and volume\nfraction over a fixed horizon and generalizes across varied ingate locations\nand process settings. On held out geometries and inlet conditions it reproduces\nlarge scale advection and the fluid air interface with errors concentrated near\nsteep gradients. Mean relative L2 errors are about 5 percent across all fields.\nInference is roughly 100 to 1000 times faster than conventional CFD\nsimulations, thereby enabling rapid in-the-loop design exploration. Ablation\nstudies show accuracy drops monotonically with stronger spatial subsampling of\ninput vertices while temporal subsampling causes a gentler decline. Cutting the\ntraining data by 50 percent yields only small error growth. Overall the results\ndemonstrate neural operators as efficient surrogates for 2D mold filling and\nrelated filling problems and enable fast exploration and optimization of gating\nsystem designs in casting workflows."}
{"id": "2510.25554", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.25554", "abs": "https://arxiv.org/abs/2510.25554", "authors": ["Sarem Norouzi", "Per Moldrup", "Ben Moseley", "David Robinson", "Dani Or", "Tobias L. Hohenbrink", "Budiman Minasny", "Morteza Sadeghi", "Emmanuel Arthur", "Markus Tuller", "Mogens H. Greve", "Lis W. de Jonge"], "title": "Learning Soil Physics from Partial Knowledge and Data: Partitioning Capillary and Adsorbed Soil Water", "comment": null, "summary": "Soil physics models have long relied on simplifying assumptions to represent\ncomplex processes, yet such assumptions can strongly bias model predictions.\nHere, we propose a paradigm-shifting differentiable hybrid modeling (DHM)\nframework that instead of simplifying the unknown, learns it from data. As a\nproof of concept, we apply the hybrid approach to the challenge of partitioning\nthe soil water retention curve (SWRC) into capillary and adsorbed water\ncomponents, a problem where traditional assumptions have led to divergent\nresults. The hybrid framework derives this partitioning directly from data\nwhile remaining guided by a few parsimonious and universally accepted physical\nconstraints. Using basic soil physical properties as inputs, the hybrid model\ncouples an analytical formula for the dry end of the SWRC with data-driven\nphysics-informed neural networks that learn the wet end, the transition between\nthe two ends, and key soil-specific parameters. The model was trained on a SWRC\ndataset from 482 undisturbed soil samples from Central Europe, spanning a broad\nrange of soil texture classes and organic carbon contents. The hybrid model\nsuccessfully learned both the overall shape and the capillary and adsorbed\ncomponents of the SWRC. Notably, the model revealed physically meaningful\npore-scale features without relying on explicit geometrical assumptions about\nsoil pore shape or its distribution. Moreover, the model revealed a distinctly\nnonlinear transition between capillary and adsorbed domains, challenging the\nlinear assumptions invoked in previous studies. The methodology introduced here\nprovides a blueprint for learning other soil processes where high-quality\ndatasets are available but mechanistic understanding is incomplete."}
{"id": "2510.25296", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25296", "abs": "https://arxiv.org/abs/2510.25296", "authors": ["Rachel Axelrod", "Uri Obolski", "Daniel Nevo"], "title": "Nonparametric bounds for vaccine effects in randomized trials", "comment": null, "summary": "Vaccine randomized trials are typically designed to be blinded, ensuring that\nthe estimated vaccine efficacy (VE) reflects the immunological effect of the\nvaccine. When blinding is broken, however, the estimated VE reflects not only\nthe immunological effect but also behavioral effects stemming from\nparticipants' awareness of their treatment status. Recent work has proposed\nalternative causal estimands to the standard VE to address this issue, but\ntheir point identification results require a strong assumption: the absence of\nunmeasured common causes of infection risk and participants' belief about\nwhether they received the vaccine. Personality traits, for example, may\nplausibly violate this assumption. We relax this assumption and derive\nnonparametric causal bounds for different types of VE. We construct these\nbounds using two approaches: linear programming-based and monotonicity-based\nmethods. We further consider several possible causal structures for vaccine\ntrials and show how the nonparametric bounds differ across these scenarios.\nFinally, we illustrate the performance of the proposed bounds using fully\nsynthetic data and a semi-synthetic data example based on a COVID-19 vaccine\ntrial."}
{"id": "2510.25658", "categories": ["physics.comp-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2510.25658", "abs": "https://arxiv.org/abs/2510.25658", "authors": ["Maximilian Graml", "Jan Wilhelm"], "title": "Optical excitations in nanographenes from the Bethe-Salpeter equation and time-dependent density functional theory: absorption spectra and spatial descriptors", "comment": null, "summary": "The GW plus Bethe-Salpeter equation (GW-BSE) formalism is a well-established\napproach for calculating excitation energies and optical spectra of molecules,\nnanostructures, and crystalline materials. We implement GW-BSE in the CP2K code\nand validate the implementation for a standard organic molecular test set,\nobtaining excellent agreement with reference data, with a mean absolute error\nin excitation energies below 3 meV. We then study optical spectra of\nnanographenes of increasing length, showing excellent agreement with\nexperiment. We further compute the size of the excitation of the lowest\noptically active excitation which converges to about 7.6 $\\r{A}$ with\nincreasing length. Comparison with time-dependent density functional theory\nusing functionals of varying exact-exchange fraction shows that none reproduce\nboth the size of the excitation and optical spectra of GW-BSE, underscoring the\nneed for many-body methods for accurate description of electronic excitations\nin nanostructures."}
{"id": "2510.25429", "categories": ["cond-mat.stat-mech", "hep-th", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.25429", "abs": "https://arxiv.org/abs/2510.25429", "authors": ["Malte Henkel", "Stoimen Stoimenov"], "title": "Schrödinger-invariance in non-equilibrium critical dynamics", "comment": "17 pages, 3 figures. Conference proceedings LT-16, based on\n  arXiv:2504.16857, arXiv:2505.22301, arXiv:2509.11654. Improves by more long\n  list of models", "summary": "The scaling functions of single-time and two-time correlators in systems\nundergoing non-equilibrium critical dynamics with dynamical exponent ${z}=2$\nare predicted from a new time-dependent non-equilibrium representation of the\nSchr\\\"odinger algebra. These explicit predictions are tested and confirmed in\nthe ageing of several exactly solvable models."}
{"id": "2510.25289", "categories": ["cs.SI", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25289", "abs": "https://arxiv.org/abs/2510.25289", "authors": ["Dong Huang", "Pengkun Yang"], "title": "Testing Correlation in Graphs by Counting Bounded Degree Motifs", "comment": "44 pages, 9 figures", "summary": "Correlation analysis is a fundamental step for extracting meaningful insights\nfrom complex datasets. In this paper, we investigate the problem of detecting\ncorrelation between two Erd\\H{o}s-R\\'enyi graphs $G(n,p)$, formulated as a\nhypothesis testing problem: under the null hypothesis, the two graphs are\nindependent, while under the alternative hypothesis, they are correlated. We\ndevelop a polynomial-time test by counting bounded degree motifs and prove its\neffectiveness for any constant correlation coefficient $\\rho$ when the edge\nconnecting probability satisfies $p\\ge n^{-2/3}$. Our results overcome the\nlimitation requiring $\\rho \\ge \\sqrt{\\alpha}$, where $\\alpha\\approx 0.338$ is\nthe Otter's constant, extending it to any constant $\\rho$. Methodologically,\nbounded degree motifs -- ubiquitous in real networks -- make the proposed\nstatistic both natural and scalable. We also validate our method on synthetic\nand real co-citation networks, further confirming that this simple motif family\neffectively captures correlation signals and exhibits strong empirical\nperformance."}
{"id": "2510.24758", "categories": ["eess.SY", "cs.CY", "cs.MA", "cs.SY", "90B", "C.3; I.6; J.7"], "pdf": "https://arxiv.org/pdf/2510.24758", "abs": "https://arxiv.org/abs/2510.24758", "authors": ["Linh Do-Bui-Khanh", "Thanh H. Nguyen", "Nghi Huynh Quang", "Doanh Nguyen-Ngoc", "Laurent El Ghaoui"], "title": "A Digital Twin Framework for Decision-Support and Optimization of EV Charging Infrastructure in Localized Urban Systems", "comment": "35 pages, 11 figures. Submitted to Computers, Environment and Urban\n  Systems (CEUS)", "summary": "As Electric Vehicle (EV) adoption accelerates in urban environments,\noptimizing charging infrastructure is vital for balancing user satisfaction,\nenergy efficiency, and financial viability. This study advances beyond static\nmodels by proposing a digital twin framework that integrates agent-based\ndecision support with embedded optimization to dynamically simulate EV charging\nbehaviors, infrastructure layouts, and policy responses across scenarios.\nApplied to a localized urban site (a university campus) in Hanoi, Vietnam, the\nmodel evaluates operational policies, EV station configurations, and renewable\nenergy sources. The interactive dashboard enables seasonal analysis, revealing\na 20% drop in solar efficiency from October to March, with wind power\ncontributing under 5% of demand, highlighting the need for adaptive energy\nmanagement. Simulations show that real-time notifications of newly available\ncharging slots improve user satisfaction, while gasoline bans and idle fees\nenhance slot turnover with minimal added complexity. Embedded metaheuristic\noptimization identifies near-optimal mixes of fast (30kW) and standard (11kW)\nsolar-powered chargers, balancing energy performance, profitability, and demand\nwith high computational efficiency. This digital twin provides a flexible,\ncomputation-driven platform for EV infrastructure planning, with a\ntransferable, modular design that enables seamless scaling from localized to\ncity-wide urban contexts."}
{"id": "2510.24758", "categories": ["eess.SY", "cs.CY", "cs.MA", "cs.SY", "90B", "C.3; I.6; J.7"], "pdf": "https://arxiv.org/pdf/2510.24758", "abs": "https://arxiv.org/abs/2510.24758", "authors": ["Linh Do-Bui-Khanh", "Thanh H. Nguyen", "Nghi Huynh Quang", "Doanh Nguyen-Ngoc", "Laurent El Ghaoui"], "title": "A Digital Twin Framework for Decision-Support and Optimization of EV Charging Infrastructure in Localized Urban Systems", "comment": "35 pages, 11 figures. Submitted to Computers, Environment and Urban\n  Systems (CEUS)", "summary": "As Electric Vehicle (EV) adoption accelerates in urban environments,\noptimizing charging infrastructure is vital for balancing user satisfaction,\nenergy efficiency, and financial viability. This study advances beyond static\nmodels by proposing a digital twin framework that integrates agent-based\ndecision support with embedded optimization to dynamically simulate EV charging\nbehaviors, infrastructure layouts, and policy responses across scenarios.\nApplied to a localized urban site (a university campus) in Hanoi, Vietnam, the\nmodel evaluates operational policies, EV station configurations, and renewable\nenergy sources. The interactive dashboard enables seasonal analysis, revealing\na 20% drop in solar efficiency from October to March, with wind power\ncontributing under 5% of demand, highlighting the need for adaptive energy\nmanagement. Simulations show that real-time notifications of newly available\ncharging slots improve user satisfaction, while gasoline bans and idle fees\nenhance slot turnover with minimal added complexity. Embedded metaheuristic\noptimization identifies near-optimal mixes of fast (30kW) and standard (11kW)\nsolar-powered chargers, balancing energy performance, profitability, and demand\nwith high computational efficiency. This digital twin provides a flexible,\ncomputation-driven platform for EV infrastructure planning, with a\ntransferable, modular design that enables seamless scaling from localized to\ncity-wide urban contexts."}
{"id": "2510.24981", "categories": ["math.OC", "90C26, 90C30"], "pdf": "https://arxiv.org/pdf/2510.24981", "abs": "https://arxiv.org/abs/2510.24981", "authors": ["Phan Quoc Khanh", "Felipe Lara"], "title": "Star Quasiconvexity: an Unified Approach for Linear Convergence of First-Order Methods Beyond Convexity", "comment": "3 figures", "summary": "We introduce a class of generalized convex functions, termed star\nquasiconvexity, to ensure the linear convergence of gradient and proximal point\nmethods. This class encompasses convex, star-convex, quasiconvex, and\nquasar-convex functions. We establish that a function is star quasiconvex if\nand only if all its sublevel sets are star-shaped with respect to the set of\nits minimizers. Furthermore, we provide several characterizations of this\nclass, including nonsmooth and differentiable cases, and derive key properties\nthat fa\\-ci\\-li\\-ta\\-te the implementation of first-order methods. Finally, we\nprove that the proximal point algorithm converges linearly to the unique\nsolution when applied to strongly star quasiconvex functions defined over\nclosed, star-shaped sets, which are not necessarily convex."}
{"id": "2510.25633", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.25633", "abs": "https://arxiv.org/abs/2510.25633", "authors": ["Wuqiushi Yao", "Or Hadas", "Yohai Kaspi"], "title": "Predictability of Storms in an Idealized Climate Revealed by Machine Learning", "comment": "Wuqiushi Yao and Or Hadas have contributed equally to this work", "summary": "The midlatitude climate and weather are shaped by storms, yet the factors\ngoverning their predictability remain insufficiently understood. Here, we use a\nConvolutional Neural Network (CNN) to predict and quantify uncertainty in the\nintensity growth and trajectory of over 200,000 storms simulated in a 200-year\naquaplanet GCM. This idealized framework provides a controlled climate\nbackground for isolating factors that govern predictability. Results show that\nstorm intensity is less predictable than trajectory. Strong baroclinicity\naccelerates storm intensification and reduces its predictability, consistent\nwith theory. Crucially, enhanced jet meanders further degrade forecast skill,\nrevealing a synoptic source of uncertainty. Using sensitivity maps from\nexplainable AI, we find that the error growth rate is nearly doubled by the\nmore meandering structure. These findings highlight the potential of machine\nlearning for advancing understanding of predictability and its governing\nmechanisms."}
{"id": "2510.25539", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2510.25539", "abs": "https://arxiv.org/abs/2510.25539", "authors": ["Marcus V. Marinho", "Eric C. Andrade"], "title": "Quantum Spin Liquids Stabilized by Disorder in Non-Kramers Pyrochlores", "comment": "9 pages, 6 figures. Contribution to the Annalen der Physik,\n  Collection: Advances in Strongly Correlated Systems", "summary": "This study investigates the emergence of quantum spin liquid phases in\npyrochlore oxides with non-Kramers ions, driven by structural randomness that\neffectively acts as a transverse field, introducing quantum fluctuations on top\nof the spin ice manifold. This is contrary to the naive expectation that\ndisorder favors phases with short-range entanglement by adjusting the spins\nwith their local environment. Given this unusual situation, it is essential to\nassess the stability of the spin-liquid phase with respect to the disorder. To\nperform this study, a minimal model for disordered quantum spin ice, the\ntransverse-field Ising model, is analyzed using a formulation of gauge\nmean-field theory (GMFT) directly in real space. This approach allows the\ninclusion of disorder effects exactly and provides access to non-perturbative\neffects. The analysis shows that the quantum spin ice remains remarkably stable\nwith respect to disorder up to the transition to the polarized phase at high\nfields, indicating that it can occur in real materials. Moreover, the Griffiths\nregion of enhanced disorder-induced fluctuations appears tiny and restricted to\nthe immediate vicinity of this transition due to the uniqueness of the\nlow-energy excitations of the problem. For most of the phase diagram, an\naverage description of the disorder captures the physical behavior well,\nindicating that the inhomogeneous quantum spin ice behaves closely to its\nhomogeneous counterpart."}
{"id": "2510.25107", "categories": ["math.NA", "cs.NA", "65P10, 68T07", "I.2.6; G.1.7; G.1.10"], "pdf": "https://arxiv.org/pdf/2510.25107", "abs": "https://arxiv.org/abs/2510.25107", "authors": ["Rui Fang", "Richard Tsai"], "title": "Learning Hamiltonian flows from numerical integrators and examples", "comment": null, "summary": "Hamiltonian systems with multiple timescales arise in molecular dynamics,\nclassical mechanics, and theoretical physics. Long-time numerical integration\nof such systems requires resolving fast dynamics with very small time steps,\nwhich incurs a high computational cost - especially in ensemble simulations for\nuncertainty quantification, sensitivity analysis, or varying initial\nconditions. We present a Deep Learning framework that learns the flow maps of\nHamiltonian systems to accelerate long-time and ensemble simulations. Neural\nnetworks are trained, according to a chosen numerical scheme, either entirely\nwithout data to approximate flows over large time intervals or with data to\nlearn flows in intervals far from the initial time. For the latter, we propose\na Hamiltonian Monte Carlo-based data generator. The architecture consists of\nsimple feedforward networks that incorporate truncated Taylor expansions of the\nflow map, with a neural network remainder capturing unresolved effects. Applied\nto benchmark non-integrable and non-canonical systems, the method achieves\nsubstantial speedups while preserving accuracy, enabling scalable simulation of\ncomplex Hamiltonian dynamics."}
{"id": "2510.24742", "categories": ["nlin.CD", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.24742", "abs": "https://arxiv.org/abs/2510.24742", "authors": ["Adam J. Czarnecki", "Andrzej Czarnecki", "Raquel Secrist", "Julia Willsey"], "title": "Shock Wave in the Beirut Explosion: Theory and Video Analysis", "comment": "5 pages, 4 figures. Submitted to the American Journal of Physics", "summary": "Videos of the 2020 Beirut explosion offer a rare opportunity to see a shock\nwave. We summarize the non-linear theory of a weak shock, derive the\nLandau-Whitham formula for the thickness of the overpressure layer and, using\nframe-by-frame video analysis, we demonstrate a semi-quantitative agreement of\ndata and theory."}
{"id": "2510.25315", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.25315", "abs": "https://arxiv.org/abs/2510.25315", "authors": ["Louis Sharrock", "Christopher Nemeth"], "title": "Tuning-Free Sampling via Optimization on the Space of Probability Measures", "comment": null, "summary": "We introduce adaptive, tuning-free step size schedules for gradient-based\nsampling algorithms obtained as time-discretizations of Wasserstein gradient\nflows. The result is a suite of tuning-free sampling algorithms, including\ntuning-free variants of the unadjusted Langevin algorithm (ULA), stochastic\ngradient Langevin dynamics (SGLD), mean-field Langevin dynamics (MFLD), Stein\nvariational gradient descent (SVGD), and variational gradient descent (VGD).\nMore widely, our approach yields tuning-free algorithms for solving a broad\nclass of stochastic optimization problems over the space of probability\nmeasures. Under mild assumptions (e.g., geodesic convexity and locally bounded\nstochastic gradients), we establish strong theoretical guarantees for our\napproach. In particular, we recover the convergence rate of optimally tuned\nversions of these algorithms up to logarithmic factors, in both nonsmooth and\nsmooth settings. We then benchmark the performance of our methods against\ncomparable existing approaches. Across a variety of tasks, our algorithms\nachieve similar performance to the optimal performance of existing algorithms,\nwith no need to tune a step size parameter."}
{"id": "2510.24861", "categories": ["math.NA", "cs.NA", "physics.comp-ph", "physics.plasm-ph", "65M70, 65F30, 35Q83, 65Y20, 82D10"], "pdf": "https://arxiv.org/pdf/2510.24861", "abs": "https://arxiv.org/abs/2510.24861", "authors": ["Nanyi Zheng", "William A. Sands", "Daniel Hayes", "Andrew J. Christlieb", "Jing-Mei Qiu"], "title": "A Semi-Lagrangian Adaptive Rank (SLAR) Method for High-Dimensional Vlasov Dynamics", "comment": "24 pages, 10 figures, 2 algorithms", "summary": "We extend our previous work on a semi-Lagrangian adaptive rank (SLAR)\nintegrator, in the finite difference framework for nonlinear Vlasov-Poisson\nsystems, to the general high-order tensor setting. The proposed scheme retains\nthe high-order accuracy of semi-Lagrangian methods, ensuring stability for\nlarge time steps and avoiding dimensional splitting errors. The primary\ncontribution of this paper is the novel extension of the algorithm from the\nmatrix to the high-dimensional tensor setting, which enables the simulation of\nVlasov models in up to six dimensions. The key technical components include (1)\na third-order high-dimensional polynomial reconstruction that scales as\n$O(d^2)$, providing a point-wise approximation of the solution at the foot of\ncharacteristics in a semi-Lagrangian scheme; (2) a recursive hierarchical\nadaptive cross approximation of high-order tensors in a hierarchical Tucker\nformat, characterized by a tensor tree; (3) a low-complexity Poisson solver in\nthe hierarchical Tucker format that leverages the FFT for efficiency. The\ncomputed adaptive rank kinetic solutions exhibit low-rank structures within\nbranches of the tensor tree resulting in substantial computational savings in\nboth storage and time. The resulting algorithm achieves a computational\ncomplexity of $O(d^4 N r^{3+\\lceil\\log_2d\\rceil})$, where $N$ is the number of\ngrid points per dimension, $d$ is the problem dimension, and $r$ is the maximum\nrank in the tensor tree, overcoming the curse of dimensionality. Through\nextensive numerical tests, we demonstrate the efficiency of the proposed\nalgorithm and highlight its ability to capture complex solution structures\nwhile maintaining a computational complexity that scales linearly with $N$."}
{"id": "2510.25454", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.25454", "abs": "https://arxiv.org/abs/2510.25454", "authors": ["Nathan O. Silvano", "Emilio Hernández-García", "Cristóbal López"], "title": "The impact of fluctuations on particle systems described by Dean-Kawasaki-type equations", "comment": "10 pages, 5 figures", "summary": "We study the role of fluctuations in particle systems modeled by\nDean-Kawasaki-type equations, which describe the evolution of particle\ndensities in systems with Brownian motion. By comparing microscopic\nsimulations, stochastic partial differential equations, and their deterministic\ncounterparts, we analyze four models of increasing complexity. Our results\nidentify macroscopic quantities that can be altered by the conserved\nmultiplicative noise that typically appears in the Dean-Kawasaki-type\ndescription. We find that this noise enhances front propagation in systems with\ndensity-dependent diffusivity, accelerates the onset of pattern formation in\nparticle systems with nonlocal interactions, and reduces hysteresis in systems\ninteracting via repulsive forces. In some cases, it accelerates transitions or\ninduces structures absent in deterministic models. These findings illustrate\nthat (conservative) fluctuations can have constructive and nontrivial effects,\nemphasizing the importance of stochastic modeling in understanding collective\nparticle dynamics."}
{"id": "2510.25521", "categories": ["math.NA", "cs.NA", "math.PR", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25521", "abs": "https://arxiv.org/abs/2510.25521", "authors": ["Jaroslav I. Borodavka", "Max Hirsch", "Sebastian Krumscheid", "Andrea Zanoni"], "title": "Nonparametric estimation of homogenized invariant measures from multiscale data via Hermite expansion", "comment": null, "summary": "We consider the problem of density estimation in the context of multiscale\nLangevin diffusion processes, where a single-scale homogenized surrogate model\ncan be derived. In particular, our aim is to learn the density of the invariant\nmeasure of the homogenized dynamics from a continuous-time trajectory generated\nby the full multiscale system. We propose a spectral method based on a\ntruncated Fourier expansion with Hermite functions as orthonormal basis. The\nFourier coefficients are computed directly from the data owing to the ergodic\ntheorem. We prove that the resulting density estimator is robust and converges\nto the invariant density of the homogenized model as the scale separation\nparameter vanishes, provided the time horizon and the number of Fourier modes\nare suitably chosen in relation to the multiscale parameter. The accuracy and\nreliability of this methodology is further demonstrated through a series of\nnumerical experiments."}
{"id": "2510.24871", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24871", "abs": "https://arxiv.org/abs/2510.24871", "authors": ["Shreshta Rajakumar Deshpande", "Mrdjan Jankovic"], "title": "Decentralized Merging Control of Connected and Automated Vehicles to Enhance Safety and Energy Efficiency using Control Barrier Functions", "comment": "This work has been submitted to a conference for possible publication\n  and is under review. Paper summary: 8 pages, 5 figures, 2 tables", "summary": "This paper presents a decentralized Control Barrier Function (CBF) based\napproach for highway merging of Connected and Automated Vehicles (CAVs). In\nthis control algorithm, each \"host\" vehicle negotiates with other agents in a\ncontrol zone of the highway network, and enacts its own action, to perform safe\nand energy-efficient merge maneuvers. It uses predictor-corrector loops within\nthe robust CBF setting for negotiation and to reconcile disagreements that may\narise. There is no explicit order of vehicles and no priority. A notable\nfeature is absence of gridlocks due to instability of the inter-agent system.\nResults from Monte Carlo simulations show significant improvement in the\nsystem-wide energy efficiency and traffic flow compared to a first-in-first-out\napproach, as well as enhanced robustness of the proposed decentralized\ncontroller compared to its centralized counterpart."}
{"id": "2510.24871", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24871", "abs": "https://arxiv.org/abs/2510.24871", "authors": ["Shreshta Rajakumar Deshpande", "Mrdjan Jankovic"], "title": "Decentralized Merging Control of Connected and Automated Vehicles to Enhance Safety and Energy Efficiency using Control Barrier Functions", "comment": "This work has been submitted to a conference for possible publication\n  and is under review. Paper summary: 8 pages, 5 figures, 2 tables", "summary": "This paper presents a decentralized Control Barrier Function (CBF) based\napproach for highway merging of Connected and Automated Vehicles (CAVs). In\nthis control algorithm, each \"host\" vehicle negotiates with other agents in a\ncontrol zone of the highway network, and enacts its own action, to perform safe\nand energy-efficient merge maneuvers. It uses predictor-corrector loops within\nthe robust CBF setting for negotiation and to reconcile disagreements that may\narise. There is no explicit order of vehicles and no priority. A notable\nfeature is absence of gridlocks due to instability of the inter-agent system.\nResults from Monte Carlo simulations show significant improvement in the\nsystem-wide energy efficiency and traffic flow compared to a first-in-first-out\napproach, as well as enhanced robustness of the proposed decentralized\ncontroller compared to its centralized counterpart."}
{"id": "2510.25060", "categories": ["math.OC", "cs.LG", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.25060", "abs": "https://arxiv.org/abs/2510.25060", "authors": ["Jingzhou Liu"], "title": "Nonlinear Dynamics In Optimization Landscape of Shallow Neural Networks with Tunable Leaky ReLU", "comment": null, "summary": "In this work, we study the nonlinear dynamics of a shallow neural network\ntrained with mean-squared loss and leaky ReLU activation. Under Gaussian inputs\nand equal layer width k, (1) we establish, based on the equivariant gradient\ndegree, a theoretical framework, applicable to any number of neurons k>= 4, to\ndetect bifurcation of critical points with associated symmetries from global\nminimum as leaky parameter $\\alpha$ varies. Typically, our analysis reveals\nthat a multi-mode degeneracy consistently occurs at the critical number 0,\nindependent of k. (2) As a by-product, we further show that such bifurcations\nare width-independent, arise only for nonnegative $\\alpha$ and that the global\nminimum undergoes no further symmetry-breaking instability throughout the\nengineering regime $\\alpha$ in range (0,1). An explicit example with k=5 is\npresented to illustrate the framework and exhibit the resulting bifurcation\ntogether with their symmetries."}
{"id": "2510.25114", "categories": ["math.NA", "cs.LG", "cs.NA", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.25114", "abs": "https://arxiv.org/abs/2510.25114", "authors": ["Yahong Yang", "Sun Lee", "Jeff Calder", "Wenrui Hao"], "title": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model with Connectivity Functional", "comment": null, "summary": "We derive an energy-based continuum limit for $\\varepsilon$-graphs endowed\nwith a general connectivity functional. We prove that the discrete energy and\nits continuum counterpart differ by at most $O(\\varepsilon)$; the prefactor\ninvolves only the $W^{1,1}$-norm of the connectivity density as\n$\\varepsilon\\to0$, so the error bound remains valid even when that density has\nstrong local fluctuations. As an application, we introduce a neural-network\nprocedure that reconstructs the connectivity density from edge-weight data and\nthen embeds the resulting continuum model into a brain-dynamics framework. In\nthis setting, the usual constant diffusion coefficient is replaced by the\nspatially varying coefficient produced by the learned density, yielding\ndynamics that differ significantly from those obtained with conventional\nconstant-diffusion models."}
{"id": "2510.25316", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25316", "abs": "https://arxiv.org/abs/2510.25316", "authors": ["Tianbo Chen"], "title": "Asymmetric Huber Periodogram", "comment": null, "summary": "This paper introduces a novel spectral M-estimator, called the asymmetric\nHuber periodogram (AHP), for periodicity detection in time series. The AHP is\nconstructed from trigonometric asymmetric Huber regression, where a specially\ndesigned check function is used to substitute the squared L2 norm that defines\nthe ordinary periodogram (PG). The AHP is statistically more efficient than the\nquantile periodogram (QP), while offering a more comprehensive picture than the\nHuber periodogram (HP) by examining the data across the entire range of the\nasymmetric parameter. We prove the theoretical properties of the AHP and\ninvestigate the relationship between the AHP and the so-called asymmetric Huber\nspectrum (AHS). Finally, simulations and three real-world data examples\ndemonstrate that the AHP's capability in detecting periodicity and its\nrobustness against outliers."}
{"id": "2510.25752", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.25752", "abs": "https://arxiv.org/abs/2510.25752", "authors": ["James V. Roggeveen", "Michael P. Brenner"], "title": "Meshless solutions of PDE inverse problems on irregular geometries", "comment": null, "summary": "Solving inverse and optimization problems over solutions of nonlinear partial\ndifferential equations (PDEs) on complex spatial domains is a long-standing\nchallenge. Here we introduce a method that parameterizes the solution using\nspectral bases on arbitrary spatiotemporal domains, whereby the basis is\ndefined on a hyperrectangle containing the true domain. We find the\ncoefficients of the basis expansion by solving an optimization problem whereby\nboth the equations, the boundary conditions and any optimization targets are\nenforced by a loss function, building on a key idea from Physics-Informed\nNeural Networks (PINNs). Since the representation of the function natively has\nexponential convergence, so does the solution of the optimization problem, as\nlong as it can be solved efficiently. We find empirically that the optimization\nprotocols developed for machine learning find solutions with exponential\nconvergence on a wide range of equations. The method naturally allows for the\nincorporation of data assimilation by including additional terms in the loss\nfunction, and for the efficient solution of optimization problems over the PDE\nsolutions."}
{"id": "2510.25519", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.25519", "abs": "https://arxiv.org/abs/2510.25519", "authors": ["Angelo Russotto", "Filiberto Ares", "Pasquale Calabrese", "Vincenzo Alba"], "title": "Dynamics of entanglement fluctuations and quantum Mpemba effect in the $ν=1$ QSSEP model", "comment": "26 pages, 8 figures", "summary": "We study the out-of-equilibrium dynamics of entanglement fluctuations in the\n$\\nu=1$ Quantum Symmetric Simple Exclusion Process, a free-fermion chain with\nhopping amplitudes that are stochastic in time but homogeneous in space.\nPrevious work showed that the average entanglement growth after a quantum\nquench can be explained in terms of pairs of entangled quasiparticles\nperforming random walks, leading to diffusive entanglement spreading. By\nincorporating the noise-induced statistical correlations between the\nquasiparticles, we extend this description to the full-time probability\ndistribution of the entanglement entropy. Our generalized quasiparticle picture\nallows us to compute the average time evolution of a generic function of the\nreduced density matrix of a subsystem. We also apply our result to the\nentanglement asymmetry. This allows us to investigate the restoration of\nparticle-number symmetry in the dynamics from initial states with no\nwell-defined particle number, and the emergence of the quantum Mpemba effect."}
{"id": "2510.24898", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24898", "abs": "https://arxiv.org/abs/2510.24898", "authors": ["Xincheng Cao", "Haochong Chen", "Levent Guvenc", "Bilin Aksun-Guvenc"], "title": "Delay Tolerant Control for Autonomous Driving Using CDOB", "comment": null, "summary": "With the rapid growth of autonomous vehicle technologies, effective\npath-tracking control has become a critical component in ensuring safety and\nefficiency in complex traffic scenarios. When a high level decision making\nagent generates a collision free path, a robust low level controller is\nrequired to precisely follow this trajectory. However, connected autonomous\nvehicles (CAV) are inherently affected by communication delays and computation\ndelays, which significantly degrade the performance of conventional controllers\nsuch as PID or other more advanced controllers like disturbance observers\n(DOB). While DOB-based designs have shown effectiveness in rejecting\ndisturbances under nominal conditions, their performance deteriorates\nconsiderably in the presence of unknown time delays. To address this challenge,\nthis paper proposes a delay-tolerant communication disturbance observer (CDOB)\nframework for path-tracking control in delayed systems. The proposed CDOB\ncompensates for the adverse effects of time delays, maintaining accurate\ntrajectory tracking even under uncertain and varying delay conditions. It is\nshown through a simulation study that the proposed control architecture\nmaintains close alignment with the reference trajectory across various\nscenarios, including single lane change, double-= lane change, and Elastic Band\ngenerated collision avoidance paths under various time delays. Simulation\nresults further demonstrate that the proposed method outperforms conventional\napproaches in both tracking accuracy and delay robustness, making it well\nsuited for autonomous driving applications."}
{"id": "2510.24898", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24898", "abs": "https://arxiv.org/abs/2510.24898", "authors": ["Xincheng Cao", "Haochong Chen", "Levent Guvenc", "Bilin Aksun-Guvenc"], "title": "Delay Tolerant Control for Autonomous Driving Using CDOB", "comment": null, "summary": "With the rapid growth of autonomous vehicle technologies, effective\npath-tracking control has become a critical component in ensuring safety and\nefficiency in complex traffic scenarios. When a high level decision making\nagent generates a collision free path, a robust low level controller is\nrequired to precisely follow this trajectory. However, connected autonomous\nvehicles (CAV) are inherently affected by communication delays and computation\ndelays, which significantly degrade the performance of conventional controllers\nsuch as PID or other more advanced controllers like disturbance observers\n(DOB). While DOB-based designs have shown effectiveness in rejecting\ndisturbances under nominal conditions, their performance deteriorates\nconsiderably in the presence of unknown time delays. To address this challenge,\nthis paper proposes a delay-tolerant communication disturbance observer (CDOB)\nframework for path-tracking control in delayed systems. The proposed CDOB\ncompensates for the adverse effects of time delays, maintaining accurate\ntrajectory tracking even under uncertain and varying delay conditions. It is\nshown through a simulation study that the proposed control architecture\nmaintains close alignment with the reference trajectory across various\nscenarios, including single lane change, double-= lane change, and Elastic Band\ngenerated collision avoidance paths under various time delays. Simulation\nresults further demonstrate that the proposed method outperforms conventional\napproaches in both tracking accuracy and delay robustness, making it well\nsuited for autonomous driving applications."}
{"id": "2510.25115", "categories": ["math.OC", "93C15, 49M15, 49K15"], "pdf": "https://arxiv.org/pdf/2510.25115", "abs": "https://arxiv.org/abs/2510.25115", "authors": ["Drake Brown", "Trevor Garrity", "Daniel Perkins", "Davis Hunter", "Wyatt Pochman"], "title": "Optimal Control Strategies for Multi-Agent Sheep Herding", "comment": "11 pages, 5 figures", "summary": "We develop a cost functional and state-space equations to model the problem\nof herding m sheep to the origin using n dogs. Our initial approach uses\nsolve_bvp to approximate optimal control trajectories. But this method often\nfails to converge due to the system's high dimensionality and nonlinearity.\nHowever, with a well-chosen initial guess and carefully selected\nhyperparameters, we succeed in getting solve_bvp to converge. We also explore\nalternatives including the shooting method and linearization with the iterative\nLinear Quadratic Regulator (iLQR). While the shooting method also suffers from\npoor convergence, the linearized iLQR approach proves more scalable and\nsuccessfully handles scenarios with more agents. However, it struggles in\nregions where dogs and sheep are in close proximity, due to strong\nnonlinearities that violate the assumptions of local linearization. This leads\nto jagged, oscillatory paths and slow convergence, particularly when the number\nof sheep exceeds the number of dogs. These challenges reveal key limitations of\nstandard numerical techniques in multi-agent control and underscore the need\nfor more robust, nonlinear strategies for coordinating interacting agents."}
{"id": "2510.25172", "categories": ["math.NA", "cs.NA", "35K61, 65N06, 65N12"], "pdf": "https://arxiv.org/pdf/2510.25172", "abs": "https://arxiv.org/abs/2510.25172", "authors": ["Changjian Xie", "Cheng Wang"], "title": "Error Analysis of Third-Order in Time and Fourth-Order Linear Finite Difference Scheme for Landau-Lifshitz-Gilbert Equation under Large Damping Parameters", "comment": null, "summary": "This work proposes and analyzes a fully discrete numerical scheme for solving\nthe Landau-Lifshitz-Gilbert (LLG) equation, which achieves fourth-order spatial\naccuracy and third-order temporal accuracy.Spatially, fourth-order accuracy is\nattained through the adoption of a long-stencil finite difference method, while\nboundary extrapolation is executed by leveraging a higher-order Taylor\nexpansion to ensure consistency at domain boundaries. Temporally, the scheme is\nconstructed based on the third-order backward differentiation formula (BDF3),\nwith implicit discretization applied to the linear diffusion term for numerical\nstability and explicit extrapolation employed for nonlinear terms to balance\ncomputational efficiency. Notably, this numerical method inherently preserves\nthe normalization constraint of the LLG equation, a key physical property of\nthe system.Theoretical analysis confirms that the proposed scheme exhibits\noptimal convergence rates under the \\(\\ell^{\\infty}([0,T],\\ell^2)\\) and\n\\(\\ell^2([0,T],H_h^1)\\) norms. Finally, numerical experiments are conducted to\nvalidate the correctness of the theoretical convergence results, demonstrating\ngood agreement between numerical observations and analytical conclusions."}
{"id": "2510.25371", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25371", "abs": "https://arxiv.org/abs/2510.25371", "authors": ["Soham Mukherjee", "Javier Enrique Aguilar", "Marcello Zago", "Manfred Claassen", "Paul-Christian Bürkner"], "title": "Latent variable estimation with composite Hilbert space Gaussian processes", "comment": "37 pages, 16 figures, 3 tables", "summary": "We develop a scalable class of models for latent variable estimation using\ncomposite Gaussian processes, with a focus on derivative Gaussian processes. We\njointly model multiple data sources as outputs to improve the accuracy of\nlatent variable inference under a single probabilistic framework. Similarly\nspecified exact Gaussian processes scale poorly with large datasets. To\novercome this, we extend the recently developed Hilbert space approximation\nmethods for Gaussian processes to obtain a reduced-rank representation of the\ncomposite covariance function through its spectral decomposition. Specifically,\nwe derive and analyze the spectral decomposition of derivative covariance\nfunctions and further study their properties theoretically. Using these\nspectral decompositions, our methods easily scale up to data scenarios\ninvolving thousands of samples. We validate our methods in terms of latent\nvariable estimation accuracy, uncertainty calibration, and inference speed\nacross diverse simulation scenarios. Finally, using a real world case study\nfrom single-cell biology, we demonstrate the potential of our models in\nestimating latent cellular ordering given gene expression levels, thus\nenhancing our understanding of the underlying biological process."}
{"id": "2510.25533", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.25533", "abs": "https://arxiv.org/abs/2510.25533", "authors": ["Bastian Castirene", "Martin HeV Groves", "Francisco J. Peña", "Eugenio E. Vogel", "Patricio Vargas"], "title": "Maximum Quantum Work at Criticality: Stirling Engines and Fibonacci-Lucas Degeneracies", "comment": null, "summary": "Many-body effects and quantum criticality play a central role in determining\nthe performance of quantum thermal machines. Although operating near a quantum\ncritical point (QCP) is known to enhance engine performance, the precise\nthermodynamic conditions required to attain the Carnot efficiency limit remain\nunsettled. Here, we derive the exact conditions for a quantum Stirling engine\nto achieve Carnot efficiency when a QCP drives its working medium. In the\nlow-temperature regime, where only the ground-state manifold is populated, the\nnet work output is given by $ W = k_B \\delta \\ln (g_{\\text{crit}}/g_0) $ with $\n\\delta = T_H - T_L $, which directly yields the Carnot efficiency $ \\eta_C = 1\n- T_L/T_H $, independent of microscopic details. Notably, whereas ideal\nStirling cycles attain Carnot efficiency only with a perfect regenerator, here\nno regenerator is required because, at low temperatures, the thermal population\nremains confined to the degenerate ground state; this represents a clear\nquantum advantage over engines with classical working substances. We validate\nthis universal result by recovering known behaviors in various quantum systems,\nincluding spin chains with Dzyaloshinskii-Moriya interactions and magnetic\nanisotropies. Applying the framework to the one-dimensional antiferromagnetic\nIsing model, we predict non-extensive scaling of the work output governed by\nFibonacci and Lucas numbers for open chains and closed rings, respectively,\nwhich converges to classical extensivity in the thermodynamic limit. This\nanalysis establishes a general and robust foundation for designing quantum\nthermal machines that reach the Carnot bound while delivering finite work."}
{"id": "2510.24933", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24933", "abs": "https://arxiv.org/abs/2510.24933", "authors": ["Chams Eddine Mballo", "Donggun Lee", "Claire J. Tomlin"], "title": "A Hamilton-Jacobi Reachability Framework with Soft Constraints for Safety-Critical Systems", "comment": null, "summary": "Traditional reachability methods provide formal guarantees of safety under\nbounded disturbances. However, they strictly enforce state constraints as\ninviolable, which can result in overly conservative or infeasible solutions in\ncomplex operational scenarios. Many constraints encountered in practice, such\nas bounds on battery state of charge in electric vehicles, recommended speed\nenvelopes, and comfort constraints in passenger-carrying vehicles, are\ninherently soft. Soft constraints allow temporary violations within predefined\nsafety margins to accommodate uncertainty and competing operational demands,\nalbeit at a cost such as increased wear or higher operational expenses. This\npaper introduces a novel soft-constrained reachability framework that extends\nHamilton-Jacobi reachability analysis for the formal verification of\nsafety-critical systems subject to both hard and soft constraints.\nSpecifically, the framework characterizes a subset of the state space, referred\nto as the soft-constrained reach-avoid set, from which the system is guaranteed\nto reach a desired set safely, under worst-case disturbances, while ensuring\nthat cumulative soft-constraint violations remain within a user-specified\nbudget. The framework comprises two principal components: (i) an\naugmented-state model with an auxiliary budget state that tracks\nsoft-constraint violations, and (ii) a regularization-based approximation of\nthe discontinuous Hamilton-Jacobi value function associated with the\nreach-avoid differential game studied herein. The effectiveness of the proposed\nframework is demonstrated through numerical examples involving the landing of a\nsimple point-mass model and a fixed-wing aircraft executing an emergency\ndescent, both under wind disturbances. The simulation results validate the\nframework's ability to simultaneously manage both hard and soft constraints in\nsafety-critical settings"}
{"id": "2510.24933", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.24933", "abs": "https://arxiv.org/abs/2510.24933", "authors": ["Chams Eddine Mballo", "Donggun Lee", "Claire J. Tomlin"], "title": "A Hamilton-Jacobi Reachability Framework with Soft Constraints for Safety-Critical Systems", "comment": null, "summary": "Traditional reachability methods provide formal guarantees of safety under\nbounded disturbances. However, they strictly enforce state constraints as\ninviolable, which can result in overly conservative or infeasible solutions in\ncomplex operational scenarios. Many constraints encountered in practice, such\nas bounds on battery state of charge in electric vehicles, recommended speed\nenvelopes, and comfort constraints in passenger-carrying vehicles, are\ninherently soft. Soft constraints allow temporary violations within predefined\nsafety margins to accommodate uncertainty and competing operational demands,\nalbeit at a cost such as increased wear or higher operational expenses. This\npaper introduces a novel soft-constrained reachability framework that extends\nHamilton-Jacobi reachability analysis for the formal verification of\nsafety-critical systems subject to both hard and soft constraints.\nSpecifically, the framework characterizes a subset of the state space, referred\nto as the soft-constrained reach-avoid set, from which the system is guaranteed\nto reach a desired set safely, under worst-case disturbances, while ensuring\nthat cumulative soft-constraint violations remain within a user-specified\nbudget. The framework comprises two principal components: (i) an\naugmented-state model with an auxiliary budget state that tracks\nsoft-constraint violations, and (ii) a regularization-based approximation of\nthe discontinuous Hamilton-Jacobi value function associated with the\nreach-avoid differential game studied herein. The effectiveness of the proposed\nframework is demonstrated through numerical examples involving the landing of a\nsimple point-mass model and a fixed-wing aircraft executing an emergency\ndescent, both under wind disturbances. The simulation results validate the\nframework's ability to simultaneously manage both hard and soft constraints in\nsafety-critical settings"}
{"id": "2510.25243", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25243", "abs": "https://arxiv.org/abs/2510.25243", "authors": ["Akansha Rautela", "Deepak U. Patil", "Ameer Mulla", "Indra Narayan Kar"], "title": "Minimum time consensus for damped second order agents using Gröbner basis", "comment": null, "summary": "A problem of achieving minimum time consensus for a set of $N$ second-order\nLTI system agents with bounded inputs and fuel constraints is considered.\nUnlike our other works, here the damping effect in agent dynamics is included.\nFirst, the attainable set for each agent with fuel budget constraints is\ncharacterized, and its boundary equations are derived. Then, using the\nconvexity property, the minimum time at which attainable sets of all agents\nhave a non-empty intersection is computed. By applying Helly's theorem, the\ncomputation reduces to finding the minimum time to consensus and the\ncorresponding consensus point for each of the triplets separately."}
{"id": "2510.25252", "categories": ["math.NA", "cs.NA", "15A18, 15B05, 65N30"], "pdf": "https://arxiv.org/pdf/2510.25252", "abs": "https://arxiv.org/abs/2510.25252", "authors": ["Samuele Ferri", "Chiara Giraudo", "Valerio Loi", "Miroslav Kuchta", "Stefano Serra-Capizzano"], "title": "Spectral analysis of the stiffness matrix sequence in the approximated Stokes equation", "comment": null, "summary": "In the present paper, we analyze in detail the spectral features of the\nmatrix sequences arising from the Taylor-Hood $\\mathbb{P}_2$-$\\mathbb{P}_1$\napproximation of variable viscosity for $2d$ Stokes problem under weak\nassumptions on the regularity of the diffusion. Localization and distributional\nspectral results are provided, accompanied by numerical tests and\nvisualizations. A preliminary study of the impact of our findings on the\npreconditioning problem is also presented. A final section with concluding\nremarks and open problems ends the current work."}
{"id": "2510.25507", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.25507", "abs": "https://arxiv.org/abs/2510.25507", "authors": ["Yuliang Xu", "Yun Wei", "Li Ma"], "title": "Distributional Evaluation of Generative Models via Relative Density Ratio", "comment": null, "summary": "We propose a functional evaluation metric for generative models based on the\nrelative density ratio (RDR) designed to characterize distributional\ndifferences between real and generated samples. We show that the RDR as a\nfunctional summary of the goodness-of-fit for the generative model, possesses\nseveral desirable theoretical properties. It preserves $\\phi$-divergence\nbetween two distributions, enables sample-level evaluation that facilitates\ndownstream investigations of feature-specific distributional differences, and\nhas a bounded range that affords clear interpretability and numerical\nstability. Functional estimation of the RDR is achieved efficiently through\nconvex optimization on the variational form of $\\phi$-divergence. We provide\ntheoretical convergence rate guarantees for general estimators based on\nM-estimator theory, as well as the convergence rates of neural network-based\nestimators when the true ratio is in the anisotropic Besov space. We\ndemonstrate the power of the proposed RDR-based evaluation through numerical\nexperiments on MNIST, CelebA64, and the American Gut project microbiome data.\nWe show that the estimated RDR not only allows for an effective comparison of\nthe overall performance of competing generative models, but it can also offer a\nconvenient means of revealing the nature of the underlying goodness-of-fit.\nThis enables one to assess support overlap, coverage, and fidelity while\npinpointing regions of the sample space where generators concentrate and\nrevealing the features that drive the most salient distributional differences."}
{"id": "2510.25565", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.25565", "abs": "https://arxiv.org/abs/2510.25565", "authors": ["Adrian Llamas-Jaramillo", "Ivan Latella", "David Reguera"], "title": "Free-energy REconstruction from Stable Clusters (FRESC): A new method to evaluate nucleation barriers from simulation", "comment": "9 pages, 9 figures", "summary": "We present a simulation technique to evaluate the most important quantity for\nnucleation processes: the nucleation barrier, i.e. the free energy of formation\nof the critical cluster. The method is based on stabilizing a small cluster by\nsimulating it in the NVT ensemble and using the thermodynamics of small systems\nto convert the properties of this stable cluster into the Gibbs free energy of\nformation of the critical cluster. We demonstrate this approach using\ncondensation in a Lennard-Jones truncated and shifted fluid as an example,\nshowing an excellent agreement with previous Umbrella Sampling simulations. The\nmethod is straightforward to implement, computationally inexpensive, requires\nonly a small number of particles comparable to the critical cluster size, does\nnot rely on the use of Classical Nucleation Theory, and does not require any\ncluster definition or reaction coordinate. All of these advantages hold the\npromise of opening the door to simulate nucleation processes in complex\nmolecules of atmospheric, chemical or pharmaceutical interest that cannot be\neasily simulated with current techniques."}
{"id": "2510.25063", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25063", "abs": "https://arxiv.org/abs/2510.25063", "authors": ["Nikki Xu", "Hien Tran"], "title": "Control Synthesis with Reinforcement Learning: A Modeling Perspective", "comment": null, "summary": "Controllers designed with reinforcement learning can be sensitive to model\nmismatch. We demonstrate that designing such controllers in a virtual\nsimulation environment with an inaccurate model is not suitable for deployment\nin a physical setup. Controllers designed using an accurate model is robust\nagainst disturbance and small mismatch between the physical setup and the\nmathematical model derived from first principles; while a poor model results in\na controller that performs well in simulation but fails in physical\nexperiments. Sensitivity analysis is used to justify these discrepancies and an\nempirical region of attraction estimation help us visualize their robustness."}
{"id": "2510.25063", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25063", "abs": "https://arxiv.org/abs/2510.25063", "authors": ["Nikki Xu", "Hien Tran"], "title": "Control Synthesis with Reinforcement Learning: A Modeling Perspective", "comment": null, "summary": "Controllers designed with reinforcement learning can be sensitive to model\nmismatch. We demonstrate that designing such controllers in a virtual\nsimulation environment with an inaccurate model is not suitable for deployment\nin a physical setup. Controllers designed using an accurate model is robust\nagainst disturbance and small mismatch between the physical setup and the\nmathematical model derived from first principles; while a poor model results in\na controller that performs well in simulation but fails in physical\nexperiments. Sensitivity analysis is used to justify these discrepancies and an\nempirical region of attraction estimation help us visualize their robustness."}
{"id": "2510.25261", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.25261", "abs": "https://arxiv.org/abs/2510.25261", "authors": ["Lei Yang", "Jiayi Zhu", "Ling Liang", "Kim-Chuan Toh"], "title": "Convergence of a Relative-type Inexact Proximal ALM for Convex Nonlinear Programming", "comment": null, "summary": "This article investigates the convergence properties of a relative-type\ninexact proximal augmented Lagrangian method (ripALM) for convex nonlinear\nprogramming, a fundamental class of optimization problems with broad\napplications in science and engineering. Inexact proximal augmented Lagrangian\nmethods have proven to be highly effective for solving such problems, owing to\ntheir attractive theoretical properties and strong practical performance.\nHowever, the convergence behavior of the relative-type inexact variant remains\ninsufficiently understood. This work aims to reduce this gap by rigorously\nestablishing the global convergence of the sequence generated by ripALM and\nproving its asymptotic (super)linear convergence rate under standard\nassumptions. In addition, we derive the global ergodic convergence rate with\nrespect to both the primal feasibility violation and the primal objective\nresidual, thereby offering a more comprehensive characterization of the overall\nperformance of ripALM."}
{"id": "2510.25292", "categories": ["math.NA", "cs.NA", "15A23, 15B34, 65F50"], "pdf": "https://arxiv.org/pdf/2510.25292", "abs": "https://arxiv.org/abs/2510.25292", "authors": ["Yannis Voet", "Leonardo De Novellis"], "title": "Identifying Kronecker product factorizations", "comment": "21 pages, 13 figures", "summary": "The Kronecker product is an invaluable tool for data-sparse representations\nof large networks and matrices with countless applications in machine learning,\ngraph theory and numerical linear algebra. In some instances, the sparsity\npattern of large matrices may already hide a Kronecker product. Similarly, a\nlarge network, represented by its adjacency matrix, may sometimes be factorized\nas a Kronecker product of smaller adjacency matrices. In this article, we\ndetermine all possible Kronecker factorizations of a binary matrix and\nvisualize them through its decomposition graph. Such sparsity-informed\nfactorizations may later enable good (approximate) Kronecker factorizations of\nreal matrices or reveal the latent structure of a network. The latter also\nsuggests a natural visualization of Kronecker graphs."}
{"id": "2510.25550", "categories": ["stat.ME", "cs.LG", "stat.CO", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.25550", "abs": "https://arxiv.org/abs/2510.25550", "authors": ["Dominik Sturm", "Ivo F. Sbalzarini"], "title": "Robust variable selection for spatial point processes observed with noise", "comment": null, "summary": "We propose a method for variable selection in the intensity function of\nspatial point processes that combines sparsity-promoting estimation with\nnoise-robust model selection. As high-resolution spatial data becomes\nincreasingly available through remote sensing and automated image analysis,\nidentifying spatial covariates that influence the localization of events is\ncrucial to understand the underlying mechanism. However, results from automated\nacquisition techniques are often noisy, for example due to measurement\nuncertainties or detection errors, which leads to spurious displacements and\nmissed events. We study the impact of such noise on sparse point-process\nestimation across different models, including Poisson and Thomas processes. To\nimprove noise robustness, we propose to use stability selection based on\npoint-process subsampling and to incorporate a non-convex best-subset penalty\nto enhance model-selection performance. In extensive simulations, we\ndemonstrate that such an approach reliably recovers true covariates under\ndiverse noise scenarios and improves both selection accuracy and stability. We\nthen apply the proposed method to a forestry data set, analyzing the\ndistribution of trees in relation to elevation and soil nutrients in a tropical\nrain forest. This shows the practical utility of the method, which provides a\nsystematic framework for robust variable selection in spatial point-process\nmodels under noise, without requiring additional knowledge of the process."}
{"id": "2510.25711", "categories": ["cond-mat.stat-mech", "hep-th", "nlin.CD", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.25711", "abs": "https://arxiv.org/abs/2510.25711", "authors": ["Nilakash Sorokhaibam", "Anjan Daimari"], "title": "ETH-monotonicity in two-dimensional systems", "comment": "5 pages in Physical Review E style", "summary": "We study a recently discovered property of many-body quantum chaotic systems\ncalled ETH-monotonicity in two-dimensional systems. Our new results further\nsupport ETH-monotonicity in these higher dimensional systems. We show that the\nflattening rate of the $f$-function is directly proportional to the number of\ndegrees of freedom in the system, so as $L^2$ where $L$ is the linear size of\nthe system, and in general, expected to be $L^d$ where $d$ is the spatial\ndimension of the system. We also show that the flattening rate is directly\nproportional to the particle (or hole) number for systems of same spatial size."}
{"id": "2510.25118", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25118", "abs": "https://arxiv.org/abs/2510.25118", "authors": ["Zhentong Shao", "Nanpeng Yu", "Daniel Wong"], "title": "Stochastic Long-Term Joint Decarbonization Planning for Power Systems and Data Centers: A Case Study in PJM", "comment": null, "summary": "With the rapid growth of artificial intelligence (AI) and cloud services,\ndata centers have become critical infrastructures driving digital economies,\nwith increasing energy demand heightening concerns over electricity use and\ncarbon emissions, emphasizing the need for carbon-aware infrastructure\nplanning. Most studies assume static power systems, focus only on operational\nemissions, and overlook co-optimization. This paper proposes a dynamic joint\nplanning framework that co-optimizes long-term data center and power system\ndevelopment over 15 years. The model determines siting, capacity, and type of\ndata centers alongside power generation expansion, storage deployment, and\nretirements, accounting for both operational and embodied emissions. To handle\nmulti-scale uncertainty, a large-scale two-stage stochastic program is\nformulated and solved via an enhanced Benders decomposition. Applied to the PJM\nInterconnection, with curated datasets released on GitHub, results show the\nsystem can support up to 55 GW peak data center demand, with Virginia (DOM) and\nNorthern Illinois (ComEd) as optimal hosts. Compared to non-joint planning, the\nframework cuts investment cost by 12.6%, operational cost by 8.25%, and\nemissions by 5.63%. Including lifecycle emissions further raises renewable\ndeployment by 25.5%, highlighting embodied carbon's role in deeper\ndecarbonization."}
{"id": "2510.25118", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25118", "abs": "https://arxiv.org/abs/2510.25118", "authors": ["Zhentong Shao", "Nanpeng Yu", "Daniel Wong"], "title": "Stochastic Long-Term Joint Decarbonization Planning for Power Systems and Data Centers: A Case Study in PJM", "comment": null, "summary": "With the rapid growth of artificial intelligence (AI) and cloud services,\ndata centers have become critical infrastructures driving digital economies,\nwith increasing energy demand heightening concerns over electricity use and\ncarbon emissions, emphasizing the need for carbon-aware infrastructure\nplanning. Most studies assume static power systems, focus only on operational\nemissions, and overlook co-optimization. This paper proposes a dynamic joint\nplanning framework that co-optimizes long-term data center and power system\ndevelopment over 15 years. The model determines siting, capacity, and type of\ndata centers alongside power generation expansion, storage deployment, and\nretirements, accounting for both operational and embodied emissions. To handle\nmulti-scale uncertainty, a large-scale two-stage stochastic program is\nformulated and solved via an enhanced Benders decomposition. Applied to the PJM\nInterconnection, with curated datasets released on GitHub, results show the\nsystem can support up to 55 GW peak data center demand, with Virginia (DOM) and\nNorthern Illinois (ComEd) as optimal hosts. Compared to non-joint planning, the\nframework cuts investment cost by 12.6%, operational cost by 8.25%, and\nemissions by 5.63%. Including lifecycle emissions further raises renewable\ndeployment by 25.5%, highlighting embodied carbon's role in deeper\ndecarbonization."}
{"id": "2510.25363", "categories": ["math.OC", "math.FA"], "pdf": "https://arxiv.org/pdf/2510.25363", "abs": "https://arxiv.org/abs/2510.25363", "authors": ["Katherine Rossella Foglia", "Vittorio Colao"], "title": "On the Rate of Convergence of Iterative Methods for Nonexpansive Mappings in CAT(0) Spaces and Hyperbolic Optimization", "comment": null, "summary": "The Krasnosel'ski\\u{\\i} Mann and Halpern iterations are classical schemes for\napproximating fixed points of nonexpansive mappings in Banach spaces, and have\nbeen widely studied in more general frameworks such as $CAT(\\kappa)$ and, more\ngenerally, geodesic spaces. Convergence results and convergence rate estimates\nin these nonlinear settings are already well established. The contribution of\nthis paper is to extend to complete $CAT(0)$ spaces the proof techniques\noriginally developed in the linear setting of Banach and Hilbert spaces,\nthereby recovering the same asymptotic regularity bounds and to introduce a\nnovel optimizer for Hyperbolic Deep learning based on Halpern Iteration\nsimilarly to HalpernSGD \\cite{foglia2024halpernsgd,colao2025optimizer} in\nEuclidean setting."}
{"id": "2510.25298", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.25298", "abs": "https://arxiv.org/abs/2510.25298", "authors": ["Liangkun Xu", "Shixi Wang", "Hai Bi"], "title": "A virtual element approximation for the modified transmission eigenvalues for natural materials", "comment": null, "summary": "In this paper, we discuss a virtual element approximation for the modified\ntransmission eigenvalue problem in inverse scattering for natural materials. In\nthis case, due to the positive artificial diffusivity parameter in the\nconsidered problem, the sesquilinear form at the left end of the variational\nform is not coercive. We first demonstrate the well-posedness of the discrete\nsource problem using the $\\mathds{T}$-coercivity property, then provide the a\npriori error estimates for the approximate eigenspaces and eigenvalues, and\nfinally reports several numerical examples. The numerical experiments show that\nthe proposed method is effective"}
{"id": "2510.25632", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.25632", "abs": "https://arxiv.org/abs/2510.25632", "authors": ["Gengyang Chen", "Mu Zhu"], "title": "Automatic selection of hyper-parameters via the use of softened profile likelihood", "comment": null, "summary": "We extend a heuristic method for automatic dimensionality selection, which\nmaximizes a profile likelihood to identify \"elbows\" in scree plots. Our\nextension enables researchers to make automatic choices of multiple\nhyper-parameters simultaneously. To facilitate our extension to\nmulti-dimensions, we propose a \"softened\" profile likelihood. We present two\ndistinct parameterizations of our solution and demonstrate our approach on\nelastic nets, support vector machines, and neural networks. We also briefly\ndiscuss applications of our method to other data-analytic tasks than\nhyper-parameter selection."}
{"id": "2510.25737", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2510.25737", "abs": "https://arxiv.org/abs/2510.25737", "authors": ["Joseph O. Indekeu", "Kenichiro Koga"], "title": "Critical exponents of fluid-fluid interfacial tensions near a critical endpoint in a nonwetting gap", "comment": null, "summary": "Fluid three-phase equilibria, with phases $\\alpha, \\beta, \\gamma$, are\nstudied close to a tricritical point, analytically and numerically, in a\nmean-field density-functional theory with two densities. Employing Griffiths'\nscaling for the densities, the interfacial tensions of the wet and nonwet\ninterfaces are analysed. The mean-field critical exponent is obtained for the\nvanishing of the critical interfacial tension $\\sigma_{\\beta\\gamma}$ as a\nfunction of the deviation of the noncritical interfacial tension\n$\\sigma_{\\alpha\\gamma}$ from its limiting value at a critical endpoint\n$\\sigma_{\\alpha,\\beta\\gamma}$. In the wet regime, this exponent is $3/2$ as\nexpected. In the nonwetting gap of the model, the exponent is again $3/2$,\nexcept for the approach to the critical endpoint on the neutral line where\n$\\sigma_{\\alpha\\beta} = \\sigma_{\\alpha\\gamma}$. When this point is approached\nalong any path with $\\sigma_{\\alpha\\beta} \\neq \\sigma_{\\alpha\\gamma}$, or along\nthe neutral line, $\\sigma_{\\beta\\gamma} \\propto | \\sigma_{\\alpha\\gamma} -\n\\sigma_{\\alpha,\\beta\\gamma}|^{3/4}$, featuring an anomalous critical exponent\n$3/4$, which is an exact result derived by analytic calculation and explained\nby geometrical arguments."}
{"id": "2510.25131", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25131", "abs": "https://arxiv.org/abs/2510.25131", "authors": ["Hisayoshi Muramatsu"], "title": "The Waterbed Effect on Quasiperiodic Disturbance Observer: Avoidance of Sensitivity Tradeoff with Time Delays", "comment": null, "summary": "In linear time-invariant systems, the sensitivity function to disturbances is\ndesigned under a sensitivity tradeoff known as the waterbed effect. To\ncompensate for a quasiperiodic disturbance, a quasiperiodic disturbance\nobserver using time delays was proposed. Its sensitivity function avoids the\nsensitivity tradeoff, achieving wideband harmonic suppression without\namplifying aperiodic disturbances or shifting harmonic suppression frequencies.\nHowever, its open-loop transfer function is not rational and does not satisfy\nthe assumptions of existing Bode sensitivity integrals due to its time delays.\nThis paper provides Bode-like sensitivity integrals for the quasiperiodic\ndisturbance observer in both continuous-time and discrete-time representations\nand clarifies the avoided sensitivity tradeoff with time delays."}
{"id": "2510.25131", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25131", "abs": "https://arxiv.org/abs/2510.25131", "authors": ["Hisayoshi Muramatsu"], "title": "The Waterbed Effect on Quasiperiodic Disturbance Observer: Avoidance of Sensitivity Tradeoff with Time Delays", "comment": null, "summary": "In linear time-invariant systems, the sensitivity function to disturbances is\ndesigned under a sensitivity tradeoff known as the waterbed effect. To\ncompensate for a quasiperiodic disturbance, a quasiperiodic disturbance\nobserver using time delays was proposed. Its sensitivity function avoids the\nsensitivity tradeoff, achieving wideband harmonic suppression without\namplifying aperiodic disturbances or shifting harmonic suppression frequencies.\nHowever, its open-loop transfer function is not rational and does not satisfy\nthe assumptions of existing Bode sensitivity integrals due to its time delays.\nThis paper provides Bode-like sensitivity integrals for the quasiperiodic\ndisturbance observer in both continuous-time and discrete-time representations\nand clarifies the avoided sensitivity tradeoff with time delays."}
{"id": "2510.25373", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.25373", "abs": "https://arxiv.org/abs/2510.25373", "authors": ["Janik Pinter", "Maximilian Beichter", "Ralf Mikut", "Frederik Zahn", "Veit Hagenmeyer"], "title": "Averaging favors MPC: How typical evaluation setups overstate MPC performance for residential battery scheduling", "comment": null, "summary": "Residential prosumers with PV-battery systems increasingly manage their\nelectricity exchange with the power grid to minimize costs. This study\ninvestigates the performance of Model Predictive Control (MPC) and Rule-Based\nControl (RBC) under 15/30/60 minute averaging commonly used in research, when\nNet Billing and battery degradation are considered. We simulate five\nconsecutive months for 15 buildings in northern Germany, generating costs at up\nto 1-minute resolution while scheduling at 15/30/60 minutes. We find that\ntime-averaged evaluations make MPC look consistently better than RBC, yet when\ncosts are recomputed at minute-level ground-truth, the reported advantage\nshrinks by 69\\% on average for hourly schedulers. For individual buildings, the\nfiner evaluation can reverse conclusions, and simple RBC can achieve lower\ntotal costs than an MPC with perfect foresight. These findings caution against\ndrawing conclusions from coarse averages and show how a fair assessment of\nbattery scheduling approaches can be obtained."}
{"id": "2510.25395", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.25395", "abs": "https://arxiv.org/abs/2510.25395", "authors": ["Joshua Vedral", "Nathaniel Morgan", "Dmitri Kuzmin", "Jacob Moore"], "title": "A structure-preserving Lagrangian discontinuous Galerkin method using flux and slope limiting", "comment": null, "summary": "We introduce a Lagrangian nodal discontinuous Galerkin (DG) cell-centered\nhydrodynamics method for solving multi-dimensional hyperbolic systems. By\nincorporating an adaptation of Zalesak's flux-corrected transport algorithm, we\ncombine a first-order positivity-preserving scheme with a higher-order target\ndiscretization. This results in a flux-corrected Lagrangian DG scheme that\nensures both global positivity preservation and second-order accuracy for the\ncell averages of specific volume. The correction factors for flux limiting are\nderived from specific volume and applied to all components of the solution\nvector. We algebraically evolve the volumes of mesh cells using a discrete\nversion of the geometric conservation law (GCL). The application of a limiter\nto the GCL fluxes is equivalent to moving the mesh using limited nodal\nvelocities. Additionally, we equip our method with a locally bound-preserving\nslope limiter to effectively suppress spurious oscillations. Nodal velocity and\nexternal forces are computed using a multidirectional approximate Riemann\nsolver to maintain conservation of momentum and total energy in vertex\nneighborhoods. Employing linear finite elements and a second-order accurate\ntime integrator guarantees GCL consistency. The results for standard test\nproblems demonstrate the stability and superb shock-capturing capabilities of\nour scheme."}
{"id": "2510.25712", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.25712", "abs": "https://arxiv.org/abs/2510.25712", "authors": ["Jack Storror Carter", "Cesare Molinari"], "title": "Existence and optimisation of the partial correlation graphical lasso", "comment": "34 pages, 11 figures", "summary": "The partial correlation graphical LASSO (PCGLASSO) is a penalised likelihood\nmethod for Gaussian graphical models which provides scale invariant sparse\nestimation of the precision matrix and improves upon the popular graphical\nLASSO method. However, the PCGLASSO suffers from computational challenges due\nto the non-convexity of its associated optimisation problem. This paper\nprovides some important breakthroughs in the computation of the PCGLASSO.\nFirst, the existence of the PCGLASSO estimate is proven when the sample size is\nsmaller than the dimension - a case in which the maximum likelihood estimate\ndoes not exist. This means that the PCGLASSO can be used with any Gaussian\ndata. Second, a new alternating algorithm for computing the PCGLASSO is\nproposed and implemented in the R package PCGLASSO available at\nhttps://github.com/JackStorrorCarter/PCGLASSO. This was the first publicly\navailable implementation of the PCGLASSO and provides competitive computation\ntime for moderate dimension size."}
{"id": "2510.25747", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.25747", "abs": "https://arxiv.org/abs/2510.25747", "authors": ["Hesam Arabzadeh", "Brad Lee Holian"], "title": "When Heating Isn't Cooling in Reverse: Nosé-Hoover Thermostat Fluctuations from Equilibrium Symmetry to Nonequilibrium Asymmetry", "comment": null, "summary": "Recent laboratory experiments suggest an intrinsic asymmetry between heating\nand cooling, with heating occurring more efficiently. Two decades earlier,\nmolecular dynamics (MD) simulations had examined a related setup - heating one\nside of a computational cell while cooling the other via distinct thermostats.\nWe revisit those calculations, recapitulating the underlying theory and showing\nthat earlier MD results already hinted at the observed laboratory asymmetry.\nRecent realizations of a simple two-dimensional single-particle model,\nthermostatted in $x$ and $y$ at different temperatures, reproduces key\nfeatures: at equilibrium, thermostat variables were identical, but under\nnonequilibrium conditions, the heating variable is weaker than the cooling one.\nAt the same time, MD simulations from four decades ago by Evans and Holian\nreported a surprising skew in the Nose--Hoover thermostat variable $\\xi$ under\nequilibrium - indicating a statistical bias in energy injection versus\nextraction. We revisit those results with exact reproduction of their setup. We\nshow that when (1) the center-of-mass velocity is set to zero, (2) integration\nis done carefully with finite differencing, and (3) sampling is sufficiently\nlong, the distribution of $\\xi$ is symmetric and Gaussian with zero mean, as\npredicted by theory and validated by two independent error estimates. However,\nin the two-temperature cell, the distribution of thermostat variables become\nasymmetric, the cold bath requires significantly stronger damping than the hot\nbath requires anti-damping, with $\\langle \\xi_x \\rangle / \\langle \\xi_y \\rangle\n= -T_y/T_x$. This exact analytic relation links thermostat effort to thermal\nbias and the negative rate of change in the entropy of the system. These\nresults identify the microscopic origin of heating-cooling asymmetry as a\ngenuine nonequilibrium effect, consistent with experimental findings."}
{"id": "2510.25208", "categories": ["eess.SY", "cs.AR", "cs.SY", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.25208", "abs": "https://arxiv.org/abs/2510.25208", "authors": ["Yusheng Xiong", "Kaveh Delfanazari"], "title": "Silicon-based Josephson junction field-effect transistors enabling cryogenic logic and quantum technologies", "comment": null, "summary": "The continuous miniaturisation of metal-oxide-semiconductor field-effect\ntransistors (MOSFETs) from long- to short-channel architectures has advanced\nbeyond the predictions of Moore's Law. Continued advances in semiconductor\nelectronics, even near current scaling and performance boundaries under\ncryogenic conditions, are driving the development of innovative device\nparadigms that enable ultra-low-power and high-speed functionality. Among\nemerging candidates, the Josephson Junction Field-Effect Transistor (JJFET or\nJoFET) provides an alternative by integrating superconducting source and drain\nelectrodes for efficient, phase-coherent operation at ultra-low temperatures.\nThese hybrid devices have the potential to bridge conventional semiconductor\nelectronics with cryogenic logic and quantum circuits, enabling\nenergy-efficient and high-coherence signal processing across temperature\ndomains. This review traces the evolution from Josephson junctions to\nfield-effect transistors, emphasising the structural and functional innovations\nthat underpin modern device scalability. The performance and material\ncompatibility of JJFETs fabricated on Si, GaAs, and InGaAs substrates are\nanalysed, alongside an assessment of their switching dynamics and material\ncompatibility. Particular attention is given to\nsuperconductor-silicon-superconductor Josephson junctions as the active core of\nJJFET architectures. By unfolding more than four decades of experimental\nprogress, this work highlights the promise of JJFETs as foundational building\nblocks for next-generation cryogenic logic and quantum electronic systems."}
{"id": "2510.25208", "categories": ["eess.SY", "cs.AR", "cs.SY", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.25208", "abs": "https://arxiv.org/abs/2510.25208", "authors": ["Yusheng Xiong", "Kaveh Delfanazari"], "title": "Silicon-based Josephson junction field-effect transistors enabling cryogenic logic and quantum technologies", "comment": null, "summary": "The continuous miniaturisation of metal-oxide-semiconductor field-effect\ntransistors (MOSFETs) from long- to short-channel architectures has advanced\nbeyond the predictions of Moore's Law. Continued advances in semiconductor\nelectronics, even near current scaling and performance boundaries under\ncryogenic conditions, are driving the development of innovative device\nparadigms that enable ultra-low-power and high-speed functionality. Among\nemerging candidates, the Josephson Junction Field-Effect Transistor (JJFET or\nJoFET) provides an alternative by integrating superconducting source and drain\nelectrodes for efficient, phase-coherent operation at ultra-low temperatures.\nThese hybrid devices have the potential to bridge conventional semiconductor\nelectronics with cryogenic logic and quantum circuits, enabling\nenergy-efficient and high-coherence signal processing across temperature\ndomains. This review traces the evolution from Josephson junctions to\nfield-effect transistors, emphasising the structural and functional innovations\nthat underpin modern device scalability. The performance and material\ncompatibility of JJFETs fabricated on Si, GaAs, and InGaAs substrates are\nanalysed, alongside an assessment of their switching dynamics and material\ncompatibility. Particular attention is given to\nsuperconductor-silicon-superconductor Josephson junctions as the active core of\nJJFET architectures. By unfolding more than four decades of experimental\nprogress, this work highlights the promise of JJFETs as foundational building\nblocks for next-generation cryogenic logic and quantum electronic systems."}
{"id": "2510.25398", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.25398", "abs": "https://arxiv.org/abs/2510.25398", "authors": ["Filippo de Feo", "Giorgio Fabbri", "Silvia Faggian", "Giuseppe Freni"], "title": "Centralized and Competitive Extraction for Distributed Renewable Resources with Nonlinear Reproduction", "comment": null, "summary": "We study optimal and strategic extraction of a renewable resource that is\ndistributed over a network, migrates mass-conservatively across nodes, and\nevolves under nonlinear (concave) growth. A subset of nodes hosts extractors\nwhile the remaining nodes serve as reserves. We analyze a centralized planner\nand a non-cooperative game with stationary Markov strategies. The migration\noperator transports shadow values along the network so that Perron-Frobenius\ngeometry governs long-run spatial allocations, while nonlinear growth couples\naggregate biomass with its spatial distribution and bounds global dynamics. For\nthree canonical growth families, logistic, power, and log-type saturating laws,\nunder related utilities, we derive closed-form value functions and feedback\nrules for the planner and construct a symmetric Markov equilibrium on strongly\nconnected networks. To our knowledge, this is the first paper to obtain\nexplicit policies for spatial resource extraction with nonlinear growth and, a\nfortiori, closed-form Markov equilibria, on general networks."}
{"id": "2510.25521", "categories": ["math.NA", "cs.NA", "math.PR", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25521", "abs": "https://arxiv.org/abs/2510.25521", "authors": ["Jaroslav I. Borodavka", "Max Hirsch", "Sebastian Krumscheid", "Andrea Zanoni"], "title": "Nonparametric estimation of homogenized invariant measures from multiscale data via Hermite expansion", "comment": null, "summary": "We consider the problem of density estimation in the context of multiscale\nLangevin diffusion processes, where a single-scale homogenized surrogate model\ncan be derived. In particular, our aim is to learn the density of the invariant\nmeasure of the homogenized dynamics from a continuous-time trajectory generated\nby the full multiscale system. We propose a spectral method based on a\ntruncated Fourier expansion with Hermite functions as orthonormal basis. The\nFourier coefficients are computed directly from the data owing to the ergodic\ntheorem. We prove that the resulting density estimator is robust and converges\nto the invariant density of the homogenized model as the scale separation\nparameter vanishes, provided the time horizon and the number of Fourier modes\nare suitably chosen in relation to the multiscale parameter. The accuracy and\nreliability of this methodology is further demonstrated through a series of\nnumerical experiments."}
{"id": "2510.25742", "categories": ["stat.ME", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.25742", "abs": "https://arxiv.org/abs/2510.25742", "authors": ["Fabio Centofanti"], "title": "Statistical Process Monitoring based on Functional Data Analysis", "comment": null, "summary": "In modern industrial settings, advanced acquisition systems allow for the\ncollection of data in the form of profiles, that is, as functional\nrelationships linking responses to explanatory variables. In this context,\nstatistical process monitoring (SPM) aims to assess the stability of profiles\nover time in order to detect unexpected behavior. This review focuses on SPM\nmethods that model profiles as functional data, i.e., smooth functions defined\nover a continuous domain, and apply functional data analysis (FDA) tools to\naddress limitations of traditional monitoring techniques. A reference framework\nfor monitoring multivariate functional data is first presented. This review\nthen offers a focused survey of several recent FDA-based profile monitoring\nmethods that extend this framework to address common challenges encountered in\nreal-world applications. These include approaches that integrate additional\nfunctional covariates to enhance detection power, a robust method designed to\naccommodate outlying observations, a real-time monitoring technique for\npartially observed profiles, and two adaptive strategies that target the\ncharacteristics of the out-of-control distribution. These methods are all\nimplemented in the R package funcharts, available on CRAN. Finally, a review of\nadditional existing FDA-based profile monitoring methods is also presented,\nalong with suggestions for future research."}
{"id": "2510.24903", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.24903", "abs": "https://arxiv.org/abs/2510.24903", "authors": ["Alejandro de Haro García", "Joaquín J. Torres"], "title": "Emergence of Chimeras States in One-dimensional Ising model with Long-Range Diffusion", "comment": "26 pages, 8 figures", "summary": "In this work, we examine the conditions for the emergence of chimera-like\nstates in Ising systems. We study an Ising chain with periodic boundaries in\ncontact with a thermal bath at temperature T, that induces stochastic changes\nin spin variables. To capture the non-locality needed for chimera formation, we\nintroduce a model setup with non-local diffusion of spin values through the\nwhole system. More precisely, diffusion is modeled through spin-exchange\ninteractions between units up to a distance R, using Kawasaki dynamics. This\nsetup mimics, e.g., neural media, as the brain, in the presence of electrical\n(diffusive) interactions. We explored the influence of such non-local dynamics\non the emergence of complex spatiotemporal synchronization patterns of\nactivity. Depending on system parameters we report here for the first time\nchimera-like states in the Ising model, characterized by relatively stable\nmoving domains of spins with different local magnetization. We analyzed the\nsystem at T=0, both analytically and via simulations and computed the system's\nphase diagram, revealing rich behavior: regions with only chimeras, coexistence\nof chimeras and stable domains, and metastable chimeras that decay into uniform\nstable domains. This study offers fundamental insights into how coherent and\nincoherent synchronization patterns can arise in complex networked systems as\nit is, e.g., the brain."}
{"id": "2510.25284", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25284", "abs": "https://arxiv.org/abs/2510.25284", "authors": ["Jiamin Wu", "Chenguang Zhao", "Huan Yu"], "title": "Shared Control for Vehicle Lane-Changing with Uncertain Driver Behaviors", "comment": null, "summary": "Lane changes are common yet challenging driving maneuvers that require\ncontinuous decision-making and dynamic interaction with surrounding vehicles.\nRelying solely on human drivers for lane-changing can lead to traffic\ndisturbances due to the stochastic nature of human behavior and its variability\nunder different task demands. Such uncertainties may significantly degrade\ntraffic string stability, which is critical for suppressing disturbance\npropagation and ensuring smooth merging of the lane-changing vehicles. This\npaper presents a human-automation shared lane-changing control framework that\npreserves driver authority while allowing automated assistance to achieve\nstable maneuvers in the presence of driver's behavioral uncertainty. Human\ndriving behavior is modeled as a Markov jump process with transitions driven by\ntask difficulty, providing a tractable representation of stochastic state\nswitching. Based on this model, we first design a nominal stabilizing\ncontroller that guarantees stochastic ${L}_2$ string stability under imperfect\nmode estimation. To further balance performance and automated effort, we then\ndevelop a Minimal Intervention Controller (MIC) that retains acceptable\nstability while limiting automation. Simulations using lane-changing data from\nthe NGSIM dataset verify that the nominal controller reduces speed\nperturbations and shorten lane-changing time, while the MIC further reduces\nautomated effort and enhances comfort but with moderate stability and\nefficiency loss. Validations on the TGSIM dataset with SAE Level 2 vehicles\nshow that the MIC enables earlier lane changes than Level 2 control while\npreserving driver authority with a slight stability compromise. These findings\nhighlight the potential of shared control strategies to balance stability,\nefficiency, and driver acceptance."}
{"id": "2510.25284", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25284", "abs": "https://arxiv.org/abs/2510.25284", "authors": ["Jiamin Wu", "Chenguang Zhao", "Huan Yu"], "title": "Shared Control for Vehicle Lane-Changing with Uncertain Driver Behaviors", "comment": null, "summary": "Lane changes are common yet challenging driving maneuvers that require\ncontinuous decision-making and dynamic interaction with surrounding vehicles.\nRelying solely on human drivers for lane-changing can lead to traffic\ndisturbances due to the stochastic nature of human behavior and its variability\nunder different task demands. Such uncertainties may significantly degrade\ntraffic string stability, which is critical for suppressing disturbance\npropagation and ensuring smooth merging of the lane-changing vehicles. This\npaper presents a human-automation shared lane-changing control framework that\npreserves driver authority while allowing automated assistance to achieve\nstable maneuvers in the presence of driver's behavioral uncertainty. Human\ndriving behavior is modeled as a Markov jump process with transitions driven by\ntask difficulty, providing a tractable representation of stochastic state\nswitching. Based on this model, we first design a nominal stabilizing\ncontroller that guarantees stochastic ${L}_2$ string stability under imperfect\nmode estimation. To further balance performance and automated effort, we then\ndevelop a Minimal Intervention Controller (MIC) that retains acceptable\nstability while limiting automation. Simulations using lane-changing data from\nthe NGSIM dataset verify that the nominal controller reduces speed\nperturbations and shorten lane-changing time, while the MIC further reduces\nautomated effort and enhances comfort but with moderate stability and\nefficiency loss. Validations on the TGSIM dataset with SAE Level 2 vehicles\nshow that the MIC enables earlier lane changes than Level 2 control while\npreserving driver authority with a slight stability compromise. These findings\nhighlight the potential of shared control strategies to balance stability,\nefficiency, and driver acceptance."}
{"id": "2510.25452", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25452", "abs": "https://arxiv.org/abs/2510.25452", "authors": ["Amir Shakouri", "Henk J. van Waarde", "Tren M. J. T. Baltussen", "W. P. M. H.", "Heemels"], "title": "Data-Driven Stabilization Using Prior Knowledge on Stabilizability and Controllability", "comment": "6 pages", "summary": "In this work, we study data-driven stabilization of linear time-invariant\nsystems using prior knowledge of system-theoretic properties, specifically\nstabilizability and controllability. To formalize this, we extend the concept\nof data informativity by requiring the existence of a controller that\nstabilizes all systems consistent with the data and the prior knowledge. We\nshow that if the system is controllable, then incorporating this as prior\nknowledge does not relax the conditions required for data-driven stabilization.\nRemarkably, however, we show that if the system is stabilizable, then using\nthis as prior knowledge leads to necessary and sufficient conditions that are\nweaker than those for data-driven stabilization without prior knowledge. In\nother words, data-driven stabilization is easier if one knows that the\nunderlying system is stabilizable. We also provide new data-driven control\ndesign methods in terms of linear matrix inequalities that complement the\nconditions for informativity."}
{"id": "2510.25699", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.25699", "abs": "https://arxiv.org/abs/2510.25699", "authors": ["Charles Hyde", "Mitch Kerver", "Christos Tsolakis", "Polykarpos Thomadakis", "Spiros Tsalikis", "Kevin Garner", "Angelos Angelopoulos", "Wirawan Purwanto", "Gagik Gavalian", "Christian Weiss", "Nikos Chrisochoides"], "title": "3-Dimensional Adaptive Unstructured Tessellated Look-up Tables for the Approximation of Compton Form Factors", "comment": "18 pages, 16 figures, 3 tables", "summary": "We describe an iterative algorithm to construct an unstructured tessellation\nof simplices (irregular tetrahedra in 3-dimensions) to approximate an arbitrary\nfunction to a desired precision by interpolation. The method is applied to the\ngeneration of Compton Form Factors for simulation and analysis of nuclear\nfemtography, as enabled by high energy exclusive processes such as\nelectron-proton scattering producing just an electron, proton, and gamma-ray in\nthe final state. While producing tessellations with only a 1% mean\ninterpolation error, our results show that the use of such tessellations can\nsignificantly decrease the computation time for Monte Carlo event generation by\n$\\sim23$ times for $10^{7}$ events (and using extrapolation, by $\\sim955$ times\nfor $10^{10}$ events)."}
{"id": "2510.25521", "categories": ["math.NA", "cs.NA", "math.PR", "math.ST", "stat.ME", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.25521", "abs": "https://arxiv.org/abs/2510.25521", "authors": ["Jaroslav I. Borodavka", "Max Hirsch", "Sebastian Krumscheid", "Andrea Zanoni"], "title": "Nonparametric estimation of homogenized invariant measures from multiscale data via Hermite expansion", "comment": null, "summary": "We consider the problem of density estimation in the context of multiscale\nLangevin diffusion processes, where a single-scale homogenized surrogate model\ncan be derived. In particular, our aim is to learn the density of the invariant\nmeasure of the homogenized dynamics from a continuous-time trajectory generated\nby the full multiscale system. We propose a spectral method based on a\ntruncated Fourier expansion with Hermite functions as orthonormal basis. The\nFourier coefficients are computed directly from the data owing to the ergodic\ntheorem. We prove that the resulting density estimator is robust and converges\nto the invariant density of the homogenized model as the scale separation\nparameter vanishes, provided the time horizon and the number of Fourier modes\nare suitably chosen in relation to the multiscale parameter. The accuracy and\nreliability of this methodology is further demonstrated through a series of\nnumerical experiments."}
{"id": "2510.25169", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.25169", "abs": "https://arxiv.org/abs/2510.25169", "authors": ["Shinji Watanabe", "Tsunetomo Yamada", "Hiroyuki Takakura", "Nobuhisa Fujita"], "title": "Monte Carlo study on critical exponents of the classical Heisenberg model in ferromagnetic icosahedral quasicrystal", "comment": "14 pages, 17 figures, 3 tables", "summary": "Quasicrystals (QCs) lack three-dimensional periodicity of atomic arrangement\nbut possess long-range structural order, which are distinct from periodic\ncrystals and random systems. Here, we show how the ferromagnetic (FM) order\narises in the icosahedral QC (i-QC) on the basis of the Monte Carlo simulation\nof the Heisenberg model on the Yb lattice of Cd$_{5.7}$Yb composed of regular\nicosahedrons. By finite-size scaling of the Monte Carlo data, we identified the\ncritical exponents of the magnetization, magnetic susceptibility, and spin\ncorrelation length, $\\beta=0.508(30)$, $\\gamma=1.361(59)$, and $\\nu=0.792(17)$,\nrespectively. We confirmed that our data satisfy the hyperscaling relation and\nestimated the other critical exponents $\\alpha=-0.376(51)$, $\\delta=3.68(23)$,\nand $\\eta=0.282(65)$. These results show a new universality class inherent in\nthe i-QC, which is different from those in periodic magnets and spin glasses.\nIn the i-QC, each Yb site at vertices of the regular icosahedrons is classified\ninto 8 classes with respect to the coordination numbers of the nearest-neighbor\nand next-nearest-neighbor bonds. We revealed the FM-transition mechanism by\nshowing that the difference in the local environment of each site is governed\nby cooperative evolution of spin correlations upon cooling, giving rise to the\ncritical phenomena."}
{"id": "2510.25309", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25309", "abs": "https://arxiv.org/abs/2510.25309", "authors": ["Sebastian Zieglmeier", "Mathias Hudoba de Badyn", "Narada D. Warakagoda", "Thomas R. Krogstad", "Paal Engelstad"], "title": "Data-Enabled Predictive Control and Guidance for Autonomous Underwater Vehicles", "comment": "12 pages, 6 figures", "summary": "This paper presents a fully data-driven control framework for autonomous\nunderwater vehicles (AUVs) based on Data-Enabled Predictive Control (DeePC).\nThe approach eliminates the need for explicit hydrodynamic modeling by\nexploiting measured input-output data to predict and optimize future system\nbehavior. Classic DeePC was employed in the heading control, while a cascaded\nDeePC architecture is proposed for depth regulation, incorporating a\nloop-frequency separation to handle the different dynamic modes of input and\noutput. For 3-D waypoint path following, the Adaptive Line-of-Sight algorithm\nis extended to a predictive formulation and integrated with DeePC. All methods\nare validated in extensive simulation on the REMUS 100 AUV and compared with\nclassical PI/PID control. The results demonstrate superior tracking performance\nand robustness of DeePC under ocean-current disturbances and nonlinear\noperating conditions, while significantly reducing modeling effort."}
{"id": "2510.25309", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25309", "abs": "https://arxiv.org/abs/2510.25309", "authors": ["Sebastian Zieglmeier", "Mathias Hudoba de Badyn", "Narada D. Warakagoda", "Thomas R. Krogstad", "Paal Engelstad"], "title": "Data-Enabled Predictive Control and Guidance for Autonomous Underwater Vehicles", "comment": "12 pages, 6 figures", "summary": "This paper presents a fully data-driven control framework for autonomous\nunderwater vehicles (AUVs) based on Data-Enabled Predictive Control (DeePC).\nThe approach eliminates the need for explicit hydrodynamic modeling by\nexploiting measured input-output data to predict and optimize future system\nbehavior. Classic DeePC was employed in the heading control, while a cascaded\nDeePC architecture is proposed for depth regulation, incorporating a\nloop-frequency separation to handle the different dynamic modes of input and\noutput. For 3-D waypoint path following, the Adaptive Line-of-Sight algorithm\nis extended to a predictive formulation and integrated with DeePC. All methods\nare validated in extensive simulation on the REMUS 100 AUV and compared with\nclassical PI/PID control. The results demonstrate superior tracking performance\nand robustness of DeePC under ocean-current disturbances and nonlinear\noperating conditions, while significantly reducing modeling effort."}
{"id": "2510.25490", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.25490", "abs": "https://arxiv.org/abs/2510.25490", "authors": ["Elena Fernández", "Nicolás Zerega"], "title": "A strong formulation for Multiple Allocation Hub Location based on supermodular inequalities", "comment": "20 pages, 4 figures, 3 tables", "summary": "We introduce a new formulation for the multiple allocation hub location\nproblem that exploits supermodular properties and uses 1- and 2-index variables\nonly. We show that the new formulation produces the same Linear Programming\nbound as the tightest existing formulations for the studied problem, which use\n4-index variables, outperforming existing supermodular formulations adapted to\nthe considered problem. Computational results are presented with instances of\nup to 200 nodes optimally solved within a time limit of two hours."}
{"id": "2510.25752", "categories": ["math.NA", "cs.LG", "cs.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.25752", "abs": "https://arxiv.org/abs/2510.25752", "authors": ["James V. Roggeveen", "Michael P. Brenner"], "title": "Meshless solutions of PDE inverse problems on irregular geometries", "comment": null, "summary": "Solving inverse and optimization problems over solutions of nonlinear partial\ndifferential equations (PDEs) on complex spatial domains is a long-standing\nchallenge. Here we introduce a method that parameterizes the solution using\nspectral bases on arbitrary spatiotemporal domains, whereby the basis is\ndefined on a hyperrectangle containing the true domain. We find the\ncoefficients of the basis expansion by solving an optimization problem whereby\nboth the equations, the boundary conditions and any optimization targets are\nenforced by a loss function, building on a key idea from Physics-Informed\nNeural Networks (PINNs). Since the representation of the function natively has\nexponential convergence, so does the solution of the optimization problem, as\nlong as it can be solved efficiently. We find empirically that the optimization\nprotocols developed for machine learning find solutions with exponential\nconvergence on a wide range of equations. The method naturally allows for the\nincorporation of data assimilation by including additional terms in the loss\nfunction, and for the efficient solution of optimization problems over the PDE\nsolutions."}
{"id": "2510.25704", "categories": ["hep-lat", "cond-mat.stat-mech", "cs.LG", "hep-ph"], "pdf": "https://arxiv.org/pdf/2510.25704", "abs": "https://arxiv.org/abs/2510.25704", "authors": ["Claudio Bonanno", "Andrea Bulgarelli", "Elia Cellini", "Alessandro Nada", "Dario Panfalone", "Davide Vadacchino", "Lorenzo Verzichelli"], "title": "Scaling flow-based approaches for topology sampling in $\\mathrm{SU}(3)$ gauge theory", "comment": "1+39 pages, 14 figures", "summary": "We develop a methodology based on out-of-equilibrium simulations to mitigate\ntopological freezing when approaching the continuum limit of lattice gauge\ntheories. We reduce the autocorrelation of the topological charge employing\nopen boundary conditions, while removing exactly their unphysical effects using\na non-equilibrium Monte Carlo approach in which periodic boundary conditions\nare gradually switched on. We perform a detailed analysis of the computational\ncosts of this strategy in the case of the four-dimensional $\\mathrm{SU}(3)$\nYang-Mills theory. After achieving full control of the scaling, we outline a\nclear strategy to sample topology efficiently in the continuum limit, which we\ncheck at lattice spacings as small as $0.045$ fm. We also generalize this\napproach by designing a customized Stochastic Normalizing Flow for evolutions\nin the boundary conditions, obtaining superior performances with respect to the\npurely stochastic non-equilibrium approach, and paving the way for more\nefficient future flow-based solutions."}
{"id": "2510.25324", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25324", "abs": "https://arxiv.org/abs/2510.25324", "authors": ["Erik Börve", "Nikolce Murgovski", "Leo Laine"], "title": "Tight Collision Avoidance for Stochastic Optimal Control: with Applications in Learning-based, Interactive Motion Planning", "comment": "Preprint article, submitted for publication", "summary": "Trajectory planning in dense, interactive traffic scenarios presents\nsignificant challenges for autonomous vehicles, primarily due to the\nuncertainty of human driver behavior and the non-convex nature of collision\navoidance constraints. This paper introduces a stochastic optimal control\nframework to address these issues simultaneously, without excessively\nconservative approximations. We opt to model human driver decisions as a Markov\nDecision Process and propose a method for handling collision avoidance between\nnon-convex vehicle shapes by imposing a positive distance constraint between\ncompact sets. In this framework, we investigate three alternative chance\nconstraint formulations. To ensure computational tractability, we introduce\ntight, continuously differentiable reformulations of both the non-convex\ndistance constraints and the chance constraints. The efficacy of our approach\nis demonstrated through simulation studies of two challenging interactive\nscenarios: an unregulated intersection crossing and a highway lane change in\ndense traffic."}
{"id": "2510.25324", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25324", "abs": "https://arxiv.org/abs/2510.25324", "authors": ["Erik Börve", "Nikolce Murgovski", "Leo Laine"], "title": "Tight Collision Avoidance for Stochastic Optimal Control: with Applications in Learning-based, Interactive Motion Planning", "comment": "Preprint article, submitted for publication", "summary": "Trajectory planning in dense, interactive traffic scenarios presents\nsignificant challenges for autonomous vehicles, primarily due to the\nuncertainty of human driver behavior and the non-convex nature of collision\navoidance constraints. This paper introduces a stochastic optimal control\nframework to address these issues simultaneously, without excessively\nconservative approximations. We opt to model human driver decisions as a Markov\nDecision Process and propose a method for handling collision avoidance between\nnon-convex vehicle shapes by imposing a positive distance constraint between\ncompact sets. In this framework, we investigate three alternative chance\nconstraint formulations. To ensure computational tractability, we introduce\ntight, continuously differentiable reformulations of both the non-convex\ndistance constraints and the chance constraints. The efficacy of our approach\nis demonstrated through simulation studies of two challenging interactive\nscenarios: an unregulated intersection crossing and a highway lane change in\ndense traffic."}
{"id": "2510.25494", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.25494", "abs": "https://arxiv.org/abs/2510.25494", "authors": ["Kira Dudziak", "Hanspeter Schmidli"], "title": "Stochastic Control of Dividends with a Drawdown Penalty", "comment": null, "summary": "We consider a diffusion risk model where dividends are paid at rate $U(t) \\in\n[0, u_0]$. We are interested in maximising the dividend payments under a\ndrawdown constraint, that is, we penalise a drawdown size larger than a level\n$d > 0$. We show that the optimal dividend rate $U(t)$ is either zero or the\nmaximal rate $u_0$ and determine the optimal strategy. Moreover, we derive an\nexplicit expression for the value function by solving a system of differential\nequations."}
{"id": "2510.24876", "categories": ["math.OC", "cs.NA", "math.AP", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.24876", "abs": "https://arxiv.org/abs/2510.24876", "authors": ["Abhishek Chaudhary"], "title": "Convergence analysis for an implementable scheme to solve the linear-quadratic stochastic optimal control problem with stochastic wave equation", "comment": "37 pages, 16 figures", "summary": "We study an optimal control problem for the stochastic wave equation driven\nby affine multiplicative noise, formulated as a stochastic linear-quadratic\n(SLQ) problem. By applying a stochastic Pontryagin's maximum principle, we\ncharacterize the optimal state-control pair via a coupled forward-backward SPDE\nsystem. We propose an implementable discretization using conforming finite\nelements in space and an implicit midpoint rule in time. By a new technical\napproach we obtain strong convergence rates for the discrete state-control pair\nwithout relying on Malliavin calculus. For the practical computation we develop\na gradient-descent algorithm based on artificial iterates that employs an exact\ncomputation for the arising conditional expectations, thereby eliminating\ncostly Monte Carlo sampling. Consequently, each iteration has a computational\ncost that is proportional to the number of spatial degrees of freedom,\nproducing a scalable method that preserves the established strong convergence\nrates. Numerical results validate its efficiency."}
{"id": "2510.25342", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25342", "abs": "https://arxiv.org/abs/2510.25342", "authors": ["Jinghong Tan", "Zhichen Zhang", "Kun Guo", "Tsung-Hui Chang", "Tony Q. S. Quek"], "title": "Lightweight Federated Learning in Mobile Edge Computing with Statistical and Device Heterogeneity Awareness", "comment": null, "summary": "Federated learning enables collaborative machine learning while preserving\ndata privacy, but high communication and computation costs, exacerbated by\nstatistical and device heterogeneity, limit its practicality in mobile edge\ncomputing. Existing compression methods like sparsification and pruning reduce\nper-round costs but may increase training rounds and thus the total training\ncost, especially under heterogeneous environments. We propose a lightweight\npersonalized FL framework built on parameter decoupling, which separates the\nmodel into shared and private subspaces, enabling us to uniquely apply gradient\nsparsification to the shared component and model pruning to the private one.\nThis structural separation confines communication compression to global\nknowledge exchange and computation reduction to local personalization,\nprotecting personalization quality while adapting to heterogeneous client\nresources. We theoretically analyze convergence under the combined effects of\nsparsification and pruning, revealing a sparsity-pruning trade-off that links\nto the iteration complexity. Guided by this analysis, we formulate a joint\noptimization that selects per-client sparsity and pruning rates and wireless\nbandwidth to reduce end-to-end training time. Simulation results demonstrate\nfaster convergence and substantial reductions in overall communication and\ncomputation costs with negligible accuracy loss, validating the benefits of\ncoordinated and resource-aware personalization in resource-constrained\nheterogeneous environments."}
{"id": "2510.25342", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25342", "abs": "https://arxiv.org/abs/2510.25342", "authors": ["Jinghong Tan", "Zhichen Zhang", "Kun Guo", "Tsung-Hui Chang", "Tony Q. S. Quek"], "title": "Lightweight Federated Learning in Mobile Edge Computing with Statistical and Device Heterogeneity Awareness", "comment": null, "summary": "Federated learning enables collaborative machine learning while preserving\ndata privacy, but high communication and computation costs, exacerbated by\nstatistical and device heterogeneity, limit its practicality in mobile edge\ncomputing. Existing compression methods like sparsification and pruning reduce\nper-round costs but may increase training rounds and thus the total training\ncost, especially under heterogeneous environments. We propose a lightweight\npersonalized FL framework built on parameter decoupling, which separates the\nmodel into shared and private subspaces, enabling us to uniquely apply gradient\nsparsification to the shared component and model pruning to the private one.\nThis structural separation confines communication compression to global\nknowledge exchange and computation reduction to local personalization,\nprotecting personalization quality while adapting to heterogeneous client\nresources. We theoretically analyze convergence under the combined effects of\nsparsification and pruning, revealing a sparsity-pruning trade-off that links\nto the iteration complexity. Guided by this analysis, we formulate a joint\noptimization that selects per-client sparsity and pruning rates and wireless\nbandwidth to reduce end-to-end training time. Simulation results demonstrate\nfaster convergence and substantial reductions in overall communication and\ncomputation costs with negligible accuracy loss, validating the benefits of\ncoordinated and resource-aware personalization in resource-constrained\nheterogeneous environments."}
{"id": "2510.25513", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25513", "abs": "https://arxiv.org/abs/2510.25513", "authors": ["Arash Bahari Kordabad", "Rupak Majumdar", "Sadegh Soudjani"], "title": "Sum-of-Squares Certificates for Almost-Sure Reachability of Stochastic Polynomial Systems", "comment": "8 Pages, 8 Figs", "summary": "In this paper, we present a computational approach to certify almost sure\nreachability for discrete-time polynomial stochastic systems by turning\ndrift--variant criteria into sum-of-squares (SOS) programs solved with standard\nsemidefinite solvers. Specifically, we provide an SOS method based on two\ncomplementary certificates: (i) a drift certificate that enforces a radially\nunbounded function to be non-increasing in expectation outside a compact set of\nstates; and (ii) a variant certificate that guarantees a one-step decrease with\npositive probability and ensures the target contains its nonpositive sublevel\nset. We transform these conditions to SOS constraints. For the variant\ncondition, we enforce a robust decrease over a parameterized disturbance ball\nwith nonzero probability and encode the constraints via an S-procedure with\npolynomial multipliers. The resulting bilinearities are handled by an\nalternating scheme that alternates between optimizing multipliers and updating\nthe variant and radius until a positive slack is obtained. Two case studies\nillustrate the workflow and certifies almost-sure reachability."}
{"id": "2510.24967", "categories": ["math.OC", "cs.NA", "math.NA", "90C30, 90C25, 49M15, 65K05"], "pdf": "https://arxiv.org/pdf/2510.24967", "abs": "https://arxiv.org/abs/2510.24967", "authors": ["Nick Tsipinakis", "Panos Parpas", "Matthias Voigt"], "title": "Adaptive Multilevel Newton: A Quadratically Convergent Optimization Method", "comment": "35 pages, 29 figures", "summary": "Newton's method may exhibit slower convergence than vanilla Gradient Descent\nin its initial phase on strongly convex problems. Classical Newton-type\nmultilevel methods mitigate this but, like Gradient Descent, achieve only\nlinear convergence near the minimizer. We introduce an adaptive multilevel\nNewton-type method with a principled automatic switch to full Newton once its\nquadratic phase is reached. The local quadratic convergence for strongly convex\nfunctions with Lipschitz continuous Hessians and for self-concordant functions\nis established and confirmed empirically. Although per-iteration cost can\nexceed that of classical multilevel schemes, the method is efficient and\nconsistently outperforms Newton's method, Gradient Descent, and the multilevel\nNewton method, indicating that second-order methods can outperform first-order\nmethods even when Newton's method is initially slow."}
{"id": "2510.25411", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25411", "abs": "https://arxiv.org/abs/2510.25411", "authors": ["Sana Hafeez", "Ghulam E Mustafa Abro", "Hifza Mustafa"], "title": "Quantum-Resilient Threat Modelling for Secure RIS-Assisted ISAC in 6G UAV Corridors", "comment": "6 Pages, 5figures", "summary": "The rapid deployment of unmanned aerial vehicle (UAV) corridors in\nsixth-generation (6G) networks requires safe, intelligence-driven integrated\nsensing and communications (ISAC). Reconfigurable intelligent surfaces (RIS)\nenhance spectrum efficiency, localisation accuracy, and situational awareness,\nwhile introducing new vulnerabilities. The rise of quantum computing increases\nthe risks associated with harvest-now-decrypt-later strategies and\nquantum-enhanced spoofing. We propose a Quantum-Resilient Threat Modelling\n(QRTM) framework for RIS-assisted ISAC in UAV corridors to address these\nchallenges. QRTM integrates classical, quantum-ready, and quantum-aided\nadversaries, countered using post-quantum cryptographic (PQC) primitives:\nML-KEM for key establishment and Falcon for authentication, both embedded\nwithin RIS control signalling and UAV coordination. To strengthen security\nsensing, the framework introduces RIS-coded scene watermarking validated\nthrough a generalised likelihood ratio test (GLRT), with its detection\nprobability characterised by the Marcum Q function. Furthermore, a Secure ISAC\nUtility (SIU) jointly optimises secrecy rate, spoofing detection, and\nthroughput under RIS constraints, enabled by a scheduler with computational\ncomplexity of O(n^2). Monte Carlo evaluations using 3GPP Release 19 mid-band\nurban-canyon models (7-15 GHz) demonstrate a spoof-detection probability\napproaching 0.99 at a false-alarm rate of 1e-3, secrecy-rate retention\nexceeding 90 percent against quantum-capable adversaries, and\nsignal-interference utilisation improvements of about 25 percent compared with\nbaselines. These results show a standards-compliant path towards reliable,\nquantum-resilient ISAC for UAV corridors in smart cities and non-terrestrial\nnetworks."}
{"id": "2510.25411", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25411", "abs": "https://arxiv.org/abs/2510.25411", "authors": ["Sana Hafeez", "Ghulam E Mustafa Abro", "Hifza Mustafa"], "title": "Quantum-Resilient Threat Modelling for Secure RIS-Assisted ISAC in 6G UAV Corridors", "comment": "6 Pages, 5figures", "summary": "The rapid deployment of unmanned aerial vehicle (UAV) corridors in\nsixth-generation (6G) networks requires safe, intelligence-driven integrated\nsensing and communications (ISAC). Reconfigurable intelligent surfaces (RIS)\nenhance spectrum efficiency, localisation accuracy, and situational awareness,\nwhile introducing new vulnerabilities. The rise of quantum computing increases\nthe risks associated with harvest-now-decrypt-later strategies and\nquantum-enhanced spoofing. We propose a Quantum-Resilient Threat Modelling\n(QRTM) framework for RIS-assisted ISAC in UAV corridors to address these\nchallenges. QRTM integrates classical, quantum-ready, and quantum-aided\nadversaries, countered using post-quantum cryptographic (PQC) primitives:\nML-KEM for key establishment and Falcon for authentication, both embedded\nwithin RIS control signalling and UAV coordination. To strengthen security\nsensing, the framework introduces RIS-coded scene watermarking validated\nthrough a generalised likelihood ratio test (GLRT), with its detection\nprobability characterised by the Marcum Q function. Furthermore, a Secure ISAC\nUtility (SIU) jointly optimises secrecy rate, spoofing detection, and\nthroughput under RIS constraints, enabled by a scheduler with computational\ncomplexity of O(n^2). Monte Carlo evaluations using 3GPP Release 19 mid-band\nurban-canyon models (7-15 GHz) demonstrate a spoof-detection probability\napproaching 0.99 at a false-alarm rate of 1e-3, secrecy-rate retention\nexceeding 90 percent against quantum-capable adversaries, and\nsignal-interference utilisation improvements of about 25 percent compared with\nbaselines. These results show a standards-compliant path towards reliable,\nquantum-resilient ISAC for UAV corridors in smart cities and non-terrestrial\nnetworks."}
{"id": "2510.25643", "categories": ["math.OC", "90C26, 65K05"], "pdf": "https://arxiv.org/pdf/2510.25643", "abs": "https://arxiv.org/abs/2510.25643", "authors": ["Karl Welzel", "Yang Liu", "Raphael A. Hauser", "Coralia Cartis"], "title": "Local Convergence of Adaptively Regularized Tensor Methods", "comment": null, "summary": "Optimization methods that make use of derivatives of the objective function\nup to order $p > 2$ are called tensor methods. Among them, ones that minimize a\nregularized $p$th-order Taylor expansion at each step have been shown to\npossess optimal global complexity, which improves as $p$ increases. The local\nconvergence of such optimization algorithms on functions that have Lipschitz\ncontinuous $p$th derivatives and are uniformly convex of order $q$ has been\nstudied by Doikov and Nesterov [Math. Program., 193 (2022), pp. 315--336]. We\nextend these local convergence results to locally uniformly convex functions\nand fully adaptive methods, which do not need knowledge of the Lipschitz\nconstant, thus providing the first sharp local rates for AR$p$. We discuss the\nsurprising new challenges encountered by nonconvex local models and non-unique\nmodel minimizers. For $p > 2$, our examples show that in particular when using\nthe global minimizer of the subproblem, even asymptotically not all iterations\nneed to be successful. Only if the \"right\" local model minimizer is used, the\n$p/(q-1)$th-order local convergence from the non-adaptive case is preserved for\n$p > q-1$, otherwise the superlinear rate can degrade. We thus confirm that\nadaptive higher-order methods achieve superlinear convergence for certain\ndegenerate problems as long as $p$ is large enough and provide sharp bounds on\nthe order of convergence one can expect in the limit."}
{"id": "2510.25501", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25501", "abs": "https://arxiv.org/abs/2510.25501", "authors": ["Tong Han", "Yan Xu", "Rui Zhang"], "title": "A New Neural Network Paradigm for Scalable and Generalizable Stability Analysis of Power Systems", "comment": null, "summary": "This paper presents a new neural network (NN) paradigm for scalable and\ngeneralizable stability analysis of power systems. The paradigm consists of two\nparts: the neural stability descriptor and the sample-augmented iterative\ntraining scheme. The first part, based on system decomposition, constructs the\nobject (such as a stability function or condition) for stability analysis as a\nscalable aggregation of multiple NNs. These NNs remain fixed across varying\npower system structures and parameters, and are repeatedly shared within each\nsystem instance defined by these variations, thereby enabling the\ngeneralization of the neural stability descriptor across a class of power\nsystems. The second part learns the neural stability descriptor by iteratively\ntraining the NNs with sample augmentation, guided by the tailored\nconservativeness-aware loss function. The training set is strategically\nconstructed to promote the descriptor's generalizability, which is\nsystematically evaluated by verification and validation during the training\nprocess. Specifically, the proposed NN paradigm is implemented for\nlarge-disturbance stability analysis of the bulk power grid and\nsmall-disturbance stability conditions of the microgrid system. Finally,\nnumerical studies for the two implementations demonstrate the applicability and\neffectiveness of the proposed NN paradigm."}
{"id": "2510.25501", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25501", "abs": "https://arxiv.org/abs/2510.25501", "authors": ["Tong Han", "Yan Xu", "Rui Zhang"], "title": "A New Neural Network Paradigm for Scalable and Generalizable Stability Analysis of Power Systems", "comment": null, "summary": "This paper presents a new neural network (NN) paradigm for scalable and\ngeneralizable stability analysis of power systems. The paradigm consists of two\nparts: the neural stability descriptor and the sample-augmented iterative\ntraining scheme. The first part, based on system decomposition, constructs the\nobject (such as a stability function or condition) for stability analysis as a\nscalable aggregation of multiple NNs. These NNs remain fixed across varying\npower system structures and parameters, and are repeatedly shared within each\nsystem instance defined by these variations, thereby enabling the\ngeneralization of the neural stability descriptor across a class of power\nsystems. The second part learns the neural stability descriptor by iteratively\ntraining the NNs with sample augmentation, guided by the tailored\nconservativeness-aware loss function. The training set is strategically\nconstructed to promote the descriptor's generalizability, which is\nsystematically evaluated by verification and validation during the training\nprocess. Specifically, the proposed NN paradigm is implemented for\nlarge-disturbance stability analysis of the bulk power grid and\nsmall-disturbance stability conditions of the microgrid system. Finally,\nnumerical studies for the two implementations demonstrate the applicability and\neffectiveness of the proposed NN paradigm."}
{"id": "2510.25716", "categories": ["math.OC", "math.FA", "49M15, 65H04, 65H10, 90C30, 47H05"], "pdf": "https://arxiv.org/pdf/2510.25716", "abs": "https://arxiv.org/abs/2510.25716", "authors": ["Nadja Vater", "Katherine Rossella Foglia", "Vittorio Colao", "Alfio Borzì"], "title": "A Low-Rank Symplectic Gradient Adjustment Method for Computing Nash Equilibria", "comment": null, "summary": "This work presents a theoretical and numerical investigation of the\nsymplectic gradient adjustment (SGA) method and of a low-rank SGA (LRSGA)\nmethod for efficiently solving two-objective optimization problems in the\nframework of Nash games. The SGA method outperforms the gradient method by\nincluding second-order mixed derivatives computed at each iterate, which\nrequires considerably larger computational effort. For this reason, a LRSGA\nmethod is proposed where the approximation to second-order mixed derivatives\nare obtained by rank-one updates. The theoretical analysis presented in this\nwork focuses on novel convergence estimates for the SGA and LRSGA methods,\nincluding parameter bounds. The superior computational complexity of the LRSGA\nmethod is demonstrated in the training of a CLIP neural architecture, where the\nLRSGA method outperforms the SGA method by orders of magnitude smaller CPU\ntime."}
{"id": "2510.25564", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25564", "abs": "https://arxiv.org/abs/2510.25564", "authors": ["Thiago S. Gomides", "Evangelos Kranakis", "Ioannis Lambadaris", "Yannis Viniotis", "Gennady Shaikhet"], "title": "Optimal and Heuristic Approaches for Platooning Systems with Deadlines", "comment": null, "summary": "Efficient truck platooning is a key strategy for reducing freight costs,\nlowering fuel consumption, and mitigating emissions. Deadlines are critical in\nthis context, as trucks must depart within specific time windows to meet\ndelivery requirements and avoid penalties. In this paper, we investigate the\noptimal formation and dispatch of truck platoons at a highway station with\nfinite capacity $L$ and deadline constraints $T$. The system operates in\ndiscrete time, with each arriving truck assigned a deadline of $T$ slot units.\nThe objective is to leverage the efficiency gains from forming large platoons\nwhile accounting for waiting costs and deadline violations. We formulate the\nproblem as a Markov decision process and analyze the structure of the optimal\npolicy $\\pi^\\star$ for $L = 3$, extending insights to arbitrary $L$. We prove\nthat the $\\pi^\\star$ is monotone in the state space $\\mathcal{S}$ and identify\nclasses of unreachable states. Moreover, since $\\mathcal{S}$ grows\nexponentially with $L$ and $T$, we propose heuristics-including conditional and\ndeep-learning based approaches-that exploit these structural insights while\nmaintaining low computational complexity."}
{"id": "2510.25564", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25564", "abs": "https://arxiv.org/abs/2510.25564", "authors": ["Thiago S. Gomides", "Evangelos Kranakis", "Ioannis Lambadaris", "Yannis Viniotis", "Gennady Shaikhet"], "title": "Optimal and Heuristic Approaches for Platooning Systems with Deadlines", "comment": null, "summary": "Efficient truck platooning is a key strategy for reducing freight costs,\nlowering fuel consumption, and mitigating emissions. Deadlines are critical in\nthis context, as trucks must depart within specific time windows to meet\ndelivery requirements and avoid penalties. In this paper, we investigate the\noptimal formation and dispatch of truck platoons at a highway station with\nfinite capacity $L$ and deadline constraints $T$. The system operates in\ndiscrete time, with each arriving truck assigned a deadline of $T$ slot units.\nThe objective is to leverage the efficiency gains from forming large platoons\nwhile accounting for waiting costs and deadline violations. We formulate the\nproblem as a Markov decision process and analyze the structure of the optimal\npolicy $\\pi^\\star$ for $L = 3$, extending insights to arbitrary $L$. We prove\nthat the $\\pi^\\star$ is monotone in the state space $\\mathcal{S}$ and identify\nclasses of unreachable states. Moreover, since $\\mathcal{S}$ grows\nexponentially with $L$ and $T$, we propose heuristics-including conditional and\ndeep-learning based approaches-that exploit these structural insights while\nmaintaining low computational complexity."}
{"id": "2510.25597", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25597", "abs": "https://arxiv.org/abs/2510.25597", "authors": ["Siddhartha Upadhyay", "Ratnangshu Das", "Pushpak Jagtap"], "title": "Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach", "comment": null, "summary": "This paper presents a decentralized control framework that incorporates\nsocial awareness into multi-agent systems with unknown dynamics to achieve\nprescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is\nassigned a social awareness index that quantifies its level of cooperation or\nself-interest, allowing heterogeneous social behaviors within the system.\nBuilding on the spatiotemporal tube (STT) framework, we propose a real-time STT\nframework that synthesizes tubes online for each agent while capturing its\nsocial interactions with others. A closed-form, approximation-free control law\nis derived to ensure that each agent remains within its evolving STT, thereby\navoiding dynamic obstacles while also preventing inter-agent collisions in a\nsocially aware manner, and reaching the target within a prescribed time. The\nproposed approach provides formal guarantees on safety and timing, and is\ncomputationally lightweight, model-free, and robust to unknown disturbances.\nThe effectiveness and scalability of the framework are validated through\nsimulation and hardware experiments on a 2D omnidirectional"}
{"id": "2510.25597", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25597", "abs": "https://arxiv.org/abs/2510.25597", "authors": ["Siddhartha Upadhyay", "Ratnangshu Das", "Pushpak Jagtap"], "title": "Incorporating Social Awareness into Control of Unknown Multi-Agent Systems: A Real-Time Spatiotemporal Tubes Approach", "comment": null, "summary": "This paper presents a decentralized control framework that incorporates\nsocial awareness into multi-agent systems with unknown dynamics to achieve\nprescribed-time reach-avoid-stay tasks in dynamic environments. Each agent is\nassigned a social awareness index that quantifies its level of cooperation or\nself-interest, allowing heterogeneous social behaviors within the system.\nBuilding on the spatiotemporal tube (STT) framework, we propose a real-time STT\nframework that synthesizes tubes online for each agent while capturing its\nsocial interactions with others. A closed-form, approximation-free control law\nis derived to ensure that each agent remains within its evolving STT, thereby\navoiding dynamic obstacles while also preventing inter-agent collisions in a\nsocially aware manner, and reaching the target within a prescribed time. The\nproposed approach provides formal guarantees on safety and timing, and is\ncomputationally lightweight, model-free, and robust to unknown disturbances.\nThe effectiveness and scalability of the framework are validated through\nsimulation and hardware experiments on a 2D omnidirectional"}
{"id": "2510.25671", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25671", "abs": "https://arxiv.org/abs/2510.25671", "authors": ["Hongjin Du", "Rahul Rane", "Weijie Xia", "Pedro P. Vergara", "Aleksandra Lekić"], "title": "An OPF-based Control Framework for Hybrid AC-MTDC Power Systems under Uncertainty", "comment": null, "summary": "The increasing integration of renewable energy, particularly offshore wind,\nintroduces significant uncertainty into hybrid AC-HVDC systems due to forecast\nerrors and power fluctuations. Conventional control strategies typically rely\non fixed setpoints and neglect frequency deviations, which can compromise\nsystem stability under rapid renewable variations. To address this challenge,\nthis paper presents a forecast-integrated, optimal power flow (OPF)-based\nadaptive control framework. Wind speed forecasts generated using a Random\nForest model are incorporated into a time-coupled OPF to determine baseline\nconverter setpoints in anticipation of wind fluctuations, which are further\nadjusted in real time based on actual operating conditions. An adaptive droop\ncontrol scheme is developed that jointly considers DC voltage and AC frequency\ndeviations. The effectiveness of the proposed control framework is validated\nthrough hardware-in-the-loop (HIL) simulations, demonstrating its capability to\nensure stable and robust operation of hybrid AC-HVDC systems under high\npenetration of renewable energy."}
{"id": "2510.25671", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25671", "abs": "https://arxiv.org/abs/2510.25671", "authors": ["Hongjin Du", "Rahul Rane", "Weijie Xia", "Pedro P. Vergara", "Aleksandra Lekić"], "title": "An OPF-based Control Framework for Hybrid AC-MTDC Power Systems under Uncertainty", "comment": null, "summary": "The increasing integration of renewable energy, particularly offshore wind,\nintroduces significant uncertainty into hybrid AC-HVDC systems due to forecast\nerrors and power fluctuations. Conventional control strategies typically rely\non fixed setpoints and neglect frequency deviations, which can compromise\nsystem stability under rapid renewable variations. To address this challenge,\nthis paper presents a forecast-integrated, optimal power flow (OPF)-based\nadaptive control framework. Wind speed forecasts generated using a Random\nForest model are incorporated into a time-coupled OPF to determine baseline\nconverter setpoints in anticipation of wind fluctuations, which are further\nadjusted in real time based on actual operating conditions. An adaptive droop\ncontrol scheme is developed that jointly considers DC voltage and AC frequency\ndeviations. The effectiveness of the proposed control framework is validated\nthrough hardware-in-the-loop (HIL) simulations, demonstrating its capability to\nensure stable and robust operation of hybrid AC-HVDC systems under high\npenetration of renewable energy."}
{"id": "2510.25695", "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25695", "abs": "https://arxiv.org/abs/2510.25695", "authors": ["Emerson J. Hollar", "Esmat Farzana"], "title": "Over 3 kV and Ultra-Low leakage Vertical (011) \\b{eta}-Ga2O3 Power Diodes with Engineered Schottky Contact and High-permittivity Dielectric Field Plate", "comment": null, "summary": "We report over 3 kV breakdown voltage and ultra-low leakage (011)\n\\b{eta}-Ga2O3 power devices utilizing Schottky barrier engineering and\nhigh-permittivity (\\k{appa}) dielectric (ZrO2) field plate. The (011)\norientation of \\b{eta}-Ga2O3 enabled low background doping and thick drift\nlayers which are promising to support kV-class vertical \\b{eta}-Ga2O3 power\nswitches. The Schottky barrier engineering was performed with a composite Pt\ncap/PtOx/Pt (1.5 nm) anode contact to take advantage of the enhanced reverse\nblocking capabilities enabled by PtOx while allowing low turn-on voltage by the\ninterfacing thin Pt layer. We also performed a systematic study using a\nco-processed Pt/(011) \\b{eta}-Ga2O3 Schottky barrier diodes (SBDs) on the same\nwafer. The bare SBDs revealed a breakdown voltage of ~1.5 kV, while the\nfield-plate Pt/(011) \\b{eta}-Ga2O3 SBDs achieved an increased breakdown voltage\nof 2.75 kV owing to the edge field management. Further enhancement of the\nbreakdown voltage was achieved by tunneling leakage management using composite\nPt cap/PtOx/Pt (1.5 nm) Schottky contacts that ultimately enabled breakdown\nvoltage of 3.7 kV for the field-plate diodes. Remarkably, the Pt cap/PtOx/Pt\n(1.5 nm) Schottky contacts maintained similar turn-on voltage as the Pt/(011)\n\\b{eta}-Ga2O3 SBDs. The combination of efficient tunneling leakage management\nby composite Pt cap/PtOx/Pt (1.5 nm) contacts with similar turn-on voltage,\nedge field reduction by high-\\k{appa} dielectric ZrO2 field plate, as well as\nthe advantageous material properties offered by (011) \\b{eta}-Ga2O3 demonstrate\na promising strategy for developing ultra-low leakage and multi-kV class\nvertical (011) \\b{eta}-Ga2O3 power devices."}
{"id": "2510.25695", "categories": ["eess.SY", "cond-mat.mtrl-sci", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.25695", "abs": "https://arxiv.org/abs/2510.25695", "authors": ["Emerson J. Hollar", "Esmat Farzana"], "title": "Over 3 kV and Ultra-Low leakage Vertical (011) \\b{eta}-Ga2O3 Power Diodes with Engineered Schottky Contact and High-permittivity Dielectric Field Plate", "comment": null, "summary": "We report over 3 kV breakdown voltage and ultra-low leakage (011)\n\\b{eta}-Ga2O3 power devices utilizing Schottky barrier engineering and\nhigh-permittivity (\\k{appa}) dielectric (ZrO2) field plate. The (011)\norientation of \\b{eta}-Ga2O3 enabled low background doping and thick drift\nlayers which are promising to support kV-class vertical \\b{eta}-Ga2O3 power\nswitches. The Schottky barrier engineering was performed with a composite Pt\ncap/PtOx/Pt (1.5 nm) anode contact to take advantage of the enhanced reverse\nblocking capabilities enabled by PtOx while allowing low turn-on voltage by the\ninterfacing thin Pt layer. We also performed a systematic study using a\nco-processed Pt/(011) \\b{eta}-Ga2O3 Schottky barrier diodes (SBDs) on the same\nwafer. The bare SBDs revealed a breakdown voltage of ~1.5 kV, while the\nfield-plate Pt/(011) \\b{eta}-Ga2O3 SBDs achieved an increased breakdown voltage\nof 2.75 kV owing to the edge field management. Further enhancement of the\nbreakdown voltage was achieved by tunneling leakage management using composite\nPt cap/PtOx/Pt (1.5 nm) Schottky contacts that ultimately enabled breakdown\nvoltage of 3.7 kV for the field-plate diodes. Remarkably, the Pt cap/PtOx/Pt\n(1.5 nm) Schottky contacts maintained similar turn-on voltage as the Pt/(011)\n\\b{eta}-Ga2O3 SBDs. The combination of efficient tunneling leakage management\nby composite Pt cap/PtOx/Pt (1.5 nm) contacts with similar turn-on voltage,\nedge field reduction by high-\\k{appa} dielectric ZrO2 field plate, as well as\nthe advantageous material properties offered by (011) \\b{eta}-Ga2O3 demonstrate\na promising strategy for developing ultra-low leakage and multi-kV class\nvertical (011) \\b{eta}-Ga2O3 power devices."}
{"id": "2510.25243", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25243", "abs": "https://arxiv.org/abs/2510.25243", "authors": ["Akansha Rautela", "Deepak U. Patil", "Ameer Mulla", "Indra Narayan Kar"], "title": "Minimum time consensus for damped second order agents using Gröbner basis", "comment": null, "summary": "A problem of achieving minimum time consensus for a set of $N$ second-order\nLTI system agents with bounded inputs and fuel constraints is considered.\nUnlike our other works, here the damping effect in agent dynamics is included.\nFirst, the attainable set for each agent with fuel budget constraints is\ncharacterized, and its boundary equations are derived. Then, using the\nconvexity property, the minimum time at which attainable sets of all agents\nhave a non-empty intersection is computed. By applying Helly's theorem, the\ncomputation reduces to finding the minimum time to consensus and the\ncorresponding consensus point for each of the triplets separately."}
{"id": "2510.25243", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25243", "abs": "https://arxiv.org/abs/2510.25243", "authors": ["Akansha Rautela", "Deepak U. Patil", "Ameer Mulla", "Indra Narayan Kar"], "title": "Minimum time consensus for damped second order agents using Gröbner basis", "comment": null, "summary": "A problem of achieving minimum time consensus for a set of $N$ second-order\nLTI system agents with bounded inputs and fuel constraints is considered.\nUnlike our other works, here the damping effect in agent dynamics is included.\nFirst, the attainable set for each agent with fuel budget constraints is\ncharacterized, and its boundary equations are derived. Then, using the\nconvexity property, the minimum time at which attainable sets of all agents\nhave a non-empty intersection is computed. By applying Helly's theorem, the\ncomputation reduces to finding the minimum time to consensus and the\ncorresponding consensus point for each of the triplets separately."}
{"id": "2510.25452", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25452", "abs": "https://arxiv.org/abs/2510.25452", "authors": ["Amir Shakouri", "Henk J. van Waarde", "Tren M. J. T. Baltussen", "W. P. M. H.", "Heemels"], "title": "Data-Driven Stabilization Using Prior Knowledge on Stabilizability and Controllability", "comment": "6 pages", "summary": "In this work, we study data-driven stabilization of linear time-invariant\nsystems using prior knowledge of system-theoretic properties, specifically\nstabilizability and controllability. To formalize this, we extend the concept\nof data informativity by requiring the existence of a controller that\nstabilizes all systems consistent with the data and the prior knowledge. We\nshow that if the system is controllable, then incorporating this as prior\nknowledge does not relax the conditions required for data-driven stabilization.\nRemarkably, however, we show that if the system is stabilizable, then using\nthis as prior knowledge leads to necessary and sufficient conditions that are\nweaker than those for data-driven stabilization without prior knowledge. In\nother words, data-driven stabilization is easier if one knows that the\nunderlying system is stabilizable. We also provide new data-driven control\ndesign methods in terms of linear matrix inequalities that complement the\nconditions for informativity."}
{"id": "2510.25452", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25452", "abs": "https://arxiv.org/abs/2510.25452", "authors": ["Amir Shakouri", "Henk J. van Waarde", "Tren M. J. T. Baltussen", "W. P. M. H.", "Heemels"], "title": "Data-Driven Stabilization Using Prior Knowledge on Stabilizability and Controllability", "comment": "6 pages", "summary": "In this work, we study data-driven stabilization of linear time-invariant\nsystems using prior knowledge of system-theoretic properties, specifically\nstabilizability and controllability. To formalize this, we extend the concept\nof data informativity by requiring the existence of a controller that\nstabilizes all systems consistent with the data and the prior knowledge. We\nshow that if the system is controllable, then incorporating this as prior\nknowledge does not relax the conditions required for data-driven stabilization.\nRemarkably, however, we show that if the system is stabilizable, then using\nthis as prior knowledge leads to necessary and sufficient conditions that are\nweaker than those for data-driven stabilization without prior knowledge. In\nother words, data-driven stabilization is easier if one knows that the\nunderlying system is stabilizable. We also provide new data-driven control\ndesign methods in terms of linear matrix inequalities that complement the\nconditions for informativity."}
{"id": "2510.25513", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25513", "abs": "https://arxiv.org/abs/2510.25513", "authors": ["Arash Bahari Kordabad", "Rupak Majumdar", "Sadegh Soudjani"], "title": "Sum-of-Squares Certificates for Almost-Sure Reachability of Stochastic Polynomial Systems", "comment": "8 Pages, 8 Figs", "summary": "In this paper, we present a computational approach to certify almost sure\nreachability for discrete-time polynomial stochastic systems by turning\ndrift--variant criteria into sum-of-squares (SOS) programs solved with standard\nsemidefinite solvers. Specifically, we provide an SOS method based on two\ncomplementary certificates: (i) a drift certificate that enforces a radially\nunbounded function to be non-increasing in expectation outside a compact set of\nstates; and (ii) a variant certificate that guarantees a one-step decrease with\npositive probability and ensures the target contains its nonpositive sublevel\nset. We transform these conditions to SOS constraints. For the variant\ncondition, we enforce a robust decrease over a parameterized disturbance ball\nwith nonzero probability and encode the constraints via an S-procedure with\npolynomial multipliers. The resulting bilinearities are handled by an\nalternating scheme that alternates between optimizing multipliers and updating\nthe variant and radius until a positive slack is obtained. Two case studies\nillustrate the workflow and certifies almost-sure reachability."}
{"id": "2510.25513", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.25513", "abs": "https://arxiv.org/abs/2510.25513", "authors": ["Arash Bahari Kordabad", "Rupak Majumdar", "Sadegh Soudjani"], "title": "Sum-of-Squares Certificates for Almost-Sure Reachability of Stochastic Polynomial Systems", "comment": "8 Pages, 8 Figs", "summary": "In this paper, we present a computational approach to certify almost sure\nreachability for discrete-time polynomial stochastic systems by turning\ndrift--variant criteria into sum-of-squares (SOS) programs solved with standard\nsemidefinite solvers. Specifically, we provide an SOS method based on two\ncomplementary certificates: (i) a drift certificate that enforces a radially\nunbounded function to be non-increasing in expectation outside a compact set of\nstates; and (ii) a variant certificate that guarantees a one-step decrease with\npositive probability and ensures the target contains its nonpositive sublevel\nset. We transform these conditions to SOS constraints. For the variant\ncondition, we enforce a robust decrease over a parameterized disturbance ball\nwith nonzero probability and encode the constraints via an S-procedure with\npolynomial multipliers. The resulting bilinearities are handled by an\nalternating scheme that alternates between optimizing multipliers and updating\nthe variant and radius until a positive slack is obtained. Two case studies\nillustrate the workflow and certifies almost-sure reachability."}
