<div id=toc></div>

# Table of Contents

- [math.NA](#math.NA) [Total: 21]
- [math.OC](#math.OC) [Total: 13]
- [hep-lat](#hep-lat) [Total: 5]
- [physics.ao-ph](#physics.ao-ph) [Total: 1]
- [quant-ph](#quant-ph) [Total: 38]
- [cs.CE](#cs.CE) [Total: 2]
- [math.ST](#math.ST) [Total: 6]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [stat.ME](#stat.ME) [Total: 13]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 11]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 3]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [eess.SY](#eess.SY) [Total: 7]
- [physics.soc-ph](#physics.soc-ph) [Total: 1]
- [q-fin.CP](#q-fin.CP) [Total: 1]


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [1] [New Adaptive Numerical Methods Based on Dual Formulation of Hyperbolic Conservation Laws](https://arxiv.org/abs/2601.20000)
*Alina Chertock,Qingcheng Fu,Alexander Kurganov,Lorenzo Micalizzi*

Main category: math.NA

TL;DR: 提出了一种基于对偶公式方法的自适应高阶格式，用于求解双曲型守恒律系统，通过保守与非保守解之间的差异构建平滑性指标，并据此自适应选择数值格式，提高了计算效率和对复杂流场特征的分辨率。


<details>
  <summary>Details</summary>
Motivation: 非保守格式在间断附近会产生非物理解，利用保守与非保守解的差异可有效识别流场中的不光滑区域，从而实现对接触间断等不同类型的间断进行区分并自适应地采用最优离散方法。

Method: 同时演化保守与非保守形式的数值解，利用二者在动量和压力变量上的差异构造平滑性指标（SI），在接触间断附近使用低耗散的中心迎风通量和二阶分段线性重构，在其他区域则采用基于A-WENO框架的五阶插值方法（光滑区无限制，非光滑区用Ai-WENO-Z）。

Result: 在一维和二维可压缩欧拉方程上的数值实验表明，该自适应方法相比非自适应的五阶A-WENO方案在计算效率和分辨率方面均有提升，能更准确捕捉复杂流场结构。

Conclusion: 所提出的自适应高阶方法通过双解差构造平滑性指标，实现了对不同流动区域的精确识别与离散策略自适应切换，显著提升了模拟精度与效率。

Abstract: In this paper, we propose an adaptive high-order method for hyperbolic systems of conservation laws. The proposed method is based on a dual formulation approach: Two numerical solutions, corresponding to conservative and nonconservative formulations of the same system, are evolved simultaneously. Since nonconservative schemes are known to produce nonphysical weak solutions near discontinuities, we exploit the difference between these two solutions to construct a smoothness indicator (SI). In smooth regions, the difference between the conservative and nonconservative solutions is of the same order as the truncation error of the underlying discretization, whereas in nonsmooth regions, it is ${\cal O}(1)$. We apply this idea to the Euler equations of gas dynamics and define the SI using differences in the momentum and pressure variables. This choice allows us to further distinguish neighborhoods of contact discontinuities from other nonsmooth parts of the computed solution. The resulting classification is used to adaptively select numerical discretizations. In the vicinities of contact discontinuities, we employ the low-dissipation central-upwind numerical flux and a second-order piecewise linear reconstruction with the slopes computed using an overcompressive SBM limiter. Elsewhere, we use an alternative weighted essentially non-oscillatory (A-WENO) framework with the central-upwind finite-volume numerical fluxes and either unlimited (in smooth regions) or Ai-WENO-Z (in the nonsmooth regions away from contact discontinuities) fifth-order interpolation. Numerical results for the one- and two-dimensional compressible Euler equations show that the proposed adaptive method improves both the computational efficiency and resolution of complex flow features compared with the non-adaptive fifth-order A-WENO scheme.

</details>


### [2] [A mixed virtual element discretization for the generalized Oseen problem](https://arxiv.org/abs/2601.20050)
*Felipe Lepe,Gonzalo Rivera*

Main category: math.NA

TL;DR: 本文提出了一种混合虚拟元方法来求解二维广义Oseen问题，通过引入伪应力作为附加未知量，消除了压力项，并可通过后处理恢复压力。该方法在标准网格假设下具有稳定性，并提供了先验误差估计，数值实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了更有效地求解二维广义Oseen问题，避免直接处理压力项带来的复杂性，本文引入伪应力变量以简化系统结构。

Method: 引入伪应力作为额外未知量，将压力从系统中消除；采用混合虚拟元方法离散化方程，在标准多边形网格上同时逼近伪应力张量和速度场，并通过后处理恢复压力。

Result: 证明了连续解的存在唯一性；所提方法被证明是稳定的，给出了先验误差估计，并通过多种多边形网格上的数值实验验证了理论结果的正确性。

Conclusion: 该混合虚拟元方法能有效求解二维广义Oseen问题，具备良好的稳定性和收敛性，适用于任意多边形网格，具有较强的灵活性和应用前景。

Abstract: In this paper we introduce a mixed virtual element method to approximate the solution for the two dimensional generalized Oseen problem. We introduce the pseudostress as an additional unknown, which allows to eliminate the pressure from the system; the pressure can be recovered via a post-process of the pseudostress tensor. We prove existence and uniqueness of the continuous solution via a fixed point argument. Under standard mesh assumptions, we develop a virtual element method to approximate both the tensor and the velocity field, and we show that it is stable. Furthermore, we provide a priori error estimates for the method and validate them through a series of numerical tests using different polygonal meshes.

</details>


### [3] [Improving Smoothed Aggregation AMG Robustness on Stretched Mesh Applications](https://arxiv.org/abs/2601.20119)
*Chris Siefert,Raymond Tuminaro,Daniel Sunderland*

Main category: math.NA

TL;DR: 本文探讨了代数多重网格（AMG）中强度连接算法的改进，提出了新的强度矩阵、非对称缩放、基于数值间隙的分类标准以及保行和的 lumping 方法，提升了在拉伸网格有限元问题中的收敛鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统的强度连接方法在某些情况下（如拉伸网格上的线性有限元）会出现失败，难以实现稳健的收敛，因此需要更鲁棒且高效的替代方案。

Method: 提出四种改进：1）使用距离拉普拉斯作为强度连接矩阵；2）采用非对称缩放；3）基于缩放后值的间隙进行强/弱连接分类；4）通过调整所有保留项而非仅对角项来保持行和的lumping策略。

Result: 数值实验表明，新方法在某些具有挑战性的矩阵上显著提高了收敛的稳健性，尤其在拉伸网格的有限元问题中表现更优。

Conclusion: 所提出的替代方案在保持计算效率的同时增强了AMG在复杂问题上的鲁棒性，为强度连接策略的设计提供了新的有效路径。

Abstract: Strength-of-connection algorithms play a key role in algebraic multigrid (AMG). Specifically, they determine which matrix nonzeros are classified as weak and so ignored when coarsening matrix graphs and defining interpolation sparsity patterns. The general goal is to encourage coarsening only in directions where error can be smoothed and to avoid coarsening across sharp problem variations. Unfortunately, developing robust and inexpensive strength-of-connection schemes is challenging.
  The classification of matrix nonzeros involves four aspects: (a) choosing a strength-of-connection matrix, (b) scaling its values, (c) choosing a criterion to classify scaled values as strong or weak, and (d) dropping weak entries which includes adjusting matrix values to account for dropped terms. Typically, smoothed aggregation AMG uses the linear system being solved as a strength-of-connection matrix. It scales values symmetrically using square-roots of the matrix diagonal. It classifies based on whether scaled values are above or below a threshold. Finally, it adjusts matrix values by modifying the diagonal so that the sum of entries within each row of the dropped matrix matches that of the original. While these procedures can work well, we illustrate failure cases that motivate alternatives. The first alternative uses a distance Laplacian strength-of-connection matrix. The second centers on non-symmetric scaling. We then investigate alternative classification criteria based on identifying gaps in the values of the scaled entries. Finally, an alternative lumping procedure is proposed where row sums are preserved by modifying all retained matrix entries (as opposed to just diagonal entries). A series of numerical results illustrates trade-offs demonstrating in some cases notably more robust convergence on matrices coming from linear finite elements on stretched meshes.

</details>


### [4] [Error estimates of $hp$-finite element method for elliptic optimal control problems with robin boundary](https://arxiv.org/abs/2601.20145)
*Xingyuan Lin,Xiuxiu Lin,Xuesong Chen*

Main category: math.NA

TL;DR: 本文研究了带有Robin边界条件和边界观测的椭圆控制问题的$hp$有限元方法的先验和后验误差分析。


<details>
  <summary>Details</summary>
Motivation: 为了提高椭圆最优控制问题数值解的精度与效率，需要对$hp$有限元方法进行严格的误差估计。

Method: 采用Clement型插值方法和辅助系统的构造推导先验误差估计；基于Scott-Zhang型拟插值和耦合的状态-控制近似推导残差型后验误差估计。

Result: 得到了椭圆最优控制问题的先验和后验误差估计，并通过数值算例验证了误差估计的准确性。

Conclusion: 所提出的$hp$有限元误差估计方法有效且可靠，适用于带有Robin边界条件和边界观测的椭圆控制问题。

Abstract: A priori and a posteriori error analysis of $hp$ finite element method for elliptic control problem with Robin boundary condition and boundary observation are presented. are presented. Through the Clément-type approach and the construction of an auxiliary system, we derived a priori error estimates for the elliptic optimal control problem. Residual-based a posteriori error estimates are derived based on the well-known Scott-Zhang-type quasi-interpolation and coupled state-control approximations, thus establishing an a posteriori error estimator for the $hp$ finite element method. The numerical example demonstrates the accuracy of error estimation for the elliptic optimal control problems with Robin boundary.

</details>


### [5] [A direct sampling method for magnetic induction tomography](https://arxiv.org/abs/2601.20191)
*Junqing Chen,Chengzhe Jiang*

Main category: math.NA

TL;DR: 提出一种用于磁感应层析成像逆问题的直接采样方法，通过定义具有显式表达式的点扩散函数，实现简单快速的成像过程。


<details>
  <summary>Details</summary>
Motivation: 为解决磁感应层析成像（MIT）逆问题，提高成像效率与准确性，提出一种无需迭代的直接采样方法。

Method: 定义一类可通过内积计算的点扩散函数，利用其随距离衰减的性质进行成像，并推导特殊情况下的具体表达式以展示衰减模式。

Result: 理论证明了点扩散函数具有距离衰减性，数值实验验证了该算法的高效性和准确性。

Conclusion: 所提方法为MIT提供了一种简单、快速且理论可靠的成像方案，适用于高效逆问题求解。

Abstract: This paper proposes a direct sampling method for the inverse problem of magnetic induction tomography (MIT). Our approach defines a class of point spread functions with explicit expressions, which are computed via inner products, leading to a simple and fast imaging process. We then prove that these point spread functions decay with distance, establishing the theoretical basis of the algorithm. Specific expressions for special cases are also derived to visually demonstrate their attenuation pattern. Numerical experimental results further confirm the efficiency and accuracy of the proposed algorithm.

</details>


### [6] [Local Regularity Estimation through Sobolev-Scale Norm Profile](https://arxiv.org/abs/2601.20207)
*Xiaobin Li,Leevan Ling,Yizhong Sun*

Main category: math.NA

TL;DR: 提出一种基于核的方法，利用Sobolev空间插值的范数变化来估计未知多变量函数在散乱采样数据下的空间变化正则性。


<details>
  <summary>Details</summary>
Motivation: 从散乱采样数据中估计未知函数的空间变化Sobolev正则性，以量化数据支持的局部可微程度。

Method: 构建一系列指定光滑阶数m的再生核插值函数，计算其在不同m下的原空间范数，形成Sobolev范数谱型，通过其拐点推断局部正则性；引入模板移动和局部-全局范数扫描策略提升精度与效率。

Result: 方法能准确恢复合成函数和湍流数据中的空间变化正则性，表现出对核基逼近与微分的强鲁棒性。

Conclusion: 该方法为从散乱数据中探测函数局部正则性提供了有效且稳健的工具，具有广泛的应用潜力。

Abstract: We develop a kernel-based approach for estimating the spatially varying Sobolev regularity~$s$ of an unknown $d$-variate function~$f$ from scattered sampling data, which quantifies the degree of local differentiability supported by the data. Relying only on neighborhood data near the point of interest $z\in Ω_z$, our method constructs a sequence of Sobolev-space reproducing kernel interpolants whose kernel smoothness order is specified by an index~$m > d/2$. The native-space norms of these interpolants are evaluated over a bounded range of~$m$, producing a \emph{Sobolev-scale norm profile}. The elbow of this profile serves as a quantitative probe of the underlying local regularity~$s(Ω_z)$. In particular, when $m > s(Ω_z)$, the profile exhibits rapid, near-worst-case growth governed by the classical upper bound associated with the conditioning of the kernel matrix. A band-limited surrogate analysis explains this transition and establishes a lower-bound relation linking native-norm growth to the Sobolev regularity of~$f$. Two complementary strategies are incorporated for further enhancement: (i)~a \emph{stencil-shift} subroutine, which repositions local neighborhoods to avoid crossing discontinuities whenever possible, thereby suppressing artifacts in the norm estimates; and (ii)~a local--global \emph{norm-sweep comparison} strategy that combines short two-point local tails with an optional one-point global screen to detect outlier $Ω_z$ of low Sobolev regularity and accelerate evaluation on large datasets. Numerical experiments on synthetic test functions and turbulent-flow data demonstrate accurate recovery of spatially varying regularity and confirm the robustness of the proposed characterization for kernel-based approximation and differentiation.

</details>


### [7] [A low regularity exponential-type integrator for the derivative nonlinear Schrödinger equation](https://arxiv.org/abs/2601.20212)
*Lun Ji,Hang Li,Alexander Ostermann*

Main category: math.NA

TL;DR: 本文提出了一种针对一维导数非线性薛定谔方程的低正则性一阶无滤波指数积分器，并证明了其在一阶收敛性，同时构造了对称版本以改善误差和守恒行为。


<details>
  <summary>Details</summary>
Motivation: 针对导数非线性薛定谔方程在低正则性初始数据下的数值求解问题，现有方法可能不适用或效率较低，因此需要开发新的低正则性积分器。

Method: 采用一阶无滤波指数积分方法，并构造对称化版本，分析其在H^s空间中的收敛性。

Result: 对于任意s>1/2，该方法在初始数据u_0属于H^{s+1}时具有一阶收敛性，且对称版本在全局误差和守恒性方面表现更优。

Conclusion: 这是首次为导数非线性薛定谔方程提出的低正则性积分器，数值实验验证了理论结果。

Abstract: In this work, we present a first-order unfiltered exponential integrator for the one-dimensional derivative nonlinear Schrödinger equation with low regularity. Our analysis shows that for any $s>\frac12$, the method converges with first-order in $H^s(\mathbb{T})$ for initial data $u_0\in H^{s+1}(\mathbb{T})$. Moreover, we constructed a symmetrized version of this method that performs better in terms of both global error and conservation behavior. To the best of our knowledge, these are the first low regularity integrators for the derivative nonlinear Schrödinger equation. Numerical experiments illustrate our theoretical findings.

</details>


### [8] [A Unified Variational Functional for Equidistribution and Alignment in Moving Mesh Adaptation](https://arxiv.org/abs/2601.20235)
*Wenbin Wang,Yunqing Huang,Huayi Wei*

Main category: math.NA

TL;DR: 提出了一种新的变分函数用于自适应移动网格生成，通过A-pullback形式实现均衡分布和对齐，无需依赖经验参数，并具有良好的理论性质和数值表现。


<details>
  <summary>Details</summary>
Motivation: 现有变分网格泛函常存在强非线性或依赖经验参数的问题，限制了其在自适应网格生成中的鲁棒性和普适性。

Method: 提出一种基于A-pullback公式的新变分泛函，结合迹项与对数行列式项，在无经验参数的情况下实现对网格尺寸和各向异性的平衡控制；并通过逆雅可比矩阵的几何离散化设计高效移动网格算法。

Result: 建立了泛函的强制性、多凸性、最小值存在性和测地凸性，数值实验验证了理论性质，并在函数诱导网格和瑞利-泰勒不稳定性模拟中表现出稳健的自适应行为。

Conclusion: 该方法提供了一种无需经验参数、兼具理论保证和高效计算的新框架，适用于复杂物理现象的自适应网格模拟。

Abstract: Existing variational mesh functionals often suffer from strong nonlinearity or dependence on empirical parameters.We propose a new variational functional for adaptive moving mesh generation that enforces equidistribution and alignment through an $\boldsymbol A$-pullback formulation, where $\boldsymbol A=\boldsymbol J^{-1}\boldsymbol M^{-1}\boldsymbol J^{-T}$. The functional combines a trace-based term with a logarithmic determinant term, achieving balanced control of mesh size and anisotropy without empirical parameters. We establish coercivity, polyconvexity, existence of minimizers, and geodesic convexity with respect to the inverse Jacobian, and derive a simplified geometric discretization leading to an efficient moving mesh algorithm. Numerical experiments confirm the theoretical properties and demonstrate robust adaptive behavior for function-induced meshes and Rayleigh-Taylor instability simulations.

</details>


### [9] [Element-based B-spline basis function spaces: construction and application in isogeometric analysis](https://arxiv.org/abs/2601.20243)
*Peng Yang,Maodong Pan,Falai Chen,Zhimin Zhang*

Main category: math.NA

TL;DR: 本文提出了一种统一的理论框架，用于构建与有限元空间结构等价的B样条基函数空间，通过显式的单元级Hermite插值实现高效等几何分析。


<details>
  <summary>Details</summary>
Motivation: 为了在等几何分析中实现高效且精确的数值计算，需要构造具有明确插值性质并与有限元方法兼容的B样条基函数空间。

Method: 通过将B样条基表示为单元级基函数的线性组合，建立满足任意光滑性要求的显式Hermite插值方案，并在单元级别进行分析以保证最优逼近误差。

Result: 该方法实现了无需求解全局线性系统的直接边界条件施加，在均匀和非均匀节点分布下均表现出最优收敛率和超收敛特性，并提升了三维等几何分析的计算效率。

Conclusion: 所提出的框架为等几何分析提供了一种高效、灵活且理论上严谨的基函数构造方法，统一处理几何参数化与数值求解过程。

Abstract: This paper develops a unified theoretical framework for constructing B-spline basis function spaces with structural equivalence to finite element spaces. The theory rigorously establishes that these bases emerge as explicit linear combinations of B-spline element bases. For any prescribed smoothness requirements, this element-wise formulation enables the Hermite interpolation at nodes, which directly utilizes function values and derivatives without solving global linear systems. By focusing on explicit interpolation properties, element-wise analysis establishes optimal approximation errors, even when the space smoothness attains its theoretical maximum for the space degree. In isogeometric analysis (IgA), the construction naturally decomposes geometric mappings into element-level representations, allowing efficient computations across elements regardless of node distribution. Notably, the same Hermite interpolation framework simultaneously handles domain parameterization and IgA solutions, allowing direct imposition of boundary conditions through function and derivative matching. Numerical tests demonstrate optimal convergence rates and superconvergence properties in 2D IgA under uniform knot configurations, and improved computational efficiency in 3D IgA with non-uniform knot distributions.

</details>


### [10] [A note on approximation in weighted Korobov spaces via multiple rank-1 lattices](https://arxiv.org/abs/2601.20290)
*Mou Cai,Takashi Goda*

Main category: math.NA

TL;DR: 本文研究了基于多重秩-1格点规则的加权Korobov空间中的多变量函数逼近，扩展了光滑性参数α在1/2 < α ≤ 1和一般权重下的最优收敛率结果，并证明了引入随机平移后算法在均方L2误差下的近似最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 扩展已有方法至更低光滑性和更一般权重的情形，以覆盖更广泛的周期函数类。

Method: 利用多重秩-1格点规则结合随机平移，分析其在加权Korobov空间中的逼近性能。

Result: 在1/2 < α ≤ 1和一般权重下实现了最优收敛率（至多差对数因子），并给出了保证强多项式可处理性的权重可和条件；引入随机平移后获得近似最优的均方L2误差收敛率。

Conclusion: 多重秩-1格点算法适用于低光滑性函数和一般权重情形，具有良好的收敛性和可处理性。

Abstract: This paper studies the multivariate approximation of functions in weighted Korobov spaces using multiple rank-1 lattice rules. It has been shown by Kämmerer and Volkmer (2019) that algorithms based on multiple rank-1 lattices achieve the optimal convergence rate for the $L_{\infty}$ error in Wiener-type spaces, up to logarithmic factors. While this result was translated to weighted Korobov spaces in the recent monograph by Dick, Kritzer, and Pillichshammer (2022), the analysis requires the smoothness parameter $α$ to be greater than $1$ and is restricted to product weights. In this paper, we extend this result for multiple rank-1 lattice-based algorithms to the case where $1/2<α\le 1$ and for general weights, covering a broader range of periodic functions with low smoothness and general relative importance of variables. We also provide a summability condition on the weights to ensure strong polynomial tractability for any $α>1/2$. Furthermore, by incorporating random shifts into multiple rank-1 lattice-based algorithms, we prove that the resulting randomized algorithm achieves a nearly optimal convergence rate in terms of the worst-case root mean squared $L_2$ error, while retaining the same tractability property.

</details>


### [11] [Refined rates of convergence for target-data dependent greedy generalized interpolation with Sobolev kernels](https://arxiv.org/abs/2601.20407)
*Bernard Haasdonk,Gabriele Santin,Tizian Wenzel,Daniel Winkle*

Main category: math.NA

TL;DR: 本文研究了贪婪方法在广义核插值中的应用，特别是针对由线性泛函生成的数据来恢复函数的问题。通过使用度量熵数的估计，成功去除了收敛率中的冗余对数因子，从而改进了高维问题下的收敛速度。


<details>
  <summary>Details</summary>
Motivation: 贪婪方法虽然在核插值中表现出良好的误差保证和收敛速度提升，但其收敛率中包含一个限制性能的对数项，本文旨在消除这一不利因素。

Method: 利用度量熵数（metric entropy numbers）的估计技术，对贪婪方法的收敛性进行重新分析，以去除收敛率中的对数因子。

Result: 成功移除了收敛率中的对数项，实现了更优的收敛速度，且该改进与维度和光滑性无关，特别有利于高维问题。

Conclusion: 通过引入度量熵数的分析工具，可以优化贪婪方法在广义核插值中的理论收敛性能，提升了其在高维函数逼近中的潜力。

Abstract: Greedy methods have recently been successfully applied to generalized kernel interpolation, or the recovery of a function from data stemming from the evaluation of linear functionals, including the approximation of solutions of linear PDEs by symmetric collocation. When applied to kernels generating Sobolev spaces as their native Hilbert spaces, some of these greedy methods can provide the same error guarantee of generalized interpolation on quasi-uniform points. More importantly, certain target-data-adaptive methods even give a dimension- and smoothness-independent improvement in the speed of convergence over quasi-uniform points, thus offering advantages for high-dimensional problems. These convergence rates however contain a spurious logarithmic term that limits this beneficial effect. The goal of this note is to remove this factor, and this is possible by using estimates on metric entropy numbers.

</details>


### [12] [Fokker--Planck Dynamics on Star Graphs with Variable Drift: Well-Posedness, Adjoint Analysis, and Numerical Approximation](https://arxiv.org/abs/2601.20456)
*Ritu Kumari,Cyrille Kenne,Landry Djomegne,Mani Mehra*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Stochastic transport processes on networked domains (modelled on metric graphs) arise in a variety of applications where diffusion and drift mechanisms interact with an underlying graph structure. The Fokker--Planck equation provides a natural framework for describing the evolution of probability densities associated with such dynamics. While Fokker--Planck equations on metric graphs have been studied from an analytical viewpoint, their optimal control remains largely unexplored, particularly in settings where the control acts through the drift term. In this paper, we investigate an optimal control problem governed by the Fokker--Planck equation on a star graph, with a bilinear control appearing in the drift. We establish the well-posedness of the state equation and prove the existence of at least one optimal control. The associated adjoint system is derived, and first-order necessary optimality conditions are formulated. A wavelet-based numerical scheme is proposed to approximate the optimal solution, and its performance is illustrated through representative numerical experiments. These results contribute to the analytical and computational understanding of controlled stochastic dynamics on network-like domains.

</details>


### [13] [Monotone-based Numerical Schemes for Two-Dimensional Systems of Nonlocal Conservation Laws](https://arxiv.org/abs/2601.20494)
*Anika Beckers,Jan Friedrich*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a class of numerical schemes for two-dimensional systems of nonlocal conservation laws, which are based on utilizing well-known monotone numerical flux functions after suitably approximating the nonlocal terms. The considered systems are weakly coupled by the nonlocal terms and the underlying flux function is rather general to guarantee that our results are applicable to a wide range of common nonlocal models. We state sufficient conditions to ensure the convergence of the monotone-based numerical schemes to the unique weak entropy solution. Moreover, we provide an error estimate that yields the convergence rate of $\mathcal{O}(\sqrt{Δt})$ for the numerical approximations of the solution. Our results include an existence and uniqueness proof of the nonlocal system, too. Numerical results illustrate our theoretical findings.

</details>


### [14] [Local convergence analysis of a linearized Alikhanov scheme for the time fractional sine-Gordon equation](https://arxiv.org/abs/2601.20566)
*Chang Hou,Hu Chen*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the time fractional sine-Gordon equation whose solution exhibits a weak singularity of type t^α. By means of the Alikhanov formula we derive a fully discrete, linearized scheme. Using the more general regularity assumption, we derive a sharp truncation-error bound for the fractional derivative. Furthermore, we prove a key inequality and a less restrictive stability result that is valid on general graded temporal meshes. Consequently, the temporal local convergence order is shown to be min{2, r} in H^1-seminorm, where r is the degree of grading; numerical experiments confirm that the optimal rate is already attained as soon as r = 2.

</details>


### [15] [Quantitative synthetic aperture radar inversion](https://arxiv.org/abs/2601.20583)
*Liliana Borcea,Josselin Garnier,Alexander V. Mamonov,Jörn Zimmerling*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study an inverse scattering problem for monostatic synthetic aperture radar (SAR): Estimate the wave speed in a heterogeneous, isotropic and nonmagnetic medium probed by waves emitted and measured by a moving antenna. The forward map, from the wave speed to the measurements, is derived from Maxwell's equations. It is a nonlinear map that accounts for multiple scattering and it is very oscillatory at high frequencies. This makes the standard, nonlinear least squares data fitting formulation of the inverse problem difficult to solve. We introduce an alternative, two-step approach: The first step computes the nonlinear map from the measurements to an approximation of the electric field inside the unknown medium aka, the internal wave. This is done for each antenna location in a non-iterative manner.
  The internal wave fits the data by construction, but it does not solve Maxwell's equations. The second step uses optimization to minimize the discrepancy between the internal wave and the solution of Maxwell's equations, for all antenna locations. The optimization is iterative. The first step defines an imaging function whose computational cost is comparable to that of standard SAR imaging, but it gives a better estimate of the support of targets. Further iterations improve the quantitative estimation of the wave speed. We assess the performance of the method with numerical simulations and compare the results with those of standard inversion.

</details>


### [16] [Unconditional full linear convergence and quasi-optimal complexity of smoothed adaptive finite element methods](https://arxiv.org/abs/2601.20677)
*Philipp Bringmann,Christoph Lietz,Dirk Praetorius*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present the first rigorous convergence analysis of the smoothed adaptive finite element method (S-AFEM) proposed in [Mulita, Giani, Heltai: SIAM J. Sci. Comput. 43, 2021]. S-AFEM modifies the classical adaptive finite element method (AFEM) by performing accurate discrete solves only on periodically determined mesh levels, while the intermediate levels employ a fixed number of cheap smoothing iterations. Numerical experiments in that work showed that this strategy generates adapted meshes comparable to those of AFEM at substantially lower computational cost. In this paper, we prove unconditional full R-linear convergence of a suitable quasi-error quantity and, for sufficiently small adaptivity parameters, optimal convergence rates with respect to the overall computational cost. The analysis requires only a mild uniform stability assumption on the employed smoother, satisfied by standard methods such as Richardson, Gauss-Seidel, conjugate gradient, and multigrid schemes. Our results apply to general second-order linear elliptic PDEs and show that S-AFEM retains all desired abstract convergence guarantees of AFEM while reducing the cumulative computational time. Numerical experiments validate the theory, analyze runtime performance, and underline the potential of S-AFEM for speed-up in AFEM computations.

</details>


### [17] [Adaptive domain decomposition method for time-dependent problems with applications in fluid dynamics](https://arxiv.org/abs/2601.20750)
*Vit Dolejsi,Jakub Sistek*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We deal with the numerical solution of the time-dependent partial differential equations using the adaptive space-time discontinuous Galerkin (DG) method. The discretization leads to a nonlinear algebraic system at each time level, the size of the system is varying due to mesh adaptation. A Newton-like iterative solver leads to a sequence of linear algebraic systems which are solved by GMRES solver with a domain decomposition preconditioner. Particularly, we consider additive and hybrid two-level Schwarz preconditioners which are efficient and easy to implement for DG discretization. We study the convergence of the linear solver in dependence on the number of subdomains and the number of element of the coarse grid. We propose a simplified cost model measuring the computational costs in terms of floating-point operations, the speed of computation, and the wall-clock time for communications among computer cores. Moreover, the cost model serves as a base of the presented adaptive domain decomposition method which chooses the number of subdomains and the number of element of the coarse grid in order to minimize the computational costs. The efficiency of the proposed technique is demonstrated by two benchmark problems of compressible flow simulations.

</details>


### [18] [Optimal Sensor Placement in Gaussian Processes via Column Subset Selection](https://arxiv.org/abs/2601.20781)
*Jessie Chen,Hangjie Ji,Arvind K. Saibaba*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gaussian process regression uses data measured at sensor locations to reconstruct a spatially dependent function with quantified uncertainty. However, if only a limited number of sensors can be deployed, it is important to determine how to optimally place the sensors to minimize a measure of the uncertainty in the reconstruction. We consider the Bayesian D-optimal criterion to determine the optimal sensor locations by choosing sensors from a candidate set of sensors. Since this is an NP-hard problem, our approach models sensor placement as a column subset selection problem (CSSP) on the covariance matrix, computed using the kernel function on the candidate sensor points. We propose an algorithm that uses the Golub-Klema-Stewart framework (GKS) to select sensors and provide an analysis of lower bounds on the D-optimality of these sensor placements. To reduce the computational cost in the GKS step, we propose and analyze algorithms for the D-optimal sensor placements using Nyström approximations on the covariance matrix. Moreover, we propose several algorithms that select sensors via Nyström approximation of the covariance matrix, utilizing the randomized Nyström approximation, random pivoted Cholesky and greedy pivoted Cholesky. We demonstrate the performance of our method on two applications: thin liquid film dynamics and sea surface temperature.

</details>


### [19] [Jacobi Hamiltonian Integrators: construction and applications](https://arxiv.org/abs/2601.20799)
*Adérito Araújo,Gonçalo Inocêncio Oliveira,João Nuno Mestre*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a systematic framework for constructing geometric integrators for Hamiltonian systems on Jacobi manifolds. By combining Poissonization of Jacobi structures with homogeneous symplectic bi-realizations, Jacobi dynamics are lifted to homogeneous Poisson Hamiltonian systems, enabling the construction of structure-preserving Jacobi Hamiltonian integrators. The resulting schemes are constructed explicitly and applied to a range of examples, including contact Hamiltonian systems and classical models. Numerical experiments highlight their qualitative advantages over standard integrators, including better preservation of geometric structure and improved long-time behavior.

</details>


### [20] [A locking-free mixed virtual element discretization for the elasticity eigenvalue problem](https://arxiv.org/abs/2601.20807)
*Felipe Leppe,Gonzalo Rivera*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we introduce a mixed virtual element method to approximate the eigenvalues and eigenfunctions of the two-dimensional elasticity eigenvalue problem. Under standard assumptions on the meshes, we prove the convergence of the discrete solution operator to the continuous one as the mesh size tends to zero. Using the theory of compact operators, we analyze the convergence of the method and derive error estimates for both the eigenvalues and eigenfunctions. We validate our theoretical results with a series of numerical tests, in which we compute convergence orders and show that the method is locking-free and capable of accurately approximating the spectrum independently of the shape of the polygons on the meshes.

</details>


### [21] [Fast Solvers for the Reynolds Equation on Piecewise Linear Geometries](https://arxiv.org/abs/2601.20841)
*Sarah Dennis,Thomas G. Fai*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The Reynolds equation is derived from the incompressible Navier Stokes equations under the lubrication assumptions of a long and thin domain geometry and a small scaled Reynolds number. The Reynolds equation is an elliptic differential equation and a dramatic simplification from the governing equations. When the fluid domain is piecewise linear, the Reynolds equation has an exact solution that we formulate by coupling the exact solutions of each piecewise component. We consider a formulation specifically for piecewise constant heights, and a more general formulation for piecewise linear heights; in both cases the linear system is inverted using the Schur complement. These methods can also be applied in the case of non-linear heights by approximating the height as piecewise constant or piecewise linear, in which case the methods achieve second order accuracy. We assess the time complexity of the two methods, and determine that the method for piecewise linear heights is linear time for the number of piecewise components. As an application of these methods, we explore the limits of validity for lubrication theory by comparing the solutions of the Reynolds and the Stokes equations for a variety of linear and non-linear textured slider geometries.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [22] [Randomized Feasibility Methods for Constrained Optimization with Adaptive Step Sizes](https://arxiv.org/abs/2601.20076)
*Abhishek Chakraborty,Angelia Nedić*

Main category: math.OC

TL;DR: 本文研究了一类带约束的优化问题，提出了一种结合随机可行性算法和（次）梯度法的新型优化方法，在强凸和非光滑情形下分别实现了线性收敛和最优收敛速率，并通过实验验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 由于约束由多个凸函数的下水平集交集定义，传统投影方法难以处理，因此需要设计无需显式投影的高效算法来解决此类复合约束优化问题。

Method: 采用带有Polyak步长的随机可行性算法，每轮迭代随机采样约束并进行可行性更新，同时对目标函数进行（次）梯度下降；针对不同目标函数类型设计自适应步长策略。

Result: 在强凸光滑情况下证明了目标函数值期望的线性收敛；在凸非光滑情况下实现了O(1/√T)的期望最坏情况收敛率，不可行性几乎必然几何衰减，特定采样增长策略下可达最优速率。

Conclusion: 所提算法能有效处理复杂约束优化问题，在保证收敛性的同时避免了昂贵的投影操作，理论与实验结果均表明其优于现有方法。

Abstract: We consider minimizing an objective function subject to constraints defined by the intersection of lower-level sets of convex functions. We study two cases: (i) strongly convex and Lipschitz-smooth objective function and (ii) convex but possibly nonsmooth objective function. To deal with the constraints that are not easy to project on, we use a randomized feasibility algorithm with Polyak steps and a random number of sampled constraints per iteration, while taking (sub)gradient steps to minimize the objective function. For case (i), we prove linear convergence in expectation of the objective function values to any prescribed tolerance using an adaptive stepsize. For case (ii), we develop a fully problem parameter-free and adaptive stepsize scheme that yields an $O(1/\sqrt{T})$ worst-case rate in expectation. The infeasibility of the iterates decreases geometrically with the number of feasibility updates almost surely, while for the averaged iterates, we establish an expected lower bound on the function values relative to the optimal value that depends on the distribution for the random number of sampled constraints. For certain choices of sample-size growth, optimal rates are achieved. Finally, simulations on a Quadratically Constrained Quadratic Programming (QCQP) problem and Support Vector Machines (SVM) demonstrate the computational efficiency of our algorithm compared to other state-of-the-art methods.

</details>


### [23] [A Fokker-Planck Framework for Control of Epidemics](https://arxiv.org/abs/2601.20181)
*Christian Parkinson,Souvik Roy*

Main category: math.OC

TL;DR: 提出了一种基于Fokker-Planck方程的随机传染病模型控制框架，通过优化分布实现对系统状态的鲁棒控制，并给出了最优控制的存在性证明与数值方法验证。


<details>
  <summary>Details</summary>
Motivation: 为了在存在动力学和初始数据不确定性的情况下，实现对流行病传播过程的可靠控制，避免直接控制随机系统的困难。

Method: 构建与随机系统相关的Fokker-Planck方程的最优控制问题，分析偏微分方程约束下的优化问题，利用控制到状态映射证明最优控制的存在性，并通过Pontryagin最小原理刻画最优控制，采用序列二次Hamilton方法进行数值求解。

Result: 证明了最优控制的存在性并获得了其必要条件，数值实验表明该方法能有效逼近最优控制策略，适用于不同成本函数下的SIR模型控制。

Conclusion: 该框架为随机 compartmental 模型提供了有效的控制手段，具有处理多重不确定性的能力，适用于流行病防控中的决策支持。

Abstract: We present a control framework for stochastic compartmental models in epidemiology. In this framework, rather than directly controlling the stochastic system, we perform optimal control of an associated Fokker-Planck equation, with the goal of steering the distribution of possible solutions of the stochastic system to some desirable state. In particular, this allows for robust control mechanism with uncertainty not only in the dynamics, but also in the initial data. We formulate and fully analyze a partial differential equation constrained optimization problem, including a proof of existence of optimal controls via analysis of the control-to-state map, and a characterization of optimal controls via the Pontryagin minimum principle. We describe the application of the sequential quadratic Hamiltonian method to our problem, which provides numerical approximations of optimal control maps. We demonstrate our method using a minimal stochastic susceptible-infected-recovered model with different choices of cost functionals that represent different policy-maker concerns.

</details>


### [24] [Improved Global Landscape Guarantees for Low-rank Factorization in Synchronization](https://arxiv.org/abs/2601.20292)
*Shuyang Ling*

Main category: math.OC

TL;DR: 本文研究了正交群同步问题中的低秩因子化方法，通过将景观分析转化为凸优化问题，提供了对所有参数对$(p,d)$的统一刻画，改进了现有结果中关于Hessian矩阵条件数的依赖性，并在$d=1$时恢复了已知的最佳界限，在$d \geq 2$时显著提升了保证条件。


<details>
  <summary>Details</summary>
Motivation: 低秩因子化方法虽高效但存在非凸性导致陷入局部极小值的问题，现有理论对其优化景观良性程度的刻画尚不清晰，尤其缺乏对条件数依赖的精确保证。

Method: 将低秩因子化对应的Stiefel流形上的非凸优化问题的景观分析转化为一个凸优化问题，从而统一分析不同参数对$(p,d)$下的优化景观性质。

Result: 给出了当$p \geq d+2$（$d\geq 1$）及$p = d+1$（$1\leq d\leq 3$）时优化景观无虚假局部极小值的统一刻画，显著改善了对Hessian条件数的依赖，恢复了$d=1$时的最优界，并大幅改进了$d \geq 2$时的理论保证。

Conclusion: 该理论为正交群同步问题中低秩方法的全局收敛性提供了更强、更广泛的保障，具有广泛适用性，可应用于多种实际场景。

Abstract: The orthogonal group synchronization problem, which aims to recover a set of $d \times d$ orthogonal matrices from their pairwise noisy products, plays a fundamental role in signal processing, computer vision, and network analysis. In recent years, numerous optimization techniques, such as semidefinite relaxation (SDR) and low-rank (Burer-Monteiro) factorization, have been proposed to address this problem and their theoretical guarantees have been extensively studied. While SDR is provably powerful and exact in recovering the least-squares estimator under certain mild conditions, it is not scalable. In contrast, the low-rank factorization is highly efficient but nonconvex, meaning its iterates may get trapped in local minima. To close the gap, we analyze the low-rank approach and focus on understanding when the associated nonconvex optimization landscape is benign, i.e., free of spurious local minima. Recent works suggest that the benignness depends on the condition number of the Hessian at the global minimizer, but it remains unclear whether sharp guarantees can be achieved. In this work, we consider the low-rank approach which corresponds to an optimization problem over the Stiefel manifold ${\rm St}(p,d)^{\otimes n}$. By formulating the landscape analysis into another convex optimization problem, we provide a unified characterization of the optimization landscape for all parameter pairs $(p,d)$ with $p \geq d+2$ for $d\geq 1$ and $p = d+1$ for $1\leq d\leq 3$ which gives a much improved dependence on the condition number of the Hessian. Our results recover the known sharp state-of-the-art bound for $d=1$ which is extremely useful for characterizing the Kuramoto synchronization, and significantly improved the guarantees for the general case $d \geq 2$ with $p \geq d+2$ over the existing results. The theoretical results are versatile and applicable to a wide range of examples.

</details>


### [25] [A novel neural network with predefined-time stability for solving generalized monotone inclusion problems with applications](https://arxiv.org/abs/2601.20338)
*Nam Van Tran*

Main category: math.OC

TL;DR: 提出了一种用于求解Hilbert空间中包含问题的新动力学框架，适用于更广泛的单调性条件，并具有固定时间与预设时间稳定性；通过前向欧拉离散化得到新的前向-后向算法，理论与数值实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 扩展经典单调性条件的限制，提升求解包含问题的收敛性能与适用范围，实现可预测收敛时间的动力系统设计。

Method: 在广义单调性假设下构建连续时间动力系统，分析其固定时间和预设时间稳定性，并采用前向欧拉法进行离散化，得到前向-后向迭代算法。

Result: 建立了系统的固定时间和预设时间稳定性，提出了具有严格收敛性证明的离散算法，并在约束优化、混合变分不等式等问题上验证了有效性。

Conclusion: 所提框架不仅拓展了传统方法的适用范围，还实现了可控收敛时间，在多种问题类型和数值实验中表现出良好的性能与灵活性。

Abstract: We propose a novel dynamical framework for solving inclusion
  problems of the form \(0 \in F(x) + G(x)\) in Hilbert spaces, where \(F\) is a
  maximal set-valued operator and \(G\) is a single-valued mapping. The analysis is
  conducted under a generalized monotonicity assumption, which relaxes the
  classical monotonicity conditions commonly imposed in the literature and thereby
  extends the applicability of the proposed approach.
  Under mild conditions on the system parameters, we establish both fixed-time and
  predefined-time stability of the resulting dynamical system. The fixed-time
  stability guarantees a uniform upper bound on the settling time that is
  independent of the initial condition, whereas the predefined-time stability
  framework allows the system parameters to be selected \emph{a priori} in order
  to ensure convergence within a user-specified time horizon.
  Moreover, we investigate an explicit forward Euler discretization of the
  continuous-time dynamics, leading to a novel forward--backward iterative
  algorithm. A rigorous convergence analysis of the resulting discrete scheme is
  provided. Finally, the effectiveness and versatility of the proposed method are
  illustrated through several classes of problems, including constrained
  optimization problems, mixed variational inequalities, and variational
  inequalities, together with numerical experiments that corroborate the
  theoretical results.

</details>


### [26] [Data-Driven Structured Control for Continuous-Time LTI Systems](https://arxiv.org/abs/2601.20340)
*Zhaohua Yang,Yuxing Zhong,Ling Shi*

Main category: math.OC

TL;DR: 本文研究了连续时间线性时不变系统的数据驱动结构化控制器设计问题，考虑了稳定化、H2和H∞性能三个控制目标。通过收集的数据构造包含所有可接受系统矩阵的极小矩阵椭球，并提出线性化技术以结合控制器的结构约束，进而为每个控制目标设计迭代算法，最后通过数值例子验证所提方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决传统模型依赖方法在复杂系统中难以准确建模的问题，利用数据驱动方式实现具有结构约束的控制器设计，提高实际应用中的可行性与鲁棒性。

Method: 基于采集的数据构建包含所有可能系统矩阵的最小矩阵椭球，采用线性化技术处理控制器的结构约束，并针对不同控制目标（稳定化、H2、H∞）设计相应的迭代算法。

Result: 成功实现了满足结构约束的控制器设计，能够在不依赖精确系统模型的情况下完成稳定化及性能优化，数值实验表明所提方法有效且具有良好的收敛性。

Conclusion: 本文提出的方法能够有效解决数据驱动下的结构化控制器设计问题，适用于无法获得精确模型的实际系统，在保证性能的同时增强了设计的实用性。

Abstract: This paper addresses the data-driven structured controller design problem for continuous-time linear time-invariant (LTI) systems. We consider three control objectives, including stabilization, $H_2$ performance, and $H_\infty$ performance. Using the collected data, we construct a minimal matrix ellipsoid that contains all admissible system matrices. We propose some linearization techniques that enable us to incorporate the structural constraint on the controller, which motivates an iterative algorithm for each control objective. Finally, we provide some numerical examples to demonstrate the effectiveness of the proposed methods.

</details>


### [27] [Reinforcement Learning for Dividend Optimization in Partially Observed Regime-Switching Diffusion Model](https://arxiv.org/abs/2601.20387)
*Zhongqin Gao,Yan Lv,Jingmin He*

Main category: math.OC

TL;DR: 本文研究了在部分可观测的 regime-switching 扩散模型中具有有界支付率的最优股息问题，提出了一种基于连续时间强化学习的探索性随机控制方法，并设计了 actor-critic 算法进行策略学习，数值实验显示其具有良好的样本外表现。


<details>
  <summary>Details</summary>
Motivation: 由于市场状态（regime）不可观测且关键参数未知，传统完全信息假设下的最优股息策略难以应用，因此需要在部分信息下构建可学习的动态决策框架。

Method: 采用探索性（熵正则化）随机控制框架，推导出具有半解析解的HJB方程系统，利用低次多项式近似ODE解，并结合信念状态滤波与actor-critic强化学习算法，在线进行策略评估与改进。

Result: 得到了价值函数和最优探索性股息策略的半解析表征，通过参数化函数族和强化学习算法实现了对最优策略的有效逼近。

Conclusion: 所提出的连续时间强化学习方法能够在部分观测和参数未知的复杂环境下有效求解最优股息问题，且学习得到的策略具有优异的样本外性能。

Abstract: This paper studies the optimal dividend problem with a bounded payout rate in a partially observed regime-switching diffusion model, where, in practice, the market regime is unobserved and key model parameters are unknown. To address this partial-information setting, we propose a continuous-time reinforcement learning (RL) approach within an exploratory (entropy-regularized) stochastic control framework for discounted dividends under regime switching. The associated exploratory Hamilton-Jacobi-Bellman (HJB) system admits semi-analytical characterizations of the value function and the optimal exploratory dividend policy, determined by two unknown functions solving two ordinary differential equations (ODEs) together with positive real roots of the induced quadratic equations. Exploiting this structure, we introduce parametric families for both the value function and the policy, using low-degree polynomial approximations to the ODE solutions. We then develop an actor-critic RL algorithm to learn the optimal exploratory policy through interactions with the market environment: it performs belief-state filtering from observed data and iterates policy evaluation and policy improvement online to refine the policy. Numerical experiments demonstrate strong out-of-sample performance of the learned dividend policies.

</details>


### [28] [Convergence Analysis of Randomized Subspace Normalized SGD under Heavy-Tailed Noise](https://arxiv.org/abs/2601.20399)
*Gaku Omiya,Pierre-Louis Poirion,Akiko Takeda*

Main category: math.OC

TL;DR: 本文提出了在非凸优化中具有高概率收敛保证的随机子空间SGD方法，并针对重尾梯度噪声设计了新的归一化算法RS-NSGD，证明其在有界p阶矩噪声下具备更优的查询复杂度。


<details>
  <summary>Details</summary>
Motivation: 由于现代机器学习中普遍存在重尾梯度噪声，而现有随机子空间方法大多仅提供期望意义下的分析，缺乏高概率保证，因此需要发展适用于更广泛噪声假设的理论与算法。

Method: 通过引入方向归一化机制设计了RS-NSGD算法，并利用鞅不等式和截断技术，在子高斯噪声和有界p阶矩噪声下分别建立高概率收敛边界。

Result: 证明了RS-SGD在子高斯噪声下具有高概率收敛性，且RS-NSGD在有界p阶矩噪声下同时具备期望和高概率收敛保证，并实现了优于全维归一化SGD的oracle复杂度。

Conclusion: 所提出的RS-NSGD算法在处理重尾噪声时更具鲁棒性，且在理论和效率上优于现有方法，扩展了随机子空间方法在非凸优化中的适用范围。

Abstract: Randomized subspace methods reduce per-iteration cost; however, in nonconvex optimization, most analyses are expectation-based, and high-probability bounds remain scarce even under sub-Gaussian noise. We first prove that randomized subspace SGD (RS-SGD) admits a high-probability convergence bound under sub-Gaussian noise, achieving the same order of oracle complexity as prior in-expectation results. Motivated by the prevalence of heavy-tailed gradients in modern machine learning, we then propose randomized subspace normalized SGD (RS-NSGD), which integrates direction normalization into subspace updates. Assuming the noise has bounded $p$-th moments, we establish both in-expectation and high-probability convergence guarantees, and show that RS-NSGD can achieve better oracle complexity than full-dimensional normalized SGD.

</details>


### [29] [Sufficiently Regularized Nonnegative Quartic Polynomials are Sum-of-Squares](https://arxiv.org/abs/2601.20418)
*Wenqi Zhu,Coralia Cartis*

Main category: math.OC

TL;DR: 本文研究了多变量四次正则化多项式中非负性与平方和（SoS）表示之间的等价性，扩展了希尔伯特第17问题的经典结果，并刻画了具有特殊结构的多项式全局优化的NP-hard边界。


<details>
  <summary>Details</summary>
Motivation: 基于Hilbert第17问题，探索在哪些特殊结构的多变量四次正则化多项式中，非负性可以被平方和表示所认证，从而为非凸优化中的高阶张量方法提供理论支持。

Method: 通过将对称三次多项式加上欧几里得范数的加权四次项进行正则化，并将其平移至全局最优值以保证非负性，分析其是否可表示为平方和；同时构造反例说明欧氏范数的关键作用。

Result: 证明在足够大的正则化参数下，这类多项式具有平方和表示；进一步识别出多个子类（如二次-四次多项式、含特定立方项的四次多项式）在所有正则化参数下均存在SoS证书；并展示了这些结果在高阶张量方法中的应用价值。

Conclusion: 该工作扩展了Hilbert关于非负多项式可表示为平方和的经典结论，明确了某些结构化四次正则化多项式的非负性可通过SoS认证，为非凸优化子问题的求解提供了有效验证工具。

Abstract: Hilbert's 17th problem famously established that not all nonnegative polynomials admit a sum-of-squares (SoS) representation. Hilbert also identified a few special classes in which nonnegativity and SoS are equivalent, such as univariate polynomials, quadratic polynomials, and bivariate quartic polynomials. In this paper, we extend this equivalence to several new subclasses of multivariate quartically regularized polynomials and characterize the NP-hardness boundary of these special-structure polynomials. Specifically, we consider the global optimization of multivariate symmetric cubic polynomials regularized by weighted quartic powers of the Euclidean norm. These special-structure polynomials arise as iterative subproblems in high-order tensor methods for nonconvex optimization problems. We consider shifting these polynomials by their global optimum so as to make them nonnegative, and show that for sufficiently large regularization parameters and under mild assumptions, these polynomials admit a sum-of-squares representation. We also identify several structured subclasses of quartically regularized cubic polynomials for which global optimality of the model implies that nonnegativity is certified by a sum-of-squares decomposition for all values of the regularization parameter, including quadratic-quartic polynomials and quartic polynomials containing a special cubic term that can be decomposed as the product of a quadratic norm and a linear form. We provide counterexamples based on quartic separable norms that demonstrate the crucial role of the Euclidean norm in these representations. Finally, we illustrate how these SoS-based certificates can be used for Taylor subproblems arising in high-order tensor methods for nonconvex optimization, with encouraging numerical results.

</details>


### [30] [Adaptive Conditional Gradient Sliding: Projection-Free and Line-Search-Free Acceleration](https://arxiv.org/abs/2601.20443)
*Shota Takahashi*

Main category: math.OC

TL;DR: 提出了一种无需投影和线搜索的自适应条件梯度滑动方法（AdCGS），在保持Nesterov加速的同时，适用于投影代价高昂但可获得线性最小化 oracle 的凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 在投影昂贵但线性最小化可行的场景下，现有加速方法依赖投影或固定步长，缺乏对局部光滑性的自适应能力，限制了效率与适用性。

Method: 结合加速外层方案与基于LMO的内层子程序，通过重用梯度减少梯度计算，并利用自适应步长和预设精度控制子问题不精确性，实现投影自由且无需线搜索。

Result: 在凸目标函数下达到与投影型加速方法相匹配的加速收敛速率；在强凸情况下无需额外几何假设即可实现线性收敛；实验表明在ℓ_p回归、逻辑回归和最小二乘问题上优于基线方法。

Conclusion: AdCGS是首个在无需投影的前提下实现Nesterov加速并具备自适应能力的条件梯度类算法，扩展了加速方法在复杂约束下的应用范围。

Abstract: We study convex optimization problems over a compact convex set where projections are expensive but a linear minimization oracle (LMO) is available. We propose the adaptive conditional gradient sliding method (AdCGS), a projection-free and line-search-free method that retains Nesterov's acceleration with adaptive stepsizes based on local Lipschitz estimates. AdCGS combines an accelerated outer scheme with an LMO-based inner routine. It reuses gradients across multiple LMO calls to reduce gradient evaluations, while controlling the subproblem inexactness via a prescribed accuracy level coupled with adaptive stepsizes. We prove accelerated convergence rates for convex objective functions matching those of projection-based accelerated methods, while requiring no projection oracle. For strongly convex objective functions, we further establish linear convergence without additional geometric assumptions on the constraint set, such as polytopes or strongly convex sets. Experiments on constrained $\ell_p$ regression, logistic regression with real-world datasets, and least-squares problems demonstrate improvements over both projection-free and projection-based baselines.

</details>


### [31] [On controllability, observability and stabilizability of the heat equation on discrete graphs](https://arxiv.org/abs/2601.20594)
*Florentin Münch,Christian Seifert,Peter Stollmann,Martin Tautenhahn*

Main category: math.OC

TL;DR: 本文研究了离散图上热方程的线性控制问题，证明了通过弱可观测性估计可实现成本一致的α-可控性，并讨论了结果的最优性和对稳定化性质的影响。


<details>
  <summary>Details</summary>
Motivation: 旨在分析离散图上热方程的控制性能，特别是在相对稠密子集上施加控制输入时的可控性问题。

Method: 利用对偶观测问题的弱可观测性估计，建立成本一致的α-可控性。

Result: 证明了在给定条件下系统具有成本一致的α-可控性，并探讨了其最优性及对稳定化的影响。

Conclusion: 该研究为图上的分布参数系统的控制提供了理论支持，表明即使在稀疏控制作用下，仍可实现有效的控制和稳定化。

Abstract: We consider linear control problems for the heat equation of the form $\dot f (t) = -Hf (t) + \mathbf{1}_D u (t)$, $f (0) \in \ell_2 (X,m)$, where $H$ is the weighted Laplacian on a discrete graph $(X,b,m)$, and where $D \subseteq X$ is relatively dense. We show cost-uniform $α$-controllability by means of a weak observability estimate for the corresponding dual observation problem. We discuss optimality of our result as well as consequences on stabilizability properties.

</details>


### [32] [Drone-Aided Blood Collection Routing Problem: A Column Generation Approach](https://arxiv.org/abs/2601.20693)
*Amirhossein Abbaszadeh,Hossein Hashemi Doulabi*

Main category: math.OC

TL;DR: 本文提出了一种无人机辅助的血液采集路径优化问题，通过卡车-无人机协同作业，在时限内最大化可回收血小板数量，并设计了基于列生成和膜遗传算法的求解方法，验证了无人机引入的运营优势及算法优越性。


<details>
  <summary>Details</summary>
Motivation: 为了在全血捐献后六小时内完成血小板提取，需高效收集献血点的血液样本，传统车辆运输面临时间紧迫与路径效率低的问题，因此需要引入无人机提升采集效率。

Method: 将问题建模为混合整数线性规划，采用列生成方法分解为主问题和子问题，主问题选择最优卡车型-无人机巡回路线组合，子问题通过定制的膜遗传算法生成新列以寻找更优解。

Result: 实验表明，相比Gurobi求解器及文献中的混合遗传算法、入侵杂草优化算法，所提算法在无人机辅助和仅卡车场景下均表现更优，能有效提高血液采集量和时效性。

Conclusion: 无人机可显著提升血液采集系统的响应速度与覆盖能力，所提出的优化模型与算法能有效支持实际运营决策，具有较强的实践价值与推广潜力。

Abstract: Platelet extraction requires whole blood to be processed within six hours of donation. To meet this deadline, blood collection organizations must optimally route a fleet of vehicles to pick up blood units from donation sites and deliver them to a processing center. This paper introduces a drone-aided blood collection routing problem in which a fleet of trucks, each equipped with a drone, operates in a synchronized manner to collect blood units before their processing time limit expires. Each truck-drone tandem can perform multiple trips throughout the planning horizon, allowing donation sites to be visited repeatedly as new blood units become available over time. We formulate this problem as a mixed-integer linear program that jointly optimizes the routing of trucks and drones, pickup schedules, and timing decisions to maximize the total number of viable blood units collected. We also develop a column generation approach that decomposes the problem into a master problem to select the optimal set of truck-drone tours and a pricing subproblem, which is solved using a tailored memetic algorithm to generate promising new columns. Through a comprehensive computational study, we show the operational benefits of integrating drones into the blood collection system. In addition, we demonstrate the superior performance of the proposed algorithm over Gurobi and two metaheuristics from the literature, namely the hybrid genetic algorithm and the invasive weed optimization, in both the drone-aided and truck-only settings.

</details>


### [33] [Adaptive Dimension Reduction for Overlapping Group Sparsity](https://arxiv.org/abs/2601.20697)
*Yifan Bai,Clarice Poon,Jingwei Liang*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Typical dimension reduction techniques for nonoverlapping sparse optimization involve screening or sieving strategies based on a dual certificate derived from the first-order optimality condition, approximating the gradients or exploiting certain inherent low-dimensional structure of the sparse solution. In comparison, dimension reduction rules for overlapping group sparsity are generally less developed because the subgradient structure is more complex, making the link between sparsity pattern and the dual variable indirect due to the non-separability. In this work, we propose new dual certificates for overlapping group sparsity and a novel adaptive scheme for identifying the support of the overlapping group LASSO. We demonstrate how this scheme can be integrated into and significantly accelerate existing algorithms, including Primal-Dual splitting method, alternating direction method of multipliers and a recently developed variable projection scheme based on over-parameterization. We provide convergence analysis of the method and verify its practical effectiveness through experiments on standard datasets.

</details>


### [34] [A penalty-interior point method combined with MADS for equality and inequality constrained optimization](https://arxiv.org/abs/2601.20811)
*Charles Audet,Andrea Brilli,Youssef Diouane,Sébastien Le Digabel,Everton J. Silva,Christophe Tribes*

Main category: math.OC

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work introduces MADS-PIP, an efficient framework that integrates a penalty-interior point strategy into the mesh adaptive direct search (MADS) algorithm for solving nonsmooth blackbox optimization problems with general inequality and equality constraints. Inequality constraints are partitioned into two subsets: one treated via a logarithmic barrier applied to an aggregated interior constraint violation, and the other handled through an exterior quadratic penalty. All equality constraints are treated by the exterior penalty. A merit function defines a sequence of unconstrained subproblems, which are solved approximately using MADS, while a carefully designed update rule drives the penalty-barrier parameter to zero. In the nonsmooth setting, we establish convergence results ensuring feasibility for general constraints as well as Clarke stationarity for inequality-constrained problems. Computational experiments on both analytical test sets and challenging blackbox problems demonstrate that the proposed MADS-PIP algorithm is competitive with, and often outperforms, MADS with the progressive barrier strategy, particularly in the presence of equality constraints.

</details>


<div id='hep-lat'></div>

# hep-lat [[Back]](#toc)

### [35] [Resurrecting the coherent state variational algorithm for large $N$ gauge theories](https://arxiv.org/abs/2601.20150)
*Laurence G. Yaffe*

Main category: hep-lat

TL;DR: 重新实现了一种适用于SU(N)格点规范理论的相干态变分方法，可用于研究大N极限下无限体积QCD样理论的性质。


<details>
  <summary>Details</summary>
Motivation: 评估使用相干态变分方法在大N极限下数值研究无限体积QCD样理论性质的可行性。

Method: 提出一种新的实现方法，适用于包含或不包含基本表示费米子的SU(N)格点规范理论，应用于最多四维的立方晶格，并测试多个案例。

Result: 给出了在无限二维空间晶格上的哈密顿杨-米尔斯理论的初步结果。

Conclusion: 新方法为研究大N极限下的格点规范理论提供了可行且有效的数值工具。

Abstract: The feasibility of studying, numerically, properties of infinite volume QCD-like theories in the large $N$ limit using coherent state variational methods is reassessed. An entirely new implementation of this approach is described, applicable to SU($N$) lattice gauge theories, with or without fundamental representation fermions, on cubic lattices of up to four dimensions. In addition to various test cases, initial results are presented for Hamiltonian Yang-Mills theory on an infinite two-dimensional spatial lattice.

</details>


### [36] [Direct numerical simulation of the 't Hooft partition function and (de)confining phases](https://arxiv.org/abs/2601.20159)
*Okuto Morikawa,Hiroshi Suzuki*

Main category: hep-lat

TL;DR: 提出了一种直接蒙特卡洛方法来测量't Hooft分区函数，无需重加权，并应用于四维SU(2)格点杨-米尔斯理论，观察到了禁闭相中的特征行为及Witten效应的影响。


<details>
  <summary>Details</summary>
Motivation: 为了更好地理解不同相（如禁闭、Higgs、Coulomb等）下的规范场理论行为，需要有效计算't Hooft分区函数。传统方法受限于重加权技术的不足，因此需要新的数值策略。

Method: 将混合蒙特卡洛算法扩展到包含背景通量变量的动力学更新，从而实现对't Hooft分区函数各通量扇区的直接测量，避免了重加权带来的误差。

Result: 在四维SU(2)格点杨-米尔斯理论中成功测量了所有通量扇区，观测到了禁闭相中预期的“轻/重”行为以及θ=2π时由Witten效应引起的偏移；初步的有限温度研究表明存在热化和扇区间分离的问题。

Conclusion: 该方法为研究规范理论中的相结构提供了有效的数值工具，但需进一步解决不同通量扇区间的热化与可分性问题以提升精度和适用范围。

Abstract: The 't Hooft partition function $Z_{\mathrm{tH}}[E_i;B_{ij}]$ is a discrete Fourier transform of Yang--Mills partition functions in background $\mathbb{Z}_N$ 2-form gauge fields and encodes information on confinement, Higgs, Coulomb and oblique-confining phases. We report a direct Monte Carlo strategy to measure $Z_{\mathrm{tH}}$ without reweighting, by extending hybrid Monte Carlo to include dynamical updates of the background flux variables. As a first application we measure all flux sectors of four-dimensional $SU(2)$ lattice Yang--Mills on $T^4$ and observe the characteristic ``light/heavy'' behavior expected in the confining phase, together with the shift implied by the Witten effect at $θ=2π$. We also present a preliminary finite-temperature study and discuss outstanding issues on thermalization and separability between different flux sectors.

</details>


### [37] [Thermodynamic Consistency as a Reliability Test for Complex Langevin Simulations](https://arxiv.org/abs/2601.20527)
*Anosh Joseph,Arpith Kumar*

Main category: hep-lat

TL;DR: 提出了一种基于构型温度的新方法来检验复杂朗之万方法（CLM）的可靠性，该方法通过复作用量的梯度和海森矩阵构建，能够直接探测热力学一致性并检测算法误差，在一维PT对称模型中表现出高精度和敏感性，可推广到高维标量和规范理论，并为耦合依赖观测量提供独立检验。


<details>
  <summary>Details</summary>
Motivation: 复杂朗之万方法在处理具有复作用量的量子场论中的符号问题时存在收敛到错误结果的风险，现有诊断方法（如漂移分布监测）间接且不够充分，需要更直接、物理意义明确的检验手段。

Method: 基于复作用量的梯度和海森矩阵构造构型温度，作为对复杂朗之万动力学的热力学一致性进行直接探测的新检验方法，并在一维PT对称模型中验证其有效性。

Result: 构型温度能够在稳定模拟中以高精度重现输入温度，灵敏地检测算法错误、步长效应和未完全热化等问题，并可自然推广到高维系统；由于温度与许多格点理论中的裸耦合相关，该方法还可用于检查耦合依赖观测量。

Conclusion: 构型温度是一种能有效提升复杂朗之万方法在包括有限密度格点QCD在内的广泛应用中可靠性的新诊断工具。

Abstract: The complex Langevin method (CLM) is a promising tool to address the sign problem in quantum field theories with complex actions. However, it can converge to incorrect results even when simulations appear stable, highlighting the need for robust diagnostics. Existing checks, such as monitoring drift distributions, are useful but indirect. We propose a complementary test based on the configurational temperature, constructed from the gradient and Hessian of the complex action. Unlike drift-based criteria, this estimator directly probes thermodynamic consistency and provides a physically interpretable cross-check of CLM dynamics. Using one-dimensional PT-symmetric models, we show that it reproduces the input temperature with high precision and sensitively detects algorithmic errors, step-size artifacts, and incomplete thermalization. While demonstrated in simple systems, the method extends naturally to higher-dimensional scalar and gauge theories. Since temperature is tied to the bare coupling in many lattice theories, configurational monitoring can also provide an independent check on coupling-dependent observables. Our results indicate that configurational temperature can enhance CLM reliability across a broad range of applications, including lattice QCD at finite density.

</details>


### [38] [Tensor renormalization group study of cold and dense QCD in the strong coupling limit](https://arxiv.org/abs/2601.20690)
*Yuto Sugimoto,Shinichiro Akiyama,Yoshinobu Kuramashi*

Main category: hep-lat

TL;DR: 研究了在强耦合极限下(3+1)维冷密QCD的相结构，利用张量重整化群方法分析手征和核相变，并确定了手征凝聚和夸克数密度的临界夸克质量。


<details>
  <summary>Details</summary>
Motivation: 探索强耦合极限下冷密QCD的相结构及其手征与核相变行为。

Method: 采用张量重整化群方法，在Nτ=8的固定时间尺度下计算手征凝聚和夸克数密度随化学势的变化。

Result: 发现手征凝聚和夸克数密度在同一夸克质量和化学势下出现不连续性，且两者的临界夸克质量一致；在1024^4格点上验证了有限夸克质量下的首阶相变。

Conclusion: 手征和核相变的临界行为一致，支持均场理论预测，并与对偶形式的蒙特卡洛模拟结果相符。

Abstract: We study the phase structure of the (3+1)-dimensional cold and dense QCD with the Kogut--Susskind quark in the strong coupling limit using the tensor renormalization group method. The chiral and nuclear transitions are investigated by calculating the chiral condensate and the quark number density as a function of the chemical potential. For a fixed temporal extent $N_τ=8$, we determine the critical quark masses $m_c^χ$ and $m_c^{n}$ for the chiral condensate and the quark number density, respectively, at which the first-order phase transition terminates with the vanishing discontinuity in thermodynamic quantities. We find that both quantities at the same quark mass exhibit a discontinuity at the same chemical potential, and the resulting critical quark masses are consistent with each other. We also compare our results for the critical quark masses with those obtained from the Monte Carlo simulation in the dual formulation and from the mean-field analysis. We further confirm the first-order phase transition at finite quark mass on a $1024^4$ lattice, which is essentially in the thermodynamic limit at zero temperature, as expected from the mean-field analysis.

</details>


### [39] [A scalable flow-based approach to mitigate topological freezing](https://arxiv.org/abs/2601.20708)
*Claudio Bonanno,Andrea Bulgarelli,Elia Cellini,Alessandro Nada,Dario Panfalone,Davide Vadacchino,Lorenzo Verzichelli*

Main category: hep-lat

TL;DR: 提出了一种基于随机归一化流（SNF）的可扩展、精确方法，用于消除开放边界条件在格点规范理论模拟中引入的非物理边界效应，成功应用于4维SU(3)杨-米尔斯理论，并验证了拓扑磁化率的结果。


<details>
  <summary>Details</summary>
Motivation: 在格点规范理论趋近连续极限时，传统马尔可夫链蒙特卡洛模拟面临拓扑冻结问题；虽然开放边界条件（OBC）可缓解该问题，但会破坏平移不变性并引入非物理边界效应，因此需要一种既能保持拓扑遍历性又能消除边界效应的方法。

Method: 采用基于随机归一化流（SNF）的方法，结合非平衡蒙特卡洛更新与局部化的、规范协变的缺陷耦合层（通过掩码参数化stout平滑实现），通过最小化平均耗散功（等价于前后向路径测度间的KL散度）来训练模型，从而实现从带OBC缺陷的构型到全周期系综的精确映射。

Result: 该方法在4维SU(3)杨-米尔斯理论中实现了高效且无偏的拓扑采样，缺陷SNF相比纯随机非平衡方法在相当成本下表现出更优性能，并能准确复现参考的拓扑磁化率结果。

Conclusion: 所提出的缺陷SNF方法是一种可扩展、精确且高效的解决方案，能够有效消除OBC带来的边界效应，同时保持拓扑遍历性，为高精度连续极限下的格点规范理论模拟提供了新途径。

Abstract: As lattice gauge theories with non-trivial topological features are driven towards the continuum limit, standard Markov Chain Monte Carlo simulations suffer for topological freezing, i.e., a dramatic growth of autocorrelations in topological observables. A widely used strategy is the adoption of Open Boundary Conditions (OBC), which restores ergodic sampling of topology but at the price of breaking translation invariance and introducing unphysical boundary artifacts. In this contribution we summarize a scalable, exact flow-based strategy to remove them by transporting configurations from a prior with a OBC defect to a fully periodic ensemble, and apply it to 4d SU(3) Yang--Mills theory. The method is based on a Stochastic Normalizing Flow (SNF) that alternates non-equilibrium Monte Carlo updates with localized, gauge-equivariant defect coupling layers implemented via masked parametric stout smearing. Training is performed by minimizing the average dissipated work, equivalent to a Kullback--Leibler divergence between forward and reverse non-equilibrium path measures, to achieve more reversible trajectories and improved efficiency. We discuss the scaling with the number of degrees of freedom affected by the defect and show that defect SNFs achieve better performances than purely stochastic non-equilibrium methods at comparable cost. Finally, we validate the approach by reproducing reference results for the topological susceptibility.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [40] [StormDiT: A generative AI model bridges the 2-6 hour 'gray zone' in precipitation nowcasting](https://arxiv.org/abs/2601.20342)
*Haofei Sun,Yunfan Yang,Wei Han,Wei Huang,Huaguan Chen,Zhiqiu Gao,Zeting Li,Zhaoyang Huo,Zeyi Niu*

Main category: physics.ao-ph

TL;DR: StormDiT是一种统一的生成模型，用于解决极端降水短临预报中的‘现在casting灰区’难题，在6小时预测范围内表现出优异的稳定性和预测能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法在2-6小时的极端降水预报中存在可预测性障碍，观测外推法因误差累积失效，数值天气预报计算速度不足，难以解析风暴尺度动力学。

Method: 提出StormDiT，一种将天气演变视为整体时空问题的统一生成模型，无需人为设定结构先验，直接学习灰区内的耦合物理过程，基于中国7720个降水事件的大规模数据集进行训练。

Result: 在强降雨测试集上，模型对强对流（≥35 dBZ）保持6小时全时段、6分钟分辨率的熟练预测，关键成功指数（CSI）接近0.2；在SEVIR基准上，1小时预报性能超过现有最优水平一倍以上，并首次建立3小时预报的稳健基线；模型具备良好的概率校准能力，可准确量化业务风险；可解释性分析显示其能关注流出边界等非局部物理前兆，验证了对对流组织的自主理解。

Conclusion: StormDiT通过统一建模方式克服了传统分解方法割裂大气过程因果关系的问题，在长时域稳定预测和实际风险评估方面表现优越，为极端降水短临预警提供了新的有效范式。

Abstract: Accurate short-term warnings for extreme precipitation are critical for global disaster mitigation but are hindered by a persistent predictability barrier at the 2-6 hour horizon -- the "nowcasting gray zone." In this window, traditional observation-based extrapolation fails due to error accumulation, while numerical weather prediction is computationally too slow to resolve storm-scale dynamics. Recent generative AI approaches attempt to bridge this gap by decomposing precipitation into separate deterministic advection and stochastic diffusion components. However, this decomposition can sever fundamental causal links between entangled atmospheric processes, such as the dynamic initiation of convection triggered by boundary advection. Here we present StormDiT, a unified generative model that treats weather evolution as a holistic spatiotemporal problem, learning the coupled physics of the gray zone without human-imposed structural priors. Trained on a massive dataset of 7,720 precipitation events from China, our model achieves a breakthrough in long-horizon stability. On a heavy-rainfall test set, it maintains skillful prediction for strong convection ($\ge$ 35 dBZ) with a Critical Success Index (CSI) near 0.2 across the full 6-hour forecast at 6-minute resolution. Crucially, the model exhibits superior probabilistic calibration, accurately quantifying operational risks. On the public SEVIR benchmark, our unified paradigm more than doubles the state-of-the-art 1-hour performance for heavy rain and establishes the first robust baseline for 3-hour forecasting. Furthermore, interpretability analysis reveals that the model attends to non-local physical precursors, such as outflow boundaries, explicitly validating its emergent understanding of convective organization.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [41] [A Surface-Scaffolded Molecular Qubit](https://arxiv.org/abs/2601.19976)
*Tian-Xing Zheng,M. Iqbal Bakti Utama,Xingyu Gao,Moumita Kar,Xiaofei Yu,Sungsu Kang,Hanyan Cai,Tengyang Ruan,David Ovetsky,Uri Zvi,Guanming Lao,Yu-Xin Wang,Omri Raz,Sanskriti Chitransh,Grant T. Smith,Leah R. Weiss,Magdalena H. Czyz,Shengsong Yang,Alex J. Fairhall,Kenji Watanabe,Takashi Taniguchi,David D. Awschalom,A. Paul Alivisatos,Randall H. Goldsmith,George C. Schatz,Mark C. Hersam,Peter C. Maurer*

Main category: quant-ph

TL;DR: 提出了一种基于五并苯分子和二维材料hBN的表面分子自旋量子比特，具有长相干时间和稳定的荧光性能，适用于量子传感、模拟和混合量子器件。


<details>
  <summary>Details</summary>
Motivation: 在保持量子比特性能的同时将其尺寸缩小至表面级别仍具挑战性，目标是实现高效的纳米尺度传感与集成。

Method: 利用五并苯分子作为自旋量子比特，并将其支撑在二维材料六方氮化硼（hBN）上，通过全氘代五并苯提升相干时间，使用Hahn-echo和动态解耦技术测量相干特性，并结合ODMR技术实现光学探测磁共振。

Result: 该量子比特在低温到室温下均表现出稳定荧光和ODMR信号；Hahn-echo相干时间达22 μs，动态解耦下延长至214 μs，优于金刚石中浅层NV中心；可分辨局部核自旋和电子自旋环境，具备作为辅助量子资源的潜力。

Conclusion: 该平台实现了真正的表面集成、长量子相干时间和可扩展制造，为量子传感、量子模拟和混合量子器件提供了新路径，并有望拓展为一类基于二维材料的分子量子比特家族。

Abstract: Fluorescent spin qubits are central building blocks of quantum technologies. Placing these qubits at surfaces maximizes coupling to nearby spins and fields, enabling nanoscale sensing and facilitating integration with photonic and superconducting devices. However, reducing the dimensions or size of established qubit systems without sacrificing the qubit performance or degrading the coherence lifetime remains challenging. Here, we introduce a surface molecular qubit formed by pentacene molecules scaffolded on a two-dimensional (2D) material, hexagonal boron nitride (hBN). The qubit exhibits stable fluorescence and optically detected magnetic resonance (ODMR) from cryogenic to ambient conditions. With fully deuterated pentacene, the Hahn-echo coherence reaches 22 $μ$s and further extends to 214 $μ$s under dynamical decoupling, outperforming state-of-the-art shallow NV centers in diamond, despite being positioned directly on the surface. We map the local spin environment, resolving couplings to nearby nuclear and electron spins that can serve as auxiliary quantum resources. This platform combines true surface integration, long qubit coherence, and scalable fabrication, opening routes to quantum sensing, quantum simulation, and hybrid quantum devices. It also paves the way for a broader family of 2D material-supported molecular qubits.

</details>


### [42] [The superradiant phase is a finite size effect in two-photon processes](https://arxiv.org/abs/2601.19986)
*Fabrizio Ramírez,David Villaseñor,Nahum Vázquez,Jorge G. Hirsch*

Main category: quant-ph

TL;DR: 两光子Dicke模型中的超辐射相并非真正的热力学相，而是有限尺寸效应，在热力学极限下消失。


<details>
  <summary>Details</summary>
Motivation: 澄清两光子系统中超辐射相的本质，避免对其在量子应用中的错误理解与实现。

Method: 结合解析分析和数值分析，研究系统尺寸增大时超辐射区域的变化行为。

Result: 随着系统尺寸增加，超辐射区域缩小，并在热力学极限下消失，而谱塌缩现象仍然存在。

Conclusion: 两光子Dicke模型中的超辐射相是有限尺寸效应，不是真实的热力学相，限制了其在量子平台中的实际应用。

Abstract: Two-photon light-matter interactions exhibit distinctive features such as spectral collapse. The two-photon Dicke model has been reported to exhibit a superradiant phase which could be useful in quantum applications. Here we show that this superradiant phase is not a genuine thermodynamic phase but a finite-size effect. Combining analytical and numerical analyses, we demonstrate that the superradiant region shrinks with increasing system size and disappears in the thermodynamic limit, while spectral collapse remains. Our results clarify the nature of superradiant conditions in two-photon systems and constrain its realization in quantum platforms.

</details>


### [43] [Optically Addressable Molecular Spins at 2D Surfaces](https://arxiv.org/abs/2601.19988)
*Xuankai Zhou,Yan-Tung Kong,Cheuk Kit Cheung,Guodong Bian,Reda Moukaouine,King Cho Wong,Yumeng Sun,Cheng-I Ho,Vladislav Bushmakin,Nils Gross,Chun-Chieh Yen,Tim Priessnitz,Malik Lenger,Sreehari Jayaram,Takashi Taniguchi,Kenji Watanabe,Anton Pershin,Ruoming Peng,Ádám Gali,Jurgen Smet,Jörg Wrachtrup*

Main category: quant-ph

TL;DR: 该研究通过将自旋活性分子锚定在六方氮化硼（hBN）表面，构建了一种新型的分子-二维材料杂化结构，实现了直接位于表面的量子自旋传感器，具备长相干时间、光学可寻址性和界面多功能性。


<details>
  <summary>Details</summary>
Motivation: 实现具有原子分辨率和量子极限灵敏度的表面量子传感，克服传统量子自旋传感器因埋藏深度限制而导致性能下降的问题。

Method: 将自旋活性分子锚定在六方氮化硼（hBN）表面，形成杂化分子-2D结构，并通过化学 deuteration 调控分子以延长自旋相干时间，在4 K至室温范围内表征其自旋性质，结合动态解耦技术提升相干寿命。

Result: Hahn-echo 自旋相干时间在4 K时超过3.4微秒，经deuteration后提升10倍以上，动态解耦下达到300微秒以上；实现了在室温下对邻近质子自旋和hBN下方二维磁体磁响应的探测。

Conclusion: 该工作展示了可在表面稳定存在的高性能量子自旋传感器，突破了传统体系中接近表面导致自旋性能退化的限制，为可扩展、可调的量子传感架构提供了新路径。

Abstract: Optically addressable spins at material surfaces have represented a long-standing ambition in quantum sensing, providing atomic resolution and quantum-limited sensitivity. However, they are constrained by a finite depth at which the quantum spins can be stabilized. Here, we demonstrate a hybrid molecular-2D architecture that realizes quantum spin sensors directly on top of the surface. By anchoring spin-active molecules onto hexagonal boron nitride (hBN), we eliminate the depth of the quantum sensor while also exhibiting robust spin properties from 4~K to room temperature (RT). The Hahn-echo spin coherence time exceeds \(T_2 = 3.4~\upmu\text{s}\) at 4~K, outperforming values in bulk organic crystals and overturning the prevailing expectation that spin inevitably deteriorates upon approaching the surface. By chemically tuning the molecule through deuteration, \(T_2\) improves by more than 10-fold, and under dynamic decoupling, coherence is prolonged to the intrinsic lifetime limit, exceeding 300~\(\upmu\text{s}\). Proximal proton spins and the magnetic response of two-dimensional magnets beneath the hBN layer have been detected at RT. These molecular spins form surface quantum sensors with long coherence, optical addressability, and interfacial versatility, enabling a scalable, adaptable architecture beyond what conventional solid-state platforms offer.

</details>


### [44] [Alternating ZX Circuit Extraction for Hardware-Adaptive Compilation](https://arxiv.org/abs/2601.20007)
*Ludwig Schmid,Korbinian Staudacher,Robert Wille*

Main category: quant-ph

TL;DR: 提出了一种结合图状ZX图与硬件自适应路由的新型量子电路提取方案，通过反馈循环优化提取过程，并支持模块化集成，适用于多种硬件平台。


<details>
  <summary>Details</summary>
Motivation: 为了更高效地将ZX图转换为符合硬件约束的量子电路，充分利用提取过程中的自由度，提升量子编译的灵活性和性能。

Method: 该方法在ZX图到量子电路的提取过程中交替生成多种提取选项，并根据硬件限制进行评估，引入路由算法指导提取，形成反馈循环，支持不同提取算法、路由策略和目标硬件的模块化集成。

Result: 实现了基于SWAP路由的中性原子硬件参考实例，在多个基准电路上进行了小到中等规模的数值评估，结果验证了该方案的有效性和通用性。

Conclusion: 该提取方案扩展了现有的图状ZX提取方法，具有良好的可扩展性和开放性，可作为量子编译中的通用构建模块，推动后续研究发展。

Abstract: We present a novel quantum circuit extraction scheme that tightly integrates graph-like ZX diagrams with hardware-adaptive routing. The method utilizes the degrees of freedom during the conversion from a ZX diagram to a quantum circuit (extraction). It alternates between generating multiple extraction options and evaluating them based on hardware constraints, allowing the routing algorithm to inform and guide the extraction process. This feedback loop extends existing graph-like ZX extraction and supports modular integration of different extraction algorithms, routing strategies, and target hardware, making it a versatile building block during compilation. To perform numerical evaluations, a reference instance of the scheme is implemented with SWAP-based routing for neutral atom hardware and evaluated using various benchmark collections on small-to mid-scale circuits. The reference code is available as open-source, allowing fast integration of other extraction and/or routing tools to stimulate further research and foster improvements of the proposed scheme.

</details>


### [45] [Foundry-Enabled Patterning of Diamond Quantum Microchiplets for Scalable Quantum Photonics](https://arxiv.org/abs/2601.20025)
*Jawaher Almutlaq,Alessandro Buzzi,Anders Khaykin,Linsen Li,William Yzaguirre,Maxim Sirotin,Gerald Gilbert,Genevieve Clark,Dirk Englund*

Main category: quant-ph

TL;DR: 提出了一种可扩展的制造方法，通过商用半导体代工厂制备硅掩模并利用微转移印刷技术将其转移到钻石上，实现了高性能钻石量子微芯片的大规模生产。


<details>
  <summary>Details</summary>
Motivation: 构建大规模量子系统面临制造难题，尤其是在钻石中加工纳米光学结构的传统方法效率低、难以扩展。

Method: 采用商用半导体代工厂制造高精度硅掩模，通过微转移印刷技术将掩模转移到钻石基底上，实现大批量、高均匀性的纳米光学结构加工。

Result: 成功制备了数百个具有优良光学性能的钻石量子微芯片，并展示了与量子发射器的可控相互作用，提升了器件良率和集成能力。

Conclusion: 该方法实现了与现有半导体制造基础设施兼容的高质量钻石量子器件规模化生产，为大规模量子光子系统和混合量子-经典技术提供了可行路径。

Abstract: Quantum technologies promise secure communication networks and powerful new forms of information processing, but building these systems at scale remains a major challenge. Diamond is an especially attractive material for quantum devices because it can host atomic-scale defects that emit single photons and store quantum information with exceptional stability. However, fabricating the optical structures needed to control light in diamond typically relies on slow, bespoke processes that are difficult to scale. In this work, we introduce a manufacturing approach that brings diamond quantum photonics closer to industrial production. Instead of sequentially defining each device by lithography written directly on diamond, we fabricate high-precision silicon masks using commercial semiconductor foundries and transfer them onto diamond via microtransfer printing. These masks define large arrays of nanoscale optical structures, shifting the most demanding pattern-definition steps away from the diamond substrate, improving uniformity, yield, and throughput. Using this method, we demonstrate hundreds of diamond "quantum microchiplets" with improved optical performance and controlled interaction with quantum emitters. The chiplet format allows defective devices to be replaced and enables integration with existing photonic and electronic circuits. Our results show that high-quality diamond quantum devices can be produced using scalable, foundry-compatible techniques. This approach provides a practical pathway toward large-scale quantum photonic systems and hybrid quantum-classical technologies built on established semiconductor manufacturing infrastructure.

</details>


### [46] [A Cyclic Layerwise QAOA Training](https://arxiv.org/abs/2601.20029)
*Enhyeok Jang,Zihan Chen,Dongho Ha,Seungwoo Choi,Yongju Lee,Jaewon Kwon,Eddy Z. Zhang,Yipeng Huang,Won Woo Ro*

Main category: quant-ph

TL;DR: 本文提出了一种名为Orbit-QAOA的新方法，用于高效训练多角度量子近似优化算法（MA-QAOA），通过循环更新和选择性冻结稳定参数，在减少训练开销的同时保持与标准MA-QAOA相当的近似性能。


<details>
  <summary>Details</summary>
Motivation: 为了在提升MA-QAOA表达能力的同时降低经典计算开销，并解决现有分层训练方法因参数固定导致精度下降的问题。

Method: 分析不同参数更新粒度对训练效率的影响，提出Orbit-QAOA：按层循环更新并根据梯度变化选择性重训和冻结参数。

Result: Orbit-QAOA在多种图基准上最多减少81.8%的训练步数，近似比误差最多降低72倍，且性能与标准MA-QAOA相当。

Conclusion: 按完整层为单位进行周期性更新并结合梯度监控的选择性重训策略，可有效平衡训练效率与最终解的质量，是MA-QAOA高效训练的可行方案。

Abstract: The quantum approximate optimization algorithm (QAOA) is a hybrid quantum-classical algorithm for solving combinatorial optimization problems. Multi-angle QAOA (MA-QAOA), which assigns independent parameters to each Hamiltonian operator term, achieves superior approximation performance even with fewer layers than standard QAOA. Unfortunately, this increased expressibility can raise the classical computational cost due to a greater number of parameters. The recently proposed Layerwise MA-QAOA (LMA-QAOA) reduces this overhead by training one layer at a time, but it may suffer from obtaining the precise solution due to the previously fixed parameters. This work addresses two questions for efficient MA-QAOA training: (i) What is the optimal granularity for parameter updates per epoch, and (ii) How can we get precise final cost function results while only partially updating the parameters per epoch? Despite the benefit of reducing the parameters that update per epoch can reduce the classical computation overhead, too fine or coarse a granularity of Hamiltonian update can degrade the MA-QAOA training efficiency. We find that optimizing one complete layer per epoch is an efficient granularity. Moreover, selectively retraining each layer by tracking gradient variations can achieve a final cost function equivalent to the standard MA-QAOA while lowering the parameter update overhead. Based on these insights, we propose Orbit-QAOA, which cyclically revisits layers and selectively freezes stabilized parameters. Across diverse graph benchmarks, Orbit-QAOA reduces training steps by up to 81.8%, reduces approximation ratio error by up to 72x compared to the unified stop condition-applied enhanced LMA-QAOA, and achieves equivalent approximation performance compared to the standard MA-QAOA.

</details>


### [47] [Time complexity of a monitored quantum search with resetting](https://arxiv.org/abs/2601.20560)
*Emma C. King,Sayan Roy,Francesco Mattiotti,Maximilian Kiefer-Emmanouilidis,Markus Bläser,Giovanna Morigi*

Main category: quant-ph

TL;DR: 该论文研究了在反馈机制下连续时间量子行走搜索算法的时间复杂度，发现尽管监测和重置策略可加速收敛，但在考虑物理测量实现的预算时间后，总体搜索时间仍无法超越Grover算法的最优界限。


<details>
  <summary>Details</summary>
Motivation: 探索在引入反馈（如持续监测和状态重置）的情况下，量子搜索算法是否能够突破Grover算法的二次加速极限。

Method: 采用连续时间量子行走模型，在完全图上进行搜索，目标节点被探测器持续监测，并在未检测到时进行量子态重置，从而构建非幺正、非马尔可夫动力学过程，并优化搜索时间与跳跃幅度、检测率和重置率的关系。

Result: 数值结果表明，反馈机制可在有限规模数据库中加快收敛速度，但在计入测量实现所需时间后，总搜索时间仍满足Grover下界，无法实现超Grover加速。

Conclusion: Grover算法的时间复杂度在包含物理测量开销后仍是不可突破的，但反馈驱动的监测策略为容错量子搜索提供了可行路径。

Abstract: Searching a database is a central task in computer science and is paradigmatic of transport and optimization problems in physics. For an unstructured search, Grover's algorithm predicts a quadratic speedup, with the search time $τ(N)=Θ(\sqrt{N})$ and $N$ the database size. Numerical studies suggest that the time complexity can change in the presence of feedback, injecting information during the search. Here, we determine the time complexity of the quantum analog of a randomized algorithm, which implements feedback in a simple form. The search is a continuous-time quantum walk on a complete graph, where the target is continuously monitored by a detector. Additionally, the quantum state is reset if the detector does not click within a specified time interval. This yields a non-unitary, non-Markovian dynamics. We optimize the search time as a function of the hopping amplitude, detection rate, and resetting rate, and identify the conditions under which time complexity could outperform Grover's scaling. The overall search time does not violate Grover's optimality bound when including the time budget of the physical implementation of the measurement. For databases of finite sizes monitoring can warrant rapid convergence and provides a promising avenue for fault-tolerant quantum searches.

</details>


### [48] [Comment on "Determining angle of arrival of radio-frequency fields using subwavelength, amplitude-only measurements of standing waves in a Rydberg atom sensor"](https://arxiv.org/abs/2601.20062)
*M. Chilcott,N. Kjærgaard*

Main category: quant-ph

TL;DR: 本文讨论了在光学EIT方案中探测场致缀饰里德堡系统时，忽略子态间允许的射频跃迁对预测光谱的影响。


<details>
  <summary>Details</summary>
Motivation: 研究场致缀饰里德堡系统中射频跃迁在光谱预测中的作用，以提高理论模型的准确性。

Method: 通过理论分析光学EIT探测方案，考察忽略允许RF跃迁对光谱结果的影响。

Result: 发现忽略这些跃迁会导致预测光谱与实际观测之间存在显著偏差。

Conclusion: 在建模和预测场致缀饰里德堡系统的光谱时，必须考虑所有允许的RF跃迁以确保准确性。

Abstract: We discuss the consequence of excluding allowed RF-transition between substates of a field-dressed Rydberg manifold when predicting the spectrum that will be observed if the dressed system is probed in an optical EIT scheme.

</details>


### [49] [Ensemble-Based Quantum Signal Processing for Error Mitigation](https://arxiv.org/abs/2601.20073)
*Suying Liu,Yulong Dong,Dong An,Murphy Yuezhen Niu*

Main category: quant-ph

TL;DR: 提出了一种抗噪声的量子信号处理（QSP）框架，通过集成噪声QSP电路和测量平均来抑制相干误差，无需增加电路深度或辅助量子比特，适用于哈密顿量模拟、量子线性系统和基态制备等应用。


<details>
  <summary>Details</summary>
Motivation: 量子硬件中的噪声，尤其是累积的随机相干误差，是当前量子算法部署的主要障碍，亟需不增加资源开销的误差缓解方案。

Method: 利用噪声QSP电路的集成与测量层面的平均，抑制Z旋转中的随机相位误差，构建鲁棒的QSP算法。

Result: 实现了多项式函数和可观测量的稳健实现，分析了逼近误差与硬件噪声之间的权衡，验证了在深度和相干时间受限条件下的实用性。

Conclusion: 该框架为将误差缓解无缝集成到算法设计中提供了实用路径，推动了近期和中期量子设备上的科学应用发展。

Abstract: Despite rapid advances in quantum hardware, noise remains a central obstacle to deploying quantum algorithms on near-term devices. In particular, random coherent errors that accumulate during circuit execution constitute a dominant and fundamentally challenging noise source. We introduce a noise-resilient framework for Quantum Signal Processing (QSP) that mitigates such coherent errors without increasing circuit depth or ancillary qubit requirements. Our approach uses ensembles of noisy QSP circuits combined with measurement-level averaging to suppress random phase errors in Z rotations. Building on this framework, we develop robust QSP algorithms for implementing polynomial functions of Hermitian matrices and for estimating observables, with applications to Hamiltonian simulation, quantum linear systems, and ground-state preparation. We analyze the trade-off between approximation error and hardware noise, which is essential for practical implementation under the stringent depth and coherence constraints of current quantum hardware. Our results establish a practical pathway for integrating error mitigation seamlessly into algorithmic design, advancing the development of robust quantum computing, and enabling the discovery of scientific applications with near- and mid-term quantum devices.

</details>


### [50] [Local Distinguishability of Multipartite Orthogonal Quantum States: Generalized and Simplified](https://arxiv.org/abs/2601.20074)
*Ian George,Mohammad A. Alhejji*

Main category: quant-ph

TL;DR: 本文将Walgate等人在有限维中关于正交纯多体量子态可由一方式局域操作和经典通信（LOCC）完美区分的结果推广至无限维，并给出了更简洁的证明；进一步构造了一个多项式时间算法来明确指定该协议，且建立了该结果与量子信道一次性环境辅助经典容量之间的等价性。


<details>
  <summary>Details</summary>
Motivation: 扩展Walgate等人在有限维下的正交纯态可由一方式LOCC完美区分的结果到无限维情形，并加强其构造性与应用联系。

Method: 利用迹为零的算子存在全零对角线基这一核心事实，结合线性代数与量子信息理论方法，给出简化证明并设计高效算法。

Result: 1. 将Walgate定理推广至无限维；2. 构造了运行时间为O(d_A²d_B²)的算法以显式给出完美一方式LOCC区分协议；3. 建立了该区分结果与量子信道一-shot环境辅助经典容量至少为1比特之间的等价性。

Conclusion: 迹为零算子的结构性质是理解多体量子态可区分性与环境辅助经典容量之间深层联系的核心，本文统一并强化了相关理论结果。

Abstract: In a seminal work [PRL85.4972], Walgate, Short, Hardy, and Vedral prove in finite dimensions that for every pair of pure multipartite orthogonal quantum states, there exists a one-way local operations and classical communication (LOCC) protocol that perfectly distinguishes the pair. We extend this result to infinite dimensions with a simpler proof. For states on $\mathbb{C}^{d_A \times d_A} \otimes \mathbb{C}^{d_B \times d_B}$, we strengthen this existence result by constructing an $O(d_A^2 d_B^2)$-time algorithm that specifies such a perfect one-way LOCC protocol. Finally, we establish the equivalence between Walgate et al.'s result and the fact that the one-shot environment-assisted classical capacity of every quantum channel is at least 1 bit per channel use, thereby clarifying the literature on these notions. At the core of all of these results is the fact that every operator with vanishing trace admits a basis where its diagonal entries are all zero.

</details>


### [51] [Spectral Transitions and Singular Continuous Spectrum in A New Family of Quasi-periodic Quantum Walks](https://arxiv.org/abs/2601.20081)
*Xinyu Yang,Long Li,Qi Zhou*

Main category: quant-ph

TL;DR: 本文提出并严格分析了一类新的由扩展CMV矩阵控制动力学的一维离散时间量子行走模型，推广了酉几乎Mathieu算子，展现出更丰富的谱相图，并首次实现了具有稳定奇异连续谱区域的可解准周期量子行走。


<details>
  <summary>Details</summary>
Motivation: 为了探索更复杂的量子行走行为及其谱特性，研究者希望构造一个能够展示丰富谱相图且具备解析可解性的新模型。

Method: 通过引入一类参数化的扩展CMV矩阵来定义量子行走的演化，并结合准周期系统中的谱理论进行严格数学分析。

Result: 该模型推广了酉几乎Mathieu算子，其谱相图类似于扩展Harper模型，并首次发现了一个稳定的纯奇异连续谱区域。

Conclusion: 该工作为理解准周期量子行走的谱性质提供了新范式，揭示了奇异连续谱的稳定性，具有重要的理论意义。

Abstract: This paper introduces and rigorously analyzes a new class of one-dimensional discrete-time quantum walks whose dynamics are governed by a parametrized family of extended CMV matrices. The model generalizes the unitary almost Mathieu operator (UAMO) and exhibits a richer spectral phase diagram, closely resembling the extended Harper's model. It provides the first example of a solvable quasi-periodic quantum walk that exhibits a stable region of purely singular continuous spectrum.

</details>


### [52] [Krypton-sputtered tantalum films for scalable high-performance quantum devices](https://arxiv.org/abs/2601.20091)
*Maciej W. Olszewski,Lingda Kong,Simon Reinhardt,Daniel Tong,Xinyi Du,Gabriele Di Gianluca,Haoran Lu,Saswata Roy,Luojia Zhang,Aleksandra B. Biedron,David A. Muller,Valla Fatemi*

Main category: quant-ph

TL;DR: 通过使用氪气溅射在较低温度下制备高性能的体心立方相钽薄膜，实现了与后端半导体工艺兼容的高导电性和高品质因子超导量子比特。


<details>
  <summary>Details</summary>
Motivation: 解决传统高温沉积钽薄膜不兼容标准半导体制造工艺的问题，实现可扩展的超导量子计算器件 fabrication。

Method: 采用氪气（Kr）替代氩气（Ar）作为溅射气体，在低至200°C的温度下沉积钽薄膜于硅基底上，并通过传输电子显微镜和共面波导谐振器测量表征其结构与微波性能。

Result: 在250°C和350°C沉积的薄膜表现出优异且集中的微波性能；低温生长的薄膜具有更高的电子导电性，接近洁净极限超导；横截面透射电镜显示高温下出现明显的Ta/Si互扩散并导致损耗增加；基于该薄膜制备的transmon量子比特在20微米电容间隙下达到中位品质因子高达1400万。

Conclusion: 使用Kr溅射可在低温下实现高质量BCC相钽薄膜，兼具优良微波性能和工艺兼容性，为大规模集成超导量子电路提供了可行路径。

Abstract: Superconducting qubits based on tantalum (Ta) thin films have demonstrated the highest-performing microwave resonators and qubits. This makes Ta an attractive material for superconducting quantum computing applications, but, so far, direct deposition has largely relied on high substrate temperatures exceeding \SI{400}{\celsius} to achieve the body-centered cubic phase, BCC (\textalpha-Ta). This leads to compatibility issues for scalable fabrication leveraging standard semiconductor fabrication lines. Here, we show that changing the sputter gas from argon (Ar) to krypton (Kr) promotes BCC Ta synthesis on silicon (Si) at temperatures as low as \SI{200}{\celsius}, providing a wide process window compatible with back-end-of-the-line fabrication standards. Furthermore, we find these films to have substantially higher electronic conductivity, consistent with clean-limit superconductivity. We validated the microwave performance through coplanar waveguide resonator measurements, finding that films deposited at \SI{250}{\celsius} and \SI{350}{\celsius} exhibit a tight performance distribution at the state of the art. Higher temperature-grown films exhibit higher losses, in correlation with the degree of Ta/Si intermixing revealed by cross-sectional transmission electron microscopy. Finally, with these films, we demonstrate transmon qubits with a relatively compact, \SI{20}{\micro\meter} capacitor gap, achieving a median quality factor up to 14 million.

</details>


### [53] [Engineering the non-Hermitian SSH model with skin effects in Rydberg atom arrays](https://arxiv.org/abs/2601.20114)
*J. N. Bai,F. Yang,D. Yan,Weibin Li,X. Q. Shao*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose and systematically analyze a practical scheme for implementing a one-dimensional non-Hermitian Su-Schrieffer-Heeger model using individually addressable Rydberg atom arrays. Our setup consists of an atomic chain with three-atom unit cells, in which a synthetic gauge field is generated by applying multi-color laser fields. By engineering fast dissipative channels for one auxiliary atom in each unit cell, the adiabatic elimination effectively gives rise to a non-Hermitian skin effect. We examine how fluctuations in the experimental parameters influence both the skin effect and the topological invariant under open and periodic boundary conditions in real space and find that both features remain highly robust. This work establishes a versatile, controllable, and programmable open-system quantum simulator with neutral atoms, providing a clear route for exploring rich non-Hermitian topological phenomena.

</details>


### [54] [Universal thermodynamic implementation of a process with a variable work cost](https://arxiv.org/abs/2601.20155)
*Philippe Faist*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The minimum amount of thermodynamic work required in order to implement a quantum computation or a quantum state transformation can be quantified using frameworks based on the resource theory of thermodynamics, deeply rooted in the works of Landauer and Bennett. For instance, the work we need to invest in order to implement $n$ independent and identically distributed (i.i.d.) copies of a quantum channel is quantified by the thermodynamic capacity of the channel when we require the implementation's accuracy to be guaranteed in diamond norm over the $n$-system input. Recent work showed that work extraction can be implemented universally, meaning the same implementation works for a large class of input states, while achieving a variable work cost that is optimal for each individual i.i.d. input state. Here, we revisit some techniques leading to derivation of the thermodynamic capacity, and leverage them to construct a thermodynamic implementation of $n$ i.i.d. copies of any time-covariant quantum channel, up to some process decoherence that is necessary because the implementation reveals the amount of consumed work. The protocol uses so-called thermal operations and achieves the optimal per-input work cost for any i.i.d. input state; it relies on the conditional erasure protocol in our earlier work, adjusted to yield variable work. We discuss the effect of the work-cost decoherence. While it can significantly corrupt the correlations between the output state and any reference system, we show that for any time-covariant i.i.d. input state, the state on the output system faithfully reproduces that of the desired process to be implemented. As an immediate consequence of our results, we recover recent results for optimal work extraction from i.i.d. states up to the error scaling and implementation specifics, and propose an optimal preparation protocol for time-covariant i.i.d. states.

</details>


### [55] [Contextuality as an Information-Theoretic Obstruction to Classical Probability](https://arxiv.org/abs/2601.20167)
*Song-Ju Kim*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Contextuality is a central feature distinguishing quantum from classical probability theories, yet its operational meaning remains subject to interpretation. We reconsider contextuality from an information-theoretic perspective, focusing on operational models constrained to maintain a single internal state with fixed semantics across multiple contexts. Under this constraint, we show that contextual statistics certify an unavoidable obstruction to classical probabilistic descriptions. Specifically, any classical model that reproduces such statistics must either embed contextual dependence into the internal state or introduce additional external labels carrying nonzero information. This result identifies contextuality as a witness of irreducible information cost in classical representations, rather than as a purely nonclassical anomaly. From this viewpoint, quantum probability emerges as a canonical framework that accommodates contextual operations without requiring explicit contextual encoding.

</details>


### [56] [A general interpretation of nonlinear connected time crystals: quantum self-sustaining combined with quantum synchronization](https://arxiv.org/abs/2601.20186)
*Song-hai Li,Najmeh Es'haqi-Sani,Xingli Li,Wenlin Li*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Although classical nonlinear dynamics suggests that sufficiently strong nonlinearity can sustain oscillations, quantization of such model typically yields a time-independent steady state that respects time-translation symmetry and thus precludes time-crystal behavior. We identify dephasing as the primary mechanism enforcing this symmetry, which can be suppressed by intercomponent phase correlations. Consequently, a sufficient condition for realizing a continuous time crystal is a nonlinear quantum self-sustaining system exhibiting quantum synchronization among its constituents. As a concrete example, we demonstrate spontaneous oscillations in a synchronized array of van der Pol oscillators, corroborated by both semiclassical dynamics and the quantum Liouville spectrum. These results reduce the identification of time crystals in many-body systems to the evaluation of only two-body correlations and provide a framework for classifying uncorrelated time crystals as trivial.

</details>


### [57] [Fast state transfer via loop weights](https://arxiv.org/abs/2601.20237)
*Gabor Lippner,Yujia Shi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We prove that almost-linear-time high-fidelity state transfer is achievable in a quantum spin chain using loop weights at the second and second-to-last nodes. We provide specific parameter values, and using a careful analysis of the eigenvectors we make precise quantitative estimates of the transfer time and strength.

</details>


### [58] [Computer Science Challenges in Quantum Computing: Early Fault-Tolerance and Beyond](https://arxiv.org/abs/2601.20247)
*Jens Palsberg,Jason Cong,Yufei Ding,Bill Fefferman,Moinuddin Qureshi,Gokul Subramanian Ravi,Kaitlin N. Smith,Hanrui Wang,Xiaodi Wu,Henry Yuen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum computing is entering a period in which progress will be shaped as much by advances in computer science as by improvements in hardware. The central thesis of this report is that early fault-tolerant quantum computing shifts many of the primary bottlenecks from device physics alone to computer-science-driven system design, integration, and evaluation. While large-scale, fully fault-tolerant quantum computers remain a long-term objective, near- and medium-term systems will support early fault-tolerant computation with small numbers of logical qubits and tight constraints on error rates, connectivity, latency, and classical control. How effectively such systems can be used will depend on advances across algorithms, error correction, software, and architecture. This report identifies key research challenges for computer scientists and organizes them around these four areas, each centered on a fundamental question.

</details>


### [59] [A Quantum Photonic Approach to Graph Coloring](https://arxiv.org/abs/2601.20263)
*Jesua Epequin,Pascale Bendotti,Joseph Mikael*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Gaussian Boson Sampling (GBS) is a quantum computational model that leverages linear optics to solve sampling problems believed to be classically intractable. Recent experimental breakthroughs have demonstrated quantum advantage using GBS, motivating its application to real-world combinatorial optimization problems.
  In this work, we reformulate the graph coloring problem as an integer programming problem using the independent set formulation. This enables the use of GBS to identify cliques in the complement graph, which correspond to independent sets in the original graph. Our method is benchmarked against classical heuristics and exact algorithms on two sets of instances: Erdős-Rényi random graphs and graphs derived from a smart-charging use case. The results demonstrate that GBS can provide competitive solutions, highlighting its potential as a quantum-enhanced heuristic for graph-based optimization.

</details>


### [60] [Fingerprints of classical memory in quantum hysteresis](https://arxiv.org/abs/2601.20287)
*Francesco Caravelli*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a simple framework for classical and quantum ``memory'' in which the Hamiltonian at time $t$ depends on past values of a control Hamiltonian through a causal kernel. This structure naturally describes finite-bandwidth or filtered control channels and provides a clean way to distinguish between memory in the control and genuine non-Markovian dynamics of the state. We focus on models where $H(t)=H_0+\int_{-\infty}^{t}K(t-s)\,H_1(s)\,ds$, and illustrate the framework on single-qubit examples such as $H(t)=σ_z+Φ(t)σ_x$ with $Φ(t)=\int_{-\infty}^{t}K(t-s)\,u(s)\,ds$. We derive basic properties of such dynamics, discuss conditions for unitarity, give an equivalent time-local description for exponential kernels, and show explicitly how hysteresis arises in the response of a driven qubit.

</details>


### [61] [Electromagnetically Induced Transparency Spectra of Ladder Four-Level System with Quantum Frequency Mixing](https://arxiv.org/abs/2601.20296)
*Sheng-Xian Xiao,Tao Wang*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In this paper, we generalized the quantum frequency mixing technology to a ladder-type four-level system and studied its effect on electromagnetically induced transparency spectra. We found a secondary splitting of Autler-Townes splitting in the probing field transmission spectra, which could be understood by the effective Hamiltonian derived with multi-mode Floquet theory. The Frequency mixing scheme developed here enables continuous tunablity of the resonant frequency between upper levels, which facilitates the broad band sensing of AC field. Furthermore, by introducing an additional periodic driving, we realize an effective model that two distinct quantum interference effects coexist: interference among Floquet channels and loop interference arising from closed coherent pathways. Both interference effects could be read out from the transmission spectra independently. The changing of the distance between double splitting peaks represents the interference of Floquet channels, while their asymmetric linewidth broadening is linked with the total effective phase of the loop. This not only provides complementary readout for extracting the phase of AC field, but also establishes a new paradigm for coherent control in multi-level quantum systems.

</details>


### [62] [Scalable Multi-QPU Circuit Design for Dicke State Preparation: Optimizing Communication Complexity and Local Circuit Costs](https://arxiv.org/abs/2601.20393)
*Ziheng Chen,Junhong Nie,Xiaoming Sun,Jialin Zhang,Jiadong Zhu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Preparing large-qubit Dicke states is of broad interest in quantum computing and quantum metrology. However, the number of qubits available on a single quantum processing unit (QPU) is limited -- motivating the distributed preparation of such states across multiple QPUs as a practical approach to scalability. In this article, we investigate the distributed preparation of $n$-qubit $k$-excitation Dicke states $D(n,k)$ across a general number $p$ of QPUs, presenting a distributed quantum circuit (each QPU hosting approximately $\lceil n/p \rceil$ qubits) that prepares the state with communication complexity $O(p \log k)$, circuit size $O(nk)$, and circuit depth $O\left(p^2 k + \log k \log (n/k)\right)$. To the best of our knowledge, this is the first construction to simultaneously achieve logarithmic communication complexity and polynomial circuit size and depth. We also establish a lower bound on the communication complexity of $p$-QPU distributed state preparation for a general target state. This lower bound is formulated in terms of the canonical polyadic rank (CP-rank) of a tensor associated with the target state. For the special case $p = 2$, we explicitly compute the CP-rank corresponding to the Dicke state $D(n,k)$ and derive a lower bound of $\lceil\log (k + 1)\rceil$, which shows that the communication complexity of our construction matches this fundamental limit.

</details>


### [63] [Network Nonlocality Sharing in Generalized Star Network from Bipartite Bell Inequalities](https://arxiv.org/abs/2601.20403)
*Hao-Miao Jiang,Xiang-Jiang Chen,Liu-Jun Wang,Qing Chen*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work investigates network nonlocality sharing for a broad class of bipartite Bell inequalities in a generalized star network with an $(n,m,k)$ configuration, comprising $n$ independent branches, $m$ sequential Alices per branch, and $k$ measurement settings per party. On each branch, the intermediate Alices implement optimal weak measurements, whereas the final Alice and the central Bob perform sharp projective measurements. Network nonlocality sharing is witnessed when the quantum values of the network correlations associated with relevant parties simultaneously violate a star-network Bell inequality generated from the given class of bipartite Bell inequalities. We streamline the calculation of the quantum values of the network correlations and derive an analytical expression for the bipartite quantum correlator, valid for arbitrary measurement settings and weak-measurement strengths. The network nonlocality sharing for Vértesi inequalities has been studied within the framework, and simultaneous violations are found in $(2,2,6)$ and $(2,2,465)$ cases, with the latter exhibiting greater robustness. Our approach suggests a practical route to studying network nonlocality sharing by utilizing diverse bipartite Bell inequalities beyond the commonly used CHSH-type constructions.

</details>


### [64] [Echo Cross Resonance gate error budgeting on a superconducting quantum processor](https://arxiv.org/abs/2601.20458)
*Travers Ward,Russell P. Rundle,Richard Bounds,Norbert Deak,Gavin Dold,Apoorva Hegde,William Howard,Ailsa Keyser,George B. Long,Benjamin Rogers,Jonathan J. Burnett,Bryn A. Bell*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: High fidelity quantum operations are key to enabling fault-tolerant quantum computation. Superconducting quantum processors have demonstrated high-fidelity operations, but on larger devices there is commonly a broad distribution of qualities, with the low-performing tail affecting near-term performance and applications. Here we present an error budgeting procedure for the native two-qubit operation on a 32-qubit superconducting-qubit-based quantum computer, the OQC Toshiko gen-1 system. We estimate the prevalence of different forms of error such as coherent error and control qubit leakage, then apply error suppression strategies based on the most significant sources of error, making use of pulse-shaping and additional compensating gates. These techniques require no additional hardware overhead and little additional calibration, making them suitable for routine adoption. An average reduction of 3.7x in error rate for two qubit operations is shown across a chain of 16 qubits, with the median error rate improving from 4.6$\%$ to 1.2$\%$ as measured by interleaved randomized benchmarking. The largest improvements are seen on previously under-performing qubit pairs, demonstrating the importance of practical error suppression in reducing the low-performing tail of gate qualities and achieving consistently good performance across a device.

</details>


### [65] [Multiple mobility rings in non-Hermitian Su-Schrieffer-Heeger chain with quasiperiodic potentials](https://arxiv.org/abs/2601.20479)
*Guan-Qiang Li,Zhi-Yu Lin,You-Jiao Dong,Ya-Feng Xue,Chun-Yang Ren,Ping Peng*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The localization property of a non-Hermitian Su-Schrieffer-Heeger (SSH) chain with quasi-periodic on-site potential is investigated. In contrast to the preceding investigations, the quantum phase transition between localized state and extended one is achieved by adjusting the strength of intracellular or intercellular hopping. The energy spectra and eigenstate distributions of the system's Hamiltonian near the boundary of the phase transition exhibit different behaviors when the Hermiticity, non-Hermiticity and mosaic modulation of the quasi-periodic potential are considered, respectively. The existence of the mobility ring is revealed in the non-Hermitian SSH chain by studying of the critical behaviors near the boundary. More interestingly, the multiple mobility rings emerge when the period number of the mosaic modulation is increased. The result is helpful for the investigation of the localization-delocalization transition in the SSH-type system under the combined action of the non-Hermiticity and quasi-periodicity.

</details>


### [66] [Will we ever quantize the center of mass of macroscopic systems? A case for a Heisenberg cut in quantum mechanics](https://arxiv.org/abs/2601.20525)
*George E. A. Matsas,Gabriel H. S. Aguiar*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The concept of quantum particles derives from quantum field theory. Accepting that quantum mechanics is valid all the way implies that not only composite particles (such as protons and neutrons) would be derived from a field theory, but also the center of mass of bodies as heavy as rocks. Despite the fabulous success of quantum mechanics, it is unreasonable to assume the existence of annihilation and creation operators for rocks, and so on. Fortunately, there are strong reasons to doubt that wave mechanics can describe the center of mass of systems at or above the Planck scale, thereby jeopardizing the construction of the corresponding Fock space. As a result, systems with masses exceeding the Planck mass would have their center of mass described through classical mechanics, regardless of being able to harbor macroscopic quantum phenomena as observed in the laboratory. Here, we briefly revisit (i) the arguments for the need for a Heisenberg cut delimitating the boundary between the quantum and classical realms and (ii) the kind of new physics expected at (the uncharted region of) the Heisenberg cut.''

</details>


### [67] [Detector's response to coherent Rindler and Minkowski photons](https://arxiv.org/abs/2601.20557)
*Pradeep Kumar Kumawat,Dipankar Barman,Bibhas Ranjan Majhi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We observe that the transition probability in a static two-level quantum detector interacting with a coherent Rindler photon is different from the same of the Rindler detector which is in interaction with a coherent Minkowski photon. Situation does not change in the response of quantum detector for the classical limit of the photon state. This we investigate in $(1+1)$ and $(3+1)$-spacetime dimensions. Interestingly, the transition probabilities of the ``classical'' detector in the classical limit of the photon state in $(1+1)$-dimensions, for these two scenarios, appear to be identical when the frequencies of photon mode and detector are taken to be same. However, our obtained detector's transition probabilities in $(3+1)$-dimensions, which are calculated under the large acceleration condition, do not show such signature. The implications of these observations are discussed as well.

</details>


### [68] [A Hybrid Jump-Diffusion Model for Coherent Optical Control of Quantum Emitters in hBN](https://arxiv.org/abs/2601.20587)
*Saifian Farooq Bhat,Michael K. Koch,Sachin Negi,Alexander Kubanek,Vibhav Bharadwaj*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Hexagonal boron nitride (hBN) has emerged as a promising two-dimensional host for stable single-photon emission owing to its wide bandgap, high photostability, and compatibility with nanophotonic integration. We present a simulation-based study of temperature-dependent spectral dynamics and optical coherence in a mechanically decoupled quantum emitter in hBN. Employing a hybrid stochastic framework that combines Ornstein--Uhlenbeck detuning fluctuations with temperature-dependent, Gaussian-distributed discrete frequency jumps, motivated by experimentally observed spectral diffusion and blinking, we reproduce the measured evolution of inhomogeneous linewidth broadening and the progressive degradation of photon coherence across the relevant cryogenic range (5-30K). The model captures phonon-related spectral diffusion with a cubic temperature dependence and the onset of jump-like spectral instabilities at higher temperatures. By calibrating the hybrid diffusion, jump parameters to the experimentally measured full width at half maximum (FWHM) of the emission line and analyzing the second-order correlation function $g^{(2)}(τ)$ under resonant driving, we establish a unified phenomenological description that links stochastic detuning dynamics to the decay of optical coherence in a resonantly driven emitter. Analysis of $g^{(2)}(τ)$ under resonant driving reveals an additional dephasing rate $γ_{\mathrm{sd+j}}$ that rises monotonically with temperature and drive strength, leading to a predicted critical crossover to overdamped dynamics at $T_{\mathrm{crit}} \approx 25.91$~K. This hybrid framework provides a quantitative connection between accessible spectroscopic observables and the dominant noise mechanisms limiting coherent optical control in mechanically decoupled quantum emitters, exemplified in hBN and generalizable to similar emitters in other materials.

</details>


### [69] [Enhanced quantum parameter estimation based on the Hardy paradox](https://arxiv.org/abs/2601.20602)
*Ming Ji,Yuxiang Yang,Holger F. Hofmann*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Statistical paradoxes such as the Hardy paradox and the enhancement of phase estimation via post-selection both draw upon the same non-classical features of quantum statistics described by non-positive quasi-probabilities. In this paper, we introduce a post-selected quantum metrology scenario where the initial state, the dynamics associated with the phase shift, and the post-selection are all inspired by the Hardy paradox. Specifically, we identify an anomalous weak value that is characteristic of both the Hardy paradox and the potential enhancement of sensitivity by the post-selection. We find that the efficiency of the enhancement is reduced when the expectation value associated with the anomalous weak value is different from the inverse of this value. We conclude that the relation between enhanced phase estimation and the Hardy paradox requires a detailed understanding of the relation between weak values and expectation values.

</details>


### [70] [Foundations of Quantum Optics for Quantum Information: Crash Course on Nonclassical States and Quantum Correlations](https://arxiv.org/abs/2601.20619)
*Jhoan Eusse,Esteban Vasquez,Tom Rivlin,Elizabeth Agudelo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Nonclassical states of light and their correlations lie at the heart of quantum optics, serving as fundamental resources that underpin both the exploration of quantum phenomena and the realisation of quantum information protocols. These lecture notes provide an accessible yet rigorous introduction to the foundations of quantum optics, emphasising their relevance to quantum information science and technology. Starting from the quantisation of the electromagnetic field and the bosonic formalism of Fock space, the notes develop a unified framework for describing and analysing quantum states of light. Key families of states -- thermal, coherent, and squeezed -- are introduced as paradigmatic examples illustrating the transition from classical to nonclassical behaviour. The concepts of convexity, classicality, and quasiprobability representations are presented as complementary tools for characterising quantumness and defining operational notions such as P-nonclassicality. The discussion extends naturally to Gaussian states, composite systems, and continuous-variable entanglement, highlighting how nonclassicality serves as a resource for generating and quantifying quantum correlations. Theoretical developments are complemented by computational and experimental perspectives, including simulations of optical states using the Python library Strawberry Fields and data analysis from simulated data. Together, these notes aim to bridge the foundational concepts of quantum optics and modern quantum information, offering both conceptual insight and practical tools for students and researchers entering the field.

</details>


### [71] [Rydberg Receivers for Space Applications](https://arxiv.org/abs/2601.20631)
*Gianluca Allinson,Mark Bason,Alexis Bonnin,Sebastian Borówka,Petronilo Martin-Iglesias,Manuel Martin Neira,Mateusz Mazelanik,Richard Murchie,Michał Parniak,Sophio Pataraia,Thibaud Ruelle,Sylvain Schwartz,Aaron Strangfeld*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Rydberg-atom sensors convert radiofrequency, microwave and terahertz fields into optical signals with SI-traceable calibration, high sensitivity, and broad tunability. This review assesses their potential for space applications by comparing five general architectures (Autler-Townes, AC-Stark, superheterodyne, radiofrequency-to-optical conversion, and fluorescence) against space application needs. We identify promising roles in radiometry, radar, terahertz sensing, and in-orbit calibration, and outline key limitations, including shot noise, sparse terahertz transitions, and currently large Size, Weight, Power and Cost. A staged roadmap highlights which uncertainties should be resolved first and how research organisations, industry and space agencies could take the lead for the different aspects.

</details>


### [72] [Co-Designed Adaptive Quantum State Preparation Protocols](https://arxiv.org/abs/2601.20681)
*Mafalda Ramôa,Luis Paulo Santos,Nicholas J. Mayhall,Edwin Barnes,Sophia E. Economou*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose a co-designed variant of ADAPT-VQE (Co-ADAPT-VQE) where the quantum hardware is taken into account in the construction of the ansatz. This framework can be readily used to optimize state preparation circuits for any device, addressing shortcomings such as limited connectivity, short coherence times, and variable gate errors. We exemplify the impact of Co-ADAPT-VQE by creating state preparation circuits for devices with linear nearest-neighbor (LNN) connectivity. We show a reduction of the CNOT count of the final circuits by up to 97% for 12-14 qubit systems, with the impact being greater for larger and more strongly correlated systems. Surprisingly, the circuits created by Co-ADAPT-VQE provide an over 70% CNOT count reduction with respect to the original ADAPT-VQE in all-to-all connectivity, despite being restricted to LNN qubit interactions.

</details>


### [73] [Entangled photon pair excitation and time-frequency filtered multidimensional photon correlation spectroscopy as a probe for dissipative exciton kinetics](https://arxiv.org/abs/2601.20700)
*Arunangshu Debnath,Shaul Mukamel*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In molecular aggregates, multiple delocalized exciton states interact with phonons, making the state-resolved spectroscopic monitoring of dynamics challenging. We propose a protocol that combines photon-entanglement-enhanced narrowband excitation of two-exciton states with time-frequency-filtered two-photon coincidence counting. It can alleviate bottlenecks associated with probing exciton dynamics spread across multiple spectral and temporal windows. We demonstrate that non-classical correlations of entangled photon pairs can be used to prepare narrowband two-exciton population distributions, circumventing transport in mediating states. The distributions thus created can be monitored using time-frequency-filtered photon coincidence counting, and the pathways contributing to photon emission events can be classified by tuning filtering parameters. Numerical simulations for a light-harvesting aggregate highlight the ability of this protocol to achieve selectivity by suppressing or amplifying specific pathways. Combining entangled photonic sources and multidimensional photon counting allow promising applications to spectroscopy and sensing.

</details>


### [74] [Spectrum-generating algebra and intertwiners of the resonant Pais-Uhlenbeck oscillator](https://arxiv.org/abs/2601.20752)
*Andreas Fring,Ian Marquette,Takano Taira*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We study the quantum Pais-Uhlenbeck oscillator at the resonant (equal-frequency) point, where the dynamics becomes non-diagonalisable and the conventional Fock-space construction collapses. At the classical level, the degenerate system admits more than one Hamiltonian formulation generating the same equations of motion, leading to a nontrivial quantisation ambiguity. Working first in the ghostly two-dimensional Hamiltonian formulation, we construct differential intertwiners that generate a spectrum-generating algebra acting on the generalised eigenspaces of the Hamiltonian. This algebra organises the generalised eigenvectors into finite Jordan chains and closes into a hidden $su(2)$ Lie algebra that exists only at resonance.
  We then show that quantising a classically equivalent Hamiltonian yields a radically different quantum theory, with a fully diagonalisable spectrum and genuine degeneracies. Our results demonstrate that the resonant Pais-Uhlenbeck oscillator provides a concrete example in which classically equivalent Hamiltonians define inequivalent quantum theories.

</details>


### [75] [Semiclassical effective description of a quantum particle on a sphere with non-central potential](https://arxiv.org/abs/2601.20787)
*Guillermo Chacon-Acosta,H. Hernandez-Hernandez,J. Ruvalcaba-Rascon*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We develop a semiclassical framework for studying quantum particles constrained to curved surfaces using the momentous quantum mechanics formalism, which extends classical phase-space to include quantum fluctuation variables (moments). In a spherical geometry, we derive quantum-corrected Hamiltonians and trajectories that incorporate quantum back-reaction effects absent in classical descriptions. For the free particle, quantum fluctuations induce measurable phase shifts in azimuthal precession of approximately 8-12%, with uncertainty growth rates proportional to initial moment correlations. When a non-central Makarov potential is introduced, quantum corrections dramatically amplify its asymmetry. For strong coupling ($γ$ = -1.9), the quantum-corrected force drives trajectories preferentially toward the southern hemisphere on timescales 40% shorter than classical predictions, with trajectory densities exhibiting up to 3-fold enhancement in the preferred region. Throughout evolution, the solutions rigorously satisfy Heisenberg uncertainty relations, validating the truncation scheme. These results demonstrate that quantum effects fundamentally alter semiclassical dynamics in curved constrained systems, with direct implications for charge transport in carbon nanostructures, exciton dynamics in curved quantum wells, and reaction pathways in cyclic molecules.

</details>


### [76] [Quantum Memory and Autonomous Computation in Two Dimensions](https://arxiv.org/abs/2601.20818)
*Gesa Dünnweber,Georgios Styliaris,Rahul Trivedi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Standard approaches to quantum error correction (QEC) require active maintenance using measurements and classical processing. The possibility of passive QEC has so far only been established in an unphysical number of spatial dimensions. In this work, we present a simple method for autonomous QEC in two spatial dimensions, formulated as a quantum cellular automaton with a fixed, local and translation-invariant update rule. The construction uses hierarchical, self-simulating control elements based on the classical schemes from the seminal results of Gács (1986, 1989) together with a measurement-free concatenated code. We analyze the system under a local noise model and prove a noise threshold below which the logical errors are suppressed arbitrarily with increasing system size and the memory lifetime diverges in the thermodynamic limit. The scheme admits a continuous-time implementation as a time-independent, translation-invariant local Lindbladian with engineered dissipative jump operators. Further, the recursive nature of our protocol allows for the fault-tolerant encoding of arbitrary quantum circuits and thus constitutes a self-correcting universal quantum computer.

</details>


### [77] [Symplectic Optimization on Gaussian States](https://arxiv.org/abs/2601.20832)
*Christopher Willby,Tomohiro Hashizume,Jason Crain,Dieter Jaksch*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Computing Gaussian ground states via variational optimization is challenging because the covariance matrices must satisfy the uncertainty principle, rendering constrained or Riemannian optimization costly, delicate, and thus difficult to scale, particularly in large and inhomogeneous systems. We introduce a symplectic optimization framework that addresses this challenge by parameterizing covariance matrices directly as positive-definite symplectic matrices using unit-triangular factorizations. This approach enforces all physical constraints exactly, yielding a globally unconstrained variational formulation of the bosonic ground-state problem. The unconstrained structure also naturally supports solution reuse across nearby Hamiltonians: warm-starting from previously optimized covariance matrices substantially reduces the number of optimization steps required for convergence in families of related configurations, as encountered in crystal lattices, molecular systems, and fluids. We demonstrate the method on weakly dipole-coupled lattices, recovering ground-state energies, covariance matrices, and spectral gaps accurately. The framework further provides a foundation for large-scale approximate treatments of weakly non-quadratic interactions and offers potential scaling advantages through tensor-network enhancements.

</details>


### [78] [Quantum teleportation in expanding FRW universe](https://arxiv.org/abs/2601.20860)
*Babak Vakili*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the process of quantum teleportation in an expanding universe modeled by Friedmann-Robertson-Walker spacetime, focusing on two cosmologically relevant scenarios: a power-law expansion and the de Sitter universe. Adopting a field-theoretical approach, we analyze the quantum correlations between two comoving observers who share an entangled mode of a scalar field. Using the Bogoliubov transformation, we compute the teleportation fidelity and examine its dependence on the expansion rate, initial entanglement, and the mode frequency. Our findings indicate that spacetime curvature and the underlying cosmological background significantly affect the efficiency of quantum teleportation, particularly through mode mixing and vacuum structure. We also compare our results with the flat Minkowski case to highlight the role of cosmic expansion in degrading or preserving quantum information.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [79] [CM-GAI: Continuum Mechanistic Generative Artificial Intelligence Theory for Data Dynamics](https://arxiv.org/abs/2601.20462)
*Shan Tang,Ziwei Cao,Zhenling Yang,Jiachen Guo,Yicheng Lu,Wing Kam Liu,Xu Guo*

Main category: cs.CE

TL;DR: 提出了一种基于连续介质力学的理论框架，推广了最优输运理论，能够在小数据条件下实现生成任务，在材料、结构和系统层面解决了多个典型工程问题。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺，当前生成式人工智能在专业领域的能力有限，因此需要发展新的理论方法来克服这一限制。

Method: 开发了一种基于连续介质力学的理论框架，推广了纯数学中的最优输运理论，用于描述数据的动力学行为，并在小数据条件下实现生成任务。

Result: 该理论成功应用于材料层次的应力-应变响应生成、结构层次的热载荷下温度依赖应力场生成以及系统层次的瞬态动力加载下塑性应变场生成。此外，该方法在图像生成等其他领域也显示出潜力。

Conclusion: 所提出的理论框架能够在小样本情况下有效完成多种复杂工程问题的生成任务，表明力学可以为计算机科学提供新工具，但也存在一定的局限性。

Abstract: Generative artificial intelligence (GAI) plays a fundamental role in high-impact AI-based systems such as SORA and AlphaFold. Currently, GAI shows limited capability in the specialized domains due to data scarcity. In this paper, we develop a continuum mechanics-based theoretical framework to generalize the optimal transport theory from pure mathematics, which can be used to describe the dynamics of data, realizing the generative tasks with a small amount of data. The developed theory is used to solve three typical problem involved in many mechanical designs and engineering applications: at material level, how to generate the stress-strain response outside the range of experimental conditions based on experimentally measured stress-strain data; at structure level, how to generate the temperature-dependent stress fields under the thermal loading; at system level, how to generate the plastic strain fields under transient dynamic loading. Our results show the proposed theory can complete the generation successfully, showing its potential to solve many difficult problems involved in engineering applications, not limited to mechanics problems, such as image generation. The present work shows that mechanics can provide new tools for computer science. The limitation of the proposed theory is also discussed.

</details>


### [80] [Idea2Story: An Automated Pipeline for Transforming Research Concepts into Complete Scientific Narratives](https://arxiv.org/abs/2601.20833)
*Tengyue Xu,Zhuoyang Qian,Gaoge Liu,Li Ling,Zhentao Zhang,Biao Wu,Shuo Zhang,Ke Lu,Wei Shi,Ziqi Wang,Zheng Feng,Yan Luo,Shu Xu,Yongjin Chen,Zhibo Feng,Zhuo Chen,Bruce Yuan,Harry Wang,Kris Chen*

Main category: cs.CE

TL;DR: Idea2Story是一种基于预计算的自主科学发现框架，通过构建结构化的方法学知识图谱，将文献理解从在线推理转为离线知识构建，从而减少重复计算、缓解上下文窗口限制，并提升科研规划的稳定性与质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型的自主科研系统依赖运行时在线处理大量文献，导致计算成本高、上下文受限、推理脆弱且易产生幻觉，亟需更高效稳定的替代范式。

Method: 提出Idea2Story框架：持续收集已发表论文及其评审反馈，提取核心方法单元，组合成可复用的研究模式，并构建成结构化的方法学知识图谱；在运行时将模糊的用户研究意图匹配到已有研究范式，实现高质量研究模式的高效检索与重用。

Result: 定性分析和初步实证研究表明，Idea2Story能生成连贯、方法严谨且新颖的研究模式，并在端到端场景中产出多个高质量研究示例，显著减少对LLM实时推理的依赖。

Conclusion: 基于离线知识构建的预计算范式为可靠、可扩展的自主科学发现提供了可行基础，有效克服了当前在线推理系统的局限性。

Abstract: Autonomous scientific discovery with large language model (LLM)-based agents has recently made substantial progress, demonstrating the ability to automate end-to-end research workflows. However, existing systems largely rely on runtime-centric execution paradigms, repeatedly reading, summarizing, and reasoning over large volumes of scientific literature online. This on-the-spot computation strategy incurs high computational cost, suffers from context window limitations, and often leads to brittle reasoning and hallucination. We propose Idea2Story, a pre-computation-driven framework for autonomous scientific discovery that shifts literature understanding from online reasoning to offline knowledge construction. Idea2Story continuously collects peer-reviewed papers together with their review feedback, extracts core methodological units, composes reusable research patterns, and organizes them into a structured methodological knowledge graph. At runtime, underspecified user research intents are aligned to established research paradigms, enabling efficient retrieval and reuse of high-quality research patterns instead of open-ended generation and trial-and-error. By grounding research planning and execution in a pre-built knowledge graph, Idea2Story alleviates the context window bottleneck of LLMs and substantially reduces repeated runtime reasoning over literature. We conduct qualitative analyses and preliminary empirical studies demonstrating that Idea2Story can generate coherent, methodologically grounded, and novel research patterns, and can produce several high-quality research demonstrations in an end-to-end setting. These results suggest that offline knowledge construction provides a practical and scalable foundation for reliable autonomous scientific discovery.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [81] [Decoupling and randomization for double-indexed permutation statistics](https://arxiv.org/abs/2601.20018)
*Mingxuan Zou,Jingfan Xu,Peng Ding,Fang Han*

Main category: math.ST

TL;DR: 本文提出了一种用于双索引排列统计量的解耦与随机化方法，建立了新的组合Hanson-Wright不等式和Bennett不等式，并在秩统计、图统计和因果推断中给出了应用示例。


<details>
  <summary>Details</summary>
Motivation: 为了处理双索引排列统计量中的复杂依赖结构，需要发展新的概率不等式工具以支持高维组合数据分析。

Method: 采用解耦和随机化技术，将复杂的排列依赖结构转化为更易处理的独立或近似独立形式，从而推导出适用于双索引排列统计的集中不等式。

Result: 得到了新的组合Hanson-Wright不等式和组合Bennett不等式，这些结果在多种非参数和图模型场景中具有直接应用。

Conclusion: 所提出的解耦方法为分析排列下的双索引统计量提供了强有力的理论工具，拓展了经典浓度不等式在组合结构中的适用范围。

Abstract: This paper introduces a version of decoupling and randomization to establish concentration inequalities for double-indexed permutation statistics. The results yield, among other applications, a new combinatorial Hanson-Wright inequality and a new combinatorial Bennett inequality. Several illustrative examples from rank-based statistics, graph-based statistics, and causal inference are also provided.

</details>


### [82] [Concentration Inequalities for Exchangeable Tensors and Matrix-valued Data](https://arxiv.org/abs/2601.20152)
*Chen Cheng,Rina Foygel Barber*

Main category: math.ST

TL;DR: 本文研究了在可交换性条件下，具有结构化权重和的随机数据（如张量内积和序列矩阵和）的集中不等式，推广了传统独立项框架下的Hoeffding和Bernstein不等式，并在多因素响应模型和联邦平均中的固定设计 sketching 方法中得到应用验证。


<details>
  <summary>Details</summary>
Motivation: 传统集中不等式多基于独立随机变量，而现实问题中数据常具有结构和依赖性。本文旨在将集中不等式扩展到具有结构化权重和的可交换随机数据，以更广泛地适用于复杂模型分析。

Method: 通过引入结构依赖的可交换性条件，发展适用于张量内积和序列矩阵和的Hoeffding型与Bernstein型不等式，并优化常数，同时改进组合矩阵数组和的集中界。

Result: 恢复了可交换随机变量加权和与i.i.d.随机矩阵和的经典结果至最优常数；获得了比Chatterjee交换对方法更紧的组合矩阵数组和集中界；并在多因素响应模型与联邦平均的sketching方法中实现理论预测与数值实验的一致性。

Conclusion: 本文建立的结构化集中不等式为依赖数据下的复杂模型分析提供了有力工具，拓展了经典理论的应用范围，并在实际问题中展现出优越性能。

Abstract: We study concentration inequalities for structured weighted sums of random data, including (i) tensor inner products and (ii) sequential matrix sums. We are interested in tail bounds and concentration inequalities for those structured weighted sums under exchangeability, extending beyond the classical framework of independent terms.
  We develop Hoeffding and Bernstein bounds provided with structure-dependent exchangeability. Along the way, we recover known results in weighted sum of exchangeable random variables and i.i.d. sums of random matrices to the optimal constants. Notably, we develop a sharper concentration bound for combinatorial sum of matrix arrays than the results previously derived from Chatterjee's method of exchangeable pairs.
  For applications, the richer structures provide us with novel analytical tools for estimating the average effect of multi-factor response models and studying fixed-design sketching methods in federated averaging. We apply our results to these problems, and find that our theoretical predictions are corroborated by numerical evidence.

</details>


### [83] [Partial heteroscedastic deconvolution estimation in nonparametric regression](https://arxiv.org/abs/2601.20341)
*Baba Thiam*

Main category: math.ST

TL;DR: 提出了一种适用于异方差测量误差的非参数回归部分去卷积核估计方法，并证明其在适当正则条件下能达到最优收敛速率。


<details>
  <summary>Details</summary>
Motivation: 在存在异方差测量误差的情况下，对部分协变量有测量误差而其他无误差的非参数回归模型进行有效估计的需求。

Method: 提出一种基于核函数的部分去卷积核估计方法，并在理论分析中考虑了异方差的测量误差结构。

Result: 所提估计量在合适正则条件下可达到最优收敛速率，且通过模拟研究验证了其在有限样本下的良好表现。

Conclusion: 该方法为存在异方差测量误差的非参数回归问题提供了一个有效的估计工具，具有理论保证和实际应用价值。

Abstract: In this paper, we consider a partial deconvolution kernel estimator for nonparametric regression when some covariates are measured with error while others are observed without error. We focus on a general and realistic setting in which the measurement errors are heteroscedastic. We propose a kernel-based estimator of the regression function in this framework and show that it achieves the optimal convergence rate under suitable regularity conditions. The finite-sample performance of the proposed estimator is illustrated through simulation studies.

</details>


### [84] [Blessing of dimensionality in cross-validated bandwidth selection on the sphere](https://arxiv.org/abs/2601.20442)
*José E. Chacón,Eduardo García-Portugués,Andrea Meilán-Vila*

Main category: math.ST

TL;DR: 研究了在d维超球面上核密度估计中最小二乘交叉验证带宽选择的渐近行为，发现其收敛速率随维度增加而接近参数率，表明高维下交叉验证法优于插件法。


<details>
  <summary>Details</summary>
Motivation: 探索在高维球面上核密度估计中带宽选择方法的渐近性能，尤其是交叉验证与插件方法之间的比较。

Method: 通过理论分析和数值实验，推导出交叉验证带宽选择相对于最优带宽的收敛速率，并与欧氏空间中的结果进行比较。

Result: 证明了在非均匀性条件下存在最优带宽，且交叉验证的收敛速率为n^{-d/(2d+8)}，随着维度d增大趋近于n^{-1/2}；数值实验验证了该收敛速度并确定了交叉验证优于插件法的临界维度。

Conclusion: 高维情况下，交叉验证带宽选择表现出优越性能，为高维数据提供了一种更优的带宽选择方法。

Abstract: We study the asymptotic behavior of least-squares cross-validation bandwidth selection in kernel density estimation on the $d$-dimensional hypersphere, $d\geq 1$. We show that the exact rate of convergence with respect to the optimal bandwidth minimizing the mean integrated squared error, shown to exist under mild non-uniformity conditions, is $n^{-d/(2d+8)}$, thus approaching the $n^{-1/2}$ parametric rate as $d$ grows. This ``blessing of dimensionality'' in bandwidth selection offers theoretical support for utilizing the conceptually simpler cross-validation selector over plug-in techniques for larger dimensions $d$. We compare this result for bandwidth estimation on the $d$-dimensional Euclidean space through explicit expressions for the asymptotic variance functionals. Numerical experiments corroborate the speed of this convergence in an array of scenarios and dimensions, precisely illustrating the tipping dimension where cross-validation outperforms plug-in approaches.

</details>


### [85] [Improved Computational Lower Bound of Estimation for Multi-Frequency Group Synchronization](https://arxiv.org/abs/2601.20522)
*Zhangsong Li*

Main category: math.ST

TL;DR: 研究了多频群同步问题中的计算相变，利用低次多项式算法框架分析信号估计任务，证明在频率数为L=n^{o(1)}时，谱方法在多项式时间内最优，扩展了先前工作，并揭示了大频率数下的统计-计算间隙。


<details>
  <summary>Details</summary>
Motivation: 探索多频群同步模型中是否存在统计与计算之间的根本差距，尤其是在频率通道数量增长情况下的计算复杂性变化。

Method: 采用低次多项式算法框架，分析在SO(2)群上的多频同步模型中估计结构化信号的能力，并与已知的统计阈值上界进行比较。

Result: 证明当频率数L=n^{o(1)}时，简单的谱方法在多项式时间内是最优估计器；结合已有统计阈值结果，表明在足够多频率下存在统计-计算间隙。

Conclusion: 在多频群同步问题中，当频率数量适中增长时，谱方法是计算上最优的，且该模型展现出从统计可解到计算难解的相变现象。

Abstract: We study the computational phase transition in a multi-frequency group synchronization problem, where pairwise relative measurements of group elements are observed across multiple frequency channels and corrupted by Gaussian noise. Using the framework of \emph{low-degree polynomial algorithms}, we analyze the task of estimating the structured signal in such observations. We show that, assuming the low-degree heuristic, in synchronization models over the circle group $\mathsf{SO}(2)$, a simple spectral method is computationally optimal among all polynomial-time estimators when the number of frequencies satisfies $L=n^{o(1)}$. This significantly extends prior work \cite{KBK24+}, which only applied to a fixed constant number of frequencies. Together with known upper bounds on the statistical threshold \cite{PWBM18a}, our results establish the existence of a \emph{statistical-to-computational gap} in this model when the number of frequencies is sufficiently large.

</details>


### [86] [Spectral Bayesian Regression on the Sphere](https://arxiv.org/abs/2601.20528)
*Claudio Durastanti*

Main category: math.ST

TL;DR: 提出了一种基于各向同性高斯场先验和球面调和结构的球面上非参数回归的全内在贝叶斯框架，推导出闭式后验分布、最优谱截断方案和尖锐的后验收缩率，并证明后验均值等价于拉普拉斯-贝尔特拉米平滑样条。


<details>
  <summary>Details</summary>
Motivation: 为了在单位球面上实现非参数回归，需要一个内在的贝叶斯方法，能够利用球面的几何结构并提供理论保证。

Method: 采用各向同性高斯场先验和拉普拉斯-贝尔特拉米算子诱导的调和结构，在均匀随机设计下通过球面谐波基实现模型对角化，得到具有频率依赖重数的高斯序列表示，并据此推导后验性质。

Result: 得到了闭式后验分布、最优谱截断方案和在积分平方损失下的尖锐后验收缩率；对于具有多项式衰减角功率谱的高斯先验（包括球面Matérn先验），在Sobolev类上实现了最小最大最优的后验收缩率；后验均值被证明是几何内在的惩罚最小二乘估计量，等价于拉普拉斯-贝尔特拉米平滑样条。

Conclusion: 所提出的贝叶斯框架充分利用了球面的内在几何结构，提供了理论最优的收敛速率和明确的变分解释，适用于球面上的非参数回归问题。

Abstract: We develop a fully intrinsic Bayesian framework for nonparametric regression on the unit sphere based on isotropic Gaussian field priors and the harmonic structure induced by the Laplace-Beltrami operator. Under uniform random design, the regression model admits an exact diagonalization in the spherical harmonic basis, yielding a Gaussian sequence representation with frequency-dependent multiplicities.
  Exploiting this structure, we derive closed-form posterior distributions, optimal spectral truncation schemes, and sharp posterior contraction rates under integrated squared loss. For Gaussian priors with polynomially decaying angular power spectra, including spherical Matérn priors, we establish posterior contraction rates over Sobolev classes, which are minimax-optimal under correct prior calibration.
  We further show that the posterior mean admits an exact variational characterization as a geometrically intrinsic penalized least-squares estimator, equivalent to a Laplace-Beltrami smoothing spline.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [87] [A Unified Symmetry Classification of Many-Body Localized Phases](https://arxiv.org/abs/2601.20532)
*Yucheng Wang*

Main category: cond-mat.dis-nn

TL;DR: 提出了一种基于对称性的多体局域化（MBL）相分类框架，通过局域运动积分（LIOMs）的代数结构判断对称性是否与稳定MBL兼容，发现阿贝尔对称性支持稳定MBL和拓扑MBL相，而非阿贝尔连续对称性通常抑制MBL。构建了完整的MBL相分类表。


<details>
  <summary>Details</summary>
Motivation: 缺乏适用于相互作用多体局域化的对称性分类框架，而安德森局域化已有AZ十重分类，因此需要建立一个类似的、基于对称性的MBL相分类体系。

Method: 在局域积分运动（LIOMs）的代数层次上发展对称性分类方法，提出对称性与稳定MBL兼容的判据：其作用可在准局域LIOM代数中一致表示，且不导致广泛简并或非局域算符混合；系统结合AZ对称性与额外的片上对称性构建分类表。

Result: 明确了阿贝尔对称性兼容稳定MBL并可支持对称保护的拓扑MBL相，而非阿贝尔连续对称性通常破坏MBL；建立了完整的MBL相分类体系，区分出稳定、脆弱和不稳定类，并给出了晶格实现模型。

Conclusion: 建立了统一且物理清晰的MBL相分类框架，揭示了对称性对MBL的约束机制，为理解多体局域化中的对称性作用提供了基础。

Abstract: Anderson localization admits a complete symmetry classification given by the Altland-Zirnbauer (AZ) tenfold scheme, whereas an analogous framework for interacting many-body localization (MBL) has remained elusive. Here we develop a symmetry-based classification of static MBL phases formulated at the level of local integrals of motion (LIOMs). We show that a symmetry is compatible with stable MBL if and only if its action can be consistently represented within a quasi-local LIOM algebra, without enforcing extensive degeneracies or nonlocal operator mixing. This criterion sharply distinguishes symmetry classes: onsite Abelian symmetries are compatible with stable MBL and can host distinct symmetry-protected topological MBL phases, whereas continuous non-Abelian symmetries generically preclude stable MBL. By systematically combining AZ symmetries with additional onsite symmetries, we construct a complete classification table of MBL phases, identify stable, fragile, and unstable classes, and provide representative lattice realizations. Our results establish a unified and physically transparent framework for understanding symmetry constraints on MBL.

</details>


### [88] [Variational Monte Carlo (VMC) with row-update Projected Entangled-Pair States (PEPS) and its applications in quantum spin glasses](https://arxiv.org/abs/2601.20608)
*Tao Chen,Jing Liu,Yantao Wu,Pan Zhang,Youjin Deng*

Main category: cond-mat.dis-nn

TL;DR: 提出了一种基于自回归的逐行采样算法，用于投影纠缠对态的变分蒙特卡洛方法，显著减少了时间相关性并缓解了临界慢化问题。


<details>
  <summary>Details</summary>
Motivation: 标准PEPS-VMC算法依赖于局部更新，存在收敛慢和临界慢化的问题，特别是在相变附近或阻挫体系中表现不佳。

Method: 设计了一种高效的自回归逐行采样算法，通过单层收缩实现直接、无拒绝的采样，并利用自回归的单层行更新生成非局域的构型建议。

Result: 在二维横场伊辛模型和量子自旋玻璃中进行了基准测试，结果表明新方法有效缓解了临界慢化，优化稳定性更好，且获得了更低的基态能量。

Conclusion: 单层自回归逐行更新为局部PEPS-VMC采样提供了灵活且鲁棒的改进，可作为更先进采样方案的基础。

Abstract: Solving the quantum many-body ground state problem remains a central challenge in computational physics. In this context, the Variational Monte Carlo (VMC) framework based on Projected Entangled Pair States (PEPS) has witnessed rapid development, establishing itself as a vital approach for investigating strongly correlated two-dimensional systems. However, standard PEPS-VMC algorithms predominantly rely on sequential local updates. This conventional approach often suffers from slow convergence and critical slowing down, particularly in the vicinity of phase transitions or within frustrated landscapes. To address these limitations, we propose an efficient autoregressive row-wise sampling algorithm for PEPS that enables direct, rejection-free sampling via single-layer contractions. By utilizing autoregressive single-layer row updates to generate collective, non-local configuration proposals, our method significantly reduces temporal correlations compared to local Metropolis moves. We benchmark the algorithm on the two-dimensional transverse-field Ising model and the quantum spin glass. Our results demonstrate that the row-wise scheme effectively mitigates critical slowing down near the Ising critical point. Furthermore, in the rugged landscape of the quantum spin glass, it yields improved optimization stability and lower ground-state energies. These findings indicate that single-layer autoregressive row updates provide a flexible and robust improvement to local PEPS-VMC sampling and may serve as a basis for more advanced sampling schemes.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [89] [Connecting reflective asymmetries in multivariate spatial and spatio-temporal covariances](https://arxiv.org/abs/2601.20132)
*Drew Yarger*

Main category: stat.ME

TL;DR: 本文提出了一种新的“反射非对称”时空协方差构建范式，扩展了多元空间数据模型的应用，并在模拟研究和爱尔兰风速数据分析中表现出更优的模型拟合与预测性能。


<details>
  <summary>Details</summary>
Motivation: 为解决多变量空间与单变量时空数据中存在的非对称依赖关系，现有方法存在参数复杂或建模视角局限的问题，因此需要一种更简洁、灵活且易于估计的非对称协方差建模方法。

Method: 利用多元空间数据的新模型构建“反射非对称”时空协方差结构，扩展了原有模型的适用性，并从不同于拉格朗日方法的新视角出发，使标准可分离模型成为特例，同时减少参数数量并统一控制时空边际协方差。

Result: 新模型在模拟研究和爱尔兰风速数据分析中显著提升了模型拟合度和预测性能，且具有更少的参数、更高的估计效率。

Conclusion: 所提出的反射非对称时空协方差模型具有更广的适用性，能够有效改进环境等领域的时空数据分析。

Abstract: In the analysis of multivariate spatial and univariate spatio-temporal data, it is commonly recognized that asymmetric dependence may exist, which can be addressed using an asymmetric (matrix or space-time, respectively) covariance function within a Gaussian process framework. This paper introduces a new paradigm for constructing asymmetric space-time covariances, which we refer to as "reflective asymmetric," by leveraging recently-introduced models for multivariate spatial data. We first provide new results for reflective asymmetric multivariate spatial models that extends their applicability. We then propose their asymmetric space-time extension, which come from a substantially different perspective than Lagrangian asymmetric space-time covariances. There are fewer parameters in the new models, one controls both the spatial and temporal marginal covariances, and the standard separable model is a special case. In simulation studies and analysis of the frequently-studied Irish wind data, these new models also improve model fit and prediction performance, and they can be easier to estimate. These features indicate broad applicability for improved analysis in environmental and other space-time data.

</details>


### [90] [Online Change Point Detection for Multivariate Inhomogeneous Poisson Processes Time Series](https://arxiv.org/abs/2601.20192)
*Xiaokai Luo,Haotian Xu,Carlos Misael Madrid Padilla,Oscar Hernan Madrid Padilla*

Main category: stat.ME

TL;DR: 提出一种用于多变量非齐次泊松点过程时间序列的在线变点检测方法，具有低计算成本和理论保证。


<details>
  <summary>Details</summary>
Motivation: 多变量非齐次泊松点过程在地震、气候和疫情监测中广泛应用，但现有机器学习与统计方法对此类数据的变点检测研究不足。

Method: 采用低秩矩阵建模多变量泊松强度函数，设计自适应非参数检测算法，实现单次扫描和每步恒定计算开销。

Result: 提供了控制总体误报率和检测延迟的理论保证，提出了适用于时序依赖泊松过程的新型矩阵Bernstein不等式，实验显示方法兼具统计鲁棒性与计算高效性。

Conclusion: 所提方法能有效应对多变量泊松点过程的在线变点检测问题，在理论和实践中均表现优异。

Abstract: We study online change point detection for multivariate inhomogeneous Poisson point process time series. This setting arises commonly in applications such as earthquake seismology, climate monitoring, and epidemic surveillance, yet remains underexplored in the machine learning and statistics literature. We propose a method that uses low-rank matrices to represent the multivariate Poisson intensity functions, resulting in an adaptive nonparametric detection procedure. Our algorithm is single-pass and requires only constant computational cost per new observation, independent of the elapsed length of the time series. We provide theoretical guarantees to control the overall false alarm probability and characterize the detection delay under temporal dependence. We also develop a new Matrix Bernstein inequality for temporally dependent Poisson point process time series, which may be of independent interest. Numerical experiments demonstrate that our method is both statistically robust and computationally efficient.

</details>


### [91] [Bias-Reduced Estimation of Finite Mixtures: An Application to Latent Group Structures in Panel Data](https://arxiv.org/abs/2601.20197)
*Raphaël Langevin*

Main category: stat.ME

TL;DR: 本文研究了有限混合模型在小样本下最大似然估计（MLE）存在显著偏差的问题，提出通过最大化分类-混合似然函数并结合一致分类器来减少偏差，并证明该方法在有限样本中表现优于传统MLE，具有更低的偏差和均方误差，且在实证应用中显著降低预测误差。


<details>
  <summary>Details</summary>
Motivation: 有限混合模型常用于捕捉未观测异质性，但标准MLE在小样本下对所有参数可能存在严重偏差，影响估计准确性，因此需要改进估计方法。

Method: 提出使用带有一致分类器的分类-混合似然函数进行最大化估计，推导其渐近分布，并给出实现Oracle有效性的条件，通过蒙特卡洛模拟和实证分析验证方法性能。

Result: 蒙特卡洛模拟显示传统MLE存在明显小样本偏差，而新方法在偏差和均方误差上均优于标准MLE；实证应用中，新方法相比标准MLE将样本外预测误差降低了约17.6%。

Conclusion: 所提出的分类-混合似然估计方法能有效缓解有限混合模型中小样本导致的估计偏差，在较弱假设下表现更优，并可达到Oracle效率。

Abstract: Finite mixture models are widely used in econometric analyses to capture unobserved heterogeneity. This paper shows that maximum likelihood estimation of finite mixtures of parametric densities can suffer from substantial finite-sample bias in all parameters under mild regularity conditions. The bias arises from the influence of outliers in component densities with unbounded or large support and increases with the degree of overlap among mixture components. I show that maximizing the classification-mixture likelihood function, equipped with a consistent classifier, yields parameter estimates that are less biased than those obtained by standard maximum likelihood estimation (MLE). I then derive the asymptotic distribution of the resulting estimator and provide conditions under which oracle efficiency is achieved. Monte Carlo simulations show that conventional mixture MLE exhibits pronounced finite-sample bias, which diminishes as the sample size or the statistical distance between component densities tends to infinity. The simulations further show that the proposed estimation strategy generally outperforms standard MLE in finite samples in terms of both bias and mean squared errors under relatively weak assumptions. An empirical application to latent group panel structures using health administrative data shows that the proposed approach reduces out-of-sample prediction error by approximately 17.6% relative to the best results obtained from standard MLE procedures.

</details>


### [92] [Wavelet Tree Ensembles for Triangulable Manifolds](https://arxiv.org/abs/2601.20254)
*Hengrui Luo,Akira Horiguchi,Li Ma*

Main category: stat.ME

TL;DR: 提出了一种在可三角化流形上用于回归的非平衡Haar小波树集成方法，该方法通过测地线三角剖分自适应地划分数据，并保持正交性和精确重构等关键性质，在球面和气候异常场等任务中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 将经典的非平衡Haar小波从欧几里得网格推广到一般可三角化流形，以处理流形上的回归问题，并保留其优良数学性质。

Method: 构建基于测地线三角形的小波原子系统，形成在经验测度下的正交基，并将其作为加性集成中的弱学习器；结合优化和贝叶斯集成策略进行回归建模。

Result: 在球面上的合成回归、气候异常场预测以及图像去噪任务中，所提方法显著优于传统树集成和非自适应小波方法；贝叶斯变体RUHWT还能提供函数估计的不确定性量化。

Conclusion: 该方法成功扩展了非平衡Haar小波至流形设置，在保持理论优势的同时实现了优越的回归性能，具有良好的应用前景。

Abstract: We develop unbalanced Haar (UH) wavelet tree ensembles for regression on triangulable manifolds. Given data sampled on a triangulated manifold, we construct UH wavelet trees whose atoms are supported on geodesic triangles and form an orthonormal system in $L^2(μ_n)$, where $μ_n$ is the empirical measure on the sample, which allows us to use UH trees as weak learners in additive ensembles. Our construction extends classical UH wavelet trees from regular Euclidean grids to generic triangulable manifolds while preserving three key properties: (i) orthogonality and exact reconstruction at the sampled locations, (ii) recursive, data-driven partitions adapted to the geometry of the manifold via geodesic triangulations, and (iii) compatibility with optimization-based and Bayesian ensemble building. In Euclidean settings, the framework reduces to standard UH wavelet tree regression and provides a baseline for comparison. We illustrate the method on synthetic regression on the sphere and on climate anomaly fields on a spherical mesh, where UH ensembles on triangulated manifolds substantially outperform classical tree ensembles and non-adaptive mesh-based wavelets. For completeness, we also report results on image denoising on regular grids. A Bayesian variant (RUHWT) provides posterior uncertainty quantification for function estimates on manifolds. Our implementation is available at http://www.github.com/hrluo/WaveletTrees.

</details>


### [93] [Confidence intervals for maximum unseen probabilities, with application to sequential sampling design](https://arxiv.org/abs/2601.20320)
*Alessandro Colombi,Mario Beraha,Amichai Painsky,Stefano Favaro*

Main category: stat.ME

TL;DR: 本文研究了在伯努利产品模型下，如何决定是否需要进一步抽样以检测出所有超过预设阈值的类别，提出了针对未见最大概率的非渐近、无分布上置信界，并在有界和无界字母表两种情况下建立了数据依赖的边界，证明了其接近最优性，同时设计了具有有限样本保证的序贯停止规则。


<details>
  <summary>Details</summary>
Motivation: 在发现类问题中，常需判断是否需要进一步抽样才能检测到所有流行度超过某一阈值的类别。现有方法在无分布假设下的理论保证不足，尤其是在类别数量未知或无限的情况下缺乏有效推断工具。

Method: 基于伯努利乘积（存在-缺失）模型，定义推断目标为“未见最大概率”，即尚未观测到的类别中的最高流行度；在有界和无界字母表两种情形下，提出非渐近、无分布的上置信界；分析数据无关的最坏情况界限的局限性，并设计数据依赖的置信界方法，建立匹配的下界以证明其近似最优性；基于此构造具有有限样本保证的序贯停止规则。

Result: 证明在无界字母表下，任何非平凡的数据无关方法都无法实现一致有效性；提出的数 据依赖上界在模拟和真实数据中表现良好，且具有近似最优性；所构建的序贯停止规则具有有限样本保证，并对引入低流行度噪声类别的污染具有鲁棒性。

Conclusion: 本文为发现类问题中的抽样决策提供了理论上严谨且实用的工具，特别是在类别空间未知或无限时，数据依赖的方法显著优于数据无关方法，所提出的置信界和停止规则具有良好的统计性能和实际适用性。

Abstract: Discovery problems often require deciding whether additional sampling is needed to detect all categories whose prevalence exceeds a prespecified threshold. We study this question under a Bernoulli product (incidence) model, where categories are observed only through presence--absence across sampling units. Our inferential target is the \emph{maximum unseen probability}, the largest prevalence among categories not yet observed. We develop nonasymptotic, distribution-free upper confidence bounds for this quantity in two regimes: bounded alphabets (finite and known number of categories) and unbounded alphabets (countably infinite under a mild summability condition). We characterise the limits of data-independent worst-case bounds, showing that in the unbounded regime no nontrivial data-independent procedure can be uniformly valid. We then propose data-dependent bounds in both regimes and establish matching lower bounds demonstrating their near-optimality. We compare empirically the resulting procedures in both simulated and real datasets. Finally, we use these bounds to construct sequential stopping rules with finite-sample guarantees, and demonstrate robustness to contamination that introduces spurious low-prevalence categories.

</details>


### [94] [SCORE: A Unified Framework for Overshoot Refund in Online FDR Control](https://arxiv.org/abs/2601.20386)
*Qi Kuang,Bowen Gang,Yin Xia*

Main category: stat.ME

TL;DR: 提出了一种基于e值的在线多重假设检验增强框架SCORE，通过回收超过拒绝阈值的多余证据来提升统计功效，同时保持有限样本下的FDR控制有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的e值在线多重检验方法在拒绝阈值以上的证据被丢弃，导致统计功效损失，缺乏有效利用超额证据的机制。

Method: 提出了SCORE框架，利用不等式 \mathbb{I}(y \ge 1) \le y - (y-1)_+ 回收超额证据，并应用于LOND、LORD、SAFFRON等算法，构建了SCORE-LOND、SCORE-LORD和SCORE-SAFFRON；引入回溯性alpha财富更新机制，通过重复使用最新决策更新历史财富。

Result: SCORE增强型算法在保持有限样本FDR控制的前提下，严格优于原始算法；模拟和真实数据实验表明其显著提升统计功效。

Conclusion: SCORE提供了一个统一且有效的框架，能够广泛提升基于e值的在线多重检验方法的功效，同时维持严格的FDR控制，为未来在线学习与序列假设检验提供了新思路。

Abstract: We propose a unified framework to enhance the power of online multiple hypothesis testing procedures based on $e$-values. While $e$-value-based methods offer robust online False Discovery Rate (FDR) control under minimal assumptions, they often suffer from power loss by discarding evidence that exceeds the rejection threshold. We address this inefficiency via the \textbf{S}equential \textbf{C}ontrol with \textbf{O}vershoot \textbf{R}efund for \textbf{E}-values (SCORE) framework, which leverages the inequality $\mathbb{I}(y \ge 1) \le y - (y-1)_+$ to reclaim this otherwise ``wasted'' evidence. This simple yet powerful insight yields a unified principle for improving a broad class of online testing algorithms. Building on this framework, we develop SCORE-enhanced versions of several state-of-the-art procedures, including SCORE-LOND, SCORE-LORD, and SCORE-SAFFRON, all of which strictly dominate their original counterparts while preserving valid finite-sample FDR control. Furthermore, under mild assumptions, SCORE permits retroactive updates of alpha-wealth by using the latest decision twice: first to determine its reward or loss, and then to refresh past wealth. Such a mechanism enables more aggressive testing strategies while maintaining valid FDR control, thereby further improving statistical power. The effectiveness of the proposed methods is validated through extensive simulation and real-data experiments.

</details>


### [95] [Causal Inference in Biomedical Imaging via Functional Linear Structural Equation Models](https://arxiv.org/abs/2601.20610)
*Ting Li,Ethan Fan,Tengfei Li,Hongtu Zhu*

Main category: stat.ME

TL;DR: 提出了一种新的函数型线性结构方程模型（FLSEM），用于从医学影像中识别器官特异性特征对临床结果的因果效应，结合标量工具变量实现可识别性，并开发了FGS-DAR算法进行高效变量选择，理论和实证结果均显示其在UK Biobank数据中具有稳健的因果检测能力。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以处理医学影像中无限维暴露变量和复杂协变量对临床结局因果效应建模的挑战，亟需一种可识别且具备理论保证的新方法。

Method: 提出函数型线性结构方程模型（FLSEM），利用标量工具变量建立可识别条件；设计FGS-DAR算法实现变量选择，提供选择一致性和参数估计的理论保证；构造检验统计量并推导其零分布以检验函数系数的显著性。

Result: 模拟实验验证了方法的有效性；在UK Biobank真实数据上的应用表明该方法能稳健地从医学影像中检测出与临床结果相关的因果关系。

Conclusion: FLSEM框架结合FGS-DAR算法为基于医学影像的因果推断提供了可识别、可解释且理论上可靠的解决方案，推动了功能影像暴露与临床结局间因果关系的研究。

Abstract: Understanding the causal effects of organ-specific features from medical imaging on clinical outcomes is essential for biomedical research and patient care. We propose a novel Functional Linear Structural Equation Model (FLSEM) to capture the relationships among clinical outcomes, functional imaging exposures, and scalar covariates like genetics, sex, and age. Traditional methods struggle with the infinite-dimensional nature of exposures and complex covariates. Our FLSEM overcomes these challenges by establishing identifiable conditions using scalar instrumental variables. We develop the Functional Group Support Detection and Root Finding (FGS-DAR) algorithm for efficient variable selection, supported by rigorous theoretical guarantees, including selection consistency and accurate parameter estimation. We further propose a test statistic to test the nullity of the functional coefficient, establishing its null limit distribution. Our approach is validated through extensive simulations and applied to UK Biobank data, demonstrating robust performance in detecting causal relationships from medical imaging.

</details>


### [96] [Exact Graph Learning via Integer Programming](https://arxiv.org/abs/2601.20589)
*Lucas Kook,Søren Wengel Mogensen*

Main category: stat.ME

TL;DR: 本文提出了一种基于非参数条件独立性检验和整数规划的图学习框架，能够全局最优地推断复杂系统中变量间的依赖结构，并在多种图类型上实现了优于现有方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现有图学习方法通常依赖于对数据生成过程的强假设，或使用贪婪算法、近似求解，导致结果不鲁棒或无法保证全局最优。本文旨在克服这些局限性，提供一种更通用且精确的解决方案。

Method: 将图学习问题重新表述为整数规划问题，结合非参数条件独立性测试和图分离准则的有效编码，以精确求解并恢复最大规模的图结构，支持有向无环图、混合图和链图的学习，并输出对应的马尔可夫等价类或弱等价类表示。

Result: 所提方法在理论上证明了其解的全局最优性，在实验中显示出比其他精确方法更快的求解速度，并在模拟数据和基准数据集上对各类图均达到最先进的性能。

Conclusion: 该非参数整数规划框架解决了传统图学习方法在假设敏感性和优化精度上的不足，为因果发现和依赖结构学习提供了高效、精确且公开可用的工具（R包glip）。

Abstract: Learning the dependence structure among variables in complex systems is a central problem across medical, natural, and social sciences. These structures can be naturally represented by graphs, and the task of inferring such graphs from data is known as graph learning or as causal discovery if the graphs are given a causal interpretation. Existing approaches typically rely on restrictive assumptions about the data-generating process, employ greedy oracle algorithms, or solve approximate formulations of the graph learning problem. As a result, they are either sensitive to violations of central assumptions or fail to guarantee globally optimal solutions. We address these limitations by introducing a nonparametric graph learning framework based on nonparametric conditional independence testing and integer programming. We reformulate the graph learning problem as an integer-programming problem and prove that solving the integer-programming problem provides a globally optimal solution to the original graph learning problem. Our method leverages efficient encodings of graphical separation criteria, enabling the exact recovery of larger graphs than was previously feasible. We provide an implementation in the openly available R package 'glip' which supports learning (acyclic) directed (mixed) graphs and chain graphs. From the resulting output one can compute representations of the corresponding Markov equivalence classes or weak equivalence classes. Empirically, we demonstrate that our approach is faster than other existing exact graph learning procedures for a large fraction of instances and graphs of various sizes. GLIP also achieves state-of-the-art performance on simulated data and benchmark datasets across all aforementioned classes of graphs.

</details>


### [97] [Effective Sample Size for Functional Spatial Data](https://arxiv.org/abs/2601.20812)
*Alfredo Alegría,John Gómez,Jorge Mateu,Ronny Vallejos*

Main category: stat.ME

TL;DR: 提出了一种用于函数型地理空间数据的有效样本量新定义，使用迹协方差作为相关性度量，并在实际气象数据中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 将经典标量有效样本量的概念扩展到函数型空间数据，以解决现有方法在处理此类数据时的不足。

Method: 引入基于迹协方差的函数型有效样本量定义，并通过函数自回归过程和真实气象数据进行验证。

Result: 所提方法保留了经典有效样本量的直观特性，能够量化函数型空间数据中的冗余并确定有效独立曲线数量。

Conclusion: 该方法为函数型地理空间数据提供了合理且可解释的有效样本量度量，具有实际应用价值。

Abstract: The effective sample size quantifies the amount of independent information contained in a dataset, accounting for redundancy due to correlation between observations. While widely used in geostatistics for scalar data, its extension to functional spatial data has remained largely unexplored. In this work, we introduce a novel definition of the effective sample size for functional geostatistical data, employing the trace-covariogram as a measure of correlation, and show that it retains the intuitive properties of the classical scalar ESS. We illustrate the behavior of this measure using a functional autoregressive process, demonstrating how serial dependence and the allocation of variability across eigen-directions influence the resulting functional ESS. Finally, the approach is applied to a real meteorological dataset of geometric vertical velocities over a portion of the Earth, showing how the method can quantify redundancy and determine the effective number of independent curves in functional spatial datasets.

</details>


### [98] [Two-dose vs. Three-Dose Optimization Under Sample Size Constraint](https://arxiv.org/abs/2601.20710)
*Linda Sun,Yixin Ren,Cong Chen*

Main category: stat.ME

TL;DR: 本文探讨了在肿瘤药物开发的剂量优化研究中，即使总样本量固定，携带三个剂量组通常优于两个，除非有非常强的证据表明可以剔除一个剂量组。


<details>
  <summary>Details</summary>
Motivation: 在早期阶段开发中，由于总体证据往往不明确，确定剂量优化研究中应包含多少剂量是一个挑战。

Method: 应用数学近似方法指导研究，并通过模拟研究补充理论发现，提供针对随机和非随机剂量优化的半定量建议。

Result: 研究表明，在固定总样本量的情况下，携带三个剂量组仍优于两个，尤其是在缺乏强烈证据支持减少剂量时。

Conclusion: 在剂量优化研究中，除非有非常强的证据支持，否则应优先考虑包含三个剂量组。

Abstract: Dose optimization is a hallmark of Project Optimus for oncology drug development. The number of doses to include in a dose optimization study depends on the totality of evidence, which is often unclear in early-phase development. With equal sample sizes per dose, carrying three doses is clearly more advantageous than two for optimization. In this paper, we show that, even when the total sample size is fixed, it is still preferable to carry three unless there is very strong evidence that one can be dropped. A mathematical approximation is applied to guide the investigation, followed by a simulation study to complement the theoretical findings. Semi-quantitative guidance is provided for practitioners, addressing both randomized and non-randomized dose optimization while considering population homogeneity.

</details>


### [99] [A General Mixture Loss Function to Optimize a Personalized PredictiveModel](https://arxiv.org/abs/2601.20788)
*Tatiana Krikella,Joel A. Dubin*

Main category: stat.ME

TL;DR: 提出一种广义损失函数以优化个性化预测模型的子群体大小，兼顾区分度和校准性能，并通过模拟研究推荐了计算高效的子群体大小范围（20%-70%），支持在精准健康研究中灵活高效地实现PPMs。


<details>
  <summary>Details</summary>
Motivation: 为了提升个性化预测模型在精准医学中的表现，需要一种能够同时优化模型区分度和校准性的方法，并减少计算负担。

Method: 提出一种可由用户指定性能指标及其权重的广义损失函数，用于调整拟合PPM时所用的子群体大小，并通过大规模模拟研究确定子群体大小的实用搜索范围。

Result: 模拟和真实数据应用表明，子群体大小与模型性能之间的关系具有鲁棒性，且损失函数中性能指标的选择会影响最优子群体大小的确定；推荐子群体大小范围为训练数据的20%至70%。

Conclusion: 该方法支持在精准健康研究中灵活、高效地实施个性化预测模型，平衡了模型性能与计算成本。

Abstract: Advances in precision medicine increasingly drive methodological innovation in health research. A key development is the use of personalized prediction models (PPMs), which are fit using a similar subpopulation tailored to a specific index patient, and have been shown to outperform one-size-fits-all models, particularly in terms of model discrimination performance. We propose a generalized loss function that enables tuning of the subpopulation size used to fit a PPM. This loss function allows joint optimization of discrimination and calibration, allowing both the performance measures and their relative weights to be specified by the user. To reduce computational burden, we conducted extensive simulation studies to identify practical bounds for the grid of subpopulation sizes. Based on these results, we recommend using a lower bound of 20\% and an upper bound of 70\% of the entire training dataset. We apply the proposed method to both simulated and real-world datasets and demonstrate that previously observed relationships between subpopulation size and model performance are robust. Furthermore, we show that the choice of performance measures in the loss function influences the optimal subpopulation size selected. These findings support the flexible and computationally efficient implementation of PPMs in precision health research.

</details>


### [100] [Plotting correlated data](https://arxiv.org/abs/2601.20805)
*Lukas Koch*

Main category: stat.ME

TL;DR: 本文探讨了在数据点不确定性相关时，传统误差棒无法有效判断模型与数据吻合度的问题，并提出通过展示不确定性主成分和条件不确定性来改进可视化方法。


<details>
  <summary>Details</summary>
Motivation: 当数据点的不确定性存在相关性时，仅显示协方差矩阵对角线元素的误差棒不足以判断模型与数据的一致性，因此需要更有效的可视化手段。

Method: 通过显式展示不确定性的第一主成分以及所有数据点的条件不确定性，增强数据与模型预测之间一致性判断的能力。

Result: 改进后的可视化方法能够更准确地反映模型与数据的吻合程度，并帮助识别模型可能存在的不足之处。

Conclusion: 在存在相关不确定性的情况下，传统的误差棒图缺乏足够信息；引入主成分和条件不确定性可显著提升数据可视化的有效性。

Abstract: A very common task in data visualization is to plot many data points with some measured y-value as a function of fixed x-values. Uncertainties on the y-values are typically presented as vertical error bars that represent either a Frequentist confidence interval or Bayesian credible interval for each data point. Most of the time, these error bars represent a 68\% confidence/credibility level, which leads to the intuition that a model fits the data reasonably well if its prediction lies within the error bars of roughly two thirds of the data points. Unfortunately, this and other intuitions no longer work when the uncertainties of the data points are correlated. If the error bars only show the square root of diagonal elements of some covariance matrix with non-negligible off-diagonal elements, we simply do not have enough information in the plot to judge whether a drawn model line agrees well with the data or not. In this paper we will demonstrate this problem and discuss ways to add more information to the plots to make it easier to judge the agreement between the data and some model prediction in the plot, as well as glean some insight where the model might be deficient. This is done by explicitly showing the contribution of the first principal component of the uncertainties, and by displaying the conditional uncertainties of all data points.

</details>


### [101] [Joint estimation of the basic reproduction number and serial interval using Sequential Bayes](https://arxiv.org/abs/2601.20809)
*Tatiana Krikella,Jane M. Heffernan,Hanna Jankowski*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Early in an infectious disease outbreak, timely and accurate estimation of the basic reproduction number ($R_0$) and the serial interval (SI) is critical for understanding transmission dynamics and informing public health responses. While many methods estimate these quantities separately, and a small number jointly estimate them from incidence data, existing joint approaches are largely likelihood-based and do not fully exploit prior information. We propose a novel Bayesian framework for the joint estimation of $R_0$ and the serial interval using only case count data, implemented through a sequential Bayes approach. Our method assumes an SIR model and employs a mildly informative joint prior constructed by linking log-Gamma marginal distributions for $R_0$ and the SI via a Gaussian copula, explicitly accounting for their dependence. The prior is updated sequentially as new incidence data become available, allowing for real-time inference. We assess the performance of the proposed estimator through extensive simulation studies under correct model specification as well as under model misspecification, including when the true data come from an SEIR or SEAIR model, and under varying degrees of prior misspecification. Comparisons with the widely used White and Pagano likelihood-based joint estimator show that our approach yields substantially more precise and stable estimates of $R_0$, with comparable or improved bias, particularly in the early stages of an outbreak. Estimation of the SI is more sensitive to prior misspecification; however, when prior information is reasonably accurate, our method provides reliable SI estimates and remains more stable than the competing approach. We illustrate the practical utility of the proposed method using Canadian COVID-19 incidence data at both national and provincial levels.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [102] [Comment on "Instability of the ferromagnetic quantum critical point and symmetry of the ferromagnetic ground state in two-dimensional and three-dimensional electron gases with arbitrary spin-orbit splitting"](https://arxiv.org/abs/2601.19959)
*D. Belitz,T. R. Kirkpatrick*

Main category: cond-mat.str-el

TL;DR: 本文评论了Miserev等人关于非中心对称金属中电子-电子相互作用导致一阶量子相变的结论，指出在三维磁体中若正确考虑屏蔽效应，该结论不成立。


<details>
  <summary>Details</summary>
Motivation: 澄清非中心对称金属中自旋轨道相互作用与电子相互作用对量子相变阶数的影响，纠正先前研究中的错误结论。

Method: 通过分析粒子-粒子通道相互作用和2kF散射过程，并严格考虑屏蔽效应对软模的影响，重新评估自由能对磁化的依赖关系。

Result: 发现当屏蔽效应被正确处理时，软模仍被抑制，不会引发一阶相变，从而否定Miserev等人的结论。

Conclusion: 在三维非中心对称金属中，适当考虑屏蔽后，自旋轨道相互作用仍可阻止一阶量子相变的发生，支持Kirkpatrick和Belitz的观点。

Abstract: Metallic quantum ferromagnets in the absence of quenched disorder are known to generically undergo a first-order quantum phase transition, avoiding the quantum critical point that had originally been expected. This is due to soft modes in the underlying Fermi liquid that lead to long-ranged correlations. These correlations in turn yield a nonanalytic dependence of the free energy on the magnetization even at a mean-field level that results in a fluctuation-induced first-order transition. Kirkpatrick and Belitz [Phys. Rev. Lett. {\bf 124}, 147201 (2020)] have pointed out that one notable exception are non-centrosymmetric metals with a strong spin-orbit interaction. In such materials the spin-orbit interaction gives the relevant soft modes a mass, which inhibits the mechanism leading to a first-order transition. Miserev, Loss, and Klinovaja [Phys. Rev. B {\bf 106}, 134417 (2022)] have claimed that this conclusion does not hold if electron-electron interactions in the particle-particle channel, or 2$\kF$ scattering processes, are considered. They concluded that this interaction channel leads to soft modes that are not rendered massive by the spin-orbit interaction and again lead to a first-order quantum phase transition. In this Comment we show that this conclusion is not correct in three-dimensional magnets if the screening of the interaction is properly taken into account.

</details>


### [103] [Unifying Dirac Spin Liquids on Square and Shastry-Sutherland Lattices via Fermionic Deconfined Criticality](https://arxiv.org/abs/2601.19980)
*Andreas Feuerpfeil,Leyna Shackleton,Atanu Maity,Ronny Thomale,Subir Sachdev,Yasir Iqbal*

Main category: cond-mat.str-el

TL;DR: 本文提出了Shastry-Sutherland晶格上无禁闭量子临界点的费米子规范理论，并揭示其与方晶格共享低能场论结构。通过构建狄拉克自旋子与SU(2)规范场及伴随希格斯场的连续理论，解释了到不同自旋液体相的转变。尽管Shastry-Sutherland晶格允许更多对称性允许的费米子双线性项，但其量子场论在无关项之外与方晶格相同。研究分析了SO(5)临界点的共形无禁闭临界行为，计算了临界指数，并指出Yukawa耦合是导致其不稳定的相关扰动，与蒙特卡洛模拟中的拟临界行为一致。结果表明，涌现的SO(5)序参量在临界点具有大的反常维度，导致Néel和VBS susceptibility显著增强，这与数值研究一致。本工作将近期关于Shastry-Sutherland晶格上无能隙Z2狄拉克自旋液体的数值证据置于可控的场论框架下，并证明方晶格上的费米子无禁闭临界现象可推广至对称性降低的阻挫晶格。


<details>
  <summary>Details</summary>
Motivation: 探索Shastry-Sutherland晶格上无禁闭量子临界点的场论描述，理解其与方晶格系统的共性与差异，并为近期数值模拟中观察到的无能隙Z2狄拉克自旋液体提供理论支持。

Method: 基于SU(2) π-通量母态，构建狄拉克自旋子与SU(2)规范场及伴随希格斯场的连续场论，利用大风味展开分析SO(5)临界点的性质，计算关键指数并研究Yukawa耦合的影响。

Result: 发现Shastry-Sutherland晶格与方晶格在低能极限下具有相同的量子场论结构（除无关项外），SO(5)临界点表现出共形无禁闭临界行为，Yukawa耦合是破坏其稳定性的相关扰动，序参量具有大的反常维度，导致Néel和VBS susceptibility显著增强。

Conclusion: 费米子无禁闭量子临界现象不仅存在于方晶格，在对称性较低的阻挫晶格如Shastry-Sutherland晶格上同样成立，且具有相似的临界行为和稳定性特征，为理解数值模拟结果提供了统一的场论框架。

Abstract: We present a fermionic gauge theory for deconfined quantum criticality on the Shastry-Sutherland lattice and reveal its shared low-energy field-theoretic structure with the square lattice. Starting from an SU(2) $π$-flux parent state, we construct a continuum theory of Dirac spinons coupled to an SU(2) gauge field and adjoint Higgs fields whose condensates drive transitions to a staggered-flux U(1) spin liquid and a gapless $\mathbb{Z}_{2}$ Dirac spin liquid. While the Shastry-Sutherland lattice permits additional symmetry-allowed fermion bilinears compared to the square lattice, the quantum field theories are identical up to additional irrelevant terms. Consequently, the Higgs potential structure and the leading low-energy theory coincide with the square-lattice case at the quantum critical point. The SO(5) critical point is expected to realize conformal deconfined criticality: we analyze it in a large flavor expansion, calculate its critical exponents, and identify the Yukawa coupling between the fermions and Higgs fields as the relevant perturbation that destabilizes it, consistent with pseudocritical behavior observed in recent Monte Carlo studies. We show that the emergent SO(5) order parameter acquires a large anomalous dimension at the critical point, leading to strongly enhanced Néel and VBS susceptibilities-a hallmark of fermionic deconfined quantum criticality consistent with numerical studies. Our results place recent numerical evidence for a gapless $\mathbb{Z}_{2}$ Dirac spin liquid on the Shastry-Sutherland lattice within a controlled field-theoretic framework and demonstrate that fermionic deconfined criticality on the square lattice-including critical exponents and stability-extends to frustrated lattices with reduced symmetry.

</details>


### [104] [High-precision ground state parameters of the two-dimensional spin-1/2 Heisenberg model on the square lattice](https://arxiv.org/abs/2601.20189)
*Anders W. Sandvik*

Main category: cond-mat.str-el

TL;DR: 通过使用随机级数展开方法的量子蒙特卡洛模拟，研究了方格子S=1/2反铁磁海森堡模型的基态性质，并在周期、开放和圆柱边界条件下进行了外推分析，结果与手征微扰理论预测高度一致，显著提高了基态能量和序参量等物理量的计算精度。


<details>
  <summary>Details</summary>
Motivation: 精确计算二维反铁磁系统的基态性质，验证手征微扰理论在有限尺寸修正中的适用性，并为不同边界条件下的数值方法提供基准数据。

Method: 采用随机级数展开的量子蒙特卡洛方法，在L∈[6,96]的周期性L×L方格子上进行低温模拟，实现T→0极限下的基态性质计算，并对有限尺寸效应进行外推分析；同时研究开放和圆柱边界系统以支持其他方法的基准测试。

Result: 获得高精度的基态能量密度e₀ = -0.669441857(7)，比此前结果精度提高三个数量级；序参量ms = 0.307447(2)；有限尺寸修正项与手征微扰理论预测一致，确认次级修正中存在ln^γ(L)项，指数γ = 0.82(4)； staggered susceptibility也显示出对数修正特征。

Conclusion: 该研究提供了高度精确的二维量子磁性系统基态参数，验证了手征微扰理论对有限尺寸效应的准确描述能力，同时为不同边界条件下的数值方法提供了可靠基准。

Abstract: Several ground state properties of the square-lattice $S=1/2$ Heisenberg antiferromagnet are computed (the energy, order parameter, spin stiffness, spinwave velocity, long-wavelength susceptibility, and staggered susceptibility) using extensive quantum Monte Carlo simulations with the stochastic series expansion method. Moderately sized lattices are studied at temperatures $T$ sufficiently low to realize the $T \to 0$ limit. Results for periodic $L\times L$ lattices with $L \in [6,96]$ are tabulated versus $L$ and extrapolations to infinite system size are carried out. The extrapolated ground state energy density is $e_0=-0.669441857(7)$, which represents an improvement in precision of three orders of magnitude over the previously best result. The leading and subleading finite-size corrections to $e_0$ are in full quantitative agreement with predictions from chiral perturbation theory, thus further supporting the soundness of both the extrapolations and the theory. The extrapolated sublattice magnetization is $m_s=0.307447(2)$, which agrees well with previous estimates but with a much smaller statistical error. The coefficient of the linear in $L^{-1}$ correction to $m^2_s$ agrees with the value from chiral perturbation theory and the presence of a factor $\ln^γ(L)$ in the second-order correction is also confirmed, with the previously not known value of the exponent being $γ= 0.82(4)$. The finite-size corrections to the staggered susceptibility point to logarithmic corrections also in this quantity. To facilitate benchmarking of methods for which periodic boundary conditions are challenging, results for systems with open and cylindrical boundaries are also listed and their spatially inhomogeneous order parameters are analyzed.

</details>


### [105] [Microscopic Determination of the c-axis-Oriented Antiferromagnetic Structure in LaMnSi by $^{55}$Mn and $^{139}$La NMR](https://arxiv.org/abs/2601.20281)
*Yusuke Sakai,Fumiya Hori,Hiroki Matsumura,Shumpei Oguchi,Shunsaku Kitagawa,Kenji Ishida,Hiroshi Tanida*

Main category: cond-mat.str-el

TL;DR: 本研究通过核磁共振（NMR）对LaMnSi在反铁磁态下的磁结构和电子性质进行了微观研究，发现其Mn有序磁矩沿c轴排列，符合C型反铁磁结构，并实现了奇宇称多极序。结果表明LaMnSi是研究不含4f电子复杂性的RT Si体系中3d电子磁性和奇宇称多极序的理想材料。


<details>
  <summary>Details</summary>
Motivation: 探索不含4f电子干扰的过渡金属硅化物中的3d电子磁性和新型奇宇称多极序，为理解巡游反铁磁性和多极序提供理想平台。

Method: 采用场扫和零场核磁共振技术（$^{55}$Mn- 和 $^{139}$La-NMR）研究LaMnSi的磁结构，测量核自旋晶格弛豫率1/T1以分析其电子动力学行为。

Result: 确定Mn有序磁矩沿c轴方向，内磁场达19.64 T（4.2 K），超精细耦合常数Ahf = 6.0 T/μB；1/T1显示巡游反铁磁特征，在低温下呈金属性，在接近Neel温度时因磁振子激发而增强。

Conclusion: LaMnSi具有清晰的C型反铁磁结构和奇宇称多极序，是研究3d电子体系中反铁磁性和多极物理的理想候选材料。

Abstract: We report a microscopic investigation of the magnetic structure and electronic properties of LaMnSi in its antiferromagnetic (AFM) state using nuclear magnetic resonance (NMR). Field-swept $^{55}$Mn- and $^{139}$La-NMR spectra, as well as zero-field 55Mn-NMR (ZFNMR) spectra, reveal that the Mn ordered moments are parallel to the tetragonal c axis, consistent with the C-type AFM structure and the realization of an odd-parity multipole order. The internal field at the Mn site is determined to be 19.64 T at 4.2 K, corresponding to a hyperfine coupling constant of Ahf = 6.0 T/uB. Nuclear spin-lattice relaxation rate 1/T1 exhibits a characteristic behavior of itinerant antiferromagnetism, showing metallic behavior at low temperatures and magnon-induced enhancement upon approaching the Neel temperature (TN = 295 K). These results show LaMnSi as an ideal compound to study 3d electron magnetism and odd-parity multipole order in the RT Si (R = rare-earth, T = transition metal) system, free of the complexities of 4f electrons.

</details>


### [106] [Ground-State Phase Diagram of (1/2,1/2,1) Mixed Diamond Chains with Single-Site Anisotropy](https://arxiv.org/abs/2601.20328)
*Kazuo Hida*

Main category: cond-mat.str-el

TL;DR: 研究了具有单点各向异性D的混合菱形链(S, τ^(1), τ^(2))=(1/2,1/2,1)的基态相，通过数值精确对角化和DMRG方法结合解析近似，确定了包含Néel有序相、无磁Tomonaga-Luttinger液体相、量化和部分铁磁相的相图，并发现了各向异性反转区域。


<details>
  <summary>Details</summary>
Motivation: 探索具有不同自旋构型和各向异性的混合菱形链的基态相行为，特别是各向异性对量子磁性相的影响。

Method: 采用数值精确对角化、DMRG方法以及在各种极限情况下的解析近似方法来确定基态相图。

Result: 得到了包含Néel有序相、Tomonaga-Luttinger液体相、量化和部分铁磁相的完整基态相图；发现了一个各向异性反转区域，其中在S=1位点上，当D>0时出现Ising-like Néel相，当D<0时出现XY-like Tomonaga-Luttinger液体相。

Conclusion: 该系统展现出丰富的量子磁性相行为，各向异性参数D在调控相变中起关键作用，特别是在各向异性反转区域表现出非寻常的相特性。

Abstract: The ground-state phases of mixed diamond chains with ($S, τ^{(1)}, τ^{(2)})=(1/2,1/2,1)$, where $S$ is the magnitude of vertex spins, and $τ^{(1)}$ and $τ^{(2)}$ are those of apical spins, are investigated with the single-site anisotropy $D$ on the $τ^{(2)}$-site. The two apical spins in each unit cell are coupled by an exchange coupling $λ$. The vertex spins are coupled with the top and bottom apical spins by exchange couplings $1+δ$ and $1-δ$, respectively. The ground-state phase diagram is determined using the numerical exact diagonalization and DMRG method in addition to the analytical approximations in various limiting cases. The phase diagram consists of a Néel ordered phase, a nonmagnetic Tomonaga-Luttinger liquid phase, quantized and partial ferrimagnetic phases. A region with anisotropy inversion is found where the Ising-like Néel phase is realized for the easy-plane anisotropy $D >0$ and the XY-like Tomonaga-Luttinger liquid phase is realized for the easy-axis anisotropy $D <0$ on the $S=1$ sites.

</details>


### [107] [Critical Charge and Current Fluctuations across a Voltage-Driven Phase Transition](https://arxiv.org/abs/2601.20474)
*José F. B. Afonso,Stefan Kirchner,Pedro Ribeiro*

Main category: cond-mat.str-el

TL;DR: 研究了偏压驱动的非平衡量子相变在相互作用量子点系统中的行为，发现电荷涨落可用有效温度描述，而电流涨落表现出真正的非平衡特性，如负的有效温度。


<details>
  <summary>Details</summary>
Motivation: 探索非平衡条件下量子相变的本质，特别是在偏压驱动下量子输运系统中的临界现象。

Method: 采用随机相位近似（RPA），在大量量子点能级极限下精确求解，绘制零温非平衡相图，并分析电荷 susceptibility 和电流噪声在相变附近的行为。

Result: 电荷涨落可通过有效温度 $T_{\text{eff}}(T,V)$ 描述并坍缩到平衡形式；而电流涨落在有序相中表现出负的涨落-耗散比，对应负的有效温度，揭示其本质的非平衡特征。

Conclusion: 电流噪声是非平衡量子相变中关键涨落的敏感探针，为研究电压驱动的临界现象提供了新方向。

Abstract: We investigate bias-driven non-equilibrium quantum phase transitions in a paradigmatic quantum-transport setup: an interacting quantum dot coupled to non-interacting metallic leads. Using the Random Phase Approximation, which is exact in the limit of a large number of dot levels, we map out the zero-temperature non-equilibrium phase diagram as a function of interaction strength and applied bias. We focus our analysis on the behavior of the charge susceptibility and the current noise in the vicinity of the transition. Remarkably, despite the intrinsically non-equilibrium nature of the steady state, critical charge fluctuations admit an effective-temperature description, $T_{\text{eff}}(T,V)$, that collapses the steady-state behavior onto its equilibrium form. In sharp contrast, current fluctuations exhibit genuinely non-equilibrium features: the fluctuation-dissipation ratio becomes negative in the ordered phase, corresponding to a negative effective temperature for the current degrees of freedom. These results establish current noise as a sensitive probe of critical fluctuations at non-equilibrium quantum phase transitions and open new directions for exploring voltage-driven critical phenomena in quantum transport systems.

</details>


### [108] [Magnetic states of the Kondo lattice Ce$_2$PdSi$_3$ and their pressure evolution](https://arxiv.org/abs/2601.20517)
*Yanan Zhang,Zhaoyang Shan,Jiawen Zhang,Kaixin Ye,Yongjian Li,Dajun Su,Pascal Manuel,Dmitry Khalyavin,Devashibhai Adroja,Daniel Mayoh,Geetha Balakrishnan,Yu Liu,Michael Smidman,Huiqiu Yuan*

Main category: cond-mat.str-el

TL;DR: Ce₂PdSi₃ 展示出两种不同的磁相变，且在压力下表现出竞争性磁序，挑战传统Doniach模型，提示几何阻挫可能起重要作用。


<details>
  <summary>Details</summary>
Motivation: 探索阻挫Kondo晶格中非常规量子临界性和新兴磁性相，并检验传统理论模型的适用性。

Method: 通过测量Ce₂PdSi₃在不同磁场和静水压下的磁性质，研究其磁相变随压力的演化行为。

Result: 在常压下观察到两个磁相变：3.8 K的类铁磁转变和2.9 K的非共线反铁磁转变；加压后前者被抑制，后者增强并保持稳定至7.5 GPa以上。

Conclusion: Ce₂PdSi₃中存在竞争性磁序，其行为无法用传统Doniach相图解释，表明几何阻挫可能在其磁性演化中起关键作用。

Abstract: Frustrated Kondo lattices are ideal platforms for exploring unconventional forms of quantum criticality, as well as magnetism and other emergent phases. Here we report the magnetic properties of the candidate frustrated heavy fermion compound Ce$_2$PdSi$_3$, and map their evolution upon applying magnetic fields and hydrostatic pressure. We find that at ambient pressure Ce$_2$PdSi$_3$ exhibits two distinct magnetic phase transitions, a ferromagnetic-like transition at $T_{\mathrm{M1}}=3.8$ K and an incommensurate antiferromagnetic transition at $T_{\mathrm{M2}}=2.9$ K. Upon applying pressure, $T_{\mathrm{M1}}$ is continuously suppressed and becomes undetectable above 4.2 GPa, whereas $T_{\mathrm{M2}}$ increases and remains robust up to at least 7.5 GPa. The observed pressure evolution of magnetic order in Ce$_2$PdSi$_3$ suggests the presence of competing magnetic orders, and cannot be simply encapsulated by the Doniach phase diagram, motivating further investigations for its origin, including discerning the role of geometric frustration.

</details>


### [109] [Quantum control of Hubbard excitons](https://arxiv.org/abs/2601.20695)
*D. R. Baykusheva,D. P. Carmichael,C. S. Weber,I-T. Lu,F. Glerean,T. Meng,P. B. M. De Oliveira,C. C. Homes,I. A. Zaliznyak,G. D. Gu,M. P. M. Dean,A. Rubio,D. M. Kennes,M. Claassen,M. Mitrano*

Main category: cond-mat.str-el

TL;DR: 该研究利用Floquet工程实现了对一维Mott绝缘体Sr₂CuO₃中强关联Hubbard激子的量子调控，通过非共振中红外光场实现激子波函数在亮态与暗态之间的超快旋转，并利用共振三次谐波生成量化了布洛赫球上的π/2旋转，推动了关联态的可编程控制与激子量子传感的发展。


<details>
  <summary>Details</summary>
Motivation: 实现对多体波函数的精确量子调控是量子材料研究的核心挑战，而现有Floquet工程多集中于弱相互作用体系，强关联体系中的调控仍待探索。

Method: 采用非共振中红外光学场对Sr₂CuO₃中的Hubbard激子进行相干修饰（Floquet工程），并通过共振三次谐波生成技术探测激子在布洛赫球上的超快旋转动力学。

Result: 成功实现了激子波函数在亮态与暗态之间的相干旋转，实验观测到皮秒尺度下的π/2旋转，验证了Floquet工程在强关联体系中的有效性。

Conclusion: Floquet工程可用于调控强关联激子态，为实现关联量子态的可编程控制和激子基量子传感提供了新路径。

Abstract: Quantum control of the many-body wavefunction is a central challenge in quantum materials research, as it could yield a precise control knob to manipulate emergent phenomena. Floquet engineering, the coherent dressing of quantum states with periodic non-resonant optical fields, has become an important strategy for quantum control. Most applications to solid-state systems have targeted weakly interacting or single-ion states, leaving the manipulation of many-body wavefunctions largely unexplored. Here, we use Floquet engineering to achieve quantum control of a strongly correlated Hubbard exciton in the one-dimensional Mott insulator Sr$_2$CuO$_3$. A nonresonant midinfrared optical field coherently dresses the exciton wavefunction, driving its rotation between bright and dark states. We use resonant third-harmonic generation to quantify ultrafast $π/2$ rotations on the Bloch sphere spanned by these exciton states. Our work advances the quest towards programmable control of correlated states and exciton-based quantum sensing.

</details>


### [110] [Collective excitations in chiral spin liquid: chiral roton and long-wavelength nematic mode](https://arxiv.org/abs/2601.20702)
*Hongyu Lu,Wei Zhu,Wang Yao*

Main category: cond-mat.str-el

TL;DR: 本研究通过精确对角化和含时变分原理计算，首次在自旋-1/2方格J₁-J₂-Jχ模型的SU(2)对称手性自旋液体相中发现两种自旋单态集体激发模式：有限动量的p波手性转子模和零动量的d波向列模。这些模式具有区别于分数量子霍尔液体的独特特征，并揭示了向列模软化及自旋三重态双自旋子束缚态可能引发的强向列和自旋条纹不稳定性，为实验探测手性自旋液体提供了新的谱学信号。


<details>
  <summary>Details</summary>
Motivation: 手性自旋液体（CSL）作为分数量子霍尔液体的磁性对应物，其集体激发的研究尚不充分，尤其是与FQH体系不同的动力学特征亟待揭示。本文旨在探究CSL中的集体激发模式及其演化，以深化对手性自旋液体及其量子相变的理解。

Method: 结合精确对角化和含时变分原理（TDVP）方法，研究自旋-1/2方格J₁-J₂-Jχ模型中SU(2)对称CSL相的集体激发行为，并分析不同参数下激发模式的变化。

Result: 发现了两个显著的自旋单态集体激发模式：一个是位于有限动量的低能p波手性转子模，另一个是位于零动量的高能d波向列模；两者在整个CSL区域内均明显存在。调节J₂时，向列模显著软化，并伴随自旋三重态双自旋子束缚态的出现，预示着强烈的向列和自旋条纹不稳定性。

Conclusion: 该工作从动力学角度揭示了CSL中新奇的集体激发模式，提供了区别于FQH系统的独特指纹，为未来实验识别CSL候选材料提供了重要的谱学依据。

Abstract: Chiral spin liquid (CSL) is a magnetic analogue of the fractional quantum Hall (FQH) liquid. Collective excitations play a vital role in shaping our understanding of these exotic quantum phases of matter and their quantum phase transitions. While the magneto-roton and long-wavelength chiral graviton modes in the FQH liquids have been extensively explored, the collective excitations of CSLs remain elusive. Here we explore the collective excitations in the SU(2) symmetric CSL phase of the spin-1/2 square-lattice $J_1-J_2-J_χ$ model, where an intriguing quantum phase diagram was recently revealed. Combining exact diagonalization and time-dependent variational principle calculations, we observe two spin-singlet collective modes: a chiral p-wave (low-energy) roton mode at finite momentum and a d-wave (higher-energy) nematic mode at zero momentum, both of which are prominent across the CSL phase. Such exotic modes exhibit fingerprints distinct from those of FQH liquids, and to the best of our knowledge, are reported for the first time. By tuning $J_2$, we find the nematic mode to be pronouncedly soft, together with the spin-triplet two-spinon bound states, potentially promoting strong nematic and spin stripe instabilities. Our work paves the way for further understanding CSL from the dynamical perspective and provides new spectroscopic signatures for future experiments of CSL candidates.

</details>


### [111] [Observation of Dipolar Spin-ice--like Correlations in the Quantum Spin Ice Candidate Ce$_2$Sn$_2$O$_7$](https://arxiv.org/abs/2601.20766)
*Bo Yuan,M. Powell,X. Liu,J. Ni,E. M. Smith,F. Ye,J. Dudemaine,A. D. Bianchi,J. W. Kolis,B. D. Gaulin*

Main category: cond-mat.str-el

TL;DR: 本研究通过高质量单晶中子散射实验，发现Ce₂Sn₂O₇具有高度结构化的漫散射，与经典偶极自旋冰相似，表明需重新考虑近邻相互作用在铈基烧绿石中的作用。


<details>
  <summary>Details</summary>
Motivation: 由于样品质量和中子信号噪声问题，Ce₂X₂O₇体系的微观交换哈密顿量和自旋关联尚不明确，亟需高质量数据以澄清其低能物理机制。

Method: 采用水热法生长高质量Ce₂Sn₂O₇单晶，并进行单晶漫散射中子实验，分析其动量空间（Q-依赖）的磁散射特征。

Result: 观察到沿布里渊区边界的强漫散射信号，其Q依赖性与常用的最近邻XYZ模型预测不符，但与经典偶极自旋冰的散射模式高度相似。

Conclusion: 次近邻相互作用在Ce基烧绿石低能物理中起关键作用，当前理论框架需修正以包含这些长程效应。

Abstract: The Ce$_2$X$_2$O$_7$ (X=Sn, Hf, Zr) family of cubic pyrochlores has emerged as one of the most promising classes of Quantum Spin Ice candidates. However, understanding their microscopic exchange Hamiltonian and spin correlations has been hampered by varying sample quality, and poor signal-to-noise in the existing neutron data due to a small Ce$^{3+}$ magnetic dipole moment. In this work, we overcome these challenges and report single-crystal diffuse neutron scattering from hydrothermally grown Ce$_2$Sn$_2$O$_7$ -- the highest quality crystals obtained to date for the Ce$_2$X$_2$O$_7$ family. In contrast to the broad diffuse scattering observed in Ce$_2$Hf$_2$O$_7$ and Ce$_2$Zr$_2$O$_7$, we find highly structured diffuse scattering from Ce$_2$Sn$_2$O$_7$ featuring strong intensities along the Brillouin zone boundaries. The observed $\mathbf{Q}$-dependence disagrees with predictions of the nearest neighbour XYZ model commonly used for Ce$_2$X$_2$O$_7$, but is remarkably similar to the diffuse scattering observed in \textit{classical} Dipolar Spin Ice. Our study highlights the importance of further neighbour interactions in determining the low energy physics of the Ce-pyrochlores, and calls for a revision of the current theoretical framework to incorporate their effects.

</details>


### [112] [Stripe antiferromagnetism and chiral superconductivity in tWSe$_2$](https://arxiv.org/abs/2601.20836)
*Erekle Jmukhadze,Sam Olin,Allan H. MacDonald,Wei-Cheng Lee*

Main category: cond-mat.str-el

TL;DR: 该论文研究了双层WSe2莫尔材料中反铁磁态与超导态之间的相互作用，结合DFT与路径积分方法构建了考虑c轴晶格弛豫的最小莫尔能带模型，并通过Hartree-Fock计算揭示了多种竞争有序态的存在。


<details>
  <summary>Details</summary>
Motivation: 探讨在费米能级接近M点范霍夫奇点且位移场较小时，tWSe2中反铁磁与超导态共存的物理机制。

Method: 结合密度泛函理论（DFT）与路径积分方法构建莫尔能带模型，并进行Hartree-Fock计算以识别电荷和自旋有序的竞争基态。

Result: 在θ=2.7°和θ=3.65°时，发现层间反铁磁、条纹自旋密度波和铁磁陈绝缘体是零位移场下的主要基态候选；次近邻自旋相互作用J2可诱导时间反演对称性破缺的手征超导态。

Conclusion: 反铁磁相互作用在调控莫尔材料中新型量子态（如手征超导）方面起关键作用，为实现拓扑量子计算提供了新思路。

Abstract: The layer-dependent Hamiltonians of parallel-stacked MoTe$_2$ and WSe$_2$ homobilayer moiré materials are topologically non-trivial, both in real space and in momentum space, and have been shown to support integer and fractional quantum anomalous Hall states, as well as antiferromagnetic and superconducting states. Here, we address the interplay between the antiferromagnetic and superconducting states observed in tWSe$_2$ when the Fermi level is close to its $M$-point van Hove singularity and the displacement field is small. We combine DFT with path-integrals to construct a minimal moiré band model that accounts for lattice relaxation along the $c$-axis and perform Hartree-Fock calculations to identify competing charge and spin ordered states. For tWSe$_2$ at $θ=2.7^\circ$ and $θ=3.65^\circ$, we find that a layer antiferromagnet (AFM), a stripe spin-density-wave (SDW), and the ferromagnetic Chern insulator (FM) are the primary candidates for the ground state at zero displacement field, and argue that antiferromagnetic spin interactions on the next neighbor bond $J_2$ can induce a time-reversal symmetry breaking chiral superconducting state.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [113] [Tuning the strength of emergent correlations in a Brownian gas via batch resetting](https://arxiv.org/abs/2601.20077)
*Gabriele de Mauro,Satya N. Majumdar,Gregory Schehr*

Main category: cond-mat.stat-mech

TL;DR: 研究了一维线上N个扩散粒子在批量重置下的非平衡稳态，发现无相互作用粒子间存在长程关联，并揭示了关联强度随子集大小m变化的非单调动力学行为及临界粒子数Nc=6的相变现象。


<details>
  <summary>Details</summary>
Motivation: 探索无相互作用扩散粒子系统在批量重置机制下如何产生非平衡稳态和长程关联，填补批量重置与同步重置之间动态行为的研究空白。

Method: 通过解析求解批量重置速率r和重置子集大小m任意取值下的相关函数时间演化，获得精确的非平衡稳态解和动态关联特性。

Result: 发现当1<m<N时关联呈现非单调时间依赖性；稳态中关联强度可由m调节，并在Nc=6处发生转变；该结果适用于任意空间维度且Nc=6保持不变。

Conclusion: 批量重置能诱导无相互作用粒子系统形成具有可调长程关联的非平衡稳态，提供了一种通过控制重置规模调控系统关联特性的新途径。

Abstract: We study a gas of $N$ diffusing particles on the line subject to batch resetting: at rate $r$, a uniformly random subset of $m$ particles is reset to the origin. Despite the absence of interactions, the dynamics generates a nonequilibrium stationary state (NESS) with long-range correlations. We obtain exact results, both for the NESS and for the time dependence of the correlations, which are valid for arbitrary $m$ and $N$. By varying $m$, the system interpolates between an uncorrelated regime ($m=1$) and the fully synchronous resetting case ($m=N$). For all $1<m<N$, correlations exhibit a non-monotonic time dependence due to the emergence of an intrinsic decorrelation mechanism. In the stationary state, the correlation strength can be tuned by varying $m$, and it displays a transition at a critical value $N_c=6$. Our predictions extend straightforwardly to any spatial dimension $d$ and the critical value $N_c=6$ remains the same in all dimensions. Our predictions are testable in existing experimental setups on optically trapped colloidal particles.

</details>


### [114] [First-Hitting Location Laws as Boundary Observables of Drift--Diffusion Processes](https://arxiv.org/abs/2601.20095)
*Yen-Chi Lee*

Main category: cond-mat.stat-mech

TL;DR: 本研究探讨了漂移-扩散过程在吸收边界域中的首次击中位置（FHL）统计特性，提出FHL作为几何与动力学共同作用下的自然可观测量，揭示了扩散与漂移对边界统计规律的影响，并建立了基于生成算子的统一分析框架。


<details>
  <summary>Details</summary>
Motivation: 旨在理解信息如何从随机输运的几何与动态结构中自然涌现，而非依赖显式编码解码机制，探索FHL作为内在信息观测量的潜力。

Method: 采用生成算子方法，将FHL视为椭圆算子诱导的边界测度，在典型几何构型下解析推导边界核函数，分析不同维度下平面吸收边界上的FHL统计行为。

Result: 发现纯扩散情形下FHL呈现无标度、重尾的空间涨落；而引入非零漂移会引入内禀长度尺度，抑制尾部并重塑出口统计；漂移可导致边界统计的定性转变。

Conclusion: FHL统计为研究随机输运中的几何、漂移与不可逆性提供了统一的结构框架，是探测系统内在特性的自然工具。

Abstract: We investigate first-hitting location (FHL) statistics induced by drift--diffusion processes in domains with absorbing boundaries, and examine how such boundary laws give rise to intrinsic information observables. Rather than introducing explicit encoding or decoding mechanisms, information is viewed as emerging directly from the geometry and dynamics of stochastic transport through first-passage events. Treating the FHL as the primary observable, we characterize how geometry and drift jointly shape the induced boundary measure. In diffusion-dominated regimes, the exit law exhibits scale-free, heavy-tailed spatial fluctuations along the boundary, whereas a nonzero drift component introduces an intrinsic length scale that suppresses these tails and reorganizes the exit statistics. Within a generator-based formulation, the FHL arises naturally as a boundary measure induced by an elliptic operator, allowing explicit boundary kernels to be derived analytically in canonical geometries. Planar absorbing boundaries in different ambient dimensions are examined as benchmark cases, illustrating how directed transport regularizes diffusion-driven fluctuations and induces qualitative transitions in boundary statistics. Overall, the present work provides a unified structural framework for first-hitting location laws and highlights FHL statistics as natural probes of geometry, drift, and irreversibility in stochastic transport.

</details>


### [115] [Complex nonlinear sigma model](https://arxiv.org/abs/2601.20166)
*Kazuki Yamamoto,Kohei Kawabata*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了具有复耦合的非线性σ模型，作为非幺正场论的一般框架，通过微扰重正化群分析揭示了复标度维度和临界指数的普遍出现，并阐明了复耦合平面上的全局相图。


<details>
  <summary>Details</summary>
Motivation: 受开放量子多体系统临界性的近期关注启发，探索复耦合下的非线性σ模型以理解非幺正场论中的普适临界现象。

Method: 应用微扰重正化群分析到十类对称空间，研究复耦合非线性σ模型的标度行为和相变特性。

Result: 发现普遍存在具有复标度维度和临界指数的不动点，这些在传统实耦合模型中没有对应；并识别出复耦合平面中的连续和不连续相变。

Conclusion: 复耦合非线性σ模型为理解复杂化场论中的临界现象提供了普适框架，揭示了非幺正系统中新类型的临界行为。

Abstract: Motivated by the recent interest in the criticality of open quantum many-body systems, we study nonlinear sigma models with complexified couplings as a general framework for nonunitary field theory. Applying the perturbative renormalization-group analysis to the tenfold symmetric spaces, we demonstrate that fixed points with complex scaling dimensions and critical exponents arise generically, without counterparts in conventional nonlinear sigma models with real couplings. We further clarify the global phase diagrams in the complex-coupling plane and identify both continuous and discontinuous phase transitions. Our work elucidates universal aspects of critical phenomena in complexified field theory.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [116] [Two-Step Diffusion: Fast Sampling and Reliable Prediction for 3D Keller--Segel and KPP Equations in Fluid Flows](https://arxiv.org/abs/2601.20024)
*Zhenda Shen,Zhongjian Wang,Jack Xin,Zhiwen Zhang*

Main category: physics.comp-ph

TL;DR: 提出了一种两阶段生成传输方法，用于在流体流动影响下快速可靠地求解3D Keller-Segel和KPP方程的初始到终态分布映射，通过结合确定性全局传输与近恒等校正器，在Wasserstein度量下实现高精度逼近。


<details>
  <summary>Details</summary>
Motivation: 为了克服直接使用Wasserstein求解器在高维、复杂物理参数下生成传输时的不准确性和计算不稳定问题，特别是在3D KS和KPP方程中存在流体流动的情况下，需要一种高效且鲁棒的方法来精确逼近初始与终态分布之间的映射。

Method: 采用两阶段管道：第一阶段使用Meanflow风格的回归器生成一步式确定性全局传输，将粒子粗略移动至终态附近；第二阶段冻结该初始化器，训练一个近恒等校正器（Deep Particle, DP），利用基于Meanflow输出的热启动最优传输耦合，直接最小化小批量Wasserstein距离目标。

Result: 该方法在具有有序和混沌流线的流体流动条件下，成功应用于3D KS和KPP方程，显著提升了Wasserstein度量下的传输精度与高维计算稳定性，同时保持了一步法的效率。

Conclusion: 所提出的两阶段生成传输框架能够在复杂流体环境中高效、准确地逼近分布映射，通过分离粗略传输与精细校正，实现了Wasserstein优化的可解性与稳定性平衡，适用于多参数、高维反应-扩散系统。

Abstract: We study fast and reliable generative transport for the 3D KS (Keller-Segel) and KPP (Kolmogorov-Petrovsky-Piskunov) equations in the presence of fluid flows with the goal to approximate the map between initial and terminal distributions for a range of physical parameters $σ$ under the Wasserstein metric. To minimize the inaccuracy of direct Wasserstein solver, we propose a two-stage pipeline that retains one-step efficiency while reinstating an explicit $W_2$ objective where it is tractable. In Stage I, a Meanflow-style regressor yields a deterministic, one-step global transport that moves particles close to their terminal states. In Stage II, we freeze this initializer and train a near-identity corrector (Deep Particle, DP) that directly minimizes a mini-batch $W_2$ objective using warm-started optimal transport couplings computed on the Meanflow outputs. Crucially, after the one-step transport (from Stage I) concentrating mass on the approximated correct support, the induced geometry stabilizes high-dimensional $W_2$ computation of the direct Wasserstein solver. We validate our construction in the 3D KS and KPP equations subject to fluid flows with ordered and chaotic streamlines.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [117] [OptAgent: an Agentic AI framework for Intelligent Building Operations](https://arxiv.org/abs/2601.20005)
*Zixin Jiang,Weili Xu,Bing Dong*

Main category: eess.SY

TL;DR: 本研究提出了一种端到端的、基于物理信息机器学习（PIML）的智能体AI环境，用于实现建筑能源建模、仿真、控制与自动化的智能化转型，通过多智能体协同和大规模基准测试，验证了其在能效、成本与舒适性优化中的潜力。


<details>
  <summary>Details</summary>
Motivation: 应对建筑脱碳的迫切需求，传统依赖人工的建筑能源管理方式难以满足复杂、动态的能效优化要求，亟需向自主、智能的AI驱动模式转变。

Method: 构建了一个模块化且物理一致的PIML数字环境，涵盖建筑热力学、HVAC系统和分布式能源资源，并设计包含11个专业智能体和72个MCP工具的AI层，支持多步骤能源分析的端到端执行；通过一个多领域案例研究和约4000次运行的大规模基准测试评估系统性能。

Result: 实现了多智能体在多域任务中的协调运作，量化了不同智能模式、模型规模、任务复杂度等因素对准确性、计算开销和推理成本的影响，验证了框架在节能、降本和提升舒适性方面的有效性。

Conclusion: 该研究为在实际建筑能源应用中部署可扩展、基于物理规律的智能体AI系统提供了坚实基础，推动未来建筑向低碳化、电网互动型智能运营转型。

Abstract: The urgent need for building decarbonization calls for a paradigm shift in future autonomous building energy operation, from human-intensive engineering workflows toward intelligent agents that interact with physics-grounded digital environments. This study proposes an end-to-end agentic AI-enabled Physics-Informed Machine Learning (PIML) environment for scalable building energy modeling, simulation, control, and automation. The framework consists of (1) a modular and physics-consistent PIML digital environment spanning building thermal dynamics, Heating, Ventilation, and Air Conditioning (HVAC), and distributed energy resources (DER) for grid-interactive energy management; and (2) an agentic AI layer with 11 specialist agents and 72 Model Context Protocol (MCP) tools that enable end-to-end execution of multi-step energy analytics. A representative case study demonstrates multi-domain, multi-agent coordination for assessing how system and control upgrades affect energy use, operating cost, thermal comfort, and flexibility. In addition, a large-scale benchmark (about 4000 runs) systematically evaluates workflow performance in terms of accuracy, token consumption, execution time, and inference cost. The results quantify the impacts of intelligence mode design, model size, task complexity, and orchestrator-specialist coordination, and provide key lessons for building future agentic AI systems in real-world building energy applications. This work establishes a scalable, physics-grounded foundation for deploying agentic AI in decarbonized and grid-interactive building operations.

</details>


### [118] [Control systems for synthetic biology and a case-study in cell fate reprogramming](https://arxiv.org/abs/2601.20135)
*Domitilla Del Vecchio*

Main category: eess.SY

TL;DR: 本文综述了控制系统工程在合成生物学中的应用，重点是通过生物分子反馈和前馈控制实现对细胞内调控因子浓度的精确控制，以应对环境不确定性和干扰，特别是在细胞命运重编程中的应用。


<details>
  <summary>Details</summary>
Motivation: 由于环境不确定性和干扰，精确控制细胞内特定调控因子浓度是一个普遍且关键的问题，尤其是在细胞治疗和再生医学相关的细胞命运重编程中。

Method: 文章分析了干扰的来源及其对被控生物分子“系统”动态的影响，介绍了可实现鲁棒输出的生物分子反馈与前馈控制架构，并讨论了仅能通过可工程化的生物分子过程实现的可行控制律。

Result: 总结了多种可在细胞内实现的生物分子控制策略，展示了其在细胞命运重编程中的应用，特别是对主调控因子的精确调控以实现皮肤细胞向多能干细胞的转化。

Conclusion: 尽管复杂的控制算法已在计算机中实现，但在细胞内通过生物分子途径实现仍受限；未来的研究需解决生物分子控制设计中的可行性、鲁棒性与复杂性之间的平衡问题。

Abstract: This paper gives an overview of the use of control systems engineering in synthetic biology, motivated by applications such as cell therapy and cell fate reprogramming for regenerative medicine. A ubiquitous problem in these and other applications is the ability to control the concentration of specific regulatory factors in the cell accurately despite environmental uncertainty and perturbations. The paper describes the origin of these perturbations and how they affect the dynamics of the biomolecular ``plant'' to be controlled. A variety of biomolecular control implementations are then introduced to achieve robustness of the plant's output to perturbations and are grouped into feedback and feedforward control architectures. Although sophisticated control laws can be implemented in a computer today, they cannot be necessarily implemented inside the cell via biomolecular processes. This fact constraints the set of feasible control laws to those realizable through biomolecular processes that can be engineered with synthetic biology. After reviewing biomolecular feedback and feedforward control implementations, mostly focusing on the author's own work, the paper illustrates the application of such control strategies to cell fate reprogramming. Within this context, a master regulatory factor needs to be controlled at a specific level inside the cell in order to reprogram skin cells to pluripotent stem cells. The article closes by highlighting on-going challenges and directions of future research for biomolecular control design.

</details>


### [119] [C-AoEI-Aware Cross-Layer Optimization in Satellite IoT Systems: Balancing Data Freshness and Transmission Efficiency](https://arxiv.org/abs/2601.20183)
*Yuhua Zhao,Tiejun Lv,Ke Wang*

Main category: eess.SY

TL;DR: 提出了一种基于交叉层优化框架的新指标C-AoEI，用于解决卫星物联网中的数据新鲜度与传输效率之间的权衡问题，并通过编码和自适应算法优化，在多网关场景下显著提升了传输效率并降低了C-AoEI。


<details>
  <summary>Details</summary>
Motivation: 卫星物联网面临传播延迟、动态衰落和带宽稀缺的三难困境，传统Age of Information（AoI）指标因L-HARQ的回溯解码导致的年龄模糊而失效，难以衡量数据新鲜度与传输效率的权衡。

Method: 提出新的交叉层年龄误差信息（C-AoEI）指标，推导其闭式表达式，建立数据新鲜度与系统参数及信道动态的显式关系；设计分组级编码的L-HARQ方案和联合优化编码与决策阈值的自适应算法，适用于多地面站场景。

Result: 仿真结果显示，所提框架相比传统方案提升31.8%传输效率，降低17.2%的C-AoEI，且对小区间干扰和信道变化具有鲁棒性。

Conclusion: 该框架有效解决了S-IoT中数据新鲜度与可靠性的耦合问题，为下一代低延迟、高效率的卫星物联网协议设计提供了理论基础与实践方案。

Abstract: Satellite-based Internet of Things (S-IoT) faces a fundamental trilemma: propagation delay, dynamic fading, and bandwidth scarcity. While Layer-coded Hybrid ARQ (L-HARQ) enhances reliability, its backtracking decoding introduces age ambiguity, undermining the standard Age of Information (AoI) metric and obscuring the critical trade-off between data freshness and transmission efficiency. To bridge this gap, we propose a novel cross-layer optimization framework centered on a new metric, the Cross-layer Age of Error Information (C-AoEI). We derive a closed-form expression for C-AoEI, explicitly linking freshness to system parameters, establishing an explicit analytical connection between freshness degradation and channel dynamics. Building on this, we develop a packet-level encoded L-HARQ scheme for multi-GBS scenarios and an adaptive algorithm that jointly optimizes coding and decision thresholds. Extensive simulations demonstrate the effectiveness of our proposed framework: it achieves 31.8% higher transmission efficiency and 17.2% lower C-AoEI than conventional schemes. The framework also proves robust against inter-cell interference and varying channel conditions, providing a foundation for designing efficient, latency-aware next-generation S-IoT protocols.

</details>


### [120] [A Data-Driven Krasovskii-Based Approach for Safety Controller Design of Time-Delayed Uncertain Polynomial Systems](https://arxiv.org/abs/2601.20298)
*Omid Akbarzadeh,MohammadHossein Ashoori,Amy Nejati,Abolfazl Lavaei*

Main category: eess.SY

TL;DR: 提出了一种基于数据驱动的Krasovskii控制屏障证书框架，用于未知动态、带有时滞和扰动的离散时间不确定系统，实现无需模型的安全控制器设计。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理具有未知时滞和扰动的系统时受限于模型依赖和缺乏对时滞的显式建模，本文旨在不依赖精确模型的情况下实现鲁棒安全控制。

Method: 基于观测到的输入-状态数据，构建Krasovskii型控制屏障证书，将时滞项纳入屏障函数，并通过数据驱动的SOS优化求解RK-CBC和R-SC。

Result: 成功实现了对三类系统（包括两个物理系统）的鲁棒安全控制，在存在未知扰动和时滞的情况下保证了无限时间范围内的安全性。

Conclusion: 所提方法能够有效应对模型未知、时滞和扰动耦合的挑战，为数据驱动的安全控制提供了可扩展的系统化设计途径。

Abstract: We develop a data-driven framework for the synthesis of robust Krasovskii control barrier certificates (RK-CBC) and corresponding robust safety controllers (R-SC) for discrete-time input-affine uncertain polynomial systems with unknown dynamics, while explicitly accounting for unknown-but-bounded disturbances and time-invariant delays using only observed input-state data. Although control barrier certificates have been extensively studied for safety analysis of control systems, existing work on unknown systems with time delays, particularly in the presence of disturbances, remains limited. The challenge of safety synthesis for such systems stems from two main factors: first, the system's mathematical model is unavailable; and second, the safety conditions should explicitly incorporate the effects of time delays on system evolution during the synthesis process, while remaining robust to unknown disturbances. To address these challenges, we develop a data-driven framework based on Krasovskii control barrier certificates, extending the classical CBC formulation for delay-free systems to explicitly account for time delays by aggregating delayed components within the barrier construction. The proposed framework relies solely on input-state data collected over a finite time horizon, enabling the direct synthesis of RK-CBC and R-SC from observed trajectories without requiring an explicit system model. The synthesis is cast as a data-driven sum-of-squares (SOS) optimization program, yielding a structured design methodology. As a result, robust safety is guaranteed in the presence of unknown disturbances and time delays over an infinite time horizon. The effectiveness of the proposed method is demonstrated through three case studies, including two physical systems.

</details>


### [121] [Reducing End-to-End Latency of Cause-Effect Chains with Shared Cache Analysis](https://arxiv.org/abs/2601.20427)
*Yixuan Zhu,Yinkang Gao,Bo Zhang,Xiaohang Gong,Binze Jiang,Lei Gong,Wenqi Lou,Teng Wang,Chao Wang,Xi Li,Xuehai Zhou*

Main category: eess.SY

TL;DR: 本文提出了一种针对多核平台上具有共享缓存的多链系统的端到端延迟分析框架，通过在基本块级别构建细粒度的跨核内存访问上下文，结合调度信息和因果链结构特征，提高了共享缓存分析精度，降低了最坏情况执行时间（WCET）的高估问题，实验显示最大端到端延迟平均减少可达34%（双核）和26%（四核）。


<details>
  <summary>Details</summary>
Motivation: 在多核平台上，传统方法因缺乏调度信息而导致共享缓存访问被过度悲观估计（如全为失效），从而高估任务的最坏执行时间（WCET），影响因果链端到端延迟分析的准确性；因此需要一种能结合调度信息与链结构特征的更精确分析方法。

Method: 提出一个新的端到端延迟分析框架，在基本块级别提取因果链的调度信息和结构特征，构建细粒度且可扩展的跨核内存访问上下文，用于时间敏感的共享缓存分析，从而获得更准确的WCET（TSC-WCET）估计，并用于计算端到端延迟。

Result: 在双核和四核系统上进行实验，结果显示在特定配置下，因果链的最大端到端延迟平均分别降低34%和26%，验证了该方法在提升分析精度方面的有效性。

Conclusion: 所提出的分析框架能够有效整合调度信息与因果链结构特征，显著提高共享缓存行为预测的精确性，减少WCET和端到端延迟的悲观性，适用于安全关键的多核实时系统设计与分析。

Abstract: Cause-effect chains, as a widely used modeling method in real-time embedded systems, are extensively applied in various safety-critical domains. End-to-end latency, as a key real-time attribute of cause-effect chains, is crucial in many applications. But the analysis of end-to-end latency for cause-effect chains on multicore platforms with shared caches still presents an unresolved issue. Traditional methods typically assume that the worst-case execution time (WCET) of each task in the cause-effect chain is known. However, in the absence of scheduling information, these methods often assume that all shared cache accesses result in misses, leading to an overestimation of WCET and, consequently, affecting the accuracy of end-to-end latency. However, effectively integrating scheduling information into the WCET analysis process of the chains may introduce two challenges: first, how to leverage the structural characteristics of the chains to optimize shared cache analysis, and second, how to improve analysis accuracy while avoiding state space explosion.
  To address these issues, this paper proposes a novel end-to-end latency analysis framework designed for multi-chain systems on multicore platforms with shared caches. This framework extracts scheduling information and structural characteristics of cause-effect chains, constructing fine-grained and scalable inter-core memory access contexts at the basic block level for time-sensitive shared cache analysis. This results in more accurate WCET (TSC-WCET) estimates, which are then used to derive the end-to-end latency. Finally, we conduct experiments on dual-core and quad-core systems with various cache configurations, which show that under certain settings, the average maximum end-to-end latency of cause-effect chains is reduced by up to 34% and 26%.

</details>


### [122] [A Timing-Anomaly Free Dynamic Scheduling on Heterogeneous Systems](https://arxiv.org/abs/2601.20445)
*Yixuan Zhu,Yinkang Gao,Lei Gong,Binze Jiang,Xiaohang Gong,Zihan Wang,Cheng Tang,Wenqi Lou,Teng Wang,Chao Wang,Xi Li,Xuehai Zhou*

Main category: eess.SY

TL;DR: 本文提出了一种针对异构系统的无时序异常的动态调度算法——确定性动态执行（Deterministic Dynamic Execution），通过引入执行约束来消除局部执行时间减少导致系统整体响应时间增加的时序异常问题，实现了安全且紧致的最坏情况响应时间（WCRT）估计。


<details>
  <summary>Details</summary>
Motivation: 动态调度算法在异构系统中广泛应用，但可能引入时序异常，使得传统WCRT分析过于悲观或不安全，且常需穷举状态空间以保证正确性，因此需要一种既能保持调度灵活性又能避免时序异常的方法。

Method: 提出确定性动态执行算法，通过在运行时对任务的资源分配和执行顺序施加部分限制的确定性执行约束来消除时序异常；基于形式化定义的异构系统调度执行进度模型，证明了约束的正确性和有效性；并提出了两种生成执行约束的方法：一种从现有调度算法的执行轨迹中直接提取，另一种采用启发式方法构建以进一步降低WCRT。

Result: 实验结果表明，在多种系统配置下的合成DAG任务集上，所提方法相比传统动态调度算法不仅能完全消除时序异常，还能显著降低WCRT和响应时间抖动。

Conclusion: 确定性动态执行是一种有效的动态调度方案，能够在保证安全性的同时提供紧致的响应时间分析，适用于对实时性要求严格的异构计算环境。

Abstract: Heterogeneous systems commonly adopt dynamic scheduling algorithms to improve resource utilization and enhance scheduling flexibility. However, such flexibility may introduce timing anomalies, wherein locally reduced execution times can lead to an increase in the overall system execution time. This phenomenon significantly complicates the analysis of Worst-Case Response Time (WCRT), rendering conventional analysis either overly pessimistic or unsafe, and often necessitating exhaustive state-space exploration to ensure correctness.
  To address this challenge, this paper presents the first timing-anomaly-free dynamic scheduling algorithm for heterogeneous systems, referred to as Deterministic Dynamic Execution. It achieves a safe and tight WCRT estimate through a single offline simulation execution. The core idea is to apply deterministic execution constraints, which partially restrict the resource allocation and execution order of tasks at runtime. Based on a formally defined execution progress model for heterogeneous system scheduling, we prove the correctness of the proposed execution constraints and their ability to eliminate timing anomalies. Furthermore, we propose two methods to generate execution constraints. The first method derives execution constraints directly from the execution traces produced by existing scheduling algorithms. The second method is a heuristic-based approach that constructs execution constraints, enabling further reduction of the WCRT. Experimental results on synthetically generated DAG task sets under various system configurations demonstrate that, compared to traditional dynamic scheduling algorithms, our approach not only eliminates timing anomalies but also effectively reduces both the WCRT and response time jitter.

</details>


### [123] [Tilt-based Aberration Estimation in Transmission Electron Microscopy](https://arxiv.org/abs/2601.20561)
*Jilles S. van Hulst,Erik M. Franken,Bart J. Janssen,W. P. M. H.,Heemels,Duarte J. Antunes*

Main category: eess.SY

TL;DR: 本文提出了一种基于卡尔曼滤波和优化电子束倾斜序列的方法，用于透射电镜中像差系数的实时估计与校正，显著缩短了对准时间。


<details>
  <summary>Details</summary>
Motivation: 透射电镜因透镜缺陷和环境因素产生像差，影响成像质量，且像差会随时间漂移，需高效、准确的估计与补偿方法。

Method: 利用电子束倾斜与图像位移的关系，采用卡尔曼滤波估计像差系数并建模其时变漂移；通过最小化预测误差协方差的迹（A最优准则）离线优化倾斜序列，并结合多起点梯度法求解非凸优化问题；使用期望最大化（EM）算法估计样本相关噪声特性以定制优化方案。

Result: 在真实TEM系统上验证了多种优化倾斜模式，结果表明优化模式显著优于传统方法，像差与漂移模型能准确反映物理现象，对准时间从数分钟减少到一分钟以内。

Conclusion: 所提方法实现了高精度、快速的像差估计与跟踪，大幅提升了TEM对准效率，具有实际应用价值。

Abstract: Transmission electron microscopes (TEMs) enable atomic-scale imaging but suffer from aberrations caused by lens imperfections and environmental conditions, reducing image quality. These aberrations can be compensated by adjusting electromagnetic lenses, but this requires accurate estimates of the aberration coefficients, which can drift over time. This paper introduces a method for the estimation of aberrations in TEM by leveraging the relationship between an induced electron beam tilt and the resulting image shift. The method uses a Kalman filter (KF) to estimate the aberration coefficients from a sequence of image shifts, while accounting for the drift of the aberrations over time. The applied tilt sequence is optimized by minimizing the trace of the predicted error covariance in the KF, which corresponds to the A-optimality criterion in experimental design. We show that this optimization can be performed offline, as the cost criterion is independent of the actual measurements. The resulting non-convex optimization problem is solved using a gradient-based, receding-horizon approach with multi-starts. Additionally, we develop an approach to estimate specimen-dependent noise properties using expectation maximization (EM), which are then used to tailor the tilt pattern optimization to the specific specimen being imaged. The proposed method is validated on a real TEM set-up with several optimized tilt patterns. The results show that optimized patterns significantly outperform naive approaches and that the aberration and drift model accurately captures the underlying physical phenomena. In total, the alignment time is reduced from typically several minutes to less than a minute compared to the state-of-the-art.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [124] [Critical Transit Infrastructure in Smart Cities and Urban Air Quality: A Multi-City Seasonal Comparison of Ridership and PM2.5](https://arxiv.org/abs/2601.19937)
*Sean Elliott,Sohini Roy*

Main category: physics.soc-ph

TL;DR: 本研究整合了美国四个大都市区的公共交通乘客量与环境PM2.5数据，构建了一个透明、多源的监测数据集，揭示了出行与空气质量之间的非一致性关系，并提出了支持可持续城市发展的可扩展分析框架。


<details>
  <summary>Details</summary>
Motivation: 缺乏可重复的智慧城市分析流程来连接公共交通出行与空气质量，限制了对城市移动性与公共健康之间关系的理解和政策制定。

Method: 整合美国环保署AQS的PM2.5数据与机构报告的乘客量数据，统一不同来源的乘客数据至月度总量，并结合月均PM2.5进行跨城市比较，采用轻量回归模型进行描述性敏感性分析。

Result: 发现各城市在公共交通规模和强度方面存在显著结构性差异，出行量和PM2.5均呈现季节性变化，但城市间出行与PM2.5的关系不一致，且受城市基线效应强烈影响。

Conclusion: 集成出行与环境监测是可行的智慧城市能力，该框架可支持以公共健康为导向的城市韧性规划和基础设施利用评估。

Abstract: Public transit is a critical component of urban mobility and equity, yet mobility and air-quality linkages are rarely operationalized in reproducible smart-city analytics workflows. This study develops a transparent, multi-source monitoring dataset that integrates agency-reported transit ridership with ambient fine particulate matter PM2.5 from the U.S. EPA Air Quality System (AQS) for four U.S. metropolitan areas - New York City, Chicago, Las Vegas, and Phoenix, using two seasonal snapshots (March and October 2024). We harmonize heterogeneous ridership feeds (daily and stop-level) to monthly system totals and pair them with monthly mean PM2.5 , reporting both absolute and per-capita metrics to enable cross-city comparability. Results show pronounced structural differences in transit scale and intensity, with consistent seasonal shifts in both ridership and PM2.5 that vary by urban context. A set of lightweight regression specifications is used as a descriptive sensitivity analysis, indicating that apparent mobility-PM2.5 relationships are not uniform across cities or seasons and are strongly shaped by baseline city effects. Overall, the paper positions integrated mobility and environment monitoring as a practical smart-city capability, offering a scalable framework for tracking infrastructure utilization alongside exposure-relevant air-quality indicators to support sustainable communities and public-health-aware urban resilience.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [125] [Do Whitepaper Claims Predict Market Behavior? Evidence from Cryptocurrency Factor Analysis](https://arxiv.org/abs/2601.20336)
*Murad Farzulla*

Main category: q-fin.CP

TL;DR: 该研究通过结合零样本NLP分类与CP张量分解，分析加密货币白皮书中的声明与市场行为之间的对齐程度，发现两者之间整体对齐性较弱。


<details>
  <summary>Details</summary>
Motivation: 探究加密货币项目白皮书中所宣称的技术功能与实际市场表现之间是否存在一致关系，以检验叙事是否影响市场因子结构。

Method: 构建一个包含24份白皮书（10个语义类别）、49种资产两年小时级市场数据的多模态分析管道，采用BART-MNLI进行零样本文本分类，CP张量分解提取潜在因子（秩为2，解释92.45%方差），并通过Procrustes旋转和Tucker一致性系数衡量三者空间（声明、市场统计、潜在因子）在23个共有实体上的对齐程度，使用DeBERTa-v3进行交叉验证。

Result: 三组对比均显示弱对齐：声明-统计（phi=0.341, p=0.332），声明-因子（phi=0.077, p=0.747），统计-因子（phi=0.197, p<0.001）；统计-因子显著说明方法有效；DeBERTa-v3验证显示32%完全一致但67%前三一致；横截面分析显示NEAR、MKR、ATOM正向对齐，ENS、UNI、比特币偏离最大；排除比特币后结果稳健。

Conclusion: 白皮书叙事与市场因子结构之间仅存在弱对齐，可排除强对齐（phi≥0.70），但受限于样本量（n=23）无法区分弱对齐与无对齐；结果对叙事经济学和投资分析具有启示意义。

Abstract: Cryptocurrency projects articulate value propositions through whitepapers, making claims about functionality and technical capabilities. This study investigates whether these narratives align with observed market behavior. We construct a pipeline combining zero-shot NLP classification (BART-MNLI) with CP tensor decomposition to compare three spaces: (1) a claims matrix from 24 whitepapers across 10 semantic categories, (2) market statistics for 49 assets over two years of hourly data, and (3) latent factors from tensor decomposition (rank 2, 92.45% variance explained). Using Procrustes rotation and Tucker's congruence coefficient, we test alignment across 23 common entities.
  Results show weak alignment: claims-statistics (phi=0.341, p=0.332), claims-factors (phi=0.077, p=0.747), and statistics-factors (phi=0.197, p<0.001). The statistics-factors significance validates our methodology, confirming the pipeline detects relationships when present. Inter-model validation with DeBERTa-v3 yields 32% exact agreement but 67% top-3 agreement. Cross-sectional analysis reveals heterogeneous contributions: NEAR, MKR, ATOM show positive alignment while ENS, UNI, Bitcoin diverge most. Excluding Bitcoin confirms results are not driven by market dominance.
  We interpret findings as weak alignment between whitepaper narratives and market factor structure. Limited power (n=23) precludes distinguishing weak from no alignment, but strong alignment (phi>=0.70) can be confidently rejected. Implications for narrative economics and investment analysis are discussed.

</details>
