{"id": "2601.14899", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.14899", "abs": "https://arxiv.org/abs/2601.14899", "authors": ["George Contopoulos", "Athanasios C. Tzemos", "Foivos Zanias"], "title": "Limits of the Formal Integrals of Motion", "comment": "10 Figures", "summary": "We consider a formal (approximate) integral of motion in Hamiltonians of the form $H=\\frac{1}{2}(X^2+Y^2+ω_1^2x^2+ω_2^2y^2)+ε(ηxy^2+αx^3+βx^2y+γy^3)$ generalizing previous cases with $β=γ=0$. First we give the general form of this integral when $ω_1/ω_2$ is irrational and then we consider the case of commensurable frequencies. In particular we study the integrals for the resonances $ω_1/ω_2=4/1, 5/1, 3/2, 4/3, 3/1$ and $2/1$. We also calculate the invariant curves and the orbits in the cases $ω_1/ω_2=2/1$ and $1/1$ (with $β=γ=0$) and we compare the exact-numerical and the theoretical results predicted by the formal integral when $βγ\\neq0$. In the special case $ω_1/ω_2=1/1$ we find an integral when $β=γ=0$ and $ηα\\neq0$ or $η=α=0$ and $βγ\\neq 0$, but this is not possible when $ηαβγ\\neq 0$. However, we find that the invariant curves and the orbits can be approximated by a non-resonant integral with $ω_1/ω_2=5\\sqrt{2}/7=1.010\\dots$."}
{"id": "2601.15225", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2601.15225", "abs": "https://arxiv.org/abs/2601.15225", "authors": ["Yiannis F. Contoyiannis", "Stelios M. Potirakis"], "title": "The phenomenon of resonance in the continuous phase transition of finite-size systems: A passage from Classical World to Quantum World through the resonance?", "comment": null, "summary": "In finite-size systems undergoing a continuous phase transition, the passage from the symmetric phase to the broken-symmetry phase is accomplished through a hysteresis zone, up to spontaneous symmetry breaking (SSB). In the present work, we find that a resonance phenomenon takes place within this zone. This resonance is manifested as a maximization of the mean waiting time as a function of temperature inside the hysteresis region. An interesting issue concerns how this resonance is connected with the existence of particles (tachyons) or quasiparticles (kink solitons) within the hysteresis zone. Finally, we introduce the idea that this resonance delineates a continuous passage from a \"classical\" phase to a \"quantum\" phase for a binary system, such as the three-dimensional Ising model, which belongs to the same universality class as a fermion-antifermion system or, more generally, a matter-antimatter system."}
{"id": "2601.14402", "categories": ["cs.SI", "cs.GT"], "pdf": "https://arxiv.org/pdf/2601.14402", "abs": "https://arxiv.org/abs/2601.14402", "authors": ["Michael Cui", "Chenxin Dai", "Yixuan Even Xu", "Fei Fang"], "title": "A Unified Framework for Scalable and Robust Paper Assignment", "comment": null, "summary": "Assigning papers to reviewers is a central challenge in the peer-review process of large academic conferences. Program chairs must balance competing objectives, including maximizing reviewer expertise, promoting diversity, and enhancing robustness to strategic manipulation, but it is challenging to do so at the modern conference scale.\n  Existing algorithmic paper assignment approaches either fail to address all of these goals simultaneously or suffer from poor scalability. To address the limitation, we propose Robust Assignment via Marginal Perturbation (RAMP), a unified framework for large-scale peer review. Our approach formulates a linearized perturbed-maximization objective with soft constraints that flexibly balance assignment quality, diversity, and robustness while maintaining runtime efficiency. We further introduce an attribute-aware sampling procedure that converts fractional solutions into integral assignments and improves the diversity and robustness of the final assignment. On datasets with over 20,000 papers and 20,000 reviewers, RAMP runs in under 20 minutes, demonstrating its suitability for real-world deployment."}
{"id": "2601.14733", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.14733", "abs": "https://arxiv.org/abs/2601.14733", "authors": ["Hongyu Wang", "Jingfang Fan", "Fei Xie", "Jingyuan Li", "Rui Shi", "Yan Xia", "Deliang Chen", "Xiaosong Chen"], "title": "The Interdecadal Bipolar Oscillation: An Atmospheric Water Vapor Mode Driving Asynchronous Polar Climate Change", "comment": "33 pages, 6 figures", "summary": "Climate change is progressing asynchronously between the Arctic and Antarctic, with important implications for global climate dynamics. While the Arctic has experienced rapid warming and pronounced amplification, the Antarctic has exhibited a delayed and heterogeneous response. Here, we identify an Interdecadal Bipolar Oscillation (IBO) in atmospheric water vapor, a coherent internal mode of variability that connects the two polar regions and helps explain their divergent climate trajectories over the past eight decades. Using reanalysis data alongside historical and pre-industrial control simulations from CMIP6, we demonstrate that the IBO is a robust internal variability mode with a quasi-period of 60 ~ 80 years. This oscillation modulates the background warming signal, with a phase shift in the late 1980s amplifying moistening and warming in the Arctic while concurrently suppressing changes in the Antarctic. Crucially, model projections suggest a possible phase reversal, which could slow water vapor increases in the Arctic while accelerating them in the Antarctic, potentially marking the start of rapid Antarctic climate change. While uncertainties remain in how climate models capture polar water vapor, our findings highlight the IBO as a pivotal driver of polar climate evolution and a potential contributor to emerging climate risks in the Southern Hemisphere."}
{"id": "2601.14607", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2601.14607", "abs": "https://arxiv.org/abs/2601.14607", "authors": ["Chaohua Liang", "Jun Matsushima"], "title": "SeisBind: Physics-Aware Tri-Modal Representation Binding for Seismic Data via Contrastive Learning", "comment": null, "summary": "This letter proposes a physics-aware multi-modal contrastive learning framework designed to transform complex seismic wavefields into human-readable physical representations. Traditional data-driven inversion methods often focus on pixel-wise mapping, which lacks physical grounding and interpretability. To address this, we introduce a novel framework that jointly aligns seismic shot gathers, subsurface velocity models, and explicit physical descriptors (e.g., mean velocity and gradients) in a shared latent space. By introducing these descriptors as a third modality, our approach encourages the learned embeddings to capture intrinsic geological semantics rather than superficial signal correlations. Experiments on the OpenFWI dataset demonstrate that the proposed method not only achieves robust seismic-to-velocity retrieval but also preserves meaningful physical semantics, enabling cross-modal inference of interpretable attributes. This representation-centric perspective provides a flexible foundation for expert-guided subsurface characterization."}
{"id": "2601.14399", "categories": ["physics.comp-ph", "hep-ex", "hep-ph", "nucl-ex", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14399", "abs": "https://arxiv.org/abs/2601.14399", "authors": ["Lukas Heinrich", "Tom Magorsch"], "title": "Differentiable quantum-trajectory simulation of Lindblad dynamics for QGP transport-coefficient inference", "comment": "13 pages, 4 figures", "summary": "We study parameter estimation for the transport coefficients of the quark-gluon plasma by differentiating open-quantum-system-based Monte Carlo simulations of quarkonium suppression. The underlying simulator requires solving a Lindblad equation in a large Hilbert space, which makes parameter estimation computationally expensive. We approach the problem using gradient-based optimization. Specifically, we apply the score-function gradient estimator to differentiate through discrete jump sampling in the Monte Carlo wave-function algorithm used to solve the Lindblad equation. The resulting stochastic gradient estimator exhibits sufficiently low variance and can still be estimated in an embarrassingly parallel manner, enabling efficient scaling of the simulations. We implement this gradient estimator in the existing open-source quarkonium suppression code QTraj. To demonstrate its utility for parameter estimation, we infer the two transport coefficients $\\hatκ$ and $\\hatγ$ using gradient-based optimization on synthetic nuclear modification factor data."}
{"id": "2601.14586", "categories": ["math.ST", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.14586", "abs": "https://arxiv.org/abs/2601.14586", "authors": ["Dan Cheng", "John Ginos"], "title": "Cluster size distributions of discrete random fields", "comment": null, "summary": "We study discrete random fields $\\{X_t: t\\in \\mathbb{Z}^d\\}$ parameterized on the $d$-dimensional integer lattice $\\mathbb{Z}^d$. For a fixed threshold $u$, the excursion set $\\{t \\in \\mathbb{Z}^d : X_t > u\\}$ decomposes into connected components or clusters, whose size, defined as the number of lattice points they contain, are random. This paper investigates the probability distribution of these cluster sizes. For stationary random fields, we derive exact expressions for the cluster size distribution. To address nonstationary settings, we introduce a peak-based cluster size distribution, which characterizes the distribution of cluster sizes conditional on the presence of a local maximum above $u$. This formulation provides a tractable alternative when exact cluster size distributions are analytically inaccessible. The proposed framework applies broadly to Gaussian and non-Gaussian random fields, relying only on their joint dependence structure. Our results provide a theoretical foundation for quantifying spatial extent in discretely sampled data, with applications to medical imaging, geoscience, environmental monitoring, and other scientific areas where thresholded random fields naturally arise."}
{"id": "2601.14573", "categories": ["hep-lat", "cond-mat.supr-con", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.14573", "abs": "https://arxiv.org/abs/2601.14573", "authors": ["M. N. Chernodub", "V. A. Goy", "A. V. Molochkov"], "title": "Acoustic phonons in a magnetized vacuum? First-principle lattice results on the mass spectrum of the electroweak model in a strong magnetic field", "comment": "10 pages, 2 figures", "summary": "We use numerical Monte Carlo simulations to determine the mass spectrum of the bosonic sector of the electroweak model in an external magnetic field of the electroweak-scale strength ($10^{20}\\,{\\rm T}$) at zero temperature. It is known that as the magnetic field gets stronger, the electroweak vacuum undergoes two consecutive crossover-type transitions, passing from (i) the conventional symmetry-broken homogeneous phase to (ii) an intermediate inhomogeneous vortex phase characterized by a (superconducting) condensate of electrically charged $W$ bosons and then to (iii) a homogeneous phase with a restored electroweak symmetry. We show that the spin component of the $W$ boson aligned with the direction of the magnetic field is the lightest excitation in all three phases. Its mass continuously decreases in the low-field broken phase and becomes very small in the intermediate phase. We argue that this nearly massless excitation corresponds to a Goldstone acoustic phonon mode associated with vibrations of the lattice of electroweak vortices. In the high-field symmetry-restored phase, where the vortices disappear, the lightest $W$ mass rises again. Neither Higgs nor $Z$ boson masses vanish across all studied phases and crossover transitions."}
{"id": "2601.14286", "categories": ["cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14286", "abs": "https://arxiv.org/abs/2601.14286", "authors": ["Wentao Jiang", "Jingxin Wang", "Zhang Hu", "Zhengyuan Shi", "Chengyu Ma", "Qiang Xu", "Weikang Qian", "Zhufei Chu"], "title": "GNN-based Path-aware multi-view Circuit Learning for Technology Mapping", "comment": "7pages, 4figures", "summary": "Traditional technology mapping suffers from systemic inaccuracies in delay estimation due to its reliance on abstract, technology-agnostic delay models that fail to capture the nuanced timing behavior behavior of real post-mapping circuits. To address this fundamental limitation, we introduce GPA(graph neural network (GNN)-based Path-Aware multi-view circuit learning), a novel GNN framework that learns precise, data-driven delay predictions by synergistically fusing three complementary views of circuit structure: And-Inverter Graphs (AIGs)-based functional encoding, post-mapping technology emphasizes critical timing paths. Trained exclusively on real cell delays extracted from critical paths of industrial-grade post-mapping netlists, GPA learns to classify cut delays with unprecedented accuracy, directly informing smarter mapping decisions. Evaluated on the 19 EPFL combinational benchmarks, GPA achieves 19.9%, 2.1% and 4.1% average delay reduction over the conventional heuristics methods (techmap, MCH) and the prior state-of-the-art ML-based approach SLAP, respectively-without compromising area efficiency."}
{"id": "2601.14468", "categories": ["eess.SY", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.14468", "abs": "https://arxiv.org/abs/2601.14468", "authors": ["Milad Hasanzadeh", "Amin Kargarian", "Javad Lavaei"], "title": "All-Pass Fractional OPF: A Solver-Friendly, Physics-Preserving Approximation of AC OPF", "comment": null, "summary": "This paper presents a fractional approximation of the AC optimal power flow (AC OPF) problem based on an all-pass approximation of the exponential power flow kernel. The classical AC OPF relies on trigonometric coupling between bus voltage phasors, which yields a nonconvex program with oscillatory derivatives that can slow, or in some cases destabilize, interior-point methods. We replace the trigonometric terms with an all-pass fractional (APF) approximation whose real and imaginary components act as smooth surrogates for the cosine and sine functions, and we introduce a pre-rotation to shift the argument of the approximation toward its most accurate region, ensuring that the reformulated power flow model preserves physical loss behavior, maintains the symmetry of the classical kernels, and improves the conditioning of the Jacobian and Hessian matrices. The proposed APF OPF formulation remains nonconvex, as in the classical model, but it eliminates trigonometric evaluations and empirically produces larger and more stable Newton steps under standard interior-point solvers. Numerical results on more than 25 IEEE and PGLib test systems ranging from 9 to 10{,}000 buses demonstrate that the APF OPF model achieves solutions with accuracy comparable to that of the classical formulation while reducing solver times, indicating a more solver-friendly nonconvex representation of AC OPF. All code, functions, verification scripts, and generated results are publicly available on \\href{https://github.com/LSU-RAISE-LAB/APF-OPF}{GitHub}, along with a README describing how to run and reproduce the experiments."}
{"id": "2601.14329", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14329", "abs": "https://arxiv.org/abs/2601.14329", "authors": ["Huawei Zhao", "Xinlei Liu", "Xinyao Huang", "Guofeng Zhang"], "title": "Advances in non-Hermitian dynamics of quadratic bosonic systems", "comment": "25 pages, in Chinese language, 9 figures,Accepted by Acta Physica Sinica", "summary": "Non-Hermitian physics has emerged as a rapidly advancing field of research, revealing a range of novel phenomena and potential applications. Traditional non-Hermitian Hamiltonians are typically simulated by constructing asymmetric couplings or by introducing dissipation and gain to realize non-Hermitian systems. The quadratic bosonic system (QBS) with squeezing interaction is intrinsically Hermitian; however, its dynamical evolution matrix in both real and momentum spaces is non-Hermitian. Based on this, applying a field-operator transformation xp to the dynamical evolution matrix yields quadrature nonreciprocal transmission between the x and p operators. This nonreciprocal characteristic can be utilized in signal amplifiers. On the other hand, within the Bogoliubov-de Gennes framework in momentum space, one can observe non-Hermitian topological phenomena such as point-gap topology and the non-Hermitian skin effect, both induced by spectra with nonzero winding numbers. Additionally, QBS can be employed to realize non-Hermitian Aharonov-Bohm cages and to extend non-Bloch band theory. Previous studies in non-Hermitian physics have largely concentrated on classical systems. The influence of non-Hermitian properties on quantum effects remains a key issue awaiting exploration and has evolved into a research direction at the interface of non-Hermitian and quantum physics."}
{"id": "2601.14382", "categories": ["cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14382", "abs": "https://arxiv.org/abs/2601.14382", "authors": ["Katarina Karlova", "Afonso Rufino", "Taras Verkholyak", "Nils Caci", "Stefan Wessel", "Jozef Strecka", "Frederic Mila", "Andreas Honecker"], "title": "Approaching Kasteleyn transition in frustrated quantum Heisenberg antiferromagnets", "comment": "9 pages of main text and 6 pages of supplemental material, 9 figures in total", "summary": "We show that the Kasteleyn transition, the abrupt proliferation of infinite strings of defects in classical dimer and related models, can also be relevant for frustrated 2d quantum magnets. This is explicitly demonstrated in a phase of the spin-1/2 Heisenberg diamond-decorated honeycomb lattice where a family of exact eigenstates built as products of dimer and plaquette singlets can be mapped onto the dimer coverings of the honeycomb lattice. The low-temperature properties of this phase are accurately described by an effective dimer model with anisotropic activities and a small, tunable density of monomers, leading to an arbitrarily sharp crossover version of the Kasteleyn transition. The generalization to other geometries and the possibility to realize this model in organo-metallic compounds are briefly discussed."}
{"id": "2601.14316", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14316", "abs": "https://arxiv.org/abs/2601.14316", "authors": ["Gabriele Cafiero", "Luca Molinari", "Jonte R. Hance"], "title": "The burden of Fundamentality: Metaphysical ambiguities and the issue of Superdeterminism", "comment": "15 pages, 2 figures", "summary": "In this paper we approach the problem of superdeterminism from a novel point of view, highlighting its character as a more metaphysical than scientific proposition. First, we introduce a distinction between two types of superdeterministic theories, naïve (NSD) and metaphysical (MSD), and argue how NSD presents significant epistemic flaws. We show how NSD justifies itself through claims to fundamentality, thus connoting itself as a metaphysical theory rather than a scientific one. We finally illustrate that the most developed MSD model so far, Invariant Set Theory, implicitly proposes a confused form of priority monism. Our paper thus reinforces the thesis that theories should demonstrate rather than assume fundamentality and that it is methodologically flawed for a theory to assume its own fundamentality for the sole purpose of defending against criticisms."}
{"id": "2601.14272", "categories": ["q-fin.RM", "cs.CE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14272", "abs": "https://arxiv.org/abs/2601.14272", "authors": ["Ekleen Kaur"], "title": "The Limits of Lognormal: Assessing Cryptocurrency Volatility and VaR using Geometric Brownian Motion", "comment": "Paper was presented at Hinweis Second International Conference on Recent Trends in Engineering and Technology (RTET) on December 28th 2025, http://rtet.thehinweis.com/. All the accepted registered conference papers will be published in the International Journal on Engineering and Technology and the same paper will be indexed as Conference Proceedings on Scopus and Cross Ref", "summary": "The integration of cryptocurrencies into institutional portfolios necessitates the adoption of robust risk modeling frameworks. This study is a part of a series of subsequent works to fine-tune model risk analysis for cryptocurrencies. Through this first research work, we establish a foundational benchmark by applying the traditional industry-standard Geometric Brownian Motion (GBM) model. Popularly used for non-crypto financial assets, GBM assumes Lognormal return distributions for a multi-asset cryptocurrency portfolio (XRP, SOL, ADA). This work utilizes Maximum Likelihood Estimation and a correlated Monte Carlo Simulation incorporating the Cholesky decomposition of historical covariance. We present our stock portfolio model as a Minimum Variance Portfolio (MVP). We observe the model's structural shift within the heavy-tailed, non-Gaussian cryptocurrency environment. The results reveal limitations of the Lognormal assumption: the calculated Value-at-Risk at the 5% confidence level over the one-year horizon. For baselining our results, we also present a holistic comparative analysis with an equity portfolio (AAPL, TSLA, NVDA), demonstrating a significantly lower failure rate. This performance provides conclusive evidence that the GBM model is fundamentally the perfect benchmark for our subsequent works. Results from this novel work will be an indicator for the success criteria in our future model for crypto risk management, rigorously motivating the development and application of advanced models."}
{"id": "2601.14754", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14754", "abs": "https://arxiv.org/abs/2601.14754", "authors": ["Guolin Nan", "Zhijian Li", "Feng Mei", "Zhihao Xu"], "title": "Anomalous Localization and Mobility Edges in Non-Hermitian Quasicrystals with Disordered Imaginary Gauge Fields", "comment": "17 pages, 10 figures", "summary": "We study anomalous localization in a one-dimensional non-Hermitian quasicrystal with a spatially disordered imaginary gauge field. The system is a generalized Aubry-André-Harper (AAH) chain with asymmetric nearest- and next-nearest-neighbor hoppings generated by a Bernoulli imaginary gauge field and a quasiperiodic onsite potential. In the standard non-Hermitian AAH limit, the system undergoes a transition from a fully erratic non-Hermitian skin effect (ENHSE) phase to a fully localized phase. We show that the fractal dimension cannot distinguish these phases, whereas the Lyapunov exponent and center-of-mass fluctuations provide sharp diagnostics. This transition is accompanied by a complex-to-real spectral change under periodic boundary conditions and a topological change of the spectral winding number. With next-nearest-neighbor hopping, we uncover an anomalous mobility edge separating Anderson-localized states from ENHSE states, rather than extended states. This mobility edge is captured by an energy-dependent winding number that vanishes in the localized regime. Finally, we propose a dynamical probe based on wave-packet expansion: for typical disorder realizations, the dynamics shows winding-controlled drift and disorder-selected pinning or boundary-wrapping recurrence, while disorder averaging restores Hermitian-like transport. These results offer practical spectral, topological, and dynamical diagnostics of anomalous localization and mobility edges in non-Hermitian quasicrystals."}
{"id": "2601.14292", "categories": ["physics.soc-ph", "cs.CY", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.14292", "abs": "https://arxiv.org/abs/2601.14292", "authors": ["Halima El Badaoui", "Siddartha Khastgir", "Mariat James Elizebeth", "Shufeng Chen", "Takuya Nakashima", "Paul Jennings"], "title": "Introducing a Novel Systems Thinking approach inspired by STPA: Road Safety Intervention design case study", "comment": null, "summary": "According to the latest provisional statistics released by the UK Department for Transport, Great Britain recorded 1,633 road deaths in 2024, representing a slight increase from 2023 and raising concerns about safety progress, which indicates that preventable fatalities remain a challenge. The deployment of advanced mobility systems, even certified and safety-assessed, is not sufficient to deliver improved safety outcomes, and existing road infrastructure is not sufficiently equipped to prevent severe collisions. Successful application of the ``Safe System'' approach demands systems thinking in an integrated and holistic manner, encompassing all aspects of road safety. This paper argues that road safety must be managed as a complex socio-technical system where risk evolves dynamically and must be continuously monitored. To address these safety gaps, we propose a systems thinking approach that identifies factors contributing to fatal outcomes and mitigates them. The framework consists of four steps: 1) List stakeholders who influence road safety, 2) Model the interactions between these stakeholders, 3) List assumptions that might be identified as factors for fatalities, and 4) Monitor these assumptions throughout the system lifecycle. The approach is applied to the United Kingdom (UK) road network to demonstrate feasibility. The study provides actionable guidance and new KPIs categories for stakeholders to implement road safety monitoring and eliminate any unreasonable road safety risks."}
{"id": "2601.14619", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.14619", "abs": "https://arxiv.org/abs/2601.14619", "authors": ["Hongbo Xia", "Shengxin Liu", "Zhaoquan Gu"], "title": "Maximum Edge-based Quasi-Clique: Novel Iterative Frameworks", "comment": "Appears in the ACM Web Conference (WWW), 2026", "summary": "Extracting cohesive subgraphs from complex networks is a fundamental task in graph analytics and is essential for understanding biological, social, and web graphs. The edge-based $γ$-quasi-clique model offers a flexible alternative by identifying subgraphs whose edge densities exceed a specified threshold $γ$. However, finding the exact maximum edge-based quasi-clique is computationally challenging, as the problem is NP-hard and lacks the hereditary property. These characteristics limit the effectiveness of conventional pruning methods and the development of efficient reduction rules. As a result, existing algorithms, such as QClique and FPCE, struggle to scale to large graphs. In this paper, we revisit the problem and propose a novel iterative framework that reformulates the problem as a sequence of hereditary subproblems, enabling more effective pruning and reduction strategies and improving the worst-case time complexity. Furthermore, we redesign the iterative process and introduce a novel heuristic to further improve practical efficiency. Extensive experiments on 253 large-scale real-world graphs demonstrate that our proposed algorithm EQC-Pro outperforms existing methods by up to four orders of magnitude."}
{"id": "2601.14712", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.14712", "abs": "https://arxiv.org/abs/2601.14712", "authors": ["Bing Xiao", "Nan Li", "Wenqian Kong", "Rui Chu", "Hongyu Zhang", "Guodong Meng", "Kai Wu", "Yonghong Cheng"], "title": "FEcMD: A multi-physics and multi-scale computational program for dynamic coupling molecular dynamics simulations with transient electric field and heat conduction in metal nanostructures", "comment": "57 pages, 18 figures, submitted to Computer Physics Communications", "summary": "Field emission coupled with molecular dynamics simulation (FEcMD) software package is a computational tool for studying atomic structure evolution, structural deformation, phase transitions, recrystallization as well as electron emission characteristics of micro- and nano-protrusions and nanowires consisting of elemental metals or multi-component alloys by means of multi-physics and multi-scale methodology. Current implementations of molecular dynamics simulation coupled with multi-scale electrodynamics (ED) and heat conduction (HC) in FEcMD program are advanced mainly in the two aspects as follows. In electrodynamics, the FEcMD program incorporates the space charge interactions (space charge potential and exchange-correlation effects) in the self-consistent solved Poisson-Schrödinger equation with Wentzel-Kramers-Brillouin-Jeffreys (WKBJ) approximation to evaluate the field emission current density and the related resistive heating process more reliably for nanowires or nano-protrusions especially for nano-gaps between two metal electrodes. Meanwhile, the two-temperature heat conduction model is implemented in electrodynamics coupled with molecular dynamics simulations (ED-MD), providing more dedicated descriptions for the hierarchical electron-phonon two-channel heat conduction mechanism and the temperature evolutions of electron and phonon subsystems under the radiofrequency (RF) or pulse electric fields. Benchmark tests are performed for some key implementations in FEcMD software to validate the numerical results, and also to demonstrate the use of program to study the atomic structure evolution of metal nano-structures under electric field and heating processes."}
{"id": "2601.14872", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14872", "abs": "https://arxiv.org/abs/2601.14872", "authors": ["Hirofumi Ota", "Masaaki Imaizumi"], "title": "Finite-Sample Inference for Sparsely Permuted Linear Regression", "comment": null, "summary": "We study a noisy linear observation model with an unknown permutation called permuted/shuffled linear regression, where responses and covariates are mismatched and the permutation forms a discrete, factorial-size parameter. This unknown permutation is a key component of the data-generating process, yet its statistical investigation remains challenging due to its discrete nature. In this study, we develop a general statistical inference framework on the permutation and regression coefficients. First, we introduce a localization step that reduces the permutation space to a small candidate set building on recent advances in the repro samples method, whose miscoverage decays polynomially with the number of Monte Carlo samples. Then, based on this localized set, we provide statistical inference procedures: a conditional Monte Carlo test of permutation structures with valid finite-sample Type-I error control. We also develop coefficient inference that remains valid under alignment uncertainty of permutations. For computational purposes, we develop a linear assignment problem computable in polynomial time complexity and demonstrate that its solution asymptotically converges to that of the conventional least squares problem with large computational cost. Extensions to partially permuted designs and ridge regularization are also discussed. Extensive simulations and an application to Beijing air-quality data corroborate finite-sample validity, strong power to detect mismatches, and practical scalability."}
{"id": "2601.14967", "categories": ["hep-lat", "hep-ex", "hep-ph"], "pdf": "https://arxiv.org/pdf/2601.14967", "abs": "https://arxiv.org/abs/2601.14967", "authors": ["Heng-Tong Ding", "Hai-Tao Shu", "Cheng Zhang"], "title": "Shear and bulk viscosities of gluon plasma across the transition temperature from lattice QCD", "comment": "16 pages, 10 figures", "summary": "We investigate the temperature dependence of the shear viscosity ($η$) and bulk viscosity ($ζ$) of the gluon plasma using lattice QCD over the range 0.76--2.25 $T_c$, extending from below the transition temperature $T_c$ across the transition region and into the deconfined phase. At each temperature, we employ three large, fine lattices, which enables controlled continuum extrapolations of the energy-momentum tensor correlators. Using gradient flow together with a recently developed blocking technique, we achieve percent level precision for these correlators, providing strong constraints for a model-based spectral analysis. Since the inversion to real-time information is intrinsically ill posed, we extract viscosities by fitting spectral functions whose ultraviolet behavior is matched to the best available perturbative result, while the infrared region is described by a Lorentzian transport peak. The dominant modeling uncertainty associated with the transport-peak width is bracketed by varying it over a physically motivated range set by thermal scales. We find that the shear-viscosity-to-entropy-density ratio, $η/s$, exhibits a minimum near the transition temperature $T_c$ and increases for $T>T_c$, whereas the bulk-viscosity-to-entropy-density ratio, $ζ/s$, decreases monotonically over the entire temperature range studied."}
{"id": "2601.14640", "categories": ["cs.ET", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.14640", "abs": "https://arxiv.org/abs/2601.14640", "authors": ["Naoya Onizawa", "Daisaku Katagiri", "Warren J. Gross", "Takahiro Hanyu"], "title": "Analog-to-Stochastic Converter Using Magnetic Tunnel Junction Devices for Vision Chips", "comment": "24 pages", "summary": "This paper introduces an analog-to-stochastic converter using a magnetic tunnel junction (MTJ) de- vice for vision chips based on stochastic computation. Stochastic computation has been recently exploited for area-efficient hardware implementation, such as low-density parity-check (LDPC) decoders and image processors. However, power-and-area hungry two-step (analog-to-digital and digital-to-stochastic) converters are required for the analog to stochastic signal conversion. To real- ize a one-step conversion, an MTJ device is used as it inherently exhibits a probabilistic switching behavior between two resistance states. Exploiting the device-based probabilistic behavior, analog signals can be directly and area-efficiently converted to stochastic signals to mitigate the signal- conversion overhead. The analog-to-stochastic signal conversion is theoretically described and the conversion characteristic is evaluated using device and circuit parameters. In addition, the resistance variability of the MTJ device is considered in order to compensate the variability effect on the sig- nal conversion. Based on the theoretical analysis, the analog-to-stochastic converter is designed in 90nm CMOS and 100nm MTJ technologies and is verified using a SPICE simulator (NS-SPICE) that handles both transistors and MTJ devices."}
{"id": "2601.14613", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14613", "abs": "https://arxiv.org/abs/2601.14613", "authors": ["Tingwei Zhang", "Jiahui Liu", "David Allstot", "Huaping Liu"], "title": "An Ion-Intercalation Memristor for Enabling Full Parallel Writing in Crossbar Networks", "comment": null, "summary": "Crossbar architectures have long been seen as a promising foundation for in-memory computing, using memristor arrays for high-density, energy-efficient analog computation. However, this conventional architecture suffers from a fundamental limitation: the inability to perform parallel write operations due to the sneak path problem. This arises from the structural overlap of read and write paths, forcing sequential or semi-parallel updates and severely limiting scalability. To address this, we introduce a new memristor design that decouples read and write operations at the device level. This design enables orthogonal conductive paths, and employs a reversible ion doping mechanism, inspired by lithium-ion battery principles, to modulate resistance states independently of computation. Fabricated devices exhibit near-ideal memristive characteristics and stable performance under isolated read/write conditions."}
{"id": "2601.14373", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14373", "abs": "https://arxiv.org/abs/2601.14373", "authors": ["Corentin Lanore", "Xavier Valcarce", "Jean Etesse", "Anthony Martin", "Jean-Daniel Bancal"], "title": "Towards Device-Independent Quantum Key Distribution with Photonic Devices", "comment": "7+21 pages; 3+11 figures", "summary": "Quantum Key Distribution (QKD) protocols enable two distant parties to communicate with information-theoretically proven secrecy. However, these protocols are generally vulnerable to potential mismatches between the physical modeling and the implementation of their quantum operations, thereby opening opportunities for side channel attacks. Device-Independent (DI) QKD addresses this problem by reducing the degree of device modeling to a black-box setting. The stronger security obtained in this way comes at the cost of a reduced noise tolerance, rendering experimental demonstrations more challenging: so far, only one experiment based on trapped ions was able to successfully generate a secret key. Photonic platforms have however long been preferred for QKD thanks to their suitability to optical fiber transmission, high repetition rates, readily available hardware, and potential for circuit integration. In this work, we assess the feasibility of DIQKD on a photonic circuit recently identified by machine learning techniques. For this, we introduce an efficient converging hierarchy of semi-definite programs (SDP) to bound the conditional von Neumann entropy and develop a finite-statistics analysis that takes into account full outcome statistics. Our analysis shows that the proposed optical circuit is sufficiently resistant to noise to make an experimental realization realistic."}
{"id": "2601.14387", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.14387", "abs": "https://arxiv.org/abs/2601.14387", "authors": ["Songela W. Chen", "David T. Limmer"], "title": "Optimal control of bit erasure in stochastic random access memory", "comment": "12 pages, 9 figures", "summary": "Energy costs of information processing are growing exponentially. Bit erasure is a key problem in this energy-information nexus, and a number of seminal relationships have been deduced regarding the relationship between thermodynamic costs and memory storage. To continue making progress in the modern era, however, requires confronting thermodynamic costs in realistic physical systems which operate away from equilibrium. Here, we explore the thermodynamic costs of bit erasure in a complementary metal oxide semiconductor model of two types of random access memory. We find dynamic random access memory dissipates the least amount of energy when operated in the quasistatic limit, where errors are also minimized. By contrast, static random access memory is most efficiently operated in finite time due to the energy required to maintain the state of the bit. We demonstrate a numerically robust optimization scheme using mean field theory and automatic differentiation, finding optimal protocols compatible with electrical engineering insights. These results provide a framework for operating realistic circuits in thermodynamically advantageous ways."}
{"id": "2601.14322", "categories": ["physics.soc-ph", "econ.GN", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2601.14322", "abs": "https://arxiv.org/abs/2601.14322", "authors": ["Karl Svozil"], "title": "Dirac's Dilemma of the Economy of Inheritance: Parental Care, Equality of Opportunity, and Managed Inequality", "comment": "7 pages", "summary": "In a brief reflection on the principles of human society, P. A. M. Dirac articulated a structural tension between two widely affirmed norms: that it is good and natural for parents to improve the prospects of their own children, and that justice requires that all children have equal opportunities in life. These principles, each compelling on its own, cannot be fully realized together. This paper reconstructs Dirac's dilemma, connects it to the dynamics of compounding advantage and inheritance, and situates it within the broader history of political philosophy, including the work of Rawls, Dworkin, Cohen, Brighouse and Swift, Nozick, Murphy and Nagel, and others. The paper argues that attempts to eliminate the resulting injustices entirely risk damaging the non--zero--sum structures that generate general prosperity, and defends a position of \"managed inequality\": a robust social floor and real mobility, combined with limits on extreme dynastic accumulation and an explicit acceptance of some residual, but constrained, inherited advantage."}
{"id": "2601.14810", "categories": ["cond-mat.dis-nn", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14810", "abs": "https://arxiv.org/abs/2601.14810", "authors": ["Anaclara Alvez-Canepa", "Cyril Furtlehner", "François Landes"], "title": "Learning and extrapolating scale-invariant processes", "comment": "29p, 22 figures", "summary": "Machine Learning (ML) has deeply changed some fields recently, like Language and Vision and we may expect it to be relevant also to the analysis of of complex systems. Here we want to tackle the question of how and to which extent can one regress scale-free processes, i.e. processes displaying power law behavior, like earthquakes or avalanches? We are interested in predicting the large ones, i.e. rare events in the training set which therefore require extrapolation capabilities of the model. For this we consider two paradigmatic problems that are statistically self-similar. The first one is a 2-dimensional fractional Gaussian field obeying linear dynamics, self-similar by construction and amenable to exact analysis. The second one is the Abelian sandpile model, exhibiting self-organized criticality. The emerging paradigm of Geometric Deep Learning shows that including known symmetries into the model's architecture is key to success. Here one may hope to extrapolate only by leveraging scale invariance. This is however a peculiar symmetry, as it involves possibly non-trivial coarse-graining operations and anomalous scaling. We perform experiments on various existing architectures like U-net, Riesz network (scale invariant by construction), or our own proposals: a wavelet-decomposition based Graph Neural Network (with discrete scale symmetry), a Fourier embedding layer and a Fourier-Mellin Neural Operator. Based on these experiments and a complete characterization of the linear case, we identify the main issues relative to spectral biases and coarse-grained representations, and discuss how to alleviate them with the relevant inductive biases."}
{"id": "2601.14795", "categories": ["cs.SI", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.14795", "abs": "https://arxiv.org/abs/2601.14795", "authors": ["Naomi Sasaya", "Shigefumi Kishida", "Ryo Kikuchi", "Akira Tajima"], "title": "Validating Behavioral Proxies for Disease Risk Monitoring via Large-Scale E-commerce Data", "comment": "12 pages, 6 figures. Cross-domain validation of behavioral disease proxies using large-scale e-commerce data", "summary": "Digital traces of everyday behavior, such as e-commerce (EC) purchase logs, provide scalable signals for population-level monitoring, yet their epidemiological validity remains unclear due to weak links to clinical outcomes.\n  We propose a behavioral proxy for disease onset based on transitions from regular to therapeutic diets observed in EC purchase histories, and evaluate its validity through large-scale cross-domain analysis. Using EC purchase data (N = 55,645 users) and independent insurance-derived clinical records, we compare ingredient-level risk patterns and seasonal disease dynamics in feline lower urinary tract disease (FLUTD) as a case study.\n  The proxy-based estimates show strong agreement with clinical data, with correlations of r = 0.74 for ingredient-level risk patterns and r = 0.82 for seasonal variation. Both data sources consistently capture elevated disease risk during winter months. Moreover, analysis using EC data alone reproduces established domain knowledge, including the association between higher wet food consumption and lower disease risk.\n  Our results demonstrate that behavioral signals derived from large-scale EC data can serve as validated, cost-effective complements to traditional surveillance systems, and suggest broader applicability to monitoring lifestyle-related and chronic conditions."}
{"id": "2601.14461", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.14461", "abs": "https://arxiv.org/abs/2601.14461", "authors": ["Lukas Netterdon", "Veronica Montanaro", "Manuel Torrilhon", "Hossein Gorji"], "title": "Variance Reduction in the Fokker-Planck Particle Method for Rarefied Gases using Quasi-Random Numbers", "comment": null, "summary": "The Fokker-Planck (FP) particle method accelerates rarefied-gas simulations by replacing the binary collisions of the commonly used Direct Simulation Monte Carlo (DSMC) method with a drift=diffusion process. Like all particle methods, the FP method is inherently stochastic, which leads to statistical fluctuations in macroscopic quantities and necessitates large particle numbers for accurate results. In this work, we investigate the use of quasi-random numbers, which sample distributions more evenly and thereby reduce the variance. To preserve the low-discrepancy structure across time steps, we employ the Array Randomized Quasi-Monte Carlo (Array-RQMC) technique. We combine the FP method with Array-RQMC and compare it in homogeneous and inhomogeneous problems with other commonly used variance-reduction techniques. The proposed FP-Array-RQMC approach achieves improved convergence rates compared with pseudo-random sampling and yields smaller estimator errors for sufficiently large particle numbers."}
{"id": "2601.14947", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14947", "abs": "https://arxiv.org/abs/2601.14947", "authors": ["Giacomo Francisci", "Claudio Agostinelli"], "title": "Central subspace data depth", "comment": "25+34 pages, 7+4 figures", "summary": "Statistical data depth plays an important role in the analysis of multivariate data sets. The main outcome is a center-outward ordering of the observations that can be used both to highlight features of the underlying distribution of the data and as input to further statistical analysis. An important property of data depth is related to symmetric distributions as the point with the highest depth value, the center, coincides with the point of symmetry. However, there are applications in which it is more natural to consider symmetry with respect to a subspace of a certain dimension rather than to a point, i.e. a subspace of dimension zero. We provide a general framework to construct statistical data depths which attain maximum value in a subspace, providing a center-outward ordering from that subspace. We refer to these data depths as central subspace data depths. Moreover, if the distribution is symmetric with respect to a subspace, then the depth is maximized at that subspace. We introduce general notions of symmetry about a subspace for distributions, study the properties of central subspace data depths and provide asymptotic convergence for the corresponding sample versions. Additionally, we discuss connections with projection pursuit and dimension reduction. An application based on custom data fraud detection shows the importance of the proposed approach and strengthens its potential."}
{"id": "2601.14643", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14643", "abs": "https://arxiv.org/abs/2601.14643", "authors": ["Bhabani Shankar Dey", "Ahan Basu", "Pushpak Jagtap"], "title": "Input-to-State Stabilizing Neural Controllers for Unknown Switched Nonlinear Systems within Compact Sets", "comment": null, "summary": "This paper develops a neural network based control framework that ensures system safety and input-to-state stability (ISS) for general nonlinear switched systems with unknown dynamics. Leveraging the concept of dwell time, we derive Lyapunov based sufficient conditions under which both safety and ISS of the closed-loop switched system are guaranteed. The feedback controllers and the associated Lyapunov functions are parameterized using neural networks and trained from data collected over a compact state space via deterministic sampling. To provide formal stability guarantees under the learned controllers, we introduce a validity condition based on Lipschitz continuity assumptions, which is embedded directly into the training framework. This ensures that the resulting neural network controllers satisfy provable correctness and stability guarantees beyond the sampled data. As a special case, the proposed framework recovers ISS and safety under arbitrary switching when a common Lyapunov function exists. Simulation results on a representative switched nonlinear system demonstrate the effectiveness of the proposed approach."}
{"id": "2601.14379", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.14379", "abs": "https://arxiv.org/abs/2601.14379", "authors": ["Pavel Kos", "Bruno Bertini", "Tomaž Prosen"], "title": "Vanishing correlations in (bi)stochastic controlled circuits", "comment": "9 pages, 1 figure", "summary": "We study the dynamics of circuits composed of stochastic and bistochastic controlled gates. This type of dynamics arises from quantum circuits with random controlled gates, as well as in stochastic circuits and deterministic classical cellular automata. We prove that stochastic and bistochastic controlled gates lead to two-point spatio-temporal correlation functions that vanish everywhere except when the two operators act on the same site. More generally, for multi-point correlations the two rightmost operators must act on the same site. We argue that autocorrelation, while hard to compute, typically decays exponentially towards a value that is exponentially small in the system size. Our results reveal a broad class of quantum systems that exhibit surprisingly simple correlation structures despite their complex microscopic dynamics."}
{"id": "2601.15095", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15095", "abs": "https://arxiv.org/abs/2601.15095", "authors": ["Biman Bagchi"], "title": "Stiffness induced structures and morphological transitions in semiflexible polymers", "comment": null, "summary": "Semiflexible polymers in poor solvents exhibit a rich variety of collapsed morphologies, including globules, toroids, and rodlike bundles, arising from the competition between attractive interactions and chain stiffness. Computer simulations and experiments on stiff and conjugated polymers have revealed complex morphological crossovers, yet a unified theoretical description remains incomplete. Here we develop a coarse-grained, field-theoretic free-energy framework for linear polymers with variable stiffness that captures these morphologies and their transitions within a common description. The theory is built on three key ingredients: a density field describing monomer attraction and excluded-volume effects, a nematic order parameter accounting for orientational ordering in dense regions, and the bending rigidity of a worm-like chain. Using simple variational ansatzes for competing morphologies, we derive analytic expressions for their free energies and identify the boundaries separating coil, globule, toroidal, and rodlike conformational regimes as functions of the reduced attraction strength and the effective persistence length. The resulting phase-diagram topology provides a transparent free-energy-based framework for interpreting morphology diagrams observed in simulations and experiments on semiflexible polymers in poor solvents. We find the possibility of the existence of a triple point involving globules, rods and toroids."}
{"id": "2601.15263", "categories": ["quant-ph", "gr-qc", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2601.15263", "abs": "https://arxiv.org/abs/2601.15263", "authors": ["Amrapali Sen", "Flavio Del Santo"], "title": "Superluminal Transformations and Indeterminism", "comment": "9 main pages and 3 figures", "summary": "Quantum theory is widely regarded as fundamentally indeterministic, yet classical frameworks can also exhibit indeterminism once infinite information is abandoned. At the same time, relativity is usually taken to forbid superluminal signalling, yet Lorentz symmetry formally admits superluminal transformations (SpTs). Dragan and Ekert have argued that SpTs entail indeterminism analogous to the quantum one. Here, we derive a no-go theorem from natural assumptions, which can be interpreted as: superluminal transformations (SpTs) and finite information cannot coexist. Any theory accommodating SpTs must therefore allow unbounded information content, leading to a deterministic ontology akin to that of classical theories formulated over the real numbers. Thus, any apparent indeterminism arising from superluminal transformations reflects only probabilities arising from subjective ignorance, unlike the objective nature of probabilities in quantum theory, indicating that the claimed indeterminacy from superluminal extensions is not quantum."}
{"id": "2601.15007", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.15007", "abs": "https://arxiv.org/abs/2601.15007", "authors": ["M. S. Laad", "Prosenjit Haldar"], "title": "Anomalous Quantum Criticality at a Continuous Metal-Insulator Transition", "comment": "17 pages, 3 figures", "summary": "The Falicov-Kimball model (FKM) is long known to be the simplest model of correlated fermions exhibiting a novel Mott-like quantum critical point (QCP) assocaited with a {\\it continuous} MIT in dimensions $D \\geq 3$. It is also known to be isomorphic to an {\\it annealed} binary-alloy disorder model. Notwithstanding extensive numerical studies for the FKM, analytic insight into the microscopic processes spawning novel Mott-like quantum criticality is scarce. Here, we develop a fully analytic theory for the Mott-like quantum criticality in the FKM on a hierarchical Cayley tree (Bethe lattice) by utilizing a single input from a 2-site cluster-dynamical mean-field theory (CDMFT). We find that density fluctuation modes acquire anomalous dimensions, originating from infra-red power-law singular cluster self-energies. Interestingly, we uncover, at $T=0$, that this {\\it sub-diffusive} metal with glassy dynamics separating a weakly ergodic metal from a non-ergodic insulator shrinks to a single point, namely the Mott-like QCP, at least on the Bethe lattice. We detail the consequences of this anomalous quantum criticality for a range of thermal and dynamical responses in a variety of physical systems that can be effectively modelled by the FKM."}
{"id": "2601.14977", "categories": ["cs.SI", "math.CO", "math.DS"], "pdf": "https://arxiv.org/pdf/2601.14977", "abs": "https://arxiv.org/abs/2601.14977", "authors": ["Nikita Deniskin", "Ernesto Estrada"], "title": "Fractional Diffusion on Graphs: Superposition of Laplacian Semigroups and Memory", "comment": "47 pages, 4 figures", "summary": "Subdiffusion on graphs is often modeled by time-fractional diffusion equations, yet its structural and dynamical consequences remain unclear. We show that subdiffusive transport on graphs is a memory-driven process generated by a random time change that compresses operational time, produces long-tailed waiting times, and breaks Markovianity while preserving linearity and mass conservation. We prove that Mittag-Leffler graph dynamics admit an exact convex, mass-preserving representation as a superposition of classical heat semigroups evaluated at rescaled times, revealing fractional diffusion as ordinary diffusion acting across multiple intrinsic time scales. This framework uncovers heterogeneous, vertex-dependent memory effects and induces transport biases absent in classical diffusion, including algebraic relaxation, degree-dependent waiting times, and early-time asymmetries between sources and neighbors. These features define a subdiffusive geometry on graphs enabling particles to locally discover global shortest paths while favoring high-degree regions. Finally, we show that time-fractional diffusion arises as a singular limit of multi-rate diffusion."}
{"id": "2601.15253", "categories": ["quant-ph", "physics.chem-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.15253", "abs": "https://arxiv.org/abs/2601.15253", "authors": ["Nathan A. Baker", "Brian Bilodeau", "Chi Chen", "Yingrong Chen", "Marco Eckhoff", "Alexandra Efimovskaya", "Piero Gasparotto", "Puck van Gerwen", "Rushi Gong", "Kevin Hoang", "Zahra Hooshmand", "Andrew J. Jenkins", "Conrad S. N. Johnston", "Run R. Li", "Jiashu Liang", "Hongbin Liu", "Alexis Mills", "Maximilian Mörchen", "George Nishibuchi", "Chong Sun", "Bill Ticehurst", "Matthias Troyer", "Jan P. Unsleber", "Stefan Wernli", "David B. Williams-Young", "Boqin Zhang"], "title": "QDK/Chemistry: A Modular Toolkit for Quantum Chemistry Applications", "comment": "32 pages, 3 figures", "summary": "We present QDK/Chemistry, a software toolkit for quantum chemistry workflows targeting quantum computers. The toolkit addresses a key challenge in the field: while quantum algorithms for chemistry have matured considerably, the infrastructure connecting classical electronic structure calculations to quantum circuit execution remains fragmented. QDK/Chemistry provides this infrastructure through a modular architecture that separates data representations from computational methods, enabling researchers to compose workflows from interchangeable components. In addition to providing native implementations of targeted algorithms in the quantum-classical pipeline, the toolkit builds upon and integrates with widely used open-source quantum chemistry packages and quantum computing frameworks through a plugin system, allowing users to combine methods from different sources without modifying workflow logic. This paper describes the design philosophy, current capabilities, and role of QDK/Chemistry as a foundation for reproducible quantum chemistry experiments."}
{"id": "2601.14937", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.14937", "abs": "https://arxiv.org/abs/2601.14937", "authors": ["Juan J. Segura"], "title": "Geostatistics from Elliptic Boundary-Value Problems: Green Operators, Transmission Conditions, and Schur Complements", "comment": null, "summary": "Classical geostatistics encodes spatial dependence by prescribing variograms or covariance kernels on Euclidean domains, whereas the SPDE--GMRF paradigm specifies Gaussian fields through an elliptic precision operator whose inverse is the corresponding Green operator. We develop an operator-based formulation of Gaussian spatial random fields on bounded domains and manifolds with internal interfaces, treating boundary and transmission conditions as explicit components of the statistical model. Starting from coercive quadratic energy functionals, variational theory yields a precise precision--covariance correspondence and shows that variograms are derived quadratic functionals of the Green operator, hence depend on boundary conditions and domain geometry. Conditioning and kriging follow from standard Gaussian update identities in both covariance and precision form, with hard constraints represented equivalently by exact interpolation constraints or by distributional source terms. Interfaces are modelled via surface penalty terms; taking variations produces flux-jump transmission conditions and induces controlled attenuation of cross-interface covariance. Finally, boundary-driven prediction and domain reduction are formulated through Dirichlet-to-Neumann operators and Schur complements, providing an operator language for upscaling, change of support, and subdomain-to-boundary mappings. Throughout, we use tools standard in spatial statistics and elliptic PDE theory to keep boundary and interface effects explicit in covariance modeling and prediction."}
{"id": "2601.14663", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14663", "abs": "https://arxiv.org/abs/2601.14663", "authors": ["Yogesh Pipada Sunil Kumar", "S. Ali Pourmousavi", "Jon A. R. Liisberg", "Julian Lesmos-Vinasco"], "title": "Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets", "comment": "Single column 31 pages, 10 figures, 3 tables, submitted for review to Applied Energy", "summary": "Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty."}
{"id": "2601.14381", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.other", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.14381", "abs": "https://arxiv.org/abs/2601.14381", "authors": ["Zixuan Dai", "Qing-Dong Jiang"], "title": "Vacuum Torque Without Anisotropy: Switchable Casimir Torque Between Altermagnets", "comment": null, "summary": "Casimir torque is conventionally associated with explicit breaking of rotational symmetry, arising from material dielectric anisotropy, geometric asymmetry, or externally applied fields that themselves break rotational invariance. Here we demonstrate a fundamentally different mechanism: an axially symmetric magnetic field can generate a Casimir torque by inducing an axially asymmetric Casimir energy - and can even reverse the torque's sign. Focusing on two-dimensional altermagnets, we show that a magnetic field applied perpendicular to the plane - while preserving in-plane rotational symmetry - activates an orientation-dependent vacuum interaction through the combined crystalline symmetry $\\mathrm{C_n T}$ inherent to altermagnetic order. The resulting torque emerges continuously and scales quadratically with the magnetic field strength. We further analyze its temperature and distance dependence, revealing scaling behaviors that are qualitatively different from those found in uniaxial bulk materials. Our results identify time-reversal symmetry breaking as a powerful route for engineering both the sign and strength of Casimir torque and establish altermagnets as an exciting platform for exploring phenomena driven by vacuum quantum fluctuations."}
{"id": "2601.14379", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.14379", "abs": "https://arxiv.org/abs/2601.14379", "authors": ["Pavel Kos", "Bruno Bertini", "Tomaž Prosen"], "title": "Vanishing correlations in (bi)stochastic controlled circuits", "comment": "9 pages, 1 figure", "summary": "We study the dynamics of circuits composed of stochastic and bistochastic controlled gates. This type of dynamics arises from quantum circuits with random controlled gates, as well as in stochastic circuits and deterministic classical cellular automata. We prove that stochastic and bistochastic controlled gates lead to two-point spatio-temporal correlation functions that vanish everywhere except when the two operators act on the same site. More generally, for multi-point correlations the two rightmost operators must act on the same site. We argue that autocorrelation, while hard to compute, typically decays exponentially towards a value that is exponentially small in the system size. Our results reveal a broad class of quantum systems that exhibit surprisingly simple correlation structures despite their complex microscopic dynamics."}
{"id": "2601.14320", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14320", "abs": "https://arxiv.org/abs/2601.14320", "authors": ["Stefan Schoder"], "title": "Convergence of finite element right-hand-side computation from finite difference data", "comment": null, "summary": "This work presents two integration methods for field transfer in computational aeroacoustics and in coupled field problems, using the finite element method to solve the acoustic field. Firstly, a high-order Gaussian quadrature computes the finite element right-hand side. In contrast, the (flow) field provided by the finite difference mesh is mapped by higher-order B-Splines or a Lagrangian function. Secondly, the cut-cell or supermesh integration with geometric clipping. For each method, the accuracy, performance characteristics, and computational complexity are analyzed. As a reference, the trapezoidal integration rule was computed from the finite difference results. The high-order quadrature converges as the B-Spline interpolation order increases, and the finite difference results and mesh resolutions are consistent. The supermesh approach eliminates interpolation and approximation errors at the grid-to-mesh level and improves accuracy. This behaviour is universal for smooth or strongly oscillating field quantities, which will be shown in a comparative study between the Lighthill-like source term and the source term of the perturbed convective wave equation for subsonic flows."}
{"id": "2601.14365", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14365", "abs": "https://arxiv.org/abs/2601.14365", "authors": ["Tianhong Lu", "Luiz H. Santos"], "title": "Exciton-Anyon Binding in Fractional Chern Insulators: Spectral Fingerprints", "comment": "Main text: 5 pages and 4 figures", "summary": "Transition--metal dichalcogenides (TMDs) uniquely combine topological electronic states realized without external magnetic fields with a strong optical response arising from long--lived excitons. Motivated by this confluence, we investigate an interacting fermion--boson system formed by coupling an exciton to a quasihole of a fractional Chern insulator (FCI) at filling fraction $1/3$. We introduce a kagome--lattice fermion--boson model hosting an electronic FCI and a mobile exciton whose dispersion is tunable from a parabolic band to a flatband. Using exact diagonalization, we demonstrate the emergence of exciton--quasihole bound states controlled by the repulsive electron--exciton interaction $V_{\\mathrm{FB}}$ and the exciton kinetic energy $t_{\\mathrm{B}}$. These states appear as low--lying levels in the fermion--boson spectrum, well separated from the scattering continuum, and arise despite repulsive interactions due to a residual attraction to the local charge depletion associated with a quasihole. Reducing $t_{\\mathrm{B}}$ enhances this effect by favoring interaction--dominated binding. Our results provide a model description of moiré TMD heterostructures, including fractional Chern insulating twisted bilayer MoTe$_2$ proximitized by excitonic TMD heterobilayers, where we estimate exciton--quasihole binding energy scales of $0.6$--$1.1$~meV, placing these effects within reach of photoluminescence spectroscopy."}
{"id": "2601.15062", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.15062", "abs": "https://arxiv.org/abs/2601.15062", "authors": ["Seorin Kim", "Vincent Holst", "Vincent Ginis"], "title": "Turning Citation Networks Inside Out: Studying Science Using Content-Based Knowledge Graphs from LLM-Derived Taxonomies", "comment": "19 pages, 10 figures", "summary": "Scientific fields are often mapped using citations and metadata, despite knowledge being transmitted primarily through content. We introduce an 'inside-out' approach that reconstructs field structure directly from text by representing each paper as a small set of interpretable knowledge components. Using a large language model to induce domain-specific taxonomies and label papers, each publication is encoded as a triplet of measure, data type, and research-question type. These triplets define a knowledge graph with edges weighted by shared papers. Applied to 617 studies on intergenerational wealth mobility, the graph reveals a stable methodological backbone centered on regression-based mobility measures, alongside substantial temporal variation in component recombination. We further utilize normalized betweenness-to-connectivity ratios to identify components and pairings that act as structural bridges disproportionate to their prevalence. This content-derived, taxonomy-driven mapping complements citation-based approaches by exposing the evolving architecture of methods, data, and questions that define a field."}
{"id": "2601.14665", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14665", "abs": "https://arxiv.org/abs/2601.14665", "authors": ["Sharaf K. Magableh", "Caisheng Wang", "Oraib Dawaghreh"], "title": "A Two-Stage Risk-Averse DRO-MILP Methodological Framework for Managing AI/Data Center Demand Shocks", "comment": "Submitted to the 2026 IEEE Power and Energy Society General Meeting", "summary": "The rapid growth of artificial intelligence (AI)-driven data centers is reshaping electricity demand patterns. This is achieved by introducing fast, multi-gigawatt load ramps that challenge the stability and resilience of modern power systems. Traditional resilience frameworks focus mainly on physical outages and largely overlook these emerging digital-era disturbances. This paper proposes a unified two-stage, risk-aware distributionally robust optimization (DRO)-MILP framework that coordinates the pre-allocation and post-event dispatch of Flexible Capacity Modules (FCMs), including BESS, fast-ramping generation, demand response, and potential long-duration storage. Stage-I optimally positions FCMs using DRO with CVaR to hedge against uncertain AI load surges. Stage-II models real-time stabilization following stochastic demand-shock scenarios, minimizing imbalance, unserved energy, and restoration penalties. The framework is designed to be applied on IEEE 33-bus system or expanded for scalability to larger IEEE test feeders capable of representing AI-scale loads. This contributes a scalable planning tool for resilient, AI-integrated distribution grids."}
{"id": "2601.14400", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14400", "abs": "https://arxiv.org/abs/2601.14400", "authors": ["Rafael Gómez-Lurbe", "Armando Pérez"], "title": "Pauli Propagation for Imaginary Time Evolution", "comment": null, "summary": "We extend the Pauli Propagation framework to simulate imaginary time evolution. By deriving explicit update rules for the propagation of Pauli operators under imaginary time evolution generated by Pauli strings, we introduce an imaginary time Pauli Propagation (ITPP) algorithm for approximating imaginary time dynamics directly in the Pauli basis. This approach enables the computation of thermal and ground-state properties while retaining the key computational advantages of Pauli Propagation. Benchmarking ITPP on the one-dimensional transverse-field Ising model demonstrates that truncation provides a controlled trade-off between accuracy and computational cost, while also revealing challenges associated with operator growth under imaginary time evolution. Finally, combining imaginary time and real-time Pauli Propagation naturally suggests a pathway toward simulating open quantum system dynamics within a unified framework."}
{"id": "2601.14398", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.14398", "abs": "https://arxiv.org/abs/2601.14398", "authors": ["Zhi-Qiang Gao", "Hui Yang", "Yan-Qi Wang"], "title": "Deconfined quantum criticality with internal supersymmetry", "comment": "10 pages, 1 figure", "summary": "Deconfined quantum critical point (DQCP) describes direct, non-fine-tuned quantum phase transition between two ordered phases that break distinct and seemingly unrelated symmetries, providing a route to continuous phase transition beyond the conventional Ginzburg--Landau paradigm. In this work we extend the DQCP paradigm to systems with internal supersymmetry (SUSY), where the on-site Hilbert space furnishes a representation of a Lie superalgebra, and the Hamiltonian is invariant under the corresponding Lie supergroup. Focusing on the minimal supersymmetric generalization of spin $SU(2)$, namely $OSp(1|2)$, we propose a supersymmetric deconfined quantum critical point (sDQCP) between a phase that breaks internal $OSp(1|2)$ and a phase that instead breaks lattice rotation symmetry. We formulate a non-linear sigma model on the supersphere target space that captures the symmetry intertwinement characteristic of the sDQCP, and we further develop a gauge theory description to address its dynamical properties, including a heuristic argument for 3D XY critical behavior. Finally, we show that explicitly breaking $OSp(1|2)$ down to $SU(2)$ continuously connects our sDQCP to the conventional DQCP scenario."}
{"id": "2601.14405", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14405", "abs": "https://arxiv.org/abs/2601.14405", "authors": ["Mathias Dauphin", "Daniele A. Di Pietro", "Jérôme Droniou", "Alexandros Skouras"], "title": "A low-order hybrid method for the variable-density incompressible Navier-Stokes equations", "comment": null, "summary": "In this work we introduce and analyse a new low-order method for the variable-density incompressible Navier-Stokes equations. The main novelty of the proposed method lies in the support of general meshes, possibly including polygonal or polyhedral elements as well as non-matching interfaces. We carry out a complete analysis, showing stability, existence and uniqueness of a discrete solution, and convergence of the latter to a suitably defined weak solution of the continuous problem. Numerical tests validate the theoretical results."}
{"id": "2601.14372", "categories": ["cond-mat.str-el", "cond-mat.mes-hall", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.14372", "abs": "https://arxiv.org/abs/2601.14372", "authors": ["Mengxing Ye"], "title": "A Quantum Many-Body Approach for Orbital Magnetism in Correlated Multiband Electron Systems", "comment": "11+7 pages. Comments are welcome", "summary": "Orbital magnetism is a purely quantum phenomenon that reflects intrinsic electronic properties of solids, yet its microscopic description in interacting multiband systems remains incomplete. We develop a general quantum many-body framework for orbital magnetic responses based on the Luttinger-Ward functional. Starting from the Dyson equation, we reformulate the thermodynamic potential in a weak magnetic field and construct a controlled expansion in powers of $B$ applicable to correlated electron systems. A key technical advance is a modified ``Fourier'' representation using noncommutative coordinates, which allows the thermodynamic potential to be expressed in an effective momentum space where the magnetic field acts perturbatively. This formulation makes analytic progress possible within the Moyal algebra. As an application, we derive the spontaneous orbital magnetization and express it entirely in terms of the zero-field Hamiltonian renormalized by the self-energy. For frequency-dependent but Hermitian self-energies, we generalize the orbital magnetic moment and Berry curvature to momentum-frequency space and identify two gauge-invariant contributions built from these quantities. For frequency-independent self-energies the result reduces to the familiar geometric formula for noninteracting systems. This framework provides a unified foundation for computing orbital magnetic responses in correlated multiband materials."}
{"id": "2601.14446", "categories": ["cs.CE", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14446", "abs": "https://arxiv.org/abs/2601.14446", "authors": ["Ye Yuan", "Can", "Chen", "Zipeng Sun", "Dinghuai Zhang", "Christopher Pal", "Xue Liu"], "title": "Diffusion Large Language Models for Black-Box Optimization", "comment": null, "summary": "Offline black-box optimization (BBO) aims to find optimal designs based solely on an offline dataset of designs and their labels. Such scenarios frequently arise in domains like DNA sequence design and robotics, where only a few labeled data points are available. Traditional methods typically rely on task-specific proxy or generative models, overlooking the in-context learning capabilities of pre-trained large language models (LLMs). Recent efforts have adapted autoregressive LLMs to BBO by framing task descriptions and offline datasets as natural language prompts, enabling direct design generation. However, these designs often contain bidirectional dependencies, which left-to-right models struggle to capture. In this paper, we explore diffusion LLMs for BBO, leveraging their bidirectional modeling and iterative refinement capabilities. This motivates our in-context denoising module: we condition the diffusion LLM on the task description and the offline dataset, both formatted in natural language, and prompt it to denoise masked designs into improved candidates. To guide the generation toward high-performing designs, we introduce masked diffusion tree search, which casts the denoising process as a step-wise Monte Carlo Tree Search that dynamically balances exploration and exploitation. Each node represents a partially masked design, each denoising step is an action, and candidates are evaluated via expected improvement under a Gaussian Process trained on the offline dataset. Our method, dLLM, achieves state-of-the-art results in few-shot settings on design-bench."}
{"id": "2601.14276", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.14276", "abs": "https://arxiv.org/abs/2601.14276", "authors": ["Nazmul Haque"], "title": "Understanding Crash Dynamics and Severity of EV Paratransit: Evidence From Easy Bike Accidents in Bangladesh", "comment": null, "summary": "Easy bikes have emerged as a popular and affordable mode of last-mile transport in Bangladesh, yet their widespread use has been accompanied by growing concerns about road safety. This study investigates the underlying factors influencing both the occurrence and severity of easy bike crashes by analyzing nationwide crash data spanning from 2016 to 2024. The findings reveal that crashes predominantly occur during daytime, on paved (pucca) roads, and in low-density peri-urban areas. Intersections and curved road segments are also identified as high-risk zones for crash occurrence. Crash severity analysis, supported by binary logit and probit models, emphasizes that the type of collision plays a crucial role in determining the likelihood of fatal outcomes. Pedestrian-involved crashes and rear-end collisions are more frequently associated with fatalities, whereas crashes involving overturns tend to result in less severe consequences. In contrast, environmental factors such as temperature, rainfall, and time of day exhibit limited impact on crash severity. The distribution of crash types also varies across vehicle categories, with motorcycles, buses, and trucks commonly involved in more dangerous collision scenarios. These findings focus on the urgent need for targeted road safety interventions focusing on specific crash types, high-risk locations such as intersections and curves, and vulnerable road users. Moreover, the study underscores the necessity for improving crash data quality, especially in underreported cases, to support informed decision-making. Based on these insights, the study also proposes a set of evidence-based and context-specific interventions aimed at reducing both the frequency and severity of easy bike crashes in Bangladesh."}
{"id": "2601.15078", "categories": ["cs.SI", "cs.LO", "math.CT"], "pdf": "https://arxiv.org/pdf/2601.15078", "abs": "https://arxiv.org/abs/2601.15078", "authors": ["Juan J. Segura"], "title": "Computable Structuralism: A Categorical Rewrite Calculus of Mythic Variants", "comment": null, "summary": "Structural approaches to myth and narrative are compelling in close reading but hard to compare across traditions, media, and scale. We propose a formal framework that renders Lévi-Straussian transformation as mathematics while remaining readable as narrative analysis. Variants, superhero continuities, and franchise arcs are modeled as typed rewrite programs on a coupled two-register state $(X,Y)$, abstracting an everyday/social channel and a symbolic/legitimation channel. The canonical formula becomes coherence data: a natural transformation $η:U\\Rightarrow V$ between update endofunctors, where $U$ updates each register in place and $V$ performs a swap+inversion. Context is internalized by operator choice, turning naturality into a corpus-facing type check: failures diagnose mis-specified oppositions or illegal transport; successes witness coherent structural models. Order effects are summarized by a five-value invariant (Key). We apply the method to 80 narratives (20 folktales, 20 religious myths, 20 superheroes, 20 franchises), each encoded as $(a,b,x,y)$ with a Key. 59/80 (74\\%) explicitly name a normative constraint in $y$ (law, taboo, contract, prophecy), supporting the two-register abstraction. The result is a testable bridge between structural anthropology and cultural analytics: stories remain interpretable yet become transportable objects for computation, comparison, and falsifiable constraints on transformation."}
{"id": "2601.14673", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14673", "abs": "https://arxiv.org/abs/2601.14673", "authors": ["Yogesh Pipada Sunil Kumar", "S. Ali Pourmousavi", "Jon A. R. Liisberg", "Julian Lesmos-Vinasco"], "title": "Efficient reformulations of ReLU deep neural networks for surrogate modelling in power system optimisation", "comment": "24 pages, 7 figures, 3 tables", "summary": "The ongoing decarbonisation of power systems is driving an increasing reliance on distributed energy resources, which introduces complex and nonlinear interactions that are difficult to capture in conventional optimisation models. As a result, machine learning based surrogate modelling has emerged as a promising approach, but integrating machine learning models such as ReLU deep neural networks (DNNs) directly into optimisation often results in nonconvex and computationally intractable formulations. This paper proposes a linear programming (LP) reformulation for a class of convexified ReLU DNNs with non-negative weight matrices beyond the first layer, enabling a tight and tractable embedding of learned surrogate models in optimisation. We evaluate the method using a case study on learning the prosumer's responsiveness within an aggregator bidding problem in the Danish tertiary capacity market. The proposed reformulation is benchmarked against state-of-the-art alternatives, including piecewise linearisation (PWL), MIP-based embedding, and other LP relaxations. Across multiple neural network architectures and market scenarios, the convexified ReLU DNN achieves solution quality comparable to PWL and MIP-based reformulations while significantly improving computational performance and preserving model fidelity, unlike penalty-based reformulations. The results demonstrate that convexified ReLU DNNs offer a scalable and reliable methodology for integrating learned surrogate models in optimisation, with applicability to a wide range of emerging power system applications."}
{"id": "2601.14410", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14410", "abs": "https://arxiv.org/abs/2601.14410", "authors": ["Debanjan Roy", "Tathagata Gupta", "Pratik Ghosal", "Samrat Sen", "Somshubhro Bandyopadhyay"], "title": "Quantum state exclusion with many copies", "comment": "14 pages", "summary": "Quantum state exclusion is the task of identifying at least one state from a known set that was not used in the preparation of a quantum system. In particular, a given set of quantum states is said to admit state exclusion if there exists a measurement such that, for each state in the set, some measurement outcome rules it out with certainty. However, state exclusion is not always possible in the single-copy setting. In this paper, we investigate whether access to multiple identical copies enables state exclusion. We prove that for any set of three or more pure states, state exclusion becomes possible with a finite number of copies. We further show that the required number of copies may be arbitrarily large -- in particular, for every natural number $N$, we construct sets of states for which exclusion remains impossible with $N$ or fewer copies."}
{"id": "2601.14632", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.14632", "abs": "https://arxiv.org/abs/2601.14632", "authors": ["Min-Kyung Chae", "Woo-Sik Son", "Sang Hoon Lee"], "title": "The missing links: Evaluating contact tracing with incomplete data in large metropolitan areas during an epidemic", "comment": "13 pages, 8 figures, 1 table", "summary": "Contact tracing (CT) plays a pivotal role in controlling early epidemic spread, particularly when a novel infectious disease emerges. However, the quantitative impact of missing information -- such as untraced cases or unnotified contacts -- on the effectiveness of CT remains insufficiently understood. Using a stochastic agent-based model with sociodemographics from metropolitan areas in South Korea, we simulate how different forms of information loss affect epidemic spreading dynamics. We construct information-loss scenarios based on two types: infector-omission (IO) and contact-omission (CO), including selective (SCO) and uniform (UCO) scenarios; IO corresponds to the omission of infected individuals (nodes) from the tracing process, leading to the loss of all movement trajectories and downstream transmission links originating from them, whereas CO corresponds to the omission of specific contact events (edges), in which infected individuals are identified but some of their transmission links fail to be detected or notified. The sensitivity of epidemic dynamics to increasing omission rates differs markedly between the two types: IO scenarios exhibit substantially stronger and more abrupt changes in transmission structure and epidemic outcomes, whereas CO scenarios produce more gradual effects. In both scenarios, the magnitude of these effects varies across cities, with a lower-population city (Busan) showing greater tolerance to information loss than the largest city (Seoul), underscoring the importance of regional tailoring in CT strategies. Both IO and CO scenarios also lead to an increase in the transmission network diameter as information loss grows, indicating that a small network diameter reflects effective contact tracing that limits the depth of transmission chains."}
{"id": "2601.14461", "categories": ["math.NA", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.14461", "abs": "https://arxiv.org/abs/2601.14461", "authors": ["Lukas Netterdon", "Veronica Montanaro", "Manuel Torrilhon", "Hossein Gorji"], "title": "Variance Reduction in the Fokker-Planck Particle Method for Rarefied Gases using Quasi-Random Numbers", "comment": null, "summary": "The Fokker-Planck (FP) particle method accelerates rarefied-gas simulations by replacing the binary collisions of the commonly used Direct Simulation Monte Carlo (DSMC) method with a drift=diffusion process. Like all particle methods, the FP method is inherently stochastic, which leads to statistical fluctuations in macroscopic quantities and necessitates large particle numbers for accurate results. In this work, we investigate the use of quasi-random numbers, which sample distributions more evenly and thereby reduce the variance. To preserve the low-discrepancy structure across time steps, we employ the Array Randomized Quasi-Monte Carlo (Array-RQMC) technique. We combine the FP method with Array-RQMC and compare it in homogeneous and inhomogeneous problems with other commonly used variance-reduction techniques. The proposed FP-Array-RQMC approach achieves improved convergence rates compared with pseudo-random sampling and yields smaller estimator errors for sufficiently large particle numbers."}
{"id": "2601.14380", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14380", "abs": "https://arxiv.org/abs/2601.14380", "authors": ["Andreas Honecker", "M. E. Zhitomirsky", "Alexander Wietek", "Johannes Richter"], "title": "Field-induced states and thermodynamics of the frustrated Heisenberg antiferromagnet on a square lattice", "comment": "15 pages including 12 (multi-panel) figures; legacy paper in honor of Johannes Richter", "summary": "We investigate the ground-state and finite-temperature properties of the $J_1$-$J_2$ Heisenberg antiferromagnet on the square lattice in the presence of an external magnetic field. We focus on the highly frustrated regime around $J_2 \\approx J_1/2$. The $h$-$T$ phase diagram is investigated with particular emphasis on the finite-temperature transition into the \"up-up-up-down\" state that is stabilized by thermal and quantum fluctuations and manifests itself as a plateau at one half of the saturation magnetization in the quantum case. We also discuss the enhanced magnetocaloric effect associated to the ground-state degeneracy that arises at the saturation field for $J_2=J_1/2$. For reference, we first study the classical case by classical Monte Carlo simulations. Then we turn to the extreme quantum limit of spin-1/2 where we perform zero- and finite-temperature Lanczos calculations."}
{"id": "2601.14927", "categories": ["cs.CE", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14927", "abs": "https://arxiv.org/abs/2601.14927", "authors": ["Silvio Meneguzzo", "Claudio Schifanella", "Valentina Gatteschi", "Giuseppe Destefanis"], "title": "Operationalising DAO Sustainability KPIs: A Multi-Chain Dashboard for Governance Analytics", "comment": null, "summary": "We present DAO Portal, a production-grade analytics pipeline and interactive dashboard for assessing the sustainability of Decentralised Autonomous Organisations (DAOs) through Key Performance Indicators (KPIs) derived from on-chain governance and token events. Building on our previous work, which defined and validated a multidimensional KPI framework for DAO sustainability, this paper moves from theory to practice by operationalising that framework in software infrastructure designed for finance and FinTech contexts. The system ingests governance and treasury data from major EVM networks, harmonises the outputs, and computes sustainability scores across four dimensions: participation, accumulated funds, voting efficiency, and decentralisation. A composite 0 to 12 score is then derived using transparent thresholds that are applied client-side in the browser.\n  Using a curated snapshot of more than 50 active DAOs covering 6,930 proposals and 317,317 unique voting addresses, we show how the platform surfaces recurring patterns such as persistently low participation and concentration of proposal activity. These results demonstrate how DAO Portal supports the diagnosis of governance risks and the comparison of design choices across DAOs. To promote reproducibility and adoption, we release source code, data schema, and dashboard implementation. By turning governance traces into measurable and explainable KPIs, DAO Portal provides auditable evidence of DAO sustainability and contributes software engineering infrastructure for financial applications where treasuries and decision-making rights involve significant assets."}
{"id": "2601.14278", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.14278", "abs": "https://arxiv.org/abs/2601.14278", "authors": ["Marc Walden", "Jason Liu", "Ryan Liu", "Hamza Khan"], "title": "Modeling Accessibility-Constrained Networks with Time-Weighted Graphs", "comment": "6 pages and 6 figures", "summary": "Accessibility for the physically disabled is a prevalent issue on university campuses, where stairs and steep slopes make navigating campus arduous. Our work proposes a pipeline to model a college campus as a network by combining Strava and other APIs with depth-first search to derive insights into wheelchair-accessible paths. We then develop a custom Least Resistance algorithm to compute optimal paths between selected nodes and benchmark it against Dijkstra's algorithm. We highlight crucial nodes on campus using centrality measures, demonstrating that wheelchair users are significantly constrained by the lack of mobility options and accommodations. Our pipeline is designed to support future expansion in scope and accuracy, while enabling the proposal of engineering solutions to improve campus accessibility for physically disabled individuals."}
{"id": "2601.14468", "categories": ["eess.SY", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.14468", "abs": "https://arxiv.org/abs/2601.14468", "authors": ["Milad Hasanzadeh", "Amin Kargarian", "Javad Lavaei"], "title": "All-Pass Fractional OPF: A Solver-Friendly, Physics-Preserving Approximation of AC OPF", "comment": null, "summary": "This paper presents a fractional approximation of the AC optimal power flow (AC OPF) problem based on an all-pass approximation of the exponential power flow kernel. The classical AC OPF relies on trigonometric coupling between bus voltage phasors, which yields a nonconvex program with oscillatory derivatives that can slow, or in some cases destabilize, interior-point methods. We replace the trigonometric terms with an all-pass fractional (APF) approximation whose real and imaginary components act as smooth surrogates for the cosine and sine functions, and we introduce a pre-rotation to shift the argument of the approximation toward its most accurate region, ensuring that the reformulated power flow model preserves physical loss behavior, maintains the symmetry of the classical kernels, and improves the conditioning of the Jacobian and Hessian matrices. The proposed APF OPF formulation remains nonconvex, as in the classical model, but it eliminates trigonometric evaluations and empirically produces larger and more stable Newton steps under standard interior-point solvers. Numerical results on more than 25 IEEE and PGLib test systems ranging from 9 to 10{,}000 buses demonstrate that the APF OPF model achieves solutions with accuracy comparable to that of the classical formulation while reducing solver times, indicating a more solver-friendly nonconvex representation of AC OPF. All code, functions, verification scripts, and generated results are publicly available on \\href{https://github.com/LSU-RAISE-LAB/APF-OPF}{GitHub}, along with a README describing how to run and reproduce the experiments."}
{"id": "2601.14262", "categories": ["stat.ME", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14262", "abs": "https://arxiv.org/abs/2601.14262", "authors": ["Hongxiao Li", "Chenxi Wang", "Fanda Fan", "Zihan Wang", "Wanling Gao", "Lei Wang", "Jianfeng Zhan"], "title": "On Meta-Evaluation", "comment": null, "summary": "Evaluation is the foundation of empirical science, yet the evaluation of evaluation itself -- so-called meta-evaluation -- remains strikingly underdeveloped. While methods such as observational studies, design of experiments (DoE), and randomized controlled trials (RCTs) have shaped modern scientific practice, there has been little systematic inquiry into their comparative validity and utility across domains. Here we introduce a formal framework for meta-evaluation by defining the evaluation space, its structured representation, and a benchmark we call AxiaBench. AxiaBench enables the first large-scale, quantitative comparison of ten widely used evaluation methods across eight representative application domains. Our analysis reveals a fundamental limitation: no existing method simultaneously achieves accuracy and efficiency across diverse scenarios, with DoE and observational designs in particular showing significant deviations from real-world ground truth. We further evaluate a unified method of entire-space stratified sampling from previous evaluatology research, and the results report that it consistently outperforms prior approaches across all tested domains. These results establish meta-evaluation as a scientific object in its own right and provide both a conceptual foundation and a pragmatic tool set for advancing trustworthy evaluation in computational and experimental research."}
{"id": "2601.14332", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.14332", "abs": "https://arxiv.org/abs/2601.14332", "authors": ["Fumiya Okazaki", "Takayuki Yamada"], "title": "Topology optimization concerning the mass distribution via filtered gradient flows on the Wasserstein space", "comment": "25 pages, 54 figures", "summary": "In this article, we formulate topology optimization problems concerning the mass distribution as minimization problems for functionals on the Wasserstein space. We relax optimization problems regarding non-convex objective functions on the Wasserstein space by using the Neumann heat semigroup and prove the existence of minimizers of relaxed problems. Furthermore, we introduce the filtered Wasserstein gradient flow and derive the error estimate between the original Wasserstein gradient flow and the filtered one in terms of the Wasserstein distance. We also construct a candidate for the optimal mass distribution for a given fixed total mass and simultaneously obtain the shape of the material by the numerical calculation of filtered Wasserstein gradient flows."}
{"id": "2601.15109", "categories": ["cs.SI", "cs.AI", "cs.CY", "cs.HC", "cs.MA"], "pdf": "https://arxiv.org/pdf/2601.15109", "abs": "https://arxiv.org/abs/2601.15109", "authors": ["Kevin Tseng", "Juan Carlos Toledano", "Bart De Clerck", "Yuliia Dukach", "Phil Tinn"], "title": "An Agentic Operationalization of DISARM for FIMI Investigation on Social Media", "comment": null, "summary": "The interoperability of data and intelligence across allied partners and their respective end-user groups is considered a foundational enabler to the collective defense capability--both conventional and hybrid--of NATO countries. Foreign Information Manipulation and Interference (FIMI) and related hybrid activities are conducted across various societal dimensions and infospheres, posing an ever greater challenge to the characterization of threats, sustaining situational awareness, and response coordination. Recent advances in AI have further led to the decreasing cost of AI-augmented trolling and interference activities, such as through the generation and amplification of manipulative content. Despite the introduction of the DISARM framework as a standardized metadata and analytical framework for FIMI, operationalizing it at the scale of social media remains a challenge. We propose a framework-agnostic agent-based operationalization of DISARM to investigate FIMI on social media. We develop a multi-agent pipeline in which specialized agentic AI components collaboratively (1) detect candidate manipulative behaviors, and (2) map these behaviors onto standard DISARM taxonomies in a transparent manner. We evaluated the approach on two real-world datasets annotated by domain practitioners. We demonstrate that our approach is effective in scaling the predominantly manual and heavily interpretive work of FIMI analysis, providing a direct contribution to enhancing the situational awareness and data interoperability in the context of operating in media and information-rich settings."}
{"id": "2601.14689", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14689", "abs": "https://arxiv.org/abs/2601.14689", "authors": ["Hyeongon Park", "Daniel K. Molzahn", "Rahul K. Gupta"], "title": "Ramping-aware Enhanced Flexibility Aggregation of Distributed Generation with Energy Storage in Power Distribution Networks", "comment": "10 pages, 4 figures", "summary": "Power distribution networks are increasingly hosting controllable and flexible distributed energy resources (DERs) that, when aggregated, can provide ancillary support to transmission systems. However, existing aggregation schemes often ignore the ramping constraints of these DERs, which can render them impractical in real deployments. This work proposes a ramping-aware flexibility aggregation scheme, computed at the transmission-distribution boundary, that explicitly accounts for DER ramp limits and yields flexibility envelopes that are provably disaggregable. To further enhance the attainable flexibility region, we introduce a novel pre-ramping strategy, which proactively adjusts resource operating points to enlarge the aggregated flexibility envelope while preserving both network feasibility and disaggregation guarantees. The proposed method demonstrates a 5.2% to 19.2% improvement in flexibility relative to the baseline model, depending on system conditions. We validate the scheme on an IEEE-33 bus distribution system and provide formal proofs showing that both aggregation strategies are disaggregable for all feasible trajectories within the aggregate flexibility envelope."}
{"id": "2601.14433", "categories": ["quant-ph", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14433", "abs": "https://arxiv.org/abs/2601.14433", "authors": ["Hsin-Yi Lin", "Huan-Hsin Tseng", "Samuel Yen-Chi Chen", "Shinjae Yoo"], "title": "Quantum Super-resolution by Adaptive Non-local Observables", "comment": "Accepted at ICASSP 2026", "summary": "Super-resolution (SR) seeks to reconstruct high-resolution (HR) data from low-resolution (LR) observations. Classical deep learning methods have advanced SR substantially, but require increasingly deeper networks, large datasets, and heavy computation to capture fine-grained correlations. In this work, we present the \\emph{first study} to investigate quantum circuits for SR. We propose a framework based on Variational Quantum Circuits (VQCs) with \\emph{Adaptive Non-Local Observable} (ANO) measurements. Unlike conventional VQCs with fixed Pauli readouts, ANO introduces trainable multi-qubit Hermitian observables, allowing the measurement process to adapt during training. This design leverages the high-dimensional Hilbert space of quantum systems and the representational structure provided by entanglement and superposition. Experiments demonstrate that ANO-VQCs achieve up to five-fold higher resolution with a relatively small model size, suggesting a promising new direction at the intersection of quantum machine learning and super-resolution."}
{"id": "2601.15026", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15026", "abs": "https://arxiv.org/abs/2601.15026", "authors": ["Hasan Mehdi Rizvi", "Devvrat Tiwari", "Subhashish Banerjee"], "title": "Two-Qubit Spin-Boson Model in the Strong Coupling Regime: Coherence, Non-Markovianity, and Quantum Thermodynamics", "comment": "11 pages, 7 figures", "summary": "We investigate the dynamics of a two-qubit open quantum system, in particular the two-qubit spin-boson model in the strong coupling regime, coupled to two thermal bosonic baths under non-Markovian and non-equilibrium conditions. Two complementary approaches, the Hierarchical Equations of Motion (HEOM) and Reaction Coordinate Mapping (RCM), are employed to examine various coupling regimes between the qubits and their respective baths. The dynamical features of the model and the impact of the tunneling amplitude on quantum coherence of the system are probed using the $l_1$-norm of coherence. The model is further shown to have non-Markovian evolution. The nontrivial task of calculating entropy production in the strong-coupling regime is performed using auxiliary density operators in HEOM. Motivated by the realization of a quantum thermal device in the strong-coupling regime, the non-equilibrium steady-state behavior of the system is investigated. Furthermore, the relationship between the heat and spin currents and the tunneling amplitude is probed."}
{"id": "2601.14488", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14488", "abs": "https://arxiv.org/abs/2601.14488", "authors": ["Moustapha Diallo", "Zelalem Arega Worku"], "title": "High-Order Symmetric Positive Interior Quadrature Rules on Two and Three Dimensional Domains", "comment": "27 pages, 17 figures", "summary": "Fully symmetric positive interior (f-SPI) quadrature rules are key building blocks for high-order discretizations of partial differential equations, yet high-degree rules with few nodes remain scarce on reference elements commonly used in mesh generation. We construct new f-SPI rules on the square, cube, prism, and pyramid by coupling a variable parameterization that enforces positivity and interiority with an efficient Levenberg-Marquardt optimization and a symmetry-aware node-reduction strategy that eliminates and collapses orbits, allowing transitions between symmetry types. The resulting rules achieve degrees up to 77 on the square, 45 on the cube, and 30 on the prism and pyramid, and for most degrees use fewer nodes than previously published f-SPI quadrature rules. Verification tests demonstrate comparable accuracy to existing rules. Complete node and weight data are also provided."}
{"id": "2601.14398", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.14398", "abs": "https://arxiv.org/abs/2601.14398", "authors": ["Zhi-Qiang Gao", "Hui Yang", "Yan-Qi Wang"], "title": "Deconfined quantum criticality with internal supersymmetry", "comment": "10 pages, 1 figure", "summary": "Deconfined quantum critical point (DQCP) describes direct, non-fine-tuned quantum phase transition between two ordered phases that break distinct and seemingly unrelated symmetries, providing a route to continuous phase transition beyond the conventional Ginzburg--Landau paradigm. In this work we extend the DQCP paradigm to systems with internal supersymmetry (SUSY), where the on-site Hilbert space furnishes a representation of a Lie superalgebra, and the Hamiltonian is invariant under the corresponding Lie supergroup. Focusing on the minimal supersymmetric generalization of spin $SU(2)$, namely $OSp(1|2)$, we propose a supersymmetric deconfined quantum critical point (sDQCP) between a phase that breaks internal $OSp(1|2)$ and a phase that instead breaks lattice rotation symmetry. We formulate a non-linear sigma model on the supersphere target space that captures the symmetry intertwinement characteristic of the sDQCP, and we further develop a gauge theory description to address its dynamical properties, including a heuristic argument for 3D XY critical behavior. Finally, we show that explicitly breaking $OSp(1|2)$ down to $SU(2)$ continuously connects our sDQCP to the conventional DQCP scenario."}
{"id": "2601.14965", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.14965", "abs": "https://arxiv.org/abs/2601.14965", "authors": ["Moritz Flaschel", "Miguel Angel Moreno-Mateos", "Simon Wiesheier", "Paul Steinmann", "Ellen Kuhl"], "title": "Unsupervised Material Fingerprinting: Ultra-fast hyperelastic model discovery from full-field experimental measurements", "comment": null, "summary": "Material Fingerprinting is a lookup table-based strategy to discover material models from experimental measurements, which completely avoids the need to solve an optimization problem. In an offline phase, a comprehensive database of simulated material responses, so-called material fingerprints, is generated for a predefined experimental setup. This database can then be used repeatedly in the online phase to discover material models corresponding to experimentally measured observations. To this end, the experimentally measured fingerprint is compared with all fingerprints in the database to identify the closest match. The primary advantage of this strategy is that it does not require solving a continuous optimization problem. This avoids the associated computational costs as well as issues of ill-posedness caused by local minima in non-convex optimization landscapes. Material Fingerprinting has been successfully demonstrated for supervised datasets consisting of stress-strain pairs, as well as for unsupervised datasets involving full-field displacements and net reaction forces. However, to date, there is no experimental validation for the latter approach which is the objective of this work."}
{"id": "2601.14281", "categories": ["physics.soc-ph", "econ.GN"], "pdf": "https://arxiv.org/pdf/2601.14281", "abs": "https://arxiv.org/abs/2601.14281", "authors": ["Binh T. Bui"], "title": "How the Shale Revolution is Shaping the Future of the Oil and Gas Market", "comment": null, "summary": "The shale revolution, driven by advances in horizontal drilling, multi-stage hydraulic fracturing, and cyclic gas injection, has reshaped the oil and gas industry over the past two decades. In the United States, these technologies transformed ultra-low permeability shale formations into commercially viable resources, increasing crude oil production from 5 million bpd in 2008 to more than 12 million by 2019. Horizontal drilling became the standard after 2010, with nearly 200,000 horizontal wells completed by the end of 2023, accounting for more than 80% of all new wells in the US. This success is now being replicated in Argentina making the country a leading unconventional producer. The common driver in both cases is the mass manufacturing approach, which industrializes oil production through standardized well designs, repeatable workflows, multi-well pad drilling, and continuous process optimization. Supported by a competitive oilfield service market and a skilled technical workforce, this model has reduced drilling times from months to weeks and cut well costs by half over the past decade. New technologies such as precision geosteering, advanced completion designs, real-time drilling analytics, and cyclic gas injection continue to improve efficiency and productivity. Applying these methods and technologies to conventional reservoirs could significantly expand global production capacity and place sustained downward pressure on crude oil prices. This paper argues that in a period of slowing economic growth and potential financial deleveraging, abundant supply from both unconventional and conventional developments could extend a prolonged phase of relatively low oil prices. Such a scenario would have far-reaching implications for energy policy, investment strategies, and the competitive position of oil-producing nations."}
{"id": "2601.14613", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14613", "abs": "https://arxiv.org/abs/2601.14613", "authors": ["Tingwei Zhang", "Jiahui Liu", "David Allstot", "Huaping Liu"], "title": "An Ion-Intercalation Memristor for Enabling Full Parallel Writing in Crossbar Networks", "comment": null, "summary": "Crossbar architectures have long been seen as a promising foundation for in-memory computing, using memristor arrays for high-density, energy-efficient analog computation. However, this conventional architecture suffers from a fundamental limitation: the inability to perform parallel write operations due to the sneak path problem. This arises from the structural overlap of read and write paths, forcing sequential or semi-parallel updates and severely limiting scalability. To address this, we introduce a new memristor design that decouples read and write operations at the device level. This design enables orthogonal conductive paths, and employs a reversible ion doping mechanism, inspired by lithium-ion battery principles, to modulate resistance states independently of computation. Fabricated devices exhibit near-ideal memristive characteristics and stable performance under isolated read/write conditions."}
{"id": "2601.14309", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14309", "abs": "https://arxiv.org/abs/2601.14309", "authors": ["Esteban Fernández-Morales", "Emily M. Ko", "Nandita Mitra", "Youjin Lee", "Arman Oganisian"], "title": "A Bayesian framework for cost-effectiveness analysis with time-varying treatment decisions", "comment": null, "summary": "Cost-effectiveness analyses (CEAs) compare the costs and health outcomes of treatment regimes to inform medical decisions. With observational claims data, CEAs must address nonrandom treatment assignment, administrative censoring, and irregularly spaced medical visits that reflect the continuous timing of care and treatment initiation. In high-risk, early-stage endometrial cancer (HR-EC), adjuvant radiation is initiated at patient-specific times following hysterectomy, causing confounding between treatment and outcomes that can evolve with post-surgical recovery and clinical course. Most existing CEA methods use point-treatment or discrete-time models. However, point-treatment approaches break down with time-varying confounding, while discrete-time models bin continuous time, expand the data into a person-period format, and can induce zero-inflation by creating many intervals with no cost-accruing events. We propose a Bayesian framework for CEAs with sequential decision-making that jointly models costs and event times in continuous time, accounts for administrative censoring, and supports dynamic treatment regimes with minimal parametric assumptions. We use Bayesian g-computation to estimate causally interpretable cost-effectiveness measures, including net monetary benefit, and to compare regimes through posterior contrasts. We evaluate the finite-sample performance of the proposed method in simulations across censoring levels and compare it against discrete-time and fully parametric alternatives. We then use SEER-Medicare data to assess the cost-effectiveness of initiating adjuvant radiation therapy within six months following hysterectomy among HR-EC patients."}
{"id": "2601.14414", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14414", "abs": "https://arxiv.org/abs/2601.14414", "authors": ["Liang Wu", "Bo Yang", "Xu Yang", "Yilin Mo", "Yang Shi", "Ján Drgoňa"], "title": "$π$MPC: A Parallel-in-horizon and Construction-free NMPC Solver", "comment": "8 pages", "summary": "The alternating direction method of multipliers (ADMM) has gained increasing popularity in embedded model predictive control (MPC) due to its code simplicity and pain-free parameter selection. However, existing ADMM solvers either target general quadratic programming (QP) problems or exploit sparse MPC formulations via Riccati recursions, which are inherently sequential and therefore difficult to parallelize for long prediction horizons. This technical note proposes a novel \\textit{parallel-in-horizon} and \\textit{construction-free} nonlinear MPC algorithm, termed $π$MPC, which combines a new variable-splitting scheme with a velocity-based system representation in the ADMM framework, enabling horizon-wise parallel execution while operating directly on system matrices without explicit MPC-to-QP construction. Numerical experiments and accompanying code are provided to validate the effectiveness of the proposed method."}
{"id": "2601.14704", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14704", "abs": "https://arxiv.org/abs/2601.14704", "authors": ["Ruixing Ren", "Minqi Tao", "Junhui Zhao", "Xiaoke Sun", "Qiuping Li"], "title": "Hierarchical Optimization Based Multi-objective Dynamic Regulation Scheme for VANET Topology", "comment": "10 pages, 6 figures. A topology optimization strategy is proposed in this paper to optimize the latency, average path length, and throughput in Vehicular Ad Hoc Networks (VANETs)", "summary": "As a core technology of intelligent transportation systems, vehicular ad-hoc networks support latency-sensitive services such as safety warning and cooperative perception via vehicle-to-everything communications. However, their highly dynamic topology increases average path length, raises latency, and reduces throughput, severely limiting communication performance. Existing topology optimization methods lack capabilities in multi-objective coordination, dynamic adaptation, and global-local synergy. To address this, this paper proposes a two-layer dynamic topology regulation scheme combining local feature aggregation and global adjustment. The scheme constructs a dynamic multi-objective optimization model integrating average path length, end-to-end latency, and network throughput, and achieves multi-index coordination via link adaptability metrics and a dynamic normalization mechanism. it quickly responds to local link changes via feature fusion of local node feature extraction and dynamic neighborhood sensing, and balances optimization accuracy and real-time performance using a dual-mode adaptive solving strategy for global topology adjustment. It reduces network oscillation risks by introducing a performance improvement threshold and a topology validity verification mechanism. Simulation results on real urban road networks via the SUMO platform show that the proposed scheme outperforms traditional methods in average path length (stabilizing at ~4 hops), end-to-end latency (remaining ~0.01 s), and network throughput."}
{"id": "2601.14513", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14513", "abs": "https://arxiv.org/abs/2601.14513", "authors": ["Nabi Zare Harofteh", "Rafael I. Nepomechie"], "title": "Spin-$s$ $U(1)$-eigenstate preparation", "comment": "13 pages, 3 figures, implementations of circuits in cirq are available on GitHub", "summary": "We formulate a deterministic algorithm for preparing a general $U(1)$-eigenstate of a spin-$s$ chain of length $n$. These states consist of linear combinations of computational basis states $|\\vec{m}\\rangle$ of $n$ qudits, each with $(2s+1)$ levels and $s= 1/2, 1, 3/2, \\ldots$, whose ditstrings $\\vec{m}$ have a fixed digit sum. Exploiting a Gray code for bounded integer compositions, whose consecutive ditstrings obey the Gray property, the quantum state is prepared by applying corresponding ``Gray gates.'' We use this algorithm to prepare exact eigenstates of integrable spin-$s$ XXX Hamiltonians."}
{"id": "2601.14508", "categories": ["math.NA", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2601.14508", "abs": "https://arxiv.org/abs/2601.14508", "authors": ["Mustafa Aggul", "Manaure Francisquez", "Daniel R. Reynolds", "Sylvia Amihere"], "title": "Super Time Stepping Methods for Diffusion using Discontinuous-Galerkin Spatial Discretizations", "comment": null, "summary": "Super-time-stepping (STS) methods provide an attractive approach for enabling explicit time integration of parabolic operators, particularly in large-scale, higher-dimensional kinetic simulations where fully implicit schemes are impractical. In this work, we present an explicit STS framework tailored for diffusion operators in gyrokinetic models, motivated by the fact that constructing and storing a Jacobian is often infeasible due to strong nonlocal couplings, high dimensionality, and memory constraints. We investigate the performance of several STS methods, including Runge-Kutta-Chebyshev (RKC) and Runge-Kutta-Legendre (RKL) schemes, applied to a diffusion equation discretized using both discontinuous Galerkin (DG) and finite-difference methods. To support time adaptivity, we introduce a novel error norm designed to more accurately track temporal error arising from DG spatial discretizations, in which degrees of freedom contribute unevenly to the solution error. Finally, we assess the performance of an automatic eigenvalue estimation algorithm for determining the required number of STS stages and compare it against an analytical estimation formula."}
{"id": "2601.14439", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14439", "abs": "https://arxiv.org/abs/2601.14439", "authors": ["Maria Chatzieleftheriou", "Jonas B. Profe", "Ying Li", "Roser Valentí"], "title": "Pressure Tuning of Electronic Correlations and Flat Bands in CsCr$_3$Sb$_5$", "comment": null, "summary": "CsCr$_3$Sb$_5$ is a newly identified strongly correlated kagome superconductor, characterized by non-Fermi-liquid behavior at elevated temperatures and intertwined charge- and spin-density-wave order below $T_{DW}\\approx 54$K. Under external pressure, this order is suppressed and a superconducting phase emerges. This phase diagram, which closely resembles that of high-$T_c$ superconductors, together with a kagome flat band near the Fermi level and possible altermagnetic order, has motivated extensive theoretical and experimental investigations. To better understand how pressure influences the ordered states, we present a systematic study of the evolution of the electronic properties under applied pressure. Performing DFT+DMFT (density functional theory combined with dynamical mean field theory) calculations, we uncover a complex interplay between the redistribution of spectral weight in the flat bands and the strength of electronic correlations under pressure. Our results further strengthen the interpretation that pressure effectively weakens electronic correlations through enhanced orbital hybridization. This, in turn, strongly suggests that superconductivity emerges as a direct consequence of the suppression of the system's ordered phase."}
{"id": "2601.14272", "categories": ["q-fin.RM", "cs.CE", "cs.CR"], "pdf": "https://arxiv.org/pdf/2601.14272", "abs": "https://arxiv.org/abs/2601.14272", "authors": ["Ekleen Kaur"], "title": "The Limits of Lognormal: Assessing Cryptocurrency Volatility and VaR using Geometric Brownian Motion", "comment": "Paper was presented at Hinweis Second International Conference on Recent Trends in Engineering and Technology (RTET) on December 28th 2025, http://rtet.thehinweis.com/. All the accepted registered conference papers will be published in the International Journal on Engineering and Technology and the same paper will be indexed as Conference Proceedings on Scopus and Cross Ref", "summary": "The integration of cryptocurrencies into institutional portfolios necessitates the adoption of robust risk modeling frameworks. This study is a part of a series of subsequent works to fine-tune model risk analysis for cryptocurrencies. Through this first research work, we establish a foundational benchmark by applying the traditional industry-standard Geometric Brownian Motion (GBM) model. Popularly used for non-crypto financial assets, GBM assumes Lognormal return distributions for a multi-asset cryptocurrency portfolio (XRP, SOL, ADA). This work utilizes Maximum Likelihood Estimation and a correlated Monte Carlo Simulation incorporating the Cholesky decomposition of historical covariance. We present our stock portfolio model as a Minimum Variance Portfolio (MVP). We observe the model's structural shift within the heavy-tailed, non-Gaussian cryptocurrency environment. The results reveal limitations of the Lognormal assumption: the calculated Value-at-Risk at the 5% confidence level over the one-year horizon. For baselining our results, we also present a holistic comparative analysis with an equity portfolio (AAPL, TSLA, NVDA), demonstrating a significantly lower failure rate. This performance provides conclusive evidence that the GBM model is fundamentally the perfect benchmark for our subsequent works. Results from this novel work will be an indicator for the success criteria in our future model for crypto risk management, rigorously motivating the development and application of advanced models."}
{"id": "2601.14282", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.14282", "abs": "https://arxiv.org/abs/2601.14282", "authors": ["Quantum Scientists for Disarmament"], "title": "Quantum scientists for disarmament: a manifesto", "comment": "A dedicated webpage can be found at https://disarmquantum.com/", "summary": "We, as researchers in quantum science and technology, are publishing this manifesto to express our deep concerns about the current geopolitical situation and the global race to rearm. We firmly oppose all forms of militarization in our societies and, in particular, within the academic world. We categorically reject the use of our research for military applications, population control, or surveillance. We stand against the practice of military funding for research. This manifesto is a call to action: to confront the elephant in the room of quantum research, and to unite all researchers who share our views. Our main goals are: i) To express, as a unified collective, our rejection of the use of our research for military purposes; ii) To open a debate in our community about the ethical implications of quantum research for military purposes; iii) To create a forum where concerned scientists can share their opinions and join forces in support of demilitarized research; iv) To advocate for the establishment of a public database listing all research projects at public universities funded by military or defense agencies. In what follows, we lay out our concerns and the rationale behind our opposition to the militarization of quantum research."}
{"id": "2601.14643", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14643", "abs": "https://arxiv.org/abs/2601.14643", "authors": ["Bhabani Shankar Dey", "Ahan Basu", "Pushpak Jagtap"], "title": "Input-to-State Stabilizing Neural Controllers for Unknown Switched Nonlinear Systems within Compact Sets", "comment": null, "summary": "This paper develops a neural network based control framework that ensures system safety and input-to-state stability (ISS) for general nonlinear switched systems with unknown dynamics. Leveraging the concept of dwell time, we derive Lyapunov based sufficient conditions under which both safety and ISS of the closed-loop switched system are guaranteed. The feedback controllers and the associated Lyapunov functions are parameterized using neural networks and trained from data collected over a compact state space via deterministic sampling. To provide formal stability guarantees under the learned controllers, we introduce a validity condition based on Lipschitz continuity assumptions, which is embedded directly into the training framework. This ensures that the resulting neural network controllers satisfy provable correctness and stability guarantees beyond the sampled data. As a special case, the proposed framework recovers ISS and safety under arbitrary switching when a common Lyapunov function exists. Simulation results on a representative switched nonlinear system demonstrate the effectiveness of the proposed approach."}
{"id": "2601.14431", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14431", "abs": "https://arxiv.org/abs/2601.14431", "authors": ["Xi Fang", "Bingkai Wang", "Guangyu Tong", "Liangyuan Hu", "Shuangge Ma", "Fan Li"], "title": "Doubly robust estimators of the restricted mean time in favor estimands in individual- and cluster-randomized trials", "comment": null, "summary": "Progressive multi-state survival outcomes are common in trials with recurrent or sequential events and require treatment effect estimands that remain interpretable without proportional intensity or Markov assumptions. The restricted mean time in favor of treatment (RMT-IF) extends the restricted mean survival time to ordered multi-state processes and provides such an interpretable estimand. However, existing RMT-IF methods are nonparametric, assume covariate-independent censoring for independent observations, and do not accommodate cluster-randomized trials (CRTs), limiting both efficiency and applicability. We develop a class of doubly robust estimators for RMT-IF under right censoring using an augmented inverse-probability weighting framework that combines stage-specific outcome regression with arm-specific censoring models, yielding consistency when either nuisance model is correctly specified. We further extend the framework to CRTs by formalizing both cluster-level and individual-level average RMT-IF estimands to address informative cluster size and by constructing corresponding doubly robust estimators that account for within-cluster correlation. For inference, we employ model-agnostic jackknife variance estimators in both individually randomized and cluster-randomized settings. Extensive simulation studies demonstrate finite-sample performance, and the methods are illustrated using two randomized trial examples."}
{"id": "2601.14416", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14416", "abs": "https://arxiv.org/abs/2601.14416", "authors": ["Victor Hugo Pereira Rodrigues", "Tiago Roux Oliveira", "Miroslav Krstic", "Paulo Tabuada"], "title": "Event-Triggered Newton Extremum Seeking for Multivariable Optimization", "comment": null, "summary": "This paper presents a static event-triggered control strategy for multivariable Newton-based extremum seeking. The proposed method integrates event-triggered actuation into the Newton-based optimization framework to reduce control updates while maintaining rapid convergence to the extremum. Unlike traditional gradient-based extremum seeking, where the convergence rate depends on the unknown Hessian of the cost function, the proposed approach employs a dynamic estimator of the Hessian inverse, formulated as a Riccati equation, enabling user-assignable convergence rates. The event-triggering mechanism is designed to minimize unnecessary actuation updates while preserving stability and performance. Using averaging theory, we establish local stability results and exponential convergence to a neighborhood of the unknown extremum point. Additionally, numerical simulations illustrate the benefits of the proposed approach over gradient-based and continuously actuated Newton-based extremum seeking, showing improved convergence rates and reduced control update frequency, leading to more efficient implementation in real-time optimization scenarios."}
{"id": "2601.14725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14725", "abs": "https://arxiv.org/abs/2601.14725", "authors": ["Zihao Ren", "Lei Wang", "Deming Yuan", "Guodong Shi"], "title": "Differential Privacy on Affine Manifolds: Geometrically Confined Privacy in Linear Dynamical Systems", "comment": null, "summary": "In this paper, we present a comprehensive framework for differential privacy over affine manifolds and validate its usefulness in the contexts of differentially private cloud-based control and average consensus. We consider differential privacy mechanisms for linear queries when the input data are constrained to lie on affine manifolds, a structural property that is assumed to be available as prior knowledge to adversaries. In this setting, the definition of neighborhood adjacency must be formulated with respect to the intrinsic geometry of the manifolds. We demonstrate that such affine-manifold constraints can fundamentally alter the attainable privacy levels relative to the unconstrained case. In particular, we derive necessary and sufficient conditions under which differential privacy can be realized via structured noise injection mechanisms, wherein correlated Gaussian or Laplace noise distributions, rather than i.i.d. perturbations, are calibrated to the dataset. Based on these characterizations, we develop explicit noise calibration procedures that guarantee the tight realization of any prescribed privacy budget with a matching noise magnitude. Finally, we show that the proposed framework admits direct applications to linear dynamical systems ranging from differentially private cloud-based control to privacy-preserving average consensus, all of which naturally involve affine-manifold constraints. The established theoretical results are illustrated through numerical examples."}
{"id": "2601.14547", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14547", "abs": "https://arxiv.org/abs/2601.14547", "authors": ["Haruki Mitarai", "Yukihiro Tadokoro", "Hiroya Tanaka"], "title": "Active interference suppression in frequency-division-multiplexed quantum gates via off-resonant microwave tones", "comment": "9 pages, 8 figures", "summary": "An increase in the number of control lines between the quantum processors and the external electronics constitutes a major bottleneck in the realization of large-scale quantum computers. Frequency-division multiplexing is expected to enable multiple qubits to be controlled through a single microwave cable; however, interference from off-resonant microwave tones hinders precise qubit control. Here, we propose an active interference suppression method for frequency-division-multiplexed simultaneous gate operations. We demonstrate that deliberate incorporation of off-resonant microwave tones improves the accuracy of single-qubit gates. Specifically, we find that by incorporating off-resonant orthogonal or quasi-orthogonal microwave tones, the gate infidelity decreases proportionally to the inverse square of the number of microwave tones. Furthermore, we show that fast oscillations neglected under the rotating wave approximation degrade gate fidelity, and that this degradation can be mitigated through optimized frequency allocation. Our approach is simple yet effective for improving the performance of frequency-division-multiplexed quantum gates."}
{"id": "2601.14548", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14548", "abs": "https://arxiv.org/abs/2601.14548", "authors": ["Timo Sprekeler"], "title": "A Cordes framework for stationary Fokker--Planck--Kolmogorov equations", "comment": "17 pages", "summary": "We first review the Cordes condition for nondivergence-form differential operators through the lens of Campanato's theory of near operators. We then survey a recently proposed Cordes framework that guarantees the existence and uniqueness of $L^2$ solutions to stationary Fokker--Planck--Kolmogorov equations subject to periodic boundary conditions, and that allows for the construction of a simple finite element method for its numerical approximation. Finally, we propose a Cordes framework for stationary Fokker--Planck--Kolmogorov-type equations subject to a homogeneous Dirichlet boundary condition."}
{"id": "2601.14458", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14458", "abs": "https://arxiv.org/abs/2601.14458", "authors": ["Wen O. Wang", "Urban F. P. Seifert", "Oleg A. Starykh", "Leon Balents"], "title": "Chirality and quasi-long-range order in finite-flux Gutzwiller states for magnetized frustrated magnets", "comment": "8 pages, 5 figures; Supplementary Materials: 7 pages", "summary": "We study Gutzwiller-projected wavefunctions for triangular-lattice U(1) Dirac spin liquids in a Zeeman field, where we allow the U(1) gauge field to develop a gauge flux, resulting in (spin-split) spinon Landau levels. We find that at a given magnetization, the optimal candidate state has a finite flux chosen such that the spinon filling lies in a $|C|=1$ Landau-level gap: it gives the lowest variational energy and the smallest energy variance within our correlation-matrix reconstruction for local Heisenberg-type models. By symmetry, we argue that the finite gauge flux results in a non-zero (staggered) scalar spin chirality, as also numerically observed, and further find that the $|C|=1$ state exhibits dominant quasi-long-ranged $120^\\circ$ magnetic correlations. Studying the next-to-optimal wavefunction with a $|C|=2$ Landau-level gap, we observe unusual spin-nematic correlations. Our results may provide guidance for analyzing the magnetic-field response of DSL candidate materials and offer numerical diagnostics that can connect to the underlying theory of spinons coupled to an emergent U(1) gauge field."}
{"id": "2601.14292", "categories": ["physics.soc-ph", "cs.CY", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.14292", "abs": "https://arxiv.org/abs/2601.14292", "authors": ["Halima El Badaoui", "Siddartha Khastgir", "Mariat James Elizebeth", "Shufeng Chen", "Takuya Nakashima", "Paul Jennings"], "title": "Introducing a Novel Systems Thinking approach inspired by STPA: Road Safety Intervention design case study", "comment": null, "summary": "According to the latest provisional statistics released by the UK Department for Transport, Great Britain recorded 1,633 road deaths in 2024, representing a slight increase from 2023 and raising concerns about safety progress, which indicates that preventable fatalities remain a challenge. The deployment of advanced mobility systems, even certified and safety-assessed, is not sufficient to deliver improved safety outcomes, and existing road infrastructure is not sufficiently equipped to prevent severe collisions. Successful application of the ``Safe System'' approach demands systems thinking in an integrated and holistic manner, encompassing all aspects of road safety. This paper argues that road safety must be managed as a complex socio-technical system where risk evolves dynamically and must be continuously monitored. To address these safety gaps, we propose a systems thinking approach that identifies factors contributing to fatal outcomes and mitigates them. The framework consists of four steps: 1) List stakeholders who influence road safety, 2) Model the interactions between these stakeholders, 3) List assumptions that might be identified as factors for fatalities, and 4) Monitor these assumptions throughout the system lifecycle. The approach is applied to the United Kingdom (UK) road network to demonstrate feasibility. The study provides actionable guidance and new KPIs categories for stakeholders to implement road safety monitoring and eliminate any unreasonable road safety risks."}
{"id": "2601.14663", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14663", "abs": "https://arxiv.org/abs/2601.14663", "authors": ["Yogesh Pipada Sunil Kumar", "S. Ali Pourmousavi", "Jon A. R. Liisberg", "Julian Lesmos-Vinasco"], "title": "Calibrated uncertainty quantification for prosumer flexibility aggregation in ancillary service markets", "comment": "Single column 31 pages, 10 figures, 3 tables, submitted for review to Applied Energy", "summary": "Reliable forecasting of prosumer flexibility is critical for demand response aggregators participating in frequency controlled ancillary services market, where strict reliability requirements such as the P90 standard are enforced. Limited historical data, dependence on exogeneous factors, and heterogenous prosumer behaviour introduce significant epistemic uncertainty, making deterministic or poorly calibrated probabilistic models unsuitable for market bidding. This paper proposes the use of scalable uncertainty quantification framework that integrates Monte Carlo dropout (MCD) with conformal prediction (CP) to produce calibrated, finite sample prediction intervals for aggregated prosumer flexibility. The proposed framework is applied to a behind-the-meter aggregator participating in the Danish manual frequency restoration reserve capacity market. A large-scale synthetic dataset is generated using a modified industry-grade home energy management system, combined with publicly available load, solar, price, activation and device-level data. The resulting machine learning surrogate model captures aggregate prosumer price responsiveness and provides uncertainty-aware estimates suitable for market bidding. Multiple multivariate CP strategies are evaluated and benchmarked against conventional MCD-based methods. Results show that standalone MCD systematically overestimates available flexibility and violates P90 compliance, whereas the proposed MCD-CP framework achieves reliable coverage with controlled conservatism. When embedded in aggregator bidding model, conformalised methods substantially reduce overbidding risk and achieve upto 70% of perfect-information profit while satisfying regulatory reliability constraints, providing practical, computationally efficient, and market-compliant solution for aggregator flexibility forecasting under uncertainty."}
{"id": "2601.14498", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14498", "abs": "https://arxiv.org/abs/2601.14498", "authors": ["Marlena Bannick", "Yuanyuan Bian", "Gregory Chen", "Liming Li", "Yuhan Qian", "Daniel Sabanés Bové", "Dong Xi", "Ting Ye", "Yanyao Yi"], "title": "The RobinCar Family: R Tools for Robust Covariate Adjustment in Randomized Clinical Trials", "comment": "On behalf of the Software Subteam ASA-BIOP Covariate Adjustment Scientific Working Group. All authors contributed equally to this work", "summary": "Purpose: Covariate adjustment is a powerful statistical technique that can increase efficiency in clinical trials. Recent guidance from the U.S. FDA provided recommendations and best practices for using covariate adjustment. However, there has existed a gap between the extensive statistical literature on covariate adjustment and software that is easy to use and abides by these best practices.\n  Methods: We have developed the RobinCar Family, which is comprised of RobinCar and RobinCar2. These two R packages enable covariate-adjusted analyses for continuous, discrete, and time-to-event outcomes that follow best practices. For continuous and discrete outcomes, the functions in the RobinCar Family facilitate traditional forms of covariate adjustment such as ANCOVA as well as more recent approaches like ANHECOVA, G-computation with generalized linear models and machine learning models, and adjustment for a super-covariate (as in PROCOVA(TM)). Functions for time-to-event outcomes implement the covariate-adjusted log-rank test, the stratified covariate-adjusted log-rank test, and the marginal covariate-adjusted hazard ratio. The RobinCar Family is supported by the ASA Biopharmaceutical Section Covariate Adjustment Scientific Working Group.\n  Results: We provide an accessible overview of the covariate-adjusted statistical methods, and describe how they are implemented in RobinCar and RobinCar2. We highlight important usage notes for clinical trial practitioners.\n  Conclusion: We apply RobinCar and RobinCar2 functions by analyzing data from the AIDS Clinical Trials Group Study 175, demonstrating that they are straightforward and user-friendly."}
{"id": "2601.14451", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14451", "abs": "https://arxiv.org/abs/2601.14451", "authors": ["Pablo Barros", "Vincent Guigues", "Roger Behling", "Luiz-Rafael Santos"], "title": "New operator designs for Halpern iterations with explicit rates under Hölder error bounds", "comment": null, "summary": "We investigate the asymptotic behavior of Halpern-type iterations applied to quasi-nonexpansive operators arising in best approximation problems over the intersection of finitely many closed convex sets in $\\mathbb{R}^n$. Assuming a local decrease condition for the underlying operator and standard requirements on the stepsizes $(α_k) \\subset (0,1)$, we first prove strong convergence of the Halpern sequence $x_{k+1} = α_k x_0 + (1-α_k) T x_k$ to the best approximation point $x^\\star$ in the intersection set, that is, the metric projection of $x_0$ onto that set. Under the additional assumption that the intersection satisfies a Hölder-type error bound with exponent $γ\\in (0,1]$, we then derive explicit convergence rates for both feasibility and norm error: the distance from $x_k$ to the intersection set decays like $\\mathcal O(α_k^{γ/(2-γ)})$, while the norm error $\\|x_k - x^\\star\\|$ decays like $\\mathcal O(α_k^{γ/(4-2γ)})$. These results apply to most projection-type operators used in convex feasibility problems (including MAP, CRM/SCCRM, Cimmino and 3PM/A3PM) and extend classical convergence analyses of the Halpern-type iterations by providing explicit, geometry-dependent rates governed by Hölder-type error bounds. Our numerical experiments show that Halpern-type iterations combined with most of these projection-type operators are quicker than Dykstra's algorithm to find the projection of a point in an intersection of ellipsoids or in an intersection of polyhedrons."}
{"id": "2601.14880", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14880", "abs": "https://arxiv.org/abs/2601.14880", "authors": ["Lei Zheng", "Luyao Zhang", "Peiqi Yu", "Yifan Sun", "Sergio Grammatico", "Jun Ma", "Changliu Liu"], "title": "Contingency Planning for Safety-Critical Autonomous Vehicles: A Review and Perspectives", "comment": "23 pages, 6 figures", "summary": "Contingency planning is the architectural capability that enables autonomous vehicles (AVs) to anticipate and mitigate discrete, high-impact hazards, such as sensor outages and adversarial interactions. This paper presents a comprehensive survey of the field, synthesizing fragmented literature into a unified logic-conditioned hybrid control framework. Within this formalism, we categorize approaches into two distinct paradigms: Reactive Safety, which responds to realized hazards by enforcing safety constraints or executing fail-safe maneuvers; and Proactive Safety, which optimizes for future recourse by branching over potential modal transitions. In addition, we propose a fine-grained taxonomy that partitions the landscape into external contingencies (environmental and interactive hazards) and internal contingencies (system faults). Through a critical comparative analysis, we reveal a fundamental structural divergence: internal faults are predominantly addressed via reactive fail-safe mechanisms, whereas external interaction uncertainties increasingly require proactive branching strategies. Furthermore, we identify a critical methodological divergence: whereas physical hazards are typically managed with formal guarantees, semantic and out-of-distribution anomalies currently rely heavily on empirical validation. We conclude by identifying the open challenges in bridging the gap between theoretical guarantees and practical validation, advocating for hybrid architectures and standardized benchmarking to transition contingency planning from formulation to certifiable real-world deployment."}
{"id": "2601.14565", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.14565", "abs": "https://arxiv.org/abs/2601.14565", "authors": ["Dylan Danese", "Vatshal Srivastav", "Will McCutcheon", "Saroch Leedumrongwatthanakun", "Mehul Malik"], "title": "Programming Quantum Measurements of Time inside a Complex Medium", "comment": "8 + 10 pages, 5 + 4 figs", "summary": "The temporal degree-of-freedom of light is incredibly powerful for modern quantum technologies, enabling large-scale quantum computing architectures and record key-rates in quantum key distribution. However, the generalized measurement of large and complex quantum superpositions of the time-of-arrival of a photon remains a unique experimental challenge. Conventional methods based on unbalanced Franson-type interferometers scale poorly with dimension, requiring multiple cascaded devices and active phase stabilization. In addition, these are limited by construction to a restricted set of phase-only superposition measurements. Here we show how the coupling of spatial and temporal information inside a single multi-mode fiber can be harnessed to program completely generalized measurements for high-dimensional superpositions of photonic time-bin. Using the multi-spectral transmission matrix of the fiber, we find special sets of spatial modes that experience distinct dispersive delays through the fiber. By exciting coherent superpositions of these spatial modes, we engineer the equivalent of large, unbalanced multi-mode interferometers inside the fiber and use them to perform high-quality measurements of arbitrary time-bin superpositions in up to dimension 11. The single fiber functions as a scalable, common-path interferometer for time-bin qudits that significantly eases the experimental overheads of standard approaches based on unbalanced Franson-type interferometers, serving as an essential tool for quantum technologies that harness the temporal properties of light."}
{"id": "2601.14740", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14740", "abs": "https://arxiv.org/abs/2601.14740", "authors": ["Xinjie Fang", "Jianhua Huang", "Fang Su", "Jun Ouyang"], "title": "Finite-dimensional approximations of random attractor for stochastic discrete complex Ginzburg-Landau equations", "comment": null, "summary": "In this paper, we apply an implicit Euler scheme to discretize the complex Ginzburg-Landau equation and prove the existence of a numerical attractor for the discrete Ginzburg-Landau system. We establish the upper semicontinuity of the numerical attractor with respect to the global attractor as the time step tends to zero. Furthermore, we provide finite-dimensional approximations for three types of attractors (global, numerical, and random), and demonstrate the existence of truncated attractors along with their convergence as the dimension of the state space tends to infinity. Finally, we prove the existence of a random attractor and establish the upper semi-continuity both of the global random attractor and the truncated random attractor."}
{"id": "2601.14496", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14496", "abs": "https://arxiv.org/abs/2601.14496", "authors": ["Shi Feng", "Nandini Trivedi"], "title": "Magnetic field induced phenomena in Kitaev spin liquids", "comment": "51 pages", "summary": "Quantum spin liquids (QSLs) host a variety of fractionalized particles. In Kitaev's paradigmatic honeycomb model a spin-$\\tfrac{1}{2}$ fractionalizes into $Z_2$ flux due to emergent $Z_2$ gauge field and matter Majorana fermions. Although these excitations have well-defined dynamics in the integrable limit, their direct experimental identification is notoriously challenging: realistic materials inevitably host additional symmetry-allowed interactions that break integrability and hybridize gauge and matter sectors, while magnetic fields, which are often required to suppress competing order and stabilize a putative QSL regime, further entangle the responses of different fractionalized quasiparticles and may even drive the system into field-induced spin-liquid phases that are not adiabatically connected to the integrable limit. A prominent example is the quantum Majorana metal, in which the distinct dynamics of fractionalized Majorana fermions can become directly visible in scattering. This report highlights recent progress on these related questions: in which field-stabilized QSL regimes and nearby emergent phases, and under what conditions, can the response of a specific fractionalized quasiparticle be isolated and positively understood, thereby clarifying the existence and the experimental scope of putative spin liquids? We review the progress on these questions across Abelian, non-Abelian, and an emergent quantum phases under magnetic field that are not perturbatively connected to the integrable limit. We connect these field-induced dynamical phenomena to concrete experimental observables, relevant for neutron scattering, resonant inelastic X-ray scattering, and pump-probe spectroscopy that are capable of resolving specific types of fractionalized particles, including Majoranas and $Z_2$ fluxes."}
{"id": "2601.14297", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14297", "abs": "https://arxiv.org/abs/2601.14297", "authors": ["Tzula B. Propp", "Brandy Todd", "Sara A. Metwalli", "Alina Helena S. Gallardo", "Michael Dascal", "Denise Ruffner", "Klaus D. Jöns", "Shaeema Zaman", "Judith Kreukels", "Marilù Chiofalo", "Lydia Sanmartí-Vila"], "title": "Meeting the Needs of the Global Quantum Science Community: A Call to Action", "comment": null, "summary": "2025 marks one hundred years since the discovery of quantum mechanics. In the century since then, quantum science has blossomed into a global community composed of academics, engineers, developers, and entrepreneurs. The world is currently in the middle of the so-called second quantum revolution, with increased public awareness of quantum science and technology, and growing investment in both quantum hardware and software applications. However, representation remains low among historically marginalized groups: women, LGBTQ+, BIPOC, and people from the global south make up disproportionately few physicists. There are numerous efforts to improve diversity within quantum science, including through workforce development. But many of the changes enacted at the highest levels have failed to result in real change, as highlighted and discussed in the recent Women For Quantum Manifesto of Values. Here, we seek to echo and amplify the need for real change in the quantum ecosystem, emphasizing intersectionality and a feminist approach that centers the most vulnerable members of the quantum community: young students and researchers, especially those communities historically marginalized from quantum science.\n  This report is our attempt to help quantum communities meet this need; we have conducted a survey of quantum scientists all over the world, and here we include both a preliminary report of our findings and policy suggestions we have built to address them. The primary results of our survey are that, 1) marginalized quantum scientists are experiencing hardships and challenges more than their more privileged peers across all metrics, 2) that this fact is hurting retention of diverse, talented quantum scientists in our field, and 3) quantum EDI is an investment in talent retention and resilience building, which are essential for a thriving, globally competitive quantum ecosystem."}
{"id": "2601.14665", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14665", "abs": "https://arxiv.org/abs/2601.14665", "authors": ["Sharaf K. Magableh", "Caisheng Wang", "Oraib Dawaghreh"], "title": "A Two-Stage Risk-Averse DRO-MILP Methodological Framework for Managing AI/Data Center Demand Shocks", "comment": "Submitted to the 2026 IEEE Power and Energy Society General Meeting", "summary": "The rapid growth of artificial intelligence (AI)-driven data centers is reshaping electricity demand patterns. This is achieved by introducing fast, multi-gigawatt load ramps that challenge the stability and resilience of modern power systems. Traditional resilience frameworks focus mainly on physical outages and largely overlook these emerging digital-era disturbances. This paper proposes a unified two-stage, risk-aware distributionally robust optimization (DRO)-MILP framework that coordinates the pre-allocation and post-event dispatch of Flexible Capacity Modules (FCMs), including BESS, fast-ramping generation, demand response, and potential long-duration storage. Stage-I optimally positions FCMs using DRO with CVaR to hedge against uncertain AI load surges. Stage-II models real-time stabilization following stochastic demand-shock scenarios, minimizing imbalance, unserved energy, and restoration penalties. The framework is designed to be applied on IEEE 33-bus system or expanded for scalability to larger IEEE test feeders capable of representing AI-scale loads. This contributes a scalable planning tool for resilient, AI-integrated distribution grids."}
{"id": "2601.14727", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14727", "abs": "https://arxiv.org/abs/2601.14727", "authors": ["Shuxing Fang", "Ruijian Han", "Yuanhang Luo", "Yiming Xu"], "title": "Recent advances in the Bradley--Terry Model: theory, algorithms, and applications", "comment": null, "summary": "This article surveys recent progress in the Bradley-Terry (BT) model and its extensions. We focus on the statistical and computational aspects, with emphasis on the regime in which both the number of objects and the volume of comparisons tend to infinity, a setting relevant to large-scale applications. The main topics include asymptotic theory for statistical estimation and inference, along with the associated algorithms. We also discuss applications of these models, including recent work on preference alignment in machine learning. Finally, we discuss several key challenges and outline directions for future research."}
{"id": "2601.14629", "categories": ["math.OC", "cs.DS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14629", "abs": "https://arxiv.org/abs/2601.14629", "authors": ["Yuze Chen", "Yuan Zhou", "Baichuan Mo", "Jie Ying", "Yufei Ruan", "Zhou Ye"], "title": "Online Linear Programming with Replenishment", "comment": "63 pages, 12 figures", "summary": "We study an online linear programming (OLP) model in which inventory is not provided upfront but instead arrives gradually through an exogenous stochastic replenishment process. This replenishment-based formulation captures operational settings, such as e-commerce fulfillment, perishable supply chains, and renewable-powered systems, where resources are accumulated gradually and initial inventories are small or zero. The introduction of dispersed, uncertain replenishment fundamentally alters the structure of classical OLPs, creating persistent stockout risk and eliminating advance knowledge of the total budget.\n  We develop new algorithms and regret analyses for three major distributional regimes studied in the OLP literature: bounded distributions, finite-support distributions, and continuous-support distributions with a non-degeneracy condition. For bounded distributions, we design an algorithm that achieves $\\widetilde{\\mathcal{O}}(\\sqrt{T})$ regret. For finite-support distributions with a non-degenerate induced LP, we obtain $\\mathcal{O}(\\log T)$ regret, and we establish an $Ω(\\sqrt{T})$ lower bound for degenerate instances, demonstrating a sharp separation from the classical setting where $\\mathcal{O}(1)$ regret is achievable. For continuous-support, non-degenerate distributions, we develop a two-stage accumulate-then-convert algorithm that achieves $\\mathcal{O}(\\log^2 T)$ regret, comparable to the $\\mathcal{O}(\\log T)$ regret in classical OLPs. Together, these results provide a near-complete characterization of the optimal regret achievable in OLP with replenishment. Finally, we empirically evaluate our algorithms and demonstrate their advantages over natural adaptations of classical OLP methods in the replenishment setting."}
{"id": "2601.14984", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14984", "abs": "https://arxiv.org/abs/2601.14984", "authors": ["Jingwei Dong", "André M. H. Teixeira"], "title": "Stealthy bias injection attack detection based on Kullback-Leibler divergence in stochastic linear systems", "comment": "26 pages, 10 figures", "summary": "This paper studies the design of detection observers against stealthy bias injection attacks in stochastic linear systems under Gaussian noise, considering adversaries that exploit noise and inject crafted bias signals into a subset of sensors in a slow and coordinated manner, thereby achieving malicious objectives while remaining stealthy. To address such attacks, we formulate the observer design as a max-min optimization problem to enhance the detectability of worst-case BIAs, which attain a prescribed attack impact with the least detectability evaluated via Kullback-Leibler divergence. To reduce the computational complexity of the derived non-convex design problem, we consider the detectability of worst-case BIAs at three specific time instants: attack onset, one step after attack occurrence, and the steady state. We prove that the Kalman filter is optimal for maximizing the BIA detectability at the attack onset, regardless of the subset of attacked sensors. For the one-step and steady-state cases, the observer design problems are approximated by bi-convex optimization problems, which can be efficiently solved using alternating optimization and alternating direction method of multipliers. Moreover, more tractable linear matrix inequality relaxations are developed. Finally, the effectiveness of the proposed stealth-aware detection framework is demonstrated through an application to a thermal system."}
{"id": "2601.14638", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14638", "abs": "https://arxiv.org/abs/2601.14638", "authors": ["Jeongho Bang", "Kyoungho Cho", "Ki Hyuk Yee"], "title": "Quantum Interference Needs Convention: Overlap-Determinability and Unified No-Superposition Principle", "comment": "24 pages, 1 figure", "summary": "Quantum superposition is often phrased as the ability to add state vectors. In practice, however, the physical quantity is a ray (a rank-one projector), so each input specifies only a projector and leaves a gauge freedom in the phases of its vector representatives. This becomes a real operational barrier when one asks for a device that, given two independently prepared unknown pure states, outputs a coherent state proportional to a prescribed linear combination. We identify the missing ingredient as not probabilistic but phase-like. One needs a physical scenario that fixes a single phase convention on the relevant set of rays, so that the overlaps become well defined complex numbers. Thus, we formalize this through phase conventions and a single notion -- dubbed as \"overlap-determinability.\" Our main theorem gives an exact equivalence: A nonzero completely positive trace-nonincreasing map that probabilistically produces superposition on a domain exists if and only if that domain is overlap-determinable. This unifies modern no-superposition results and characterizes the exceptional yes-go protocols, which succeed precisely when side information supplies the required missing resource. We then show that granting universal access to such convention-fixed overlaps destabilizes the familiar foundational and computational constraints. It enables forbidden transformations akin to quantum cloning and yields super-luminal signaling. It would also permit reflections about unknown states, leading to exponentially fast overlap amplification and a collapse of Grover's search lower bound to a logarithmic query complexity."}
{"id": "2601.14794", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.14794", "abs": "https://arxiv.org/abs/2601.14794", "authors": ["Dimitrios G. Patsatzis", "Alessandro Della Pia", "Lucia Russo", "Constantinos Siettos"], "title": "RANDSMAPs: Random-Feature/multi-Scale Neural Decoders with Mass Preservation", "comment": "47 pages (23 in main text, 24 in Appendix), 19 figures (4 in main text, 15 in Appendix), 10 Tables (in Appendix)", "summary": "We introduce RANDSMAPs (Random-feature/multi-scale neural decoders with Mass Preservation), numerical analysis-informed, explainable neural decoders designed to explicitly respect conservation laws when solving the challenging ill-posed pre-image problem in manifold learning. We start by proving the equivalence of vanilla random Fourier feature neural networks to Radial Basis Function interpolation and the double Diffusion Maps (based on Geometric Harmonics) decoders in the deterministic limit. We then establish the theoretical foundations for RANDSMAP and introduce its multiscale variant to capture structures across multiple scales. We formulate and derive the closed-form solution of the corresponding constrained optimization problem and prove the mass preservation property. Numerically, we assess the performance of RANDSMAP on three benchmark problems/datasets with mass preservation obtained by the Lighthill-Whitham-Richards traffic flow PDE with shock waves, 2D rotated MRI brain images, and the Hughes crowd dynamics PDEs. We demonstrate that RANDSMAPs yield high reconstruction accuracy at low computational cost and maintain mass conservation at single-machine precision. In its vanilla formulation, the scheme remains applicable to the classical pre-image problem, i.e., when mass-preservation constraints are not imposed."}
{"id": "2601.14817", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14817", "abs": "https://arxiv.org/abs/2601.14817", "authors": ["Gennadiy Ivanovich Mironov"], "title": "Ionization energy and electron affinity of fullerene C60 in the Hubbard model in the static fluctuation approximation", "comment": "7", "summary": "Within the Hubbard model, the ionization energy and electron affinity of the icosahedral C60 fullerene are calculated in the static fluctuation approximation. A graphical representation of the chemical potential equation is first obtained. The correlation function, which describes the transitions of π-electrons from one fullerene site to the nearest site, and the thermodynamic average, which characterizes the probability of detecting two π-electrons with oppositely oriented spin projections on a single fullerene site, are then calculated. The theoretically obtained values for the ionization energy of 7.57 eV and the electron affinity of 2.67 eV coincide with the experimentally observed values and demonstrate that, during photoionization or another process leading to either the acquisition or loss of a π-electron, the fullerene responds to external perturbations as a single system of strongly correlated π-electrons."}
{"id": "2601.14307", "categories": ["physics.soc-ph", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.14307", "abs": "https://arxiv.org/abs/2601.14307", "authors": ["Tianqi Wang", "Teemu Jama", "Henrikki Tenkanen"], "title": "Assessing the livability within the 15-minute city concept based on mobile phone data", "comment": "29 pages", "summary": "Many cities promote walkability through concepts such as the compact city and 15-minute city to enhance urban livability, yet few methods link spatial walkability features to empirically measured livability and account for temporal dynamics. The method developed for this study uses mobile phone data from the Helsinki Metropolitan Area (Finland) to assess whether commonly used, literature-derived livability indicators (diversity, density, proximity, accessibility) predict observed human activity patterns across different times of day.\n  We constructed two key dimensions of livability: attractiveness and walkability with quantifiable sub-indicators that were selected based on literature. Our analysis shows that walkability, and even more so the combined livability index, correlates with activity patterns, outperforming the pure attractiveness perspective. However, this relationship is temporally unstable, significantly weakening at night and fluctuating daily. Moreover, based on Geographically Weighted Regression analysis, our results reveal significant spatial variation in the relationship between livability and the intensity of human activities. The findings suggest that traditional urban planning goals, such as functional diversity to enhance walkability, contribute to livability but have a limited impact on the 15-minute city's overall sustainable mobility objectives, necessitating a larger-scale perspective and more functionally profiled approaches for urban development."}
{"id": "2601.14673", "categories": ["eess.SY", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14673", "abs": "https://arxiv.org/abs/2601.14673", "authors": ["Yogesh Pipada Sunil Kumar", "S. Ali Pourmousavi", "Jon A. R. Liisberg", "Julian Lesmos-Vinasco"], "title": "Efficient reformulations of ReLU deep neural networks for surrogate modelling in power system optimisation", "comment": "24 pages, 7 figures, 3 tables", "summary": "The ongoing decarbonisation of power systems is driving an increasing reliance on distributed energy resources, which introduces complex and nonlinear interactions that are difficult to capture in conventional optimisation models. As a result, machine learning based surrogate modelling has emerged as a promising approach, but integrating machine learning models such as ReLU deep neural networks (DNNs) directly into optimisation often results in nonconvex and computationally intractable formulations. This paper proposes a linear programming (LP) reformulation for a class of convexified ReLU DNNs with non-negative weight matrices beyond the first layer, enabling a tight and tractable embedding of learned surrogate models in optimisation. We evaluate the method using a case study on learning the prosumer's responsiveness within an aggregator bidding problem in the Danish tertiary capacity market. The proposed reformulation is benchmarked against state-of-the-art alternatives, including piecewise linearisation (PWL), MIP-based embedding, and other LP relaxations. Across multiple neural network architectures and market scenarios, the convexified ReLU DNN achieves solution quality comparable to PWL and MIP-based reformulations while significantly improving computational performance and preserving model fidelity, unlike penalty-based reformulations. The results demonstrate that convexified ReLU DNNs offer a scalable and reliable methodology for integrating learned surrogate models in optimisation, with applicability to a wide range of emerging power system applications."}
{"id": "2601.14752", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14752", "abs": "https://arxiv.org/abs/2601.14752", "authors": ["Shushi Nishina", "Takahiro Onizuka", "Shintaro Hashimoto"], "title": "Global-local shrinkage priors for modeling random effects in multivariate spatial small area estimation", "comment": "39 pages, 10 figures", "summary": "Small area estimation (SAE) plays a central role in survey statistics and epidemiology, providing reliable estimates for domains with limited sample sizes. The multivariate Fay-Herriot model has been extensively used for this purpose, because it enhances estimation accuracy by borrowing strength across multiple correlated variables. In this paper, we develop a Bayesian extension of the multivariate Fay-Herriot model that enables flexible, component-specific shrinkage of the random effects. The proposed approach employs global-local priors formulated through a sandwich mixture representation, allowing adaptive regularization of each element of the random-effect vectors. This construction yields greater robustness and prevents excessive shrinkage in areas exhibiting strong underlying signals. In addition, we incorporate spatial dependence into the model to account for geographical correlation across small areas. The resulting spatial multivariate framework simultaneously exploits cross-variable relationships and spatial structure, yielding improved estimation efficiency. The utility of the proposed method is demonstrated through simulation studies and an empirical application to real survey data."}
{"id": "2601.14647", "categories": ["math.OC", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14647", "abs": "https://arxiv.org/abs/2601.14647", "authors": ["Yuchen Fang", "Xinshou Zheng", "Javad Lavaei"], "title": "TRSVR: An Adaptive Stochastic Trust-Region Method with Variance Reduction", "comment": "22 pages", "summary": "We propose a stochastic trust-region method for unconstrained nonconvex optimization that incorporates stochastic variance-reduced gradients (SVRG) to accelerate convergence. Unlike classical trust-region methods, the proposed algorithm relies solely on stochastic gradient information and does not require function value evaluations. The trust-region radius is adaptively adjusted based on a radius-control parameter and the stochastic gradient estimate. Under mild assumptions, we establish that the algorithm converges in expectation to a first-order stationary point. Moreover, the method achieves iteration and sample complexity bounds that match those of SVRG-based first-order methods, while allowing stochastic and potentially gradient-dependent second-order information. Extensive numerical experiments demonstrate that incorporating SVRG accelerates convergence, and that the use of trust-region methods and Hessian information further improves performance. We also highlight the impact of batch size and inner-loop length on efficiency, and show that the proposed method outperforms SGD and Adam on several machine learning tasks."}
{"id": "2601.15040", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15040", "abs": "https://arxiv.org/abs/2601.15040", "authors": ["Maiken Borud Omtveit", "Qian Long", "Valentin Chabaud", "Marte Ruud-Olsen", "Steinar Halsne", "Tor-Christian Ystgaard"], "title": "Electrical Design of a Clean Offshore Heat and Power (CleanOFF) Hub", "comment": null, "summary": "This paper presents an innovative offshore solution where oil & gas platform clusters are powered by a wind farm and a hydrogen hub. The results show a feasible off-grid design as an alternative to conventional electrification solutions. To address the challenges of design and operation of such a system, a power system model of the equipment and control was developed in a power system simulator called Process Power Simulator (PPSim). Power fluctuations in the wind farm are modelled using a state-of-the-art method encompassing turbulence and wakes. Various operation scenarios were used to evaluate the system design and find the right equipment size. An expensive component to over dimension is the battery energy storage system (BESS). The BESS power rating and energy capacity were found by running a combination of scenarios with extreme and natural wind variations, and contingencies. The control strategy and ramp rates of electrolyzers have significant impact on both system performance and design. A ramp rate in the order of seconds as opposed to minutes will decrease the required BESS size by 60-70%. Choosing synchronized control of the electrolyzers can further reduce the BESS size by 15-20%. The simulations also revealed challenges to achieve self-sufficiency of hydrogen and potential design improvements are suggested."}
{"id": "2601.14708", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.14708", "abs": "https://arxiv.org/abs/2601.14708", "authors": ["Binke Xia", "Zhaotong Cui", "Jingzheng Huang", "Yuxiang Yang", "Guihua Zeng"], "title": "Scaling Enhancement in Distributed Quantum Sensing via Causal Order Switching", "comment": null, "summary": "Sensing networks underpin applications from fundamental physics to real-world engineering. Recently, distributed quantum sensing (DQS) has been investigated to boost the sensing performance, yet current schemes typically rely on entangled probes that are fragile to noise and difficult to scale. Here, we propose a DQS protocol that incorporates a causal-order switch into a cyclic network, enabling a single probe to sequentially query N independent sensors in a coherent superposition or a probabilistic mixture of opposite causal orders. By exploiting the noncommutativity between propagation and sensing processes, our scheme achieves a 1/N^2-scaling precision limit without involving entangled probes. Importantly, our approach utilizes a classical mixture of causal orders rather than a quantum switch, making it more feasible for practical realization. We experimentally implement this scheme for distributed beam tilts sensing in a free-space quantum optical network comprising up to 9 sensors, achieving picoradian-scale precision in estimating tilt angle. Our results demonstrate a robust and scalable DQS protocol that surpasses the conventional 1/N Heisenberg scaling in precision, advancing the practical deployment of quantum sensing networks."}
{"id": "2601.14858", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14858", "abs": "https://arxiv.org/abs/2601.14858", "authors": ["Rohit Sunil Kanchi", "Sicheng He"], "title": "Modal-Centric Field Inversion via Differentiable Proper Orthogonal Decomposition", "comment": null, "summary": "Inverse problems in computational physics often require matching high-dimensional spatio-temporal fields, leading to prohibitive computational costs and ill-conditioned optimizations. We introduce modal-centric field inversion (MCFI), a paradigm that reformulates inverse problems in the reduced space of proper orthogonal decomposition (POD) modes rather than the full physical state space. By targeting dominant flow structures instead of point-wise field values, MCFI provides a compact, physically meaningful objective that naturally regularizes the inversion and dramatically reduces computational burden. Central to this framework is the differentiable POD: an adjoint-based method that efficiently computes sensitivities of POD modes with respect to model parameters, enabling gradient-based optimization in the modal space. We demonstrate MCFI on a one and two-dimensional modified viscous Burger's equation, optimizing spatially varying coefficients to match target dynamics through mode-matching. The adjoint formulation achieves computational cost independent of parameter dimension, in contrast to finite-difference approaches that scale linearly. MCFI establishes a foundation for scalable inverse design and model calibration in unsteady, high-dimensional systems."}
{"id": "2601.14878", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14878", "abs": "https://arxiv.org/abs/2601.14878", "authors": ["V. P. Mineev"], "title": "Altermagnets versus Antiferromagnets", "comment": "4 pages, 3 figures", "summary": "Altermagnets are metals with a momentum-dependent spin splitting of electron bands due to a specific crystal structure, which is invariant under time reversal only in combination with rotations and reflections. The developed phenomenological approach makes it possible to obtain a spectrum of electron bands in an altermagnet corresponding to an antiferromagnet with the same symmetry. The anomalous Hall effect is an inherent property of substances whose electron band dispersion is characterized by the Berry curvature. Calculations of the Berry curvature were performed for altermagnet analogs of collinear antiferromagnet, weak ferromagnetic antiferromagnet, and ferrimagnetic structures. It was shown that in the specific cases under consideration, the anomalous Hall effect in the absence of an external magnetic field is possible only in the state of a weak ferromagnet."}
{"id": "2601.14319", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.14319", "abs": "https://arxiv.org/abs/2601.14319", "authors": ["Fabian Veider", "Georg Jäger", "Bao Quoc Tang"], "title": "How Recommendation Algorithms Shape Social Networks: An Adaptive Voter Model Approach", "comment": "21 pages, 11 figures", "summary": "The rise of social media and recommendation algorithms has sparked concerns about their role in fostering opinion polarization and echo chambers. We study these phenomena using an adaptive voter model to compare two connection mechanisms: \"free\" global rewiring, where individuals connect with anyone sharing their opinion, and \"friend-of-a-friend\" local rewiring, which mimics algorithmic link recommendations on platforms like Facebook or LinkedIn. Simulations across different network topologies reveal that local rewiring increases final-state polarization of the system and fragments social networks into many disconnected components. The usual phase transition into two disconnected components turns into a fragmentation of smaller components, leading to an increase in echo chambers as well as many isolated nodes. This effect is most pronounced in clustered networks with high homophily in rewiring, illustrating how recommendation algorithms can intensify social fragmentation by changing the very structure of the network."}
{"id": "2601.14689", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14689", "abs": "https://arxiv.org/abs/2601.14689", "authors": ["Hyeongon Park", "Daniel K. Molzahn", "Rahul K. Gupta"], "title": "Ramping-aware Enhanced Flexibility Aggregation of Distributed Generation with Energy Storage in Power Distribution Networks", "comment": "10 pages, 4 figures", "summary": "Power distribution networks are increasingly hosting controllable and flexible distributed energy resources (DERs) that, when aggregated, can provide ancillary support to transmission systems. However, existing aggregation schemes often ignore the ramping constraints of these DERs, which can render them impractical in real deployments. This work proposes a ramping-aware flexibility aggregation scheme, computed at the transmission-distribution boundary, that explicitly accounts for DER ramp limits and yields flexibility envelopes that are provably disaggregable. To further enhance the attainable flexibility region, we introduce a novel pre-ramping strategy, which proactively adjusts resource operating points to enlarge the aggregated flexibility envelope while preserving both network feasibility and disaggregation guarantees. The proposed method demonstrates a 5.2% to 19.2% improvement in flexibility relative to the baseline model, depending on system conditions. We validate the scheme on an IEEE-33 bus distribution system and provide formal proofs showing that both aggregation strategies are disaggregable for all feasible trajectories within the aggregate flexibility envelope."}
{"id": "2601.14849", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14849", "abs": "https://arxiv.org/abs/2601.14849", "authors": ["Laura Ferrini", "Federico Castelletti"], "title": "Graphical model-based clustering of categorical data", "comment": null, "summary": "Clustering multivariate data is a pervasive task in many applied problems, particularly in social studies and life science. Model-based approaches to clustering rely on mixture models, where each mixture component corresponds to the kernel of a distribution characterizing a latent sub-group. Current methods developed within this framework employ multivariate distributions built under the assumption of independence among variables given the cluster allocation. Accordingly, possible dependence structures characterizing differences across groups are not directly accounted for during the clustering process. In this paper we consider multivariate categorical data, and introduce a model-based clustering method which employs graphical models as a tool to encode dependencies between variables. Specifically, we consider a Dirichlet Process mixture of categorical graphical models, which clusters individuals into groups that are homogeneous in terms of dependence (graphical) structure and allied parameters. We provide full Bayesian inference for the model and develop a Markov chain Monte Carlo scheme for posterior analysis. Our method is evaluated through simulations and applied to real case studies, including the analysis of genomic data and voting records. Results reveal the merits of a graphical model-based clustering, in comparison with approaches that do not explicitly account for dependencies in the multivariate distribution of variables."}
{"id": "2601.14680", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14680", "abs": "https://arxiv.org/abs/2601.14680", "authors": ["Zhenwei Lin", "Zhe Zhang"], "title": "Optimal Methods for Unknown Piecewise Smooth Problems I: Convex Optimization", "comment": "37 pages, 6 figures", "summary": "We introduce an optimal and nearly parameter-free algorithm for minimizing piecewise smooth (PWS) convex functions under the quadratic growth (QG) condition, where the locations and structure of the smooth regions are entirely \\textit{unknown}. Our algorithm, \\apex{} (Accelerated Prox-Level method for Exploring Piecewise Smoothness), is an accelerated bundle-level method designed to adaptively exploit the underlying PWS structure. APEX enjoys optimal theoretical guarantees, achieving a tight oracle complexity bound that matches the lower bound established in this work for convex PWS optimization. Furthermore, APEX generates a verifiable and accurate termination certificate, enabling a robust, almost parameter-free implementation. To the best of our knowledge, APEX is the first algorithm to simultaneously achieve the optimal convergence rate for PWS optimization and provide certificate guarantees."}
{"id": "2601.15099", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.15099", "abs": "https://arxiv.org/abs/2601.15099", "authors": ["A. Vaca", "J. Gutierrez Florensa", "F. Milano"], "title": "Instantaneous Frequency in Power Systems using the Teager-Kaiser Energy Operator", "comment": null, "summary": "This paper develops an instantaneous-frequency (IF) local estimator calculated with the complex Teager-Kaiser energy operator (CTKEO) and the dynamic-signal identity. The contribution is a novel IF expression that makes the envelope-curvature terms explicit, thus correcting the bias that affects conventional estimators used in power systems. The estimator aligns with complex-frequency (CF) kinematics and admits a geometric interpretation (curvature/torsion) without phase unwrapping. Simulations and data-driven examples demonstrate the accuracy of the proposed approach."}
{"id": "2601.14713", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.14713", "abs": "https://arxiv.org/abs/2601.14713", "authors": ["Tingting Li", "Ziming Zhao", "Jianwei Yin"], "title": "Adaptive Fidelity Estimation for Quantum Programs with Graph-Guided Noise Awareness", "comment": "Published in AAAI 2026;", "summary": "Fidelity estimation is a critical yet resource-intensive step in testing quantum programs on noisy intermediate-scale quantum (NISQ) devices, where the required number of measurements is difficult to predefine due to hardware noise, device heterogeneity, and transpilation-induced circuit transformations. We present QuFid, an adaptive and noise-aware framework that determines measurement budgets online by leveraging circuit structure and runtime statistical feedback. QuFid models a quantum program as a directed acyclic graph (DAG) and employs a control-flow-aware random walk to characterize noise propagation along gate dependencies. Backend-specific effects are captured via transpilation-induced structural deformation metrics, which are integrated into the random-walk formulation to induce a noise-propagation operator. Circuit complexity is then quantified through the spectral characteristics of this operator, providing a principled and lightweight basis for adaptive measurement planning. Experiments on 18 quantum benchmarks executed on IBM Quantum backends show that QuFid significantly reduces measurement cost compared to fixed-shot and learning-based baselines, while consistently maintaining acceptable fidelity bias."}
{"id": "2601.14911", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14911", "abs": "https://arxiv.org/abs/2601.14911", "authors": ["Paula Hilbert", "Ani Miraçi", "Dirk Praetorius"], "title": "Generalized preconditioned conjugate gradients for adaptive FEM with optimal complexity", "comment": null, "summary": "We consider adaptive finite element methods (AFEMs) with inexact algebraic solver for second-order symmetric linear elliptic diffusion problems. We formulate and analyze a non-linear and non-symmetric geometric multigrid preconditioner for the generalized preconditioned conjugate gradient method (GPCG) used to solve the arising finite element systems. Moreover, a linear and symmetric variant of the geometric multigrid preconditioner that is suitable for the (standard) preconditioned conjugate gradient method (PCG) is provided and analyzed. We show that both preconditioners are optimal in the sense that, first, the resulting algebraic solvers admit a contraction factor that is independent of the local mesh size h and the polynomial degree p, and, second, that they can be applied with linear computational complexity. Related to this, quasi-optimal computational cost of the overall adaptive finite element method is addressed. Numerical experiments underline the theoretical findings."}
{"id": "2601.14989", "categories": ["cond-mat.str-el", "cond-mat.quant-gas", "physics.plasm-ph"], "pdf": "https://arxiv.org/pdf/2601.14989", "abs": "https://arxiv.org/abs/2601.14989", "authors": ["Fotios Kalkavouras", "Tobias Dornheim", "Paul Hamann", "Panagiotis Tolias"], "title": "Dielectric formalism of the 2D uniform electron gas at finite temperatures", "comment": "18 pages, 9 figures", "summary": "We present a comprehensive analysis of the two-dimensional uniform electron gas (2D-UEG or more commonly 2DEG) at finite temperature, spanning a broad range of densities / coupling strengths ($0.01\\le{r}_s\\le20$) and temperatures / degeneracy parameters ($0.01\\leΘ= k_B T/E_F \\le 10$). Within the self-consistent dielectric formalism, we construct two-dimensional versions of the Singwi-Tosi-Land-Sjölander (STLS) and hypernetted-chain (HNC) approximation based schemes. We benchmark the accuracy of the STLS and the HNC schemes against new state-of-the-art path-integral Monte Carlo data. We also report structural and thermodynamic properties across the full $(r_s,Θ)$ phase diagram domain studied, identify regimes in which these schemes remain quantitatively reliable, and provide an accurate parametrization of the exchange--correlation free energy of the finite-temperature 2DEG."}
{"id": "2601.14322", "categories": ["physics.soc-ph", "econ.GN", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2601.14322", "abs": "https://arxiv.org/abs/2601.14322", "authors": ["Karl Svozil"], "title": "Dirac's Dilemma of the Economy of Inheritance: Parental Care, Equality of Opportunity, and Managed Inequality", "comment": "7 pages", "summary": "In a brief reflection on the principles of human society, P. A. M. Dirac articulated a structural tension between two widely affirmed norms: that it is good and natural for parents to improve the prospects of their own children, and that justice requires that all children have equal opportunities in life. These principles, each compelling on its own, cannot be fully realized together. This paper reconstructs Dirac's dilemma, connects it to the dynamics of compounding advantage and inheritance, and situates it within the broader history of political philosophy, including the work of Rawls, Dworkin, Cohen, Brighouse and Swift, Nozick, Murphy and Nagel, and others. The paper argues that attempts to eliminate the resulting injustices entirely risk damaging the non--zero--sum structures that generate general prosperity, and defends a position of \"managed inequality\": a robust social floor and real mobility, combined with limits on extreme dynastic accumulation and an explicit acceptance of some residual, but constrained, inherited advantage."}
{"id": "2601.14704", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14704", "abs": "https://arxiv.org/abs/2601.14704", "authors": ["Ruixing Ren", "Minqi Tao", "Junhui Zhao", "Xiaoke Sun", "Qiuping Li"], "title": "Hierarchical Optimization Based Multi-objective Dynamic Regulation Scheme for VANET Topology", "comment": "10 pages, 6 figures. A topology optimization strategy is proposed in this paper to optimize the latency, average path length, and throughput in Vehicular Ad Hoc Networks (VANETs)", "summary": "As a core technology of intelligent transportation systems, vehicular ad-hoc networks support latency-sensitive services such as safety warning and cooperative perception via vehicle-to-everything communications. However, their highly dynamic topology increases average path length, raises latency, and reduces throughput, severely limiting communication performance. Existing topology optimization methods lack capabilities in multi-objective coordination, dynamic adaptation, and global-local synergy. To address this, this paper proposes a two-layer dynamic topology regulation scheme combining local feature aggregation and global adjustment. The scheme constructs a dynamic multi-objective optimization model integrating average path length, end-to-end latency, and network throughput, and achieves multi-index coordination via link adaptability metrics and a dynamic normalization mechanism. it quickly responds to local link changes via feature fusion of local node feature extraction and dynamic neighborhood sensing, and balances optimization accuracy and real-time performance using a dual-mode adaptive solving strategy for global topology adjustment. It reduces network oscillation risks by introducing a performance improvement threshold and a topology validity verification mechanism. Simulation results on real urban road networks via the SUMO platform show that the proposed scheme outperforms traditional methods in average path length (stabilizing at ~4 hops), end-to-end latency (remaining ~0.01 s), and network throughput."}
{"id": "2601.14937", "categories": ["stat.ME", "math.ST", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.14937", "abs": "https://arxiv.org/abs/2601.14937", "authors": ["Juan J. Segura"], "title": "Geostatistics from Elliptic Boundary-Value Problems: Green Operators, Transmission Conditions, and Schur Complements", "comment": null, "summary": "Classical geostatistics encodes spatial dependence by prescribing variograms or covariance kernels on Euclidean domains, whereas the SPDE--GMRF paradigm specifies Gaussian fields through an elliptic precision operator whose inverse is the corresponding Green operator. We develop an operator-based formulation of Gaussian spatial random fields on bounded domains and manifolds with internal interfaces, treating boundary and transmission conditions as explicit components of the statistical model. Starting from coercive quadratic energy functionals, variational theory yields a precise precision--covariance correspondence and shows that variograms are derived quadratic functionals of the Green operator, hence depend on boundary conditions and domain geometry. Conditioning and kriging follow from standard Gaussian update identities in both covariance and precision form, with hard constraints represented equivalently by exact interpolation constraints or by distributional source terms. Interfaces are modelled via surface penalty terms; taking variations produces flux-jump transmission conditions and induces controlled attenuation of cross-interface covariance. Finally, boundary-driven prediction and domain reduction are formulated through Dirichlet-to-Neumann operators and Schur complements, providing an operator language for upscaling, change of support, and subdomain-to-boundary mappings. Throughout, we use tools standard in spatial statistics and elliptic PDE theory to keep boundary and interface effects explicit in covariance modeling and prediction."}
{"id": "2601.14819", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14819", "abs": "https://arxiv.org/abs/2601.14819", "authors": ["José Niño-Mora"], "title": "A fast-pivoting algorithm for Whittle's restless bandit index", "comment": "23 pages", "summary": "The Whittle index for restless bandits (two-action semi-Markov decision processes) provides an intuitively appealing optimal policy for controlling a single generic project that can be active (engaged) or passive (rested) at each decision epoch, and which can change state while passive. It further provides a practical heuristic priority-index policy for the computationally intractable multi-armed restless bandit problem, which has been widely applied over the last three decades in multifarious settings, yet mostly restricted to project models with a one-dimensional state. This is due in part to the difficulty of establishing indexability (existence of the index) and of computing the index for projects with large state spaces. This paper draws on the author's prior results on sufficient indexability conditions and an adaptive-greedy algorithmic scheme for restless bandits to obtain a new fast-pivoting algorithm that computes the $n$ Whittle index values of an $n$-state restless bandit by performing, after an initialization stage, $n$ steps that entail $(2/3) n^3 + O(n^2)$ arithmetic operations. This algorithm also draws on the parametric simplex method, and is based on elucidating the pattern of parametric simplex tableaux, which allows to exploit special structure to substantially simplify and reduce the complexity of simplex pivoting steps. A numerical study demonstrates substantial runtime speed-ups versus alternative algorithms."}
{"id": "2601.15135", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15135", "abs": "https://arxiv.org/abs/2601.15135", "authors": ["Natanon Tongamrak", "Kannapha Amaruchkul", "Wijarn Wangdee", "Jitkomut Songsiri"], "title": "Stochastic EMS for Optimal 24/7 Carbon-Free Energy Operations", "comment": "23 pages", "summary": "This paper proposes a two-stage stochastic optimization formulation to determine optimal operation and procurement plans for achieving a 24/7 carbon-free energy (CFE) compliance at minimized cost. The system in consideration follows primary energy technologies in Thailand including solar power, battery storage, and a diverse portfolio of renewable and carbon-based energy procurement sources. Unlike existing literature focused on long-term planning, this study addresses near real-time operations using a 15-minute resolution. A novel feature of the formulation is the explicit treatment of CFE compliance as a model parameter, enabling flexible targets such as a minimum percentage of hourly matching or a required number of carbon-free days within a multi-day horizon. The mixed-integer linear programming formulation accounts for uncertainties in load and solar generation by integrating deep learning-based forecasting within a receding horizon framework. By optimizing battery profiles and multi-source procurement simultaneously, the proposed system provides a feasible pathway for transitioning to carbon-free operations in emerging energy markets."}
{"id": "2601.14734", "categories": ["quant-ph", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.14734", "abs": "https://arxiv.org/abs/2601.14734", "authors": ["Seng W. Loke"], "title": "On Distributed Quantum Computing with Distributed Fan-Out Operations", "comment": "5 pages, 8 figures", "summary": "We compare different circuits implementing distributed versions of quantum computations, using entangled pairs only, and using distributed fan-out operations (using GHZ states). We highlight the advantages of using distributed fan-out operations in terms of reductions in circuit depth and (possibly) entanglement resources. We note that distributed fan-out operations (or notably, distributed GHZ states) could be a ``primitive'' building block for distributed quantum operations in the same way as entangled pairs are, if distributed GHZ states could be realized efficiently."}
{"id": "2601.14933", "categories": ["math.NA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14933", "abs": "https://arxiv.org/abs/2601.14933", "authors": ["Yogesh Darmwal", "Ketan Rajawat"], "title": "Rank-one Riemannian Subspace Descent for Nonlinear Matrix Equations", "comment": null, "summary": "We propose a rank-one Riemannian subspace descent algorithm for computing symmetric positive definite (SPD) solutions to nonlinear matrix equations arising in control theory, dynamic programming, and stochastic filtering. For solution matrices of size $n\\times n$, standard approaches for dense matrix equations typically incur $\\mathcal{O}(n^3)$ cost per-iteration, while the efficient $\\mathcal{O}(n^2)$ methods either rely on sparsity or low-rank solutions, or have iteration counts that scale poorly. The proposed method entails updating along the dominant eigen-component of a transformed Riemannian gradient, identified using at most $\\mathcal{O}(\\log(n))$ power iterations. The update structure also enables exact step-size selection in many cases at minimal additional cost. For objectives defined as compositions of standard matrix operations, each iteration can be implemented using only matrix--vector products, yielding $\\mathcal{O}(n^2)$ arithmetic cost. We prove an $\\mathcal{O}(n)$ iteration bound under standard smoothness assumptions, with improved bounds under geodesic strong convexity. Numerical experiments on large-scale CARE, DARE, and other nonlinear matrix equations show that the proposed algorithm solves instances (up to $n=10{,}000$ in our tests) for which the compared solvers, including MATLAB's \\texttt{icare}, structure-preserving doubling, and subspace-descent baselines fail to return a solution. These results demonstrate that rank-one manifold updates provide a practical approach for high-dimensional and dense SPD-constrained matrix equations. MATLAB code implementation is publicly available on GitHub : \\href{https://github.com/yogeshd-iitk/nonlinear_matrix_equation_R1RSD}{\\textcolor{blue}{https://github.com/yogeshd-iitk/nonlinear\\_matrix \\_equation\\_R1RSD}}"}
{"id": "2601.15007", "categories": ["cond-mat.str-el", "cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.15007", "abs": "https://arxiv.org/abs/2601.15007", "authors": ["M. S. Laad", "Prosenjit Haldar"], "title": "Anomalous Quantum Criticality at a Continuous Metal-Insulator Transition", "comment": "17 pages, 3 figures", "summary": "The Falicov-Kimball model (FKM) is long known to be the simplest model of correlated fermions exhibiting a novel Mott-like quantum critical point (QCP) assocaited with a {\\it continuous} MIT in dimensions $D \\geq 3$. It is also known to be isomorphic to an {\\it annealed} binary-alloy disorder model. Notwithstanding extensive numerical studies for the FKM, analytic insight into the microscopic processes spawning novel Mott-like quantum criticality is scarce. Here, we develop a fully analytic theory for the Mott-like quantum criticality in the FKM on a hierarchical Cayley tree (Bethe lattice) by utilizing a single input from a 2-site cluster-dynamical mean-field theory (CDMFT). We find that density fluctuation modes acquire anomalous dimensions, originating from infra-red power-law singular cluster self-energies. Interestingly, we uncover, at $T=0$, that this {\\it sub-diffusive} metal with glassy dynamics separating a weakly ergodic metal from a non-ergodic insulator shrinks to a single point, namely the Mott-like QCP, at least on the Bethe lattice. We detail the consequences of this anomalous quantum criticality for a range of thermal and dynamical responses in a variety of physical systems that can be effectively modelled by the FKM."}
{"id": "2601.14325", "categories": ["physics.soc-ph", "econ.EM"], "pdf": "https://arxiv.org/pdf/2601.14325", "abs": "https://arxiv.org/abs/2601.14325", "authors": ["Li Tuobang"], "title": "The Maintenance and Necessity of Universal Rules: Scale, Hierarchy, the Cost of Justice, and Civilizational Development", "comment": null, "summary": "Building upon previous research, this paper further explores the topological foundations for maintaining universal rules within ultra-large-scale societies. It finds that in small-scale societies, absolute egalitarianism and the rule of law can be compatible through peer monitoring within a fully connected network. However, in ultra-large-scale societies, to maintain high-dimensional rules capable of protecting innovation and property rights, a complex hierarchical structure including \"high-fragility\" nodes must be constructed. Through quantitative analysis of power structures, this paper proves that a flattened, two-tier structure inevitably leads to the degradation of the rule of law. Only a social topology with sufficient hierarchical depth can escape the deathly trap of the Leviathan while expanding in scale, thereby sustaining the dynamic evolution of civilization."}
{"id": "2601.14725", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14725", "abs": "https://arxiv.org/abs/2601.14725", "authors": ["Zihao Ren", "Lei Wang", "Deming Yuan", "Guodong Shi"], "title": "Differential Privacy on Affine Manifolds: Geometrically Confined Privacy in Linear Dynamical Systems", "comment": null, "summary": "In this paper, we present a comprehensive framework for differential privacy over affine manifolds and validate its usefulness in the contexts of differentially private cloud-based control and average consensus. We consider differential privacy mechanisms for linear queries when the input data are constrained to lie on affine manifolds, a structural property that is assumed to be available as prior knowledge to adversaries. In this setting, the definition of neighborhood adjacency must be formulated with respect to the intrinsic geometry of the manifolds. We demonstrate that such affine-manifold constraints can fundamentally alter the attainable privacy levels relative to the unconstrained case. In particular, we derive necessary and sufficient conditions under which differential privacy can be realized via structured noise injection mechanisms, wherein correlated Gaussian or Laplace noise distributions, rather than i.i.d. perturbations, are calibrated to the dataset. Based on these characterizations, we develop explicit noise calibration procedures that guarantee the tight realization of any prescribed privacy budget with a matching noise magnitude. Finally, we show that the proposed framework admits direct applications to linear dynamical systems ranging from differentially private cloud-based control to privacy-preserving average consensus, all of which naturally involve affine-manifold constraints. The established theoretical results are illustrated through numerical examples."}
{"id": "2601.14991", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14991", "abs": "https://arxiv.org/abs/2601.14991", "authors": ["Martin Bladt", "Rasmus Frigaard Lemvig"], "title": "Consistency of Honest Decision Trees and Random Forests", "comment": null, "summary": "We study various types of consistency of honest decision trees and random forests in the regression setting. In contrast to related literature, our proofs are elementary and follow the classical arguments used for smoothing methods. Under mild regularity conditions on the regression function and data distribution, we establish weak and almost sure convergence of honest trees and honest forest averages to the true regression function, and moreover we obtain uniform convergence over compact covariate domains. The framework naturally accommodates ensemble variants based on subsampling and also a two-stage bootstrap sampling scheme. Our treatment synthesizes and simplifies existing analyses, in particular recovering several results as special cases. The elementary nature of the arguments clarifies the close relationship between data-adaptive partitioning and kernel-type methods, providing an accessible approach to understanding the asymptotic behavior of tree-based methods."}
{"id": "2601.14828", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14828", "abs": "https://arxiv.org/abs/2601.14828", "authors": ["Deniz Tuncer", "Burak Kocuk"], "title": "MIQCP and MISOCP-Based Solution Methods for the Multi-Layer Thin Films Problem", "comment": null, "summary": "The Multi-Layer Thin Films Problem is a materials science problem that aims to enhance the reflectance of a metallic substrate by designing multi-layer coatings composed of different dielectric materials and thicknesses. While previous studies on the problem mostly rely on heuristic approaches and are designed for single wavelength applications, this work addresses the problem using global optimization techniques for multiple wavelengths. We develop an exact nonconvex mixed-integer quadratically constrained programming (MIQCP) model to solve this problem. We also develop a mixed-integer second-order cone programming relaxation that has computational advantage over the MIQCP model. Our numerical experiments yield solutions that have average reflectance of 99% over the visible spectrum (380-770 nm) and 95% over the broad spectrum (300-3000 nm)."}
{"id": "2601.15196", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15196", "abs": "https://arxiv.org/abs/2601.15196", "authors": ["Jianye Xu", "Bassam Alrifaee"], "title": "TTCBF: A Truncated Taylor Control Barrier Function for High-Order Safety Constraints", "comment": null, "summary": "Control Barrier Functions (CBFs) enforce safety by rendering a prescribed safe set forward invariant. However, standard CBFs are limited to safety constraints with relative degree one, while High-Order CBF (HOCBF) methods address higher relative degree at the cost of introducing a chain of auxiliary functions and multiple class K functions whose tuning scales with the relative degree. In this paper, we introduce a Truncated Taylor Control Barrier Function (TTCBF), which generalizes standard discrete-time CBFs to consider high-order safety constraints and requires only one class K function, independent of the relative degree. We also propose an adaptive variant, adaptive TTCBF (aTTCBF), that optimizes an online gain on the class K function to improve adaptability, while requiring fewer control design parameters than existing adaptive HOCBF variants. Numerical experiments in a relative-degree-six spring-mass system and a cluttered corridor navigation validate the above theoretical findings."}
{"id": "2601.14763", "categories": ["quant-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14763", "abs": "https://arxiv.org/abs/2601.14763", "authors": ["Qinghao Wen", "Zihao Ren", "Lei Wang", "Hyungbo Shim", "Guodong Shi"], "title": "Blended Dynamics and Emergence in Open Quantum Networks", "comment": null, "summary": "In this paper, we develop a blended dynamics framework for open quantum networks with diffusive couplings. The network consists of qubits interconnected through Hamiltonian couplings, environmental dissipation, and consensus-like diffusive interactions. Such networks commonly arise in spontaneous emission processes and non-Hermitian quantum computing, and their evolution follows a Lindblad master equation. Blended dynamics theory is well established in the classical setting as a tool for analyzing emergent behaviors in heterogeneous networks with diffusive couplings. Its key insight is to blend the local dynamics rather than the trajectories of individual nodes. Perturbation analysis then shows that, under sufficiently strong coupling, all node trajectories tend to stay close to those of the blended system over time. We first show that this theory extends naturally to the reduced-state dynamics of quantum networks, revealing classical-like clustering phenomena in which qubits converge to a shared equilibrium or a common trajectory determined by the quantum blended reduced-state dynamics. We then extend the analysis to qubit coherent states using quantum Laplacians and induced graphs, proving orbit attraction of the network density operator toward the quantum blended coherent dynamics, establishing the emergence of intrinsically quantum and dynamically clustering behaviors. Finally, numerical examples validate the theoretical results."}
{"id": "2601.14940", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.14940", "abs": "https://arxiv.org/abs/2601.14940", "authors": ["Inna K. Shingareva", "Andrei D. Polyanin"], "title": "Nonclassical symmetries of polynomial equations and test problems with parameters for computer algebra systems", "comment": "25 pages, 3 figures, 2 Tables", "summary": "Nonclassical symmetries and reductions of polynomial equations and systems of polynomial equations are considered. It is shown that specific polynomial equations having \"hidden\" symmetries can be reduced to classical symmetric systems of polynomial equations by introducing a new additional variable. It has been established that symmetric systems of polynomial equations of mixed type, consisting of symmetric and anti-symmetric polynomials, can be transformed into simpler systems. A method is presented for solving nonclassical symmetric systems of two polynomial equations that change places when the unknowns are permuted. We study polynomial equations containing the second iteration of a given polynomial, which are reduced to nonclassical symmetric systems of equations. New higher-degree polynomial equations containing free parameters that admit solutions in radicals are found. Three such equations of the sixth and ninth degrees are further used as test problems with parameters for analyzing the capabilities of two leading computer algebra systems. It is shown that currently, the Maple and Mathematica systems do not allow us to efficiently find analytical solutions (in radicals) of polynomial equations with free parameters, but they allow us to obtain numerical solutions of equations for fixed numerical values of the parameters. The results of this work and the proposed test problems with parameters can be used to further improve existing computer algebra systems."}
{"id": "2601.15169", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.15169", "abs": "https://arxiv.org/abs/2601.15169", "authors": ["Cody A. Melton", "Jaron T. Krogel"], "title": "Assessing Orbital Optimization in Variational and Diffusion Monte Carlo", "comment": "12 pages, 10 figures", "summary": "In this work, we investigate the fidelity of orbital optimization in variational Monte Carlo to improve diffusion Monte Carlo results on correlated magnetic systems, using CrSBr as a model system. We compare the performance of different optimization methods, showing that stochastic reconfiguration is a robust and reliable optimizer. We show that short range Jastrow factors are important for improving diffusion Monte Carlo, regardless of the quality of orbitals. Large active spaces are required to converge the variational energy, but ulitmately orbital optimization produces worse diffusion Monte Carlo energies when compared to standard orbitals from density functional theory. We show that this increased bias is due to larger locality errors from the use of pseudopotentials, while the fixed-node error is actually improved by using orbital optimization. Additionally, for observables other than energy, orbital optimization produces a systematically smaller mixed-estimator bias. Ultimately, we believe orbital optimization provides a reliable method to improve variational and pure fixed-node energies as well as lower mixed-estimator bias."}
{"id": "2601.14344", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.14344", "abs": "https://arxiv.org/abs/2601.14344", "authors": ["Sam Turley", "Matthew Turner"], "title": "Causal Entropy, Control and Leadership Dynamics", "comment": "Submitted to EPJ E Topical Issue: Endowing Active Particles with Artificial Intelligence", "summary": "Collective motion in animal groups provide examples of emergent, decentralised coordination. Here, we examine a bottom-up model of collective behavior based on Future State Maximisation (FSM). In this model agents seek to maximise the diversity of their future visual states over a finite time horizon. We further assume that a subset of agents have a directional bias, e.g. towards different destinations. We observe swarm fragmentation on increasing (i) the strength of these preferences, or (ii) the difference in preferred directions, or (iii) the number of biased agents. Depending on these factors, biased agents can leave the swarm alone, leaving behind all other agents, or they can entrain some fraction of the group to leave with them. We further study the role of a classical nearest-neighbor alignment term on cohesion. Notably, we identify the existence of an finite, optimal coupling strength that suppresses fragmentation and maximises the flock cohesion. Our results demonstrate that FSM can be successfully combined with classical flocking rules, offering a flexible framework for modeling intelligent collective systems."}
{"id": "2601.14880", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14880", "abs": "https://arxiv.org/abs/2601.14880", "authors": ["Lei Zheng", "Luyao Zhang", "Peiqi Yu", "Yifan Sun", "Sergio Grammatico", "Jun Ma", "Changliu Liu"], "title": "Contingency Planning for Safety-Critical Autonomous Vehicles: A Review and Perspectives", "comment": "23 pages, 6 figures", "summary": "Contingency planning is the architectural capability that enables autonomous vehicles (AVs) to anticipate and mitigate discrete, high-impact hazards, such as sensor outages and adversarial interactions. This paper presents a comprehensive survey of the field, synthesizing fragmented literature into a unified logic-conditioned hybrid control framework. Within this formalism, we categorize approaches into two distinct paradigms: Reactive Safety, which responds to realized hazards by enforcing safety constraints or executing fail-safe maneuvers; and Proactive Safety, which optimizes for future recourse by branching over potential modal transitions. In addition, we propose a fine-grained taxonomy that partitions the landscape into external contingencies (environmental and interactive hazards) and internal contingencies (system faults). Through a critical comparative analysis, we reveal a fundamental structural divergence: internal faults are predominantly addressed via reactive fail-safe mechanisms, whereas external interaction uncertainties increasingly require proactive branching strategies. Furthermore, we identify a critical methodological divergence: whereas physical hazards are typically managed with formal guarantees, semantic and out-of-distribution anomalies currently rely heavily on empirical validation. We conclude by identifying the open challenges in bridging the gap between theoretical guarantees and practical validation, advocating for hybrid architectures and standardized benchmarking to transition contingency planning from formulation to certifiable real-world deployment."}
{"id": "2601.15132", "categories": ["stat.ME", "astro-ph.CO", "astro-ph.IM"], "pdf": "https://arxiv.org/pdf/2601.15132", "abs": "https://arxiv.org/abs/2601.15132", "authors": ["Zixiao Hu", "Jason D. McEwen"], "title": "Efficient prior sensitivity analysis for Bayesian model comparison", "comment": "11 pages, 4 figures; submitted conference proceedings for MaxEnt 2025", "summary": "Bayesian model comparison implements Occam's razor through its sensitivity to the prior. However, prior-dependence makes it important to assess the influence of plausible alternative priors. Such prior sensitivity analyses for the Bayesian evidence are expensive, either requiring repeated, costly model re-fits or specialised sampling schemes. By exploiting the learned harmonic mean estimator (LHME) for evidence calculation we decouple sampling and evidence calculation, allowing resampled posterior draws to be used directly to calculate the evidence without further likelihood evaluations. This provides an alternative approach to prior sensitivity analysis for Bayesian model comparison that dramatically alleviates the computational cost and is agnostic to the method used to generate posterior samples. We validate our method on toy problems and a cosmological case study, reproducing estimates obtained by full Markov chain Monte Carlo (MCMC) sampling and nested sampling re-fits. For the cosmological example considered our approach achieves up to $6000\\times$ lower computational cost."}
{"id": "2601.14839", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14839", "abs": "https://arxiv.org/abs/2601.14839", "authors": ["Daizhan Cheng"], "title": "On Dimension Varying Control Systems: A Universal State Space Approach", "comment": null, "summary": "A cross-dimensional Euclidian space ($Ω$) is proposed for the state space of dimension varying (control) systems. It is shown that the topological structure of $Ω$ is consistent with all $\\mathbb{R}^n$, which are the state spaces of each component modes of a dimension varying system. Using the universal metric from $Ω$, the switching laws are assumed to be Lipschitz. Some reasonable conventional switching laws are proposed. Under the topology deduced by the metric on $Ω$ some fundamental properties of dimension varying dynamic systems, such as stability and robustness, are investigated. Then some control problems of dimension varying control systems, including controllability, observability, stabilization, disturbance decoupling, etc. are investigated. Finally, an aggregation approach for large scale hierarchical dimension varying networks is proposed."}
{"id": "2601.14414", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14414", "abs": "https://arxiv.org/abs/2601.14414", "authors": ["Liang Wu", "Bo Yang", "Xu Yang", "Yilin Mo", "Yang Shi", "Ján Drgoňa"], "title": "$π$MPC: A Parallel-in-horizon and Construction-free NMPC Solver", "comment": "8 pages", "summary": "The alternating direction method of multipliers (ADMM) has gained increasing popularity in embedded model predictive control (MPC) due to its code simplicity and pain-free parameter selection. However, existing ADMM solvers either target general quadratic programming (QP) problems or exploit sparse MPC formulations via Riccati recursions, which are inherently sequential and therefore difficult to parallelize for long prediction horizons. This technical note proposes a novel \\textit{parallel-in-horizon} and \\textit{construction-free} nonlinear MPC algorithm, termed $π$MPC, which combines a new variable-splitting scheme with a velocity-based system representation in the ADMM framework, enabling horizon-wise parallel execution while operating directly on system matrices without explicit MPC-to-QP construction. Numerical experiments and accompanying code are provided to validate the effectiveness of the proposed method."}
{"id": "2601.14789", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14789", "abs": "https://arxiv.org/abs/2601.14789", "authors": ["Toshihiro Yada", "Nobuyuki Yoshioka", "Takahiro Sagawa"], "title": "Testing the equivalence to thermal states via extractable work under LOCC", "comment": "19 pages, 2 figures", "summary": "Understanding the thermal behavior of quantum many-body pure states is one of the most fundamental issues in quantum thermodynamics. It is widely known that typical pure states yield vanishing work, just as thermal states do, when one restricts to local operations that cannot access correlations among subsystems. However, it remains unclear whether this equivalence to thermal states persists under LOCC (local operations and classical communication), where classically accessible correlations can be exploited for work extraction. In this work, we establish criteria for determining whether many-body pure states remain equivalent to thermal states even under LOCC, and show that this thermal equivalence is governed by their multipartite quantum correlation structure. We show that states with asymptotically maximal multipartite entanglement, such as Haar-random states, cannot yield extensive work under LOCC, whereas some states with limited multipartite entanglement, such as constant-degree graph states, allow extensive work extraction despite being locally indistinguishable from thermal states. Thus, our work provides a refined operational notion of thermal equivalence beyond the traditional local regime, which is becoming increasingly important due to the recent expansion of experimentally accessible operations."}
{"id": "2601.15070", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.15070", "abs": "https://arxiv.org/abs/2601.15070", "authors": ["Gerardo Cicalese", "Gabriele Ciaramella", "Ilario Mazzieri", "Martin J. Gander"], "title": "Optimized Schwarz Waveform Relaxation for the Damped Wave Equation", "comment": null, "summary": "The performance of Schwarz Waveform Relaxation is critically dependent on the choice of transmission conditions. While classical absorbing conditions work well for wave propagation, they prove insufficient for damped wave equations, particularly in viscoelastic damping regimes where convergence becomes prohibitively slow. This paper addresses this limitation by introducing a more general transmission operator with two free parameters for the one-dimensional damped wave equation. Through frequency-domain analysis, we derive an explicit expression for the convergence factor governing the convergence rate. We propose and compare two optimization strategies (L-infinity and L-2 minimization) for determining optimal transmission parameters. Numerical experiments demonstrate that our optimized approach significantly accelerates convergence compared to standard absorbing conditions, especially for viscoelastic damping cases. The method provides a computationally efficient alternative to exhaustive parameter search while maintaining robust performance across different damping regimes."}
{"id": "2601.14382", "categories": ["cond-mat.stat-mech", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.14382", "abs": "https://arxiv.org/abs/2601.14382", "authors": ["Katarina Karlova", "Afonso Rufino", "Taras Verkholyak", "Nils Caci", "Stefan Wessel", "Jozef Strecka", "Frederic Mila", "Andreas Honecker"], "title": "Approaching Kasteleyn transition in frustrated quantum Heisenberg antiferromagnets", "comment": "9 pages of main text and 6 pages of supplemental material, 9 figures in total", "summary": "We show that the Kasteleyn transition, the abrupt proliferation of infinite strings of defects in classical dimer and related models, can also be relevant for frustrated 2d quantum magnets. This is explicitly demonstrated in a phase of the spin-1/2 Heisenberg diamond-decorated honeycomb lattice where a family of exact eigenstates built as products of dimer and plaquette singlets can be mapped onto the dimer coverings of the honeycomb lattice. The low-temperature properties of this phase are accurately described by an effective dimer model with anisotropic activities and a small, tunable density of monomers, leading to an arbitrarily sharp crossover version of the Kasteleyn transition. The generalization to other geometries and the possibility to realize this model in organo-metallic compounds are briefly discussed."}
{"id": "2601.14632", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2601.14632", "abs": "https://arxiv.org/abs/2601.14632", "authors": ["Min-Kyung Chae", "Woo-Sik Son", "Sang Hoon Lee"], "title": "The missing links: Evaluating contact tracing with incomplete data in large metropolitan areas during an epidemic", "comment": "13 pages, 8 figures, 1 table", "summary": "Contact tracing (CT) plays a pivotal role in controlling early epidemic spread, particularly when a novel infectious disease emerges. However, the quantitative impact of missing information -- such as untraced cases or unnotified contacts -- on the effectiveness of CT remains insufficiently understood. Using a stochastic agent-based model with sociodemographics from metropolitan areas in South Korea, we simulate how different forms of information loss affect epidemic spreading dynamics. We construct information-loss scenarios based on two types: infector-omission (IO) and contact-omission (CO), including selective (SCO) and uniform (UCO) scenarios; IO corresponds to the omission of infected individuals (nodes) from the tracing process, leading to the loss of all movement trajectories and downstream transmission links originating from them, whereas CO corresponds to the omission of specific contact events (edges), in which infected individuals are identified but some of their transmission links fail to be detected or notified. The sensitivity of epidemic dynamics to increasing omission rates differs markedly between the two types: IO scenarios exhibit substantially stronger and more abrupt changes in transmission structure and epidemic outcomes, whereas CO scenarios produce more gradual effects. In both scenarios, the magnitude of these effects varies across cities, with a lower-population city (Busan) showing greater tolerance to information loss than the largest city (Seoul), underscoring the importance of regional tailoring in CT strategies. Both IO and CO scenarios also lead to an increase in the transmission network diameter as information loss grows, indicating that a small network diameter reflects effective contact tracing that limits the depth of transmission chains."}
{"id": "2601.14984", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14984", "abs": "https://arxiv.org/abs/2601.14984", "authors": ["Jingwei Dong", "André M. H. Teixeira"], "title": "Stealthy bias injection attack detection based on Kullback-Leibler divergence in stochastic linear systems", "comment": "26 pages, 10 figures", "summary": "This paper studies the design of detection observers against stealthy bias injection attacks in stochastic linear systems under Gaussian noise, considering adversaries that exploit noise and inject crafted bias signals into a subset of sensors in a slow and coordinated manner, thereby achieving malicious objectives while remaining stealthy. To address such attacks, we formulate the observer design as a max-min optimization problem to enhance the detectability of worst-case BIAs, which attain a prescribed attack impact with the least detectability evaluated via Kullback-Leibler divergence. To reduce the computational complexity of the derived non-convex design problem, we consider the detectability of worst-case BIAs at three specific time instants: attack onset, one step after attack occurrence, and the steady state. We prove that the Kalman filter is optimal for maximizing the BIA detectability at the attack onset, regardless of the subset of attacked sensors. For the one-step and steady-state cases, the observer design problems are approximated by bi-convex optimization problems, which can be efficiently solved using alternating optimization and alternating direction method of multipliers. Moreover, more tractable linear matrix inequality relaxations are developed. Finally, the effectiveness of the proposed stealth-aware detection framework is demonstrated through an application to a thermal system."}
{"id": "2601.14872", "categories": ["math.ST", "cs.LG", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.14872", "abs": "https://arxiv.org/abs/2601.14872", "authors": ["Hirofumi Ota", "Masaaki Imaizumi"], "title": "Finite-Sample Inference for Sparsely Permuted Linear Regression", "comment": null, "summary": "We study a noisy linear observation model with an unknown permutation called permuted/shuffled linear regression, where responses and covariates are mismatched and the permutation forms a discrete, factorial-size parameter. This unknown permutation is a key component of the data-generating process, yet its statistical investigation remains challenging due to its discrete nature. In this study, we develop a general statistical inference framework on the permutation and regression coefficients. First, we introduce a localization step that reduces the permutation space to a small candidate set building on recent advances in the repro samples method, whose miscoverage decays polynomially with the number of Monte Carlo samples. Then, based on this localized set, we provide statistical inference procedures: a conditional Monte Carlo test of permutation structures with valid finite-sample Type-I error control. We also develop coefficient inference that remains valid under alignment uncertainty of permutations. For computational purposes, we develop a linear assignment problem computable in polynomial time complexity and demonstrate that its solution asymptotically converges to that of the conventional least squares problem with large computational cost. Extensions to partially permuted designs and ridge regularization are also discussed. Extensive simulations and an application to Beijing air-quality data corroborate finite-sample validity, strong power to detect mismatches, and practical scalability."}
{"id": "2601.14882", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14882", "abs": "https://arxiv.org/abs/2601.14882", "authors": ["Mehdi Golestani", "Yongduan Song", "Weizhen Liu", "Guangren Duan", "He Kong"], "title": "Practical prescribed-time prescribed performance control with asymptotic convergence - A vanishing sigma-modification approach", "comment": null, "summary": "In this paper, we present a method capable of ensuring practical prescribed-time control with guaranteed performance for a class of nonlinear systems in the presence of time-varying parametric and dynamic uncertainties, and uncertain control coefficients. Our design consists of two key steps. First, we construct a performance-rate function that freezes at and after a user-specified time T, playing a crucial role in achieving desired precision within prescribed time T and dealing with unmodeled dynamics. Next, based on this function and a sigma-modification strategy in which the leakage term starts to vanish at t > T, we develop an adaptive dynamic surface control framework to reduce control complexity, deal with uncertainties, ensure prescribed performance, practical prescribed-time convergence to a specific region, and ultimately achieve asymptotic convergence. The effectiveness of the proposed control method is validated through numerical simulations."}
{"id": "2601.14416", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14416", "abs": "https://arxiv.org/abs/2601.14416", "authors": ["Victor Hugo Pereira Rodrigues", "Tiago Roux Oliveira", "Miroslav Krstic", "Paulo Tabuada"], "title": "Event-Triggered Newton Extremum Seeking for Multivariable Optimization", "comment": null, "summary": "This paper presents a static event-triggered control strategy for multivariable Newton-based extremum seeking. The proposed method integrates event-triggered actuation into the Newton-based optimization framework to reduce control updates while maintaining rapid convergence to the extremum. Unlike traditional gradient-based extremum seeking, where the convergence rate depends on the unknown Hessian of the cost function, the proposed approach employs a dynamic estimator of the Hessian inverse, formulated as a Riccati equation, enabling user-assignable convergence rates. The event-triggering mechanism is designed to minimize unnecessary actuation updates while preserving stability and performance. Using averaging theory, we establish local stability results and exponential convergence to a neighborhood of the unknown extremum point. Additionally, numerical simulations illustrate the benefits of the proposed approach over gradient-based and continuously actuated Newton-based extremum seeking, showing improved convergence rates and reduced control update frequency, leading to more efficient implementation in real-time optimization scenarios."}
{"id": "2601.14824", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14824", "abs": "https://arxiv.org/abs/2601.14824", "authors": ["Claudia Benedetti", "Giovanni Ragazzi", "Simone Cavazzoni", "Paolo Bordone", "Matteo G. A. Paris"], "title": "Routing Qubits on Noisy Networks", "comment": null, "summary": "Robust quantum routing is essential for scalable quantum technologies. This paper investigates the resilience of routing protocols in network architectures designed for perfect, high-fidelity transfer of both classical and quantum information under ideal conditions. We encode information in the position of a quantum walker on a graph, modelling the routing of a generic qubit state from a single input to multiple (orthogonal) outputs. We analyse and assess routing performance in various regimes, evaluating their robustness against static and dynamical noise."}
{"id": "2601.15191", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.15191", "abs": "https://arxiv.org/abs/2601.15191", "authors": ["Iñigo Jimenez-Ciga", "Francisco Gaspar", "Kundan Kumar", "Florin A. Radu"], "title": "Parareal algorithm for coupled elliptic-parabolic problems", "comment": "25 pages, 6 figures", "summary": "We present a convergence analysis of the parallel-in-time integration method known as the Parareal algorithm for degenerate differential-algebraic systems arising from quasi-static Biot models, which govern coupled flow and deformation in porous media. The underlying system exhibits a saddle-point structure and degeneracy due to the quasi-static assumption. We extend the Parareal algorithm to this setting and propose three coarse propagators: monolithic, fixed-stress, and multirate fixed-stress schemes. For each, we derive sufficient conditions for convergence and establish explicit time step restrictions that guarantee contractivity of the iteration matrix. Numerical experiments show computational savings accrued by using a parareal solver in multiphysics simulations involving poroelasticity and other coupled systems."}
{"id": "2601.14747", "categories": ["physics.soc-ph", "cs.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.14747", "abs": "https://arxiv.org/abs/2601.14747", "authors": ["Si-Yao Wei", "Wei-Xing Zhou"], "title": "On the existence of Ulanowicz's optimal structural resilience in complex networks", "comment": null, "summary": "This study investigates the mathematical existence and asymptotic properties of Ulanowicz's structural resilience in complex systems such as supply chain networks. While ecological evidence suggests that sustainable systems gravitate toward an optimal state at $α= 1/\\mathrm{e}$, the universality of this configuration in generalized networks remains theoretically unverified. We prove that while optimal resilience is unattainable in two-node networks due to structural over-determinacy, it exists for any directed graph with $N_\\mathcal{V} \\geq 3$. By constructing a symmetric network model with three types of link weights $(x, y, z)$ and uniform marginal distributions, we derive the governing equations for the optimal resilience configuration. Our analytical and numerical results reveal that as the network size $N_\\mathcal{V}$ increases, the link weights required to maintain optimal resilience exhibit a power-law scaling behavior: the adjacent links scale as $O(N_\\mathcal{V}^{-1})$, while the non-adjacent links scale as $O(N_\\mathcal{V}^{-2})$, both accompanied by specific logarithmic corrections. This work establishes a rigorous mathematical foundation for the optimal resilience framework and provides a unified perspective on how entropy-based principles govern the robustness and evolution of large-scale complex networks, which may offer quantitative guidance for designing large-scale networked systems under robustness constraints."}
{"id": "2601.15040", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15040", "abs": "https://arxiv.org/abs/2601.15040", "authors": ["Maiken Borud Omtveit", "Qian Long", "Valentin Chabaud", "Marte Ruud-Olsen", "Steinar Halsne", "Tor-Christian Ystgaard"], "title": "Electrical Design of a Clean Offshore Heat and Power (CleanOFF) Hub", "comment": null, "summary": "This paper presents an innovative offshore solution where oil & gas platform clusters are powered by a wind farm and a hydrogen hub. The results show a feasible off-grid design as an alternative to conventional electrification solutions. To address the challenges of design and operation of such a system, a power system model of the equipment and control was developed in a power system simulator called Process Power Simulator (PPSim). Power fluctuations in the wind farm are modelled using a state-of-the-art method encompassing turbulence and wakes. Various operation scenarios were used to evaluate the system design and find the right equipment size. An expensive component to over dimension is the battery energy storage system (BESS). The BESS power rating and energy capacity were found by running a combination of scenarios with extreme and natural wind variations, and contingencies. The control strategy and ramp rates of electrolyzers have significant impact on both system performance and design. A ramp rate in the order of seconds as opposed to minutes will decrease the required BESS size by 60-70%. Choosing synchronized control of the electrolyzers can further reduce the BESS size by 15-20%. The simulations also revealed challenges to achieve self-sufficiency of hydrogen and potential design improvements are suggested."}
{"id": "2601.14947", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.14947", "abs": "https://arxiv.org/abs/2601.14947", "authors": ["Giacomo Francisci", "Claudio Agostinelli"], "title": "Central subspace data depth", "comment": "25+34 pages, 7+4 figures", "summary": "Statistical data depth plays an important role in the analysis of multivariate data sets. The main outcome is a center-outward ordering of the observations that can be used both to highlight features of the underlying distribution of the data and as input to further statistical analysis. An important property of data depth is related to symmetric distributions as the point with the highest depth value, the center, coincides with the point of symmetry. However, there are applications in which it is more natural to consider symmetry with respect to a subspace of a certain dimension rather than to a point, i.e. a subspace of dimension zero. We provide a general framework to construct statistical data depths which attain maximum value in a subspace, providing a center-outward ordering from that subspace. We refer to these data depths as central subspace data depths. Moreover, if the distribution is symmetric with respect to a subspace, then the depth is maximized at that subspace. We introduce general notions of symmetry about a subspace for distributions, study the properties of central subspace data depths and provide asymptotic convergence for the corresponding sample versions. Additionally, we discuss connections with projection pursuit and dimension reduction. An application based on custom data fraud detection shows the importance of the proposed approach and strengthens its potential."}
{"id": "2601.14908", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.14908", "abs": "https://arxiv.org/abs/2601.14908", "authors": ["Haibin Chen", "Yixuan Chen", "Liqun Qi"], "title": "Biquadratic Cauchy Tensors and Spherical Biquadratic Polynomial Programming", "comment": null, "summary": "This paper addresses biquadratic polynomial programming (BPP), an NP-hard optimization problem closely related to biquadratic tensors. We first establish several necessary and sufficient conditions for the positive semi-definiteness and positive definiteness of biquadratic Cauchy tensors. Leveraging the structured properties of these tensors, we then prove that the BPP and its equivalent multilinear formulation share the same set of optimal solutions. This result allows us to establish the global sequence convergence of the proximal alternating minimization (PAM) algorithm via the Kurdyka- Lojasiewicz (KL) property, extending the analysis in [8]. Furthermore, by reformulating the equivalent multilinear problem as an unconstrained optimization model, we enable the analysis of its KL exponent and derive an explicit expression for the convergence rate of PAM. Finally, numerical experiments are conducted on both biquadratic Cauchy tensors and general biquadratic tensor instances to evaluate the efficiency, stability, and practical performance of the proposed algorithm."}
{"id": "2601.14763", "categories": ["quant-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14763", "abs": "https://arxiv.org/abs/2601.14763", "authors": ["Qinghao Wen", "Zihao Ren", "Lei Wang", "Hyungbo Shim", "Guodong Shi"], "title": "Blended Dynamics and Emergence in Open Quantum Networks", "comment": null, "summary": "In this paper, we develop a blended dynamics framework for open quantum networks with diffusive couplings. The network consists of qubits interconnected through Hamiltonian couplings, environmental dissipation, and consensus-like diffusive interactions. Such networks commonly arise in spontaneous emission processes and non-Hermitian quantum computing, and their evolution follows a Lindblad master equation. Blended dynamics theory is well established in the classical setting as a tool for analyzing emergent behaviors in heterogeneous networks with diffusive couplings. Its key insight is to blend the local dynamics rather than the trajectories of individual nodes. Perturbation analysis then shows that, under sufficiently strong coupling, all node trajectories tend to stay close to those of the blended system over time. We first show that this theory extends naturally to the reduced-state dynamics of quantum networks, revealing classical-like clustering phenomena in which qubits converge to a shared equilibrium or a common trajectory determined by the quantum blended reduced-state dynamics. We then extend the analysis to qubit coherent states using quantum Laplacians and induced graphs, proving orbit attraction of the network density operator toward the quantum blended coherent dynamics, establishing the emergence of intrinsically quantum and dynamically clustering behaviors. Finally, numerical examples validate the theoretical results."}
{"id": "2601.14845", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14845", "abs": "https://arxiv.org/abs/2601.14845", "authors": ["Kenny Campbell", "Ahmed Lawey", "Mohsen Razavi"], "title": "Combatting noise in near-term quantum data centres", "comment": "13 pages, 8 figures", "summary": "We analyse the performance of different error handling methods in the quantum data centre paradigm of distributed quantum computing. We compare the impact of quantum error detection, using the three-qubit repetition code and the [[4, 1, 2]] Leung-Nielsen-Chuang-Yamamoto code, on remote gates with that of conventional entanglement distillation techniques. Detailed classical simulation is used to obtain results for realistic near-term hardware."}
{"id": "2601.11959", "categories": ["quant-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.11959", "abs": "https://arxiv.org/abs/2601.11959", "authors": ["Shan Jiang", "Dong An"], "title": "Contour-integral based quantum eigenvalue transformation: analysis and applications", "comment": "31 pages including appendix", "summary": "Eigenvalue transformations appear ubiquitously in scientific computation, ranging from matrix polynomials to differential equations, and are beyond the reach of the quantum singular value transformation framework. In this work, we study the efficiency of quantum algorithms based on contour integral representation for eigenvalue transformations from both theoretical and practical aspects. Theoretically, we establish a complete complexity analysis of the contour integral approach proposed in [Takahira, Ohashi, Sogabe, and Usuda. Quant. Inf. Comput., 22, 11\\&12, 965--979 (2021)]. Moreover, we combine the contour integral approach and the sampling-based linear combination of unitaries to propose a quantum algorithm for estimating observables of eigenvalue transformations using only $3$ additional qubits. Practically, we design contour integral based quantum algorithms for Hamiltonian simulation, matrix polynomials, and solving linear ordinary differential equations, and show that the contour integral algorithm can outperform all the existing quantum algorithms in the case of solving asymptotically stable differential equations."}
{"id": "2601.15199", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.15199", "abs": "https://arxiv.org/abs/2601.15199", "authors": ["Andrés Guzmán", "Federico Malizia", "István Z. Kiss"], "title": "Unveiling the impact of cross-order hyperdegree correlations in contagion processes on hypergraphs", "comment": "Supplementary material is from page 15 onwards", "summary": "Contagion processes in social systems often involve interactions that go beyond pairwise contacts. Higher-order networks, represented as hypergraphs, have been widely used to model multi-body interactions, and their presence can drastically alter contagion dynamics compared to traditional network models. However, existing analytical approaches typically assume independence between pairwise and higher-order degrees, and thus study their roles in isolation. In this paper, we develop an effective hyperdegree model (EHDM) to describe Susceptible-Infected-Susceptible (SIS) dynamics on hypergraphs that explicitly captures correlations between the distribution of groups with different sizes. Our effective hyperdegree model shows excellent agreement with stochastic simulations across different types of higher-order networks, including those with heterogeneous degree distributions. We explore the critical role of cross-order degree correlations, specifically, whether nodes that are hubs in pairwise interactions also serve as hubs in higher-order interactions. We show that positive correlation decreases the epidemic threshold and anti-correlation temporally desynchronizes infection pathways (pairwise and group interactions). Finally, we demonstrate that, depending on the level of correlation, the optimal control strategy shifts -- from one that is purely pairwise- or higher-order-focused to one in which a mixed strategy becomes optimal."}
{"id": "2601.15099", "categories": ["eess.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.15099", "abs": "https://arxiv.org/abs/2601.15099", "authors": ["A. Vaca", "J. Gutierrez Florensa", "F. Milano"], "title": "Instantaneous Frequency in Power Systems using the Teager-Kaiser Energy Operator", "comment": null, "summary": "This paper develops an instantaneous-frequency (IF) local estimator calculated with the complex Teager-Kaiser energy operator (CTKEO) and the dynamic-signal identity. The contribution is a novel IF expression that makes the envelope-curvature terms explicit, thus correcting the bias that affects conventional estimators used in power systems. The estimator aligns with complex-frequency (CF) kinematics and admits a geometric interpretation (curvature/torsion) without phase unwrapping. Simulations and data-driven examples demonstrate the accuracy of the proposed approach."}
{"id": "2601.15090", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15090", "abs": "https://arxiv.org/abs/2601.15090", "authors": ["Mehrnaz Anvari", "Marius Neuwirth", "Okan Akca", "Luna Lütz", "Simon Lukas Bussmann", "Tobias Fleiter", "Bernhard Klaassen"], "title": "From carbon management strategies to implementation: Modeling and physical simulation of CO2 pipeline infrastructure - a case study for Germany", "comment": "35 pages, 9 figures, preprint submitted to a journal", "summary": "Carbon capture and storage or utilization (CCUS) will play an important role to achieve climate neutrality in many economies. Pipelines are widely regarded as the most efficient means of CO2 transport; however, they are currently non-existent. Policy-makers and companies need to develop large-scale infrastructure under substantial uncertainty. Methods and analyses are needed to support pipeline planning and strategy development. This paper presents an integrated method for designing CO2 pipeline networks by combining energy system scenarios with physical network simulation. Using Germany as a case study, we derive spatially highly resolved CO2 balances to develop a dense-phase CO2 pipeline topology that follows existing gas pipeline corridors. The analyzed system includes existing sites for cement and lime production, waste incineration, carbon users, four coastal CO2 hubs, and border crossing points. We then apply the multiphysical network simulator MYNTS to assess the technical feasibility of this network. We determine pipeline diameters, pump locations, and operating conditions that ensure stable dense-phase transport. The method explicitly accounts for elevation and possible impurities. The results indicate that a system of about 7000 km pipeline length and a mixed normed diameter of DN700 on main corridors and of DN500/DN400 on branches presents a feasible solution to connect most sites. Investment costs for the optimized pipeline system are calculated to be about 17 billion Euros. The method provides a reproducible framework and is transferable to other countries and to European scope."}
{"id": "2601.14882", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14882", "abs": "https://arxiv.org/abs/2601.14882", "authors": ["Mehdi Golestani", "Yongduan Song", "Weizhen Liu", "Guangren Duan", "He Kong"], "title": "Practical prescribed-time prescribed performance control with asymptotic convergence - A vanishing sigma-modification approach", "comment": null, "summary": "In this paper, we present a method capable of ensuring practical prescribed-time control with guaranteed performance for a class of nonlinear systems in the presence of time-varying parametric and dynamic uncertainties, and uncertain control coefficients. Our design consists of two key steps. First, we construct a performance-rate function that freezes at and after a user-specified time T, playing a crucial role in achieving desired precision within prescribed time T and dealing with unmodeled dynamics. Next, based on this function and a sigma-modification strategy in which the leakage term starts to vanish at t > T, we develop an adaptive dynamic surface control framework to reduce control complexity, deal with uncertainties, ensure prescribed performance, practical prescribed-time convergence to a specific region, and ultimately achieve asymptotic convergence. The effectiveness of the proposed control method is validated through numerical simulations."}
{"id": "2601.14867", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14867", "abs": "https://arxiv.org/abs/2601.14867", "authors": ["Qing-Yang Qiu", "Wen Huang", "Lei Du", "Xin-You Lü"], "title": "Exotic collective behaviors of giant quantum emitters in two-dimensional baths", "comment": "16 pages, 9 figures", "summary": "Nonlocal light-matter interactions with giant atoms in high-dimensional environments are not only fundamentally intriguing for testing quantum electrodynamics beyond the dipole approximation but also crucial for building high-dimensional quantum networks and engineering multipartite entangled states. Given the enigmatic and largely uncharted collective signatures exhibited by multiple giant atoms within two-dimensional optical baths, we delve into their nonperturbative collective dynamics within the single-excitation subspace, focusing on the case where they are coupled to a common two-dimensional photonic reservoir and employing a resolvent operator approach. We demonstrate that precisely engineered atomic arrangements lead to unconventional quantum dynamics, featuring non-Markovianity-induced beats and long-lived bound states in the continuum, thereby providing a versatile platform for implementing two-dimensional quantum memory. Phenomenologically, we observe the emergence of exotic photon emission patterns in both two- and three-dimensional (3D) baths. The emission directions are shown to be precisely controllable on demand through exact phase engineering of the coupling parameters, enabling a highly efficient chiral light-matter interface. Moreover, our generalization to a 3D bath reveals that coherent dipole-dipole interactions can survive despite the coupling to a continuum of modes, a finding that challenges conventional wisdom regarding decoherence."}
{"id": "2601.14468", "categories": ["eess.SY", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.14468", "abs": "https://arxiv.org/abs/2601.14468", "authors": ["Milad Hasanzadeh", "Amin Kargarian", "Javad Lavaei"], "title": "All-Pass Fractional OPF: A Solver-Friendly, Physics-Preserving Approximation of AC OPF", "comment": null, "summary": "This paper presents a fractional approximation of the AC optimal power flow (AC OPF) problem based on an all-pass approximation of the exponential power flow kernel. The classical AC OPF relies on trigonometric coupling between bus voltage phasors, which yields a nonconvex program with oscillatory derivatives that can slow, or in some cases destabilize, interior-point methods. We replace the trigonometric terms with an all-pass fractional (APF) approximation whose real and imaginary components act as smooth surrogates for the cosine and sine functions, and we introduce a pre-rotation to shift the argument of the approximation toward its most accurate region, ensuring that the reformulated power flow model preserves physical loss behavior, maintains the symmetry of the classical kernels, and improves the conditioning of the Jacobian and Hessian matrices. The proposed APF OPF formulation remains nonconvex, as in the classical model, but it eliminates trigonometric evaluations and empirically produces larger and more stable Newton steps under standard interior-point solvers. Numerical results on more than 25 IEEE and PGLib test systems ranging from 9 to 10{,}000 buses demonstrate that the APF OPF model achieves solutions with accuracy comparable to that of the classical formulation while reducing solver times, indicating a more solver-friendly nonconvex representation of AC OPF. All code, functions, verification scripts, and generated results are publicly available on \\href{https://github.com/LSU-RAISE-LAB/APF-OPF}{GitHub}, along with a README describing how to run and reproduce the experiments."}
{"id": "2601.15135", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15135", "abs": "https://arxiv.org/abs/2601.15135", "authors": ["Natanon Tongamrak", "Kannapha Amaruchkul", "Wijarn Wangdee", "Jitkomut Songsiri"], "title": "Stochastic EMS for Optimal 24/7 Carbon-Free Energy Operations", "comment": "23 pages", "summary": "This paper proposes a two-stage stochastic optimization formulation to determine optimal operation and procurement plans for achieving a 24/7 carbon-free energy (CFE) compliance at minimized cost. The system in consideration follows primary energy technologies in Thailand including solar power, battery storage, and a diverse portfolio of renewable and carbon-based energy procurement sources. Unlike existing literature focused on long-term planning, this study addresses near real-time operations using a 15-minute resolution. A novel feature of the formulation is the explicit treatment of CFE compliance as a model parameter, enabling flexible targets such as a minimum percentage of hourly matching or a required number of carbon-free days within a multi-day horizon. The mixed-integer linear programming formulation accounts for uncertainties in load and solar generation by integrating deep learning-based forecasting within a receding horizon framework. By optimizing battery profiles and multi-source procurement simultaneously, the proposed system provides a feasible pathway for transitioning to carbon-free operations in emerging energy markets."}
{"id": "2601.15092", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15092", "abs": "https://arxiv.org/abs/2601.15092", "authors": ["Sudkobfa Boontawee", "Mootta Prangprakhon", "Nimit Nimana"], "title": "Federated Incremental Subgradient Method for Convex Bilevel Optimization Problems", "comment": "6 pages", "summary": "In this letter, we consider a bilevel optimization problem in which the outer-level objective function is strongly convex, whereas the inner-level problem consists of a finite sum of convex functions. Bilevel optimization problems arise in situations where the inner-level problem does not have a unique solution. This has led to the idea of introducing an outer-level objective function to select a solution with the specific desired properties. We propose an iterative method that combines an incremental algorithm with a broadcast algorithm, both based on the principles of federated learning. Under appropriate assumptions, we establish the convergence results of the proposed algorithm. To demonstrate its performance, we present two numerical examples related to binary classification and a location problem."}
{"id": "2601.14933", "categories": ["math.NA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14933", "abs": "https://arxiv.org/abs/2601.14933", "authors": ["Yogesh Darmwal", "Ketan Rajawat"], "title": "Rank-one Riemannian Subspace Descent for Nonlinear Matrix Equations", "comment": null, "summary": "We propose a rank-one Riemannian subspace descent algorithm for computing symmetric positive definite (SPD) solutions to nonlinear matrix equations arising in control theory, dynamic programming, and stochastic filtering. For solution matrices of size $n\\times n$, standard approaches for dense matrix equations typically incur $\\mathcal{O}(n^3)$ cost per-iteration, while the efficient $\\mathcal{O}(n^2)$ methods either rely on sparsity or low-rank solutions, or have iteration counts that scale poorly. The proposed method entails updating along the dominant eigen-component of a transformed Riemannian gradient, identified using at most $\\mathcal{O}(\\log(n))$ power iterations. The update structure also enables exact step-size selection in many cases at minimal additional cost. For objectives defined as compositions of standard matrix operations, each iteration can be implemented using only matrix--vector products, yielding $\\mathcal{O}(n^2)$ arithmetic cost. We prove an $\\mathcal{O}(n)$ iteration bound under standard smoothness assumptions, with improved bounds under geodesic strong convexity. Numerical experiments on large-scale CARE, DARE, and other nonlinear matrix equations show that the proposed algorithm solves instances (up to $n=10{,}000$ in our tests) for which the compared solvers, including MATLAB's \\texttt{icare}, structure-preserving doubling, and subspace-descent baselines fail to return a solution. These results demonstrate that rank-one manifold updates provide a practical approach for high-dimensional and dense SPD-constrained matrix equations. MATLAB code implementation is publicly available on GitHub : \\href{https://github.com/yogeshd-iitk/nonlinear_matrix_equation_R1RSD}{\\textcolor{blue}{https://github.com/yogeshd-iitk/nonlinear\\_matrix \\_equation\\_R1RSD}}"}
{"id": "2601.14876", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14876", "abs": "https://arxiv.org/abs/2601.14876", "authors": ["Antonin Grateau", "Alexander Boeschoten", "Tanguy Favin-Lévêque", "Isael Herrera", "Nicolas Treps"], "title": "Multiparameter estimation for the superresolution of two incoherent sources", "comment": null, "summary": "We experimentally demonstrate the simultaneous estimation of the three parameters characterizing a pair of incoherent optical sources in the sub-Rayleigh regime, enabling super-resolved scene characterization. Using spatial-mode demultiplexing (SPADE) with two demultiplexers--one deliberately shifted--we determine separations well below the diffraction limit and achieve sensitive joint estimation of separation, centroid, and relative brightness over a broad range of scene configurations in a single experimental setting. We benchmark our performance using Fisher-information-based Cramér-Rao bounds, and discuss the corresponding quantum limits. We investigate two complementary scenarios: a realistic case with slightly non-identical sources, and an idealized case of indistinguishable sources."}
{"id": "2601.14747", "categories": ["physics.soc-ph", "cs.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.14747", "abs": "https://arxiv.org/abs/2601.14747", "authors": ["Si-Yao Wei", "Wei-Xing Zhou"], "title": "On the existence of Ulanowicz's optimal structural resilience in complex networks", "comment": null, "summary": "This study investigates the mathematical existence and asymptotic properties of Ulanowicz's structural resilience in complex systems such as supply chain networks. While ecological evidence suggests that sustainable systems gravitate toward an optimal state at $α= 1/\\mathrm{e}$, the universality of this configuration in generalized networks remains theoretically unverified. We prove that while optimal resilience is unattainable in two-node networks due to structural over-determinacy, it exists for any directed graph with $N_\\mathcal{V} \\geq 3$. By constructing a symmetric network model with three types of link weights $(x, y, z)$ and uniform marginal distributions, we derive the governing equations for the optimal resilience configuration. Our analytical and numerical results reveal that as the network size $N_\\mathcal{V}$ increases, the link weights required to maintain optimal resilience exhibit a power-law scaling behavior: the adjacent links scale as $O(N_\\mathcal{V}^{-1})$, while the non-adjacent links scale as $O(N_\\mathcal{V}^{-2})$, both accompanied by specific logarithmic corrections. This work establishes a rigorous mathematical foundation for the optimal resilience framework and provides a unified perspective on how entropy-based principles govern the robustness and evolution of large-scale complex networks, which may offer quantitative guidance for designing large-scale networked systems under robustness constraints."}
{"id": "2601.15196", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.15196", "abs": "https://arxiv.org/abs/2601.15196", "authors": ["Jianye Xu", "Bassam Alrifaee"], "title": "TTCBF: A Truncated Taylor Control Barrier Function for High-Order Safety Constraints", "comment": null, "summary": "Control Barrier Functions (CBFs) enforce safety by rendering a prescribed safe set forward invariant. However, standard CBFs are limited to safety constraints with relative degree one, while High-Order CBF (HOCBF) methods address higher relative degree at the cost of introducing a chain of auxiliary functions and multiple class K functions whose tuning scales with the relative degree. In this paper, we introduce a Truncated Taylor Control Barrier Function (TTCBF), which generalizes standard discrete-time CBFs to consider high-order safety constraints and requires only one class K function, independent of the relative degree. We also propose an adaptive variant, adaptive TTCBF (aTTCBF), that optimizes an online gain on the class K function to improve adaptability, while requiring fewer control design parameters than existing adaptive HOCBF variants. Numerical experiments in a relative-degree-six spring-mass system and a cluttered corridor navigation validate the above theoretical findings."}
{"id": "2601.15168", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15168", "abs": "https://arxiv.org/abs/2601.15168", "authors": ["J. Nicholas Neuberger", "Alen Alexanderian", "Bart van Bloemen Waanders", "Ahmed Attia"], "title": "Path-OED for infinite-dimensional Bayesian linear inverse problems governed by PDEs", "comment": null, "summary": "We consider infinite-dimensional Bayesian linear inverse problems governed by time-dependent partial differential equations (PDEs) and develop a mathematical and computational framework for optimal design of mobile sensor paths in this setting. The proposed path optimal experimental design (path-OED) framework is established rigorously in a function space setting and elaborated for the case of Bayesian c-optimality, which quantifies the posterior variance in a linear functional of the inverse parameter. The latter is motivated by goal-oriented formulations, where we seek to minimize the uncertainty in a scalar prediction of interest. To facilitate computations, we complement the proposed infinite-dimensional framework with discretized formulations, in suitably weighted finite-dimensional inner product spaces, and derive efficient methods for finding optimal sensor paths. The resulting computational framework is flexible, scalable, and can be adapted to a broad range of linear inverse problems and design criteria. We also present extensive computational experiments, for a model inverse problem constrained by an advection-diffusion equation, to demonstrate the effectiveness of the proposed approach."}
{"id": "2601.14941", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14941", "abs": "https://arxiv.org/abs/2601.14941", "authors": ["Tim Palmer"], "title": "Impossible Counterfactuals, Discrete Hilbert Space and Bell's Theorem", "comment": "Journal of Physics Conference Series - Memorial Issue for Basil Hiley. IOP Publishing", "summary": "Negating the Measurement Independence assumption (MI) is often referred to as the `third way' to account for the experimental violation of Bell's inequality. However, this route is generally viewed as ludicrously contrived, implying some implausible conspiracy where experimenters are denied the freedom to choose measurement settings as they like. Here, a locally realistic model of quantum physics is developed (Rational Mechanics - RaQM - based on a gravitational discretisation of Hilbert Space) which violates MI without denying free will. Crucially, RaQM distinguishes experimenters' ability to freely choose measurement settings to some nominal accuracy, from an inability to choose exact settings, which were never under their control anyway. In RaQM, Hilbert states are necessarily undefined in bases where squared amplitudes and/or complex phases are irrational numbers. Such `irrational' bases correspond to conceivable but necessarily impossible counterfactual measurements, and are shown to play a ubiquitous role in the analysis of both single- and entangled-particle quantum physics. It is concluded that violation of Bell inequalities can be understood with none of the strange processes historically associated with it. Instead, using concepts from (non-classical) $p$-adic number theory, we relate RaQM to Bohm and Hiley's concept of a holistic Machian-like Undivided Universe. If this interpretation of Bell's Theorem is correct, building more and more energetic particle accelerators to probe smaller and smaller scales, in the search for a theory which synthesises quantum and gravitational physics and hence a Theory of Everything, may be a fruitless exercise."}
{"id": "2601.14414", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14414", "abs": "https://arxiv.org/abs/2601.14414", "authors": ["Liang Wu", "Bo Yang", "Xu Yang", "Yilin Mo", "Yang Shi", "Ján Drgoňa"], "title": "$π$MPC: A Parallel-in-horizon and Construction-free NMPC Solver", "comment": "8 pages", "summary": "The alternating direction method of multipliers (ADMM) has gained increasing popularity in embedded model predictive control (MPC) due to its code simplicity and pain-free parameter selection. However, existing ADMM solvers either target general quadratic programming (QP) problems or exploit sparse MPC formulations via Riccati recursions, which are inherently sequential and therefore difficult to parallelize for long prediction horizons. This technical note proposes a novel \\textit{parallel-in-horizon} and \\textit{construction-free} nonlinear MPC algorithm, termed $π$MPC, which combines a new variable-splitting scheme with a velocity-based system representation in the ADMM framework, enabling horizon-wise parallel execution while operating directly on system matrices without explicit MPC-to-QP construction. Numerical experiments and accompanying code are provided to validate the effectiveness of the proposed method."}
{"id": "2601.15184", "categories": ["math.OC", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15184", "abs": "https://arxiv.org/abs/2601.15184", "authors": ["Julius A. Zeiss", "Gereon Koßmann", "René Schwonnek", "Martin Plávala"], "title": "Finite de Finetti for convex bodies and Polynomial Optimization", "comment": "36 + 13 pages; Julius A. Zeiss and Gereon Koßmann contributed equally to this work", "summary": "Leveraging a recently proposed notion of relative entropy in general probabilistic theories (GPT), we prove a finite de Finetti representation theorem for general convex bodies. We apply this result to address a fundamental question in polynomial optimization: the existence of a convergent outer hierarchy for problems with inequality constraints and analytical convergence guarantees. Our strategy generalizes a quantitative monogamy-of-entanglement argument from quantum theory to arbitrary convex bodies, establishing a uniform upper bound on mutual information in multipartite extensions. This leads to a finite de Finetti theorem and, subsequently, a convergent conic hierarchy for a wide class of polynomial optimization problems subject to both equality and inequality constraints. We further provide a constructive rounding scheme that yields certified interior points with controlled approximation error. As an application, we express the optimal GPT value of a two-player non-local game as a polynomial optimization problem, allowing our techniques to produce approximation schemes with finite convergence guarantees."}
{"id": "2601.14963", "categories": ["quant-ph", "cond-mat.mes-hall", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.14963", "abs": "https://arxiv.org/abs/2601.14963", "authors": ["Devashish Pandey", "Corne Koks", "Martijn Wubs", "Nicolas Stenger", "Jake Iles-Smith"], "title": "Resonant Excitation Induced Vibronic Mollow Triplets", "comment": "Main text 7 pages, 3 Figures: Supplementary Information 7 Pages, 4 Figures", "summary": "The Mollow triplet is the definitive spectral signature of an optically dressed quantum emitter. We predict that for emitters coupled to localized phonons, this signature is not confined to the zero-phonon line. Under a strong resonant drive, we show that Mollow triplets are strikingly replicated on the associated phonon sidebands -a surprising result, given that phonon sidebands are typically viewed as incoherent, inelastic scattering pathways. These vibronic Mollow triplets are a direct fingerprint of dynamically generated dressed states that hybridize the emitter's electronic, photonic, and vibrational degrees of freedom. We develop a scalable analytical formalism to model this effect in complex, multi-mode molecular systems, such as dibenzoterrylene. Our work provides the precise driving conditions for observing these novel spectral features, establishing a new signature of coherence in vibronically coupled systems."}
{"id": "2601.14416", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14416", "abs": "https://arxiv.org/abs/2601.14416", "authors": ["Victor Hugo Pereira Rodrigues", "Tiago Roux Oliveira", "Miroslav Krstic", "Paulo Tabuada"], "title": "Event-Triggered Newton Extremum Seeking for Multivariable Optimization", "comment": null, "summary": "This paper presents a static event-triggered control strategy for multivariable Newton-based extremum seeking. The proposed method integrates event-triggered actuation into the Newton-based optimization framework to reduce control updates while maintaining rapid convergence to the extremum. Unlike traditional gradient-based extremum seeking, where the convergence rate depends on the unknown Hessian of the cost function, the proposed approach employs a dynamic estimator of the Hessian inverse, formulated as a Riccati equation, enabling user-assignable convergence rates. The event-triggering mechanism is designed to minimize unnecessary actuation updates while preserving stability and performance. Using averaging theory, we establish local stability results and exponential convergence to a neighborhood of the unknown extremum point. Additionally, numerical simulations illustrate the benefits of the proposed approach over gradient-based and continuously actuated Newton-based extremum seeking, showing improved convergence rates and reduced control update frequency, leading to more efficient implementation in real-time optimization scenarios."}
{"id": "2601.15208", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15208", "abs": "https://arxiv.org/abs/2601.15208", "authors": ["Samir Adly", "Juan José Maulén", "Emilio Vilches"], "title": "Penalty-Based Smoothing of Convex Nonsmooth Supremum Functions with Accelerated Inertial Dynamics", "comment": null, "summary": "We propose a penalty-based smoothing framework for convex nonsmooth functions with a supremum structure. The regularization yields a differentiable surrogate with controlled approximation error, a single-valued dual maximizer, and explicit gradient formulas. We then study an accelerated inertial dynamic with vanishing damping driven by a time-dependent regularized function whose parameter decreases to zero. Under mild integrability and boundedness conditions on the regularization schedule, we establish an accelerated $\\mathcal{O}(t^{-2})$ decay estimate for the regularized residual and, in the regime $α>3$, a sharper $o(t^{-2})$ decay together with weak convergence of trajectories to a minimizer of the original nonsmooth problem via an Opial-type argument. Applications to multiobjective optimization (through Chebyshev/max scalarization) and to distributionally robust optimization (via entropic regularization over ambiguity sets) illustrate the scope of the framework."}
{"id": "2601.14964", "categories": ["quant-ph", "gr-qc"], "pdf": "https://arxiv.org/pdf/2601.14964", "abs": "https://arxiv.org/abs/2601.14964", "authors": ["Robert Amelung", "Hanno Sahlmann"], "title": "Multipartite entanglement in the quantum tetrahedron", "comment": "13 pages, 24 figures", "summary": "The space $\\mathrm{Inv}(j_1,j_2,j_3,j_4)$ of SU(2)-invariant four-valent tensors, also known as intertwiners, can be understood as the quantum states of a tetrahedron in Euclidean space with fixed areas. In loop quantum gravity, they are states of the smallest \"atom of space\" with non-zero volume. At the same time they correspond to four-party tensor product states invariant under global rotations. We consider the multipartite entanglement of states in $\\mathrm{Inv}(j_1,j_2,j_3,j_4)$ using the recently proposed entropic fill.\n  Numerically evaluating entropic fill in the case of equal spins between $1/2$ and $11$, we find that the distributions of entanglement are very different for intertwiners as compared to generic tensors, and for coherent intertwiners as compared to generic ones. The peak in the distribution seems to be at the highest entanglement for generic intertwiners and at the lowest for generic tensors, but in terms of average entanglement, the roles are switched: average entanglement is highest in arbitrary tensors and lower in intertwiners, at least in the regime of large $j$. We also find that entanglement depends on the geometric data of coherent intertwiners in a complicated way."}
{"id": "2601.14763", "categories": ["quant-ph", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14763", "abs": "https://arxiv.org/abs/2601.14763", "authors": ["Qinghao Wen", "Zihao Ren", "Lei Wang", "Hyungbo Shim", "Guodong Shi"], "title": "Blended Dynamics and Emergence in Open Quantum Networks", "comment": null, "summary": "In this paper, we develop a blended dynamics framework for open quantum networks with diffusive couplings. The network consists of qubits interconnected through Hamiltonian couplings, environmental dissipation, and consensus-like diffusive interactions. Such networks commonly arise in spontaneous emission processes and non-Hermitian quantum computing, and their evolution follows a Lindblad master equation. Blended dynamics theory is well established in the classical setting as a tool for analyzing emergent behaviors in heterogeneous networks with diffusive couplings. Its key insight is to blend the local dynamics rather than the trajectories of individual nodes. Perturbation analysis then shows that, under sufficiently strong coupling, all node trajectories tend to stay close to those of the blended system over time. We first show that this theory extends naturally to the reduced-state dynamics of quantum networks, revealing classical-like clustering phenomena in which qubits converge to a shared equilibrium or a common trajectory determined by the quantum blended reduced-state dynamics. We then extend the analysis to qubit coherent states using quantum Laplacians and induced graphs, proving orbit attraction of the network density operator toward the quantum blended coherent dynamics, establishing the emergence of intrinsically quantum and dynamically clustering behaviors. Finally, numerical examples validate the theoretical results."}
{"id": "2601.15218", "categories": ["math.OC", "math.AP"], "pdf": "https://arxiv.org/pdf/2601.15218", "abs": "https://arxiv.org/abs/2601.15218", "authors": ["Luigi De Pascale", "Igor Pinheiro"], "title": "Some reverse inequality in optimal mass transportation", "comment": null, "summary": "Controlling the $\\mathcal W_\\infty$ Wasserstein distance by the $\\mathcal W_p$ Wasserstein distance is interesting both for theorical and numerical applications. A first paper on this problem was written several years ago [3]. Some year later [14] framed it in the same inequality for more general costs which increase with the distance. In this paper, we prove this type of inequality for optimal transport problems with pointwise cost which is a decreasing function of the distance. We show, in particular, that there is a general framework that encompasses all the cases above."}
{"id": "2601.14995", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14995", "abs": "https://arxiv.org/abs/2601.14995", "authors": ["Mojuan Yin", "Ruohui Wang", "Rui Zhou", "Xueguang Qiao", "Shougang Zhang"], "title": "Low-frequency fiber-optic vibration sensing with a Floquet-engineered optical lattice clock", "comment": null, "summary": "We propose a Floquet-engineered optical lattice clock based demodulation scheme to enhance the low-frequency performance of wound fiber-optic vibration sensors. Vibration-induced phase variations in the sensing fiber are demodulated by the Floquet-engineered Rabi spectra of the clock transition. The lattice depth with the fiber length and the Floquet-engineered Rabi spectra under the vibration from 200 Hz down to 0.5 Hz are simulated. With a fiber length of 4 km and transmission loss of 2 dB/km, a phase change sensitivity higher than 6 * 10^3 rad per g is achieved at both vibration frequencies of 200 Hz and 0.5 Hz."}
{"id": "2601.14882", "categories": ["math.OC", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14882", "abs": "https://arxiv.org/abs/2601.14882", "authors": ["Mehdi Golestani", "Yongduan Song", "Weizhen Liu", "Guangren Duan", "He Kong"], "title": "Practical prescribed-time prescribed performance control with asymptotic convergence - A vanishing sigma-modification approach", "comment": null, "summary": "In this paper, we present a method capable of ensuring practical prescribed-time control with guaranteed performance for a class of nonlinear systems in the presence of time-varying parametric and dynamic uncertainties, and uncertain control coefficients. Our design consists of two key steps. First, we construct a performance-rate function that freezes at and after a user-specified time T, playing a crucial role in achieving desired precision within prescribed time T and dealing with unmodeled dynamics. Next, based on this function and a sigma-modification strategy in which the leakage term starts to vanish at t > T, we develop an adaptive dynamic surface control framework to reduce control complexity, deal with uncertainties, ensure prescribed performance, practical prescribed-time convergence to a specific region, and ultimately achieve asymptotic convergence. The effectiveness of the proposed control method is validated through numerical simulations."}
{"id": "2601.15242", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15242", "abs": "https://arxiv.org/abs/2601.15242", "authors": ["Kush Kinra", "Fernanda Cipriano"], "title": "Optimal control problem associated with three-dimensional critical convective Brinkman-Forchheimer equations", "comment": null, "summary": "In this article, we are concerned about the velocity tracking optimal control problem for 3D critical convective Brinkman-Forchheimer equations defined on a simply connected bounded domain $\\mathbb{D}\\subset\\mathbb{R}^3$ with $\\mathrm{C}^2$-boundary $\\partial\\mathbb{D}$. The control is introduced through an external force. The objective is to optimally minimize a velocity tracking cost functional, for which the velocity vector field is oriented towards a target velocity. Most importantly, we are concerned about the first-order necessary optimality conditions for above-mentioned optimal control problem which is the main challenging task of this article. To overcome the difficulties related to the differentiability of the control-to-state mapping, consequence of the lack of regularity of the state variable on bounded domains, we first establish some intermediate optimality conditions and then pass to the limit."}
{"id": "2601.15019", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15019", "abs": "https://arxiv.org/abs/2601.15019", "authors": ["G. P. Teja", "Radim Filip"], "title": "Cavity-QED tools for MBQC with optical binomial-codes", "comment": null, "summary": "Measurement-based quantum computation (MBQC) offers a promising paradigm for photonic quantum computing, but its implementation requires the generation of specific non-Gaussian resource states. While continuous-variable encodings such as the highly complex (GKP) states have been widely studied, the much simpler binomial codes offer an experimentally accessible alternative, though they demand a distinct set of operational tools. Here, we present a toolkit for MBQC using optical binomial codes, detailing a cavity-QED protocol for conditional generation of cluster states and the implementation of Pauli measurements. Our work proposes the first steps for existing optical atom-cavity architectures to lay the groundwork for their use in quantum computation."}
{"id": "2601.14933", "categories": ["math.NA", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.14933", "abs": "https://arxiv.org/abs/2601.14933", "authors": ["Yogesh Darmwal", "Ketan Rajawat"], "title": "Rank-one Riemannian Subspace Descent for Nonlinear Matrix Equations", "comment": null, "summary": "We propose a rank-one Riemannian subspace descent algorithm for computing symmetric positive definite (SPD) solutions to nonlinear matrix equations arising in control theory, dynamic programming, and stochastic filtering. For solution matrices of size $n\\times n$, standard approaches for dense matrix equations typically incur $\\mathcal{O}(n^3)$ cost per-iteration, while the efficient $\\mathcal{O}(n^2)$ methods either rely on sparsity or low-rank solutions, or have iteration counts that scale poorly. The proposed method entails updating along the dominant eigen-component of a transformed Riemannian gradient, identified using at most $\\mathcal{O}(\\log(n))$ power iterations. The update structure also enables exact step-size selection in many cases at minimal additional cost. For objectives defined as compositions of standard matrix operations, each iteration can be implemented using only matrix--vector products, yielding $\\mathcal{O}(n^2)$ arithmetic cost. We prove an $\\mathcal{O}(n)$ iteration bound under standard smoothness assumptions, with improved bounds under geodesic strong convexity. Numerical experiments on large-scale CARE, DARE, and other nonlinear matrix equations show that the proposed algorithm solves instances (up to $n=10{,}000$ in our tests) for which the compared solvers, including MATLAB's \\texttt{icare}, structure-preserving doubling, and subspace-descent baselines fail to return a solution. These results demonstrate that rank-one manifold updates provide a practical approach for high-dimensional and dense SPD-constrained matrix equations. MATLAB code implementation is publicly available on GitHub : \\href{https://github.com/yogeshd-iitk/nonlinear_matrix_equation_R1RSD}{\\textcolor{blue}{https://github.com/yogeshd-iitk/nonlinear\\_matrix \\_equation\\_R1RSD}}"}
{"id": "2601.15252", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.15252", "abs": "https://arxiv.org/abs/2601.15252", "authors": ["Jamie Fravel", "Robert Hildebrand"], "title": "Automating Idealness Proofs for Binary Programs with Application to Rectangle Packing", "comment": "Associated git repo: https://github.com/jfravel/Ideal-O-Matic . 30 pages main body, 45 pages total", "summary": "An integer program is called ideal if its continuous relaxation coincides with its convex hull allowing the problem to be solved as a continuous program and offering substantial computational advantages. Proving idealness analytically can be extraordinarily tedious -- even for small formulations -- such proofs often span many pages of intricate case analysis which motivates the development of automated verification methods. We develop a general-purpose framework for certifying idealness in Mixed Binary Linear Programs (MBLPs), formulating the verification problem as a linear program when the data is fixed and as a nonconvex quadratic program when the data is parametric. We apply this framework to study several formulations of the rectangle packing problem that are conjectured to be pairwise-ideal, obtaining computational proofs where analytic proofs were previously unknown or impractical. As our second contribution, we introduce and model a novel generalization of the rectangle packing problem that enforces edge clearances between selected rectangles. We present both existing and novel MBLP formulations which arise from different encodings of the underlying disjunctive constraints. We perform some computational experiments on these formulations under a strip-packing objective to determine the importance of pairwise-idealness in practice."}
{"id": "2601.15026", "categories": ["quant-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.15026", "abs": "https://arxiv.org/abs/2601.15026", "authors": ["Hasan Mehdi Rizvi", "Devvrat Tiwari", "Subhashish Banerjee"], "title": "Two-Qubit Spin-Boson Model in the Strong Coupling Regime: Coherence, Non-Markovianity, and Quantum Thermodynamics", "comment": "11 pages, 7 figures", "summary": "We investigate the dynamics of a two-qubit open quantum system, in particular the two-qubit spin-boson model in the strong coupling regime, coupled to two thermal bosonic baths under non-Markovian and non-equilibrium conditions. Two complementary approaches, the Hierarchical Equations of Motion (HEOM) and Reaction Coordinate Mapping (RCM), are employed to examine various coupling regimes between the qubits and their respective baths. The dynamical features of the model and the impact of the tunneling amplitude on quantum coherence of the system are probed using the $l_1$-norm of coherence. The model is further shown to have non-Markovian evolution. The nontrivial task of calculating entropy production in the strong-coupling regime is performed using auxiliary density operators in HEOM. Motivated by the realization of a quantum thermal device in the strong-coupling regime, the non-equilibrium steady-state behavior of the system is investigated. Furthermore, the relationship between the heat and spin currents and the tunneling amplitude is probed."}
{"id": "2601.14468", "categories": ["eess.SY", "math.NA", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.14468", "abs": "https://arxiv.org/abs/2601.14468", "authors": ["Milad Hasanzadeh", "Amin Kargarian", "Javad Lavaei"], "title": "All-Pass Fractional OPF: A Solver-Friendly, Physics-Preserving Approximation of AC OPF", "comment": null, "summary": "This paper presents a fractional approximation of the AC optimal power flow (AC OPF) problem based on an all-pass approximation of the exponential power flow kernel. The classical AC OPF relies on trigonometric coupling between bus voltage phasors, which yields a nonconvex program with oscillatory derivatives that can slow, or in some cases destabilize, interior-point methods. We replace the trigonometric terms with an all-pass fractional (APF) approximation whose real and imaginary components act as smooth surrogates for the cosine and sine functions, and we introduce a pre-rotation to shift the argument of the approximation toward its most accurate region, ensuring that the reformulated power flow model preserves physical loss behavior, maintains the symmetry of the classical kernels, and improves the conditioning of the Jacobian and Hessian matrices. The proposed APF OPF formulation remains nonconvex, as in the classical model, but it eliminates trigonometric evaluations and empirically produces larger and more stable Newton steps under standard interior-point solvers. Numerical results on more than 25 IEEE and PGLib test systems ranging from 9 to 10{,}000 buses demonstrate that the APF OPF model achieves solutions with accuracy comparable to that of the classical formulation while reducing solver times, indicating a more solver-friendly nonconvex representation of AC OPF. All code, functions, verification scripts, and generated results are publicly available on \\href{https://github.com/LSU-RAISE-LAB/APF-OPF}{GitHub}, along with a README describing how to run and reproduce the experiments."}
{"id": "2601.15046", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15046", "abs": "https://arxiv.org/abs/2601.15046", "authors": ["Nils Klement", "Veronika Eyring", "Mierk Schwabe"], "title": "Explaining the advantage of quantum-enhanced physics-informed neural networks", "comment": null, "summary": "Partial differential equations (PDEs) form the backbone of simulations of many natural phenom- ena, for example in climate modeling, material science, and even financial markets. The application of physics-informed neural networks to accelerate the solution of PDEs is promising, but not compet- itive with numerical solvers yet. Here, we show how quantum computing can improve the ability of physics-informed neural networks to solve partial differential equations. For this, we develop hybrid networks consisting of quantum circuits combined with classical layers and systematically test them on various non linear PDEs and boundary conditions in comparison with purely classical networks. We demonstrate that the advantage of using quantum networks lies in their ability to achieve an accurate approximation of the solution in substantially fewer training epochs, particularly for more complex problems. These findings provide the basis for targeted developments of hybrid quantum neural networks with the goal to significantly accelerate numerical modeling."}
{"id": "2601.15101", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15101", "abs": "https://arxiv.org/abs/2601.15101", "authors": ["Patrick Navez", "Valentina Di Meo", "Berardo Ruggiero", "Claudio Gatti", "Fabio Chiarello", "Alessandro D'Elia", "Alessio Rettaroli", "Emanuele Enrico", "Luca Fasolo", "Mikhail Fistul", "Ilya Eremin", "Alexandre Zagoskin", "Paolo Vanacore", "Paolo Silvestrini", "Mikhail Lisitskiy"], "title": "Bose condensation and Bogoliubov excitation in resonator-embedded superconducting qubit network", "comment": null, "summary": "Superconducting qubit networks (SQNs) embedded in a low-dissipative resonator is a promising device allowing one not only to establish the collective quantum dynamics on a macroscopic scale but also to greatly enhance the sensitivity of detectors of microwave photons. A quantum ac Stark effect provided by coupling between an SQN and microwave photons of a resonator, leads to a strong nonlinear interaction between photons. Here, we present a two-tone spectroscopy experiment in which a set of 10 superconducting flux qubits is coupled to the input R- resonator and the output T- transmission line. An external microwave pump field close to the resonance frequency populates macroscopically the resonator mode as a Bose-Einstein condensate, while a second probe beam scans the resonances referred also as Bogoliubov-like excitations. The corresponding excitation frequency measured from the transmission coefficient, |S21(f)| displays an abrupt change of the resonant dip position once the power of the pump field overcomes a critical value Pcr. This sharp shift occurs in a narrow region of pump frequencies, and can be tuned by an applied magnetic field. It is a signature of bistability of the photon number inside the resonator, in agreement with theory."}
{"id": "2601.15112", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15112", "abs": "https://arxiv.org/abs/2601.15112", "authors": ["Lana Bozanic", "Alex May", "Stanley Miao"], "title": "Entanglement summoning from entanglement sharing", "comment": null, "summary": "In an entanglement summoning task, a set of distributed, co-operating parties attempt to fulfill requests to prepare entanglement between distant locations. The parties share limited communication resources: timing constraints may require the entangled state be prepared before some pairs of distant parties can communicate, and a restricted set of links in a quantum network may further constrain communication. Building on earlier work, we continue the characterization of entanglement summoning. We give an if and only if condition on entanglement summoning tasks with only bidirected causal connections, and provide a set of sufficient conditions addressing the most general case containing both oriented and bidirected causal connections. Our results rely on the recent development of entanglement sharing schemes."}
{"id": "2601.15171", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15171", "abs": "https://arxiv.org/abs/2601.15171", "authors": ["Ansis Rosmanis"], "title": "A nearly linear-time Decoded Quantum Interferometry algorithm for the Optimal Polynomial Intersection problem", "comment": "52 pages, 5 figures", "summary": "Recently, Jordan et al. (Nature, 2025) introduced a novel quantum-algorithmic technique called Decoded Quantum Interferometry (DQI) for solving specific combinatorial optimization problems associated with classical codes. They presented a constraint-satisfaction problem called Optimal Polynomial Intersection (OPI) and showed that, for this problem, a DQI algorithm running in polynomial time can satisfy a larger fraction of constraints than any known polynomial-time classical algorithm.\n  In this work, we propose several improvements to the DQI algorithm, including sidestepping the quadratic-time Dicke state preparation. Given random access to the input, we show how these improvements result in a nearly linear-time DQI algorithm for the OPI problem. Concurrently and independently with this work, Khattar et al. (arXiv:2510:10967) also construct a nearly linear-time DQI algorithm for OPI using slightly different techniques."}
{"id": "2601.15193", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.15193", "abs": "https://arxiv.org/abs/2601.15193", "authors": ["Marta Mastrangelo", "Djamal Gacemi", "Axel Evirgen", "Salvatore Pes", "Alexandre Larrue", "Pascal Filloux", "Isabelle Sagnes", "Abdelmounaim Harouri", "Angela Vasanelli", "Carlo Sirtori"], "title": "Purcell enhanced electroluminescence of a unipolar light emitting quantum device at 10 micron", "comment": null, "summary": "Efficient generation of radiation in the mid- and far- infrared relies primarily on lasers and coherent nonlinear optical phenomena driven by lasers. This wavelength range lacks of luminescent devices because the spontaneous emission rate becomes much longer than the nonradiative energy relaxation processes and therefore emitters have to count on stimulated emission produced by linear or non-linear optical gain. However, spontaneous emission is not a fundamental property of the emitter. By engineering metamaterials composed of arrays of nano-emitters into microcavities coupled to patch antennas, we have demonstrated mid-infrared electroluminescent devices emitting a collimated beam with excellent spatial properties and a factor 100 increase in the collected power, compared to standard devices. Our results illustrate that by reshaping the photonic environment around emitting dipoles, as in the Purcell effect, it is possible to enhance the spontaneous emission and conceive efficient optoelectronic light emitting devices that operate close to the thermodynamical equilibrium as LEDs in the visible range."}
{"id": "2601.15237", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15237", "abs": "https://arxiv.org/abs/2601.15237", "authors": ["Debarupa Saha", "Ujjwal Sen"], "title": "Precision Enhancement in Transient Quantum Thermometry:Cold-Probe Bias and Its Removal", "comment": "11 pages, 2 figures", "summary": "We unveil a temperature bias of the probe in transient quantum thermometry under Markovian dynamics. Specifically, for qubit thermometers evolving under Markovian dynamics, we show that enhanced precision beyond the steady state limit can be achieved if and only if the probe is initially colder than the thermal state corresponding to the bath temperature to be estimated. In contrast, this temperature bias can be lifted when the probe dynamics is non-Markovian. In the non-Markovian regime, both hot and cold probes can simultaneously attain the same transient maximum precision, well above the steady-state value."}
{"id": "2601.15253", "categories": ["quant-ph", "physics.chem-ph", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.15253", "abs": "https://arxiv.org/abs/2601.15253", "authors": ["Nathan A. Baker", "Brian Bilodeau", "Chi Chen", "Yingrong Chen", "Marco Eckhoff", "Alexandra Efimovskaya", "Piero Gasparotto", "Puck van Gerwen", "Rushi Gong", "Kevin Hoang", "Zahra Hooshmand", "Andrew J. Jenkins", "Conrad S. N. Johnston", "Run R. Li", "Jiashu Liang", "Hongbin Liu", "Alexis Mills", "Maximilian Mörchen", "George Nishibuchi", "Chong Sun", "Bill Ticehurst", "Matthias Troyer", "Jan P. Unsleber", "Stefan Wernli", "David B. Williams-Young", "Boqin Zhang"], "title": "QDK/Chemistry: A Modular Toolkit for Quantum Chemistry Applications", "comment": "32 pages, 3 figures", "summary": "We present QDK/Chemistry, a software toolkit for quantum chemistry workflows targeting quantum computers. The toolkit addresses a key challenge in the field: while quantum algorithms for chemistry have matured considerably, the infrastructure connecting classical electronic structure calculations to quantum circuit execution remains fragmented. QDK/Chemistry provides this infrastructure through a modular architecture that separates data representations from computational methods, enabling researchers to compose workflows from interchangeable components. In addition to providing native implementations of targeted algorithms in the quantum-classical pipeline, the toolkit builds upon and integrates with widely used open-source quantum chemistry packages and quantum computing frameworks through a plugin system, allowing users to combine methods from different sources without modifying workflow logic. This paper describes the design philosophy, current capabilities, and role of QDK/Chemistry as a foundation for reproducible quantum chemistry experiments."}
{"id": "2601.15263", "categories": ["quant-ph", "gr-qc", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2601.15263", "abs": "https://arxiv.org/abs/2601.15263", "authors": ["Amrapali Sen", "Flavio Del Santo"], "title": "Superluminal Transformations and Indeterminism", "comment": "9 main pages and 3 figures", "summary": "Quantum theory is widely regarded as fundamentally indeterministic, yet classical frameworks can also exhibit indeterminism once infinite information is abandoned. At the same time, relativity is usually taken to forbid superluminal signalling, yet Lorentz symmetry formally admits superluminal transformations (SpTs). Dragan and Ekert have argued that SpTs entail indeterminism analogous to the quantum one. Here, we derive a no-go theorem from natural assumptions, which can be interpreted as: superluminal transformations (SpTs) and finite information cannot coexist. Any theory accommodating SpTs must therefore allow unbounded information content, leading to a deterministic ontology akin to that of classical theories formulated over the real numbers. Thus, any apparent indeterminism arising from superluminal transformations reflects only probabilities arising from subjective ignorance, unlike the objective nature of probabilities in quantum theory, indicating that the claimed indeterminacy from superluminal extensions is not quantum."}
{"id": "2601.14297", "categories": ["physics.soc-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14297", "abs": "https://arxiv.org/abs/2601.14297", "authors": ["Tzula B. Propp", "Brandy Todd", "Sara A. Metwalli", "Alina Helena S. Gallardo", "Michael Dascal", "Denise Ruffner", "Klaus D. Jöns", "Shaeema Zaman", "Judith Kreukels", "Marilù Chiofalo", "Lydia Sanmartí-Vila"], "title": "Meeting the Needs of the Global Quantum Science Community: A Call to Action", "comment": null, "summary": "2025 marks one hundred years since the discovery of quantum mechanics. In the century since then, quantum science has blossomed into a global community composed of academics, engineers, developers, and entrepreneurs. The world is currently in the middle of the so-called second quantum revolution, with increased public awareness of quantum science and technology, and growing investment in both quantum hardware and software applications. However, representation remains low among historically marginalized groups: women, LGBTQ+, BIPOC, and people from the global south make up disproportionately few physicists. There are numerous efforts to improve diversity within quantum science, including through workforce development. But many of the changes enacted at the highest levels have failed to result in real change, as highlighted and discussed in the recent Women For Quantum Manifesto of Values. Here, we seek to echo and amplify the need for real change in the quantum ecosystem, emphasizing intersectionality and a feminist approach that centers the most vulnerable members of the quantum community: young students and researchers, especially those communities historically marginalized from quantum science.\n  This report is our attempt to help quantum communities meet this need; we have conducted a survey of quantum scientists all over the world, and here we include both a preliminary report of our findings and policy suggestions we have built to address them. The primary results of our survey are that, 1) marginalized quantum scientists are experiencing hardships and challenges more than their more privileged peers across all metrics, 2) that this fact is hurting retention of diverse, talented quantum scientists in our field, and 3) quantum EDI is an investment in talent retention and resilience building, which are essential for a thriving, globally competitive quantum ecosystem."}
{"id": "2601.14316", "categories": ["physics.hist-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14316", "abs": "https://arxiv.org/abs/2601.14316", "authors": ["Gabriele Cafiero", "Luca Molinari", "Jonte R. Hance"], "title": "The burden of Fundamentality: Metaphysical ambiguities and the issue of Superdeterminism", "comment": "15 pages, 2 figures", "summary": "In this paper we approach the problem of superdeterminism from a novel point of view, highlighting its character as a more metaphysical than scientific proposition. First, we introduce a distinction between two types of superdeterministic theories, naïve (NSD) and metaphysical (MSD), and argue how NSD presents significant epistemic flaws. We show how NSD justifies itself through claims to fundamentality, thus connoting itself as a metaphysical theory rather than a scientific one. We finally illustrate that the most developed MSD model so far, Invariant Set Theory, implicitly proposes a confused form of priority monism. Our paper thus reinforces the thesis that theories should demonstrate rather than assume fundamentality and that it is methodologically flawed for a theory to assume its own fundamentality for the sole purpose of defending against criticisms."}
{"id": "2601.14399", "categories": ["physics.comp-ph", "hep-ex", "hep-ph", "nucl-ex", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14399", "abs": "https://arxiv.org/abs/2601.14399", "authors": ["Lukas Heinrich", "Tom Magorsch"], "title": "Differentiable quantum-trajectory simulation of Lindblad dynamics for QGP transport-coefficient inference", "comment": "13 pages, 4 figures", "summary": "We study parameter estimation for the transport coefficients of the quark-gluon plasma by differentiating open-quantum-system-based Monte Carlo simulations of quarkonium suppression. The underlying simulator requires solving a Lindblad equation in a large Hilbert space, which makes parameter estimation computationally expensive. We approach the problem using gradient-based optimization. Specifically, we apply the score-function gradient estimator to differentiate through discrete jump sampling in the Monte Carlo wave-function algorithm used to solve the Lindblad equation. The resulting stochastic gradient estimator exhibits sufficiently low variance and can still be estimated in an embarrassingly parallel manner, enabling efficient scaling of the simulations. We implement this gradient estimator in the existing open-source quarkonium suppression code QTraj. To demonstrate its utility for parameter estimation, we infer the two transport coefficients $\\hatκ$ and $\\hatγ$ using gradient-based optimization on synthetic nuclear modification factor data."}
{"id": "2601.14754", "categories": ["cond-mat.dis-nn", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.14754", "abs": "https://arxiv.org/abs/2601.14754", "authors": ["Guolin Nan", "Zhijian Li", "Feng Mei", "Zhihao Xu"], "title": "Anomalous Localization and Mobility Edges in Non-Hermitian Quasicrystals with Disordered Imaginary Gauge Fields", "comment": "17 pages, 10 figures", "summary": "We study anomalous localization in a one-dimensional non-Hermitian quasicrystal with a spatially disordered imaginary gauge field. The system is a generalized Aubry-André-Harper (AAH) chain with asymmetric nearest- and next-nearest-neighbor hoppings generated by a Bernoulli imaginary gauge field and a quasiperiodic onsite potential. In the standard non-Hermitian AAH limit, the system undergoes a transition from a fully erratic non-Hermitian skin effect (ENHSE) phase to a fully localized phase. We show that the fractal dimension cannot distinguish these phases, whereas the Lyapunov exponent and center-of-mass fluctuations provide sharp diagnostics. This transition is accompanied by a complex-to-real spectral change under periodic boundary conditions and a topological change of the spectral winding number. With next-nearest-neighbor hopping, we uncover an anomalous mobility edge separating Anderson-localized states from ENHSE states, rather than extended states. This mobility edge is captured by an energy-dependent winding number that vanishes in the localized regime. Finally, we propose a dynamical probe based on wave-packet expansion: for typical disorder realizations, the dynamics shows winding-controlled drift and disorder-selected pinning or boundary-wrapping recurrence, while disorder averaging restores Hermitian-like transport. These results offer practical spectral, topological, and dynamical diagnostics of anomalous localization and mobility edges in non-Hermitian quasicrystals."}
{"id": "2601.15184", "categories": ["math.OC", "math-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.15184", "abs": "https://arxiv.org/abs/2601.15184", "authors": ["Julius A. Zeiss", "Gereon Koßmann", "René Schwonnek", "Martin Plávala"], "title": "Finite de Finetti for convex bodies and Polynomial Optimization", "comment": "36 + 13 pages; Julius A. Zeiss and Gereon Koßmann contributed equally to this work", "summary": "Leveraging a recently proposed notion of relative entropy in general probabilistic theories (GPT), we prove a finite de Finetti representation theorem for general convex bodies. We apply this result to address a fundamental question in polynomial optimization: the existence of a convergent outer hierarchy for problems with inequality constraints and analytical convergence guarantees. Our strategy generalizes a quantitative monogamy-of-entanglement argument from quantum theory to arbitrary convex bodies, establishing a uniform upper bound on mutual information in multipartite extensions. This leads to a finite de Finetti theorem and, subsequently, a convergent conic hierarchy for a wide class of polynomial optimization problems subject to both equality and inequality constraints. We further provide a constructive rounding scheme that yields certified interior points with controlled approximation error. As an application, we express the optimal GPT value of a two-player non-local game as a polynomial optimization problem, allowing our techniques to produce approximation schemes with finite convergence guarantees."}
