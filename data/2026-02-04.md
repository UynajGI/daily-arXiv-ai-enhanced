<div id=toc></div>

# Table of Contents

- [cs.SI](#cs.SI) [Total: 9]
- [cs.CE](#cs.CE) [Total: 2]
- [stat.ME](#stat.ME) [Total: 14]
- [q-fin.CP](#q-fin.CP) [Total: 1]
- [physics.ao-ph](#physics.ao-ph) [Total: 2]
- [cond-mat.dis-nn](#cond-mat.dis-nn) [Total: 2]
- [physics.hist-ph](#physics.hist-ph) [Total: 1]
- [eess.SY](#eess.SY) [Total: 10]
- [quant-ph](#quant-ph) [Total: 40]
- [cond-mat.stat-mech](#cond-mat.stat-mech) [Total: 7]
- [physics.comp-ph](#physics.comp-ph) [Total: 1]
- [math.NA](#math.NA) [Total: 11]
- [math.ST](#math.ST) [Total: 3]
- [nlin.AO](#nlin.AO) [Total: 2]
- [physics.geo-ph](#physics.geo-ph) [Total: 3]
- [math.OC](#math.OC) [Total: 5]
- [physics.soc-ph](#physics.soc-ph) [Total: 9]
- [cond-mat.str-el](#cond-mat.str-el) [Total: 13]


<div id='cs.SI'></div>

# cs.SI [[Back]](#toc)

### [1] [Community Norms in the Spotlight: Enabling Task-Agnostic Unsupervised Pre-Training to Benefit Online Social Media](https://arxiv.org/abs/2602.02525)
*Liam Hebert,Lucas Kopp,Robin Cohen*

Main category: cs.SI

TL;DR: 本文提出了一种基于社区规范的无监督预训练范式，以解决在线社交平台中因依赖人工标注数据而导致的讨论转换器模型发展受限问题。


<details>
  <summary>Details</summary>
Motivation: 现有的讨论转换器模型严重依赖高质量的人工标注数据，限制了其在复杂社交动态建模中的潜力，尤其是在处理仇恨言论和错误信息等社会挑战时。

Method: 提出从任务特定微调转向基于社区规范的无监督预训练框架，利用图结构建模对话，并通过社区行为模式学习隐含的社会规范。

Result: 该框架缓解了数据稀缺问题，并增强了AI系统决策背后社会规范的可解释性。

Conclusion: 这种新范式不仅提升了模型的适用性和可扩展性，还为人工智能促进社会善治提供了新的机遇。

Abstract: Modelling the complex dynamics of online social platforms is critical for addressing challenges such as hate speech and misinformation. While Discussion Transformers, which model conversations as graph structures, have emerged as a promising architecture, their potential is severely constrained by reliance on high-quality, human-labelled datasets. In this paper, we advocate a paradigm shift from task-specific fine-tuning to unsupervised pretraining, grounded in an entirely novel consideration of community norms. We posit that this framework not only mitigates data scarcity but also enables interpretation of the social norms underlying the decisions made by such an AI system. Ultimately, we believe that this direction offers many opportunities for AI for Social Good.

</details>


### [2] [DualMind: Towards Understanding Cognitive-Affective Cascades in Public Opinion Dissemination via Multi-Agent Simulation](https://arxiv.org/abs/2602.02534)
*Enhao Huang,Tongtong Pan,Shuhuai Zhang,Qishu Jin,Liheng Zheng,Kaichun Hu,Yiming Li,Zhan Qin,Kui Ren*

Main category: cs.SI

TL;DR: 提出了一种名为DualMind的LLM驱动多智能体平台，用于在公关危机中建模情感反应与认知信念的相互作用，实验证明其在15个真实危机中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有框架通常忽略了短暂情感反应与持久认知信念之间的交互，导致在公关危机中公众舆论预测不准确。

Method: 设计了一个名为DualMind的LLM驱动多智能体平台，模拟情感与认知的双成分互动，并在15个2024年8月后的真实危机中使用社交媒体数据进行评估。

Result: DualMind能够高保真地重建舆论轨迹，并显著优于当前最先进的基线模型。

Conclusion: DualMind为公关危机中的舆论预测提供了高保真工具，有助于主动式危机管理。

Abstract: Forecasting public opinion during PR crises is challenging, as existing frameworks often overlook the interaction between transient affective responses and persistent cognitive beliefs. To address this, we propose DualMind, an LLM-driven multi-agent platform designed to model this dual-component interplay. We evaluate the system on 15 real-world crises occurring post-August 2024 using social media data as ground truth. Empirical results demonstrate that DualMind faithfully reconstructs opinion trajectories, significantly outperforming state-of-the-art baselines. This work offers a high-fidelity tool for proactive crisis management. Code is available at https://github.com/EonHao/DualMind.

</details>


### [3] [Recommender system in X inadvertently profiles ideological positions of users](https://arxiv.org/abs/2602.02624)
*Paul Bouchaud,Pedro Ramaciotti*

Main category: cs.SI

TL;DR: 该研究利用X平台上的250万条好友推荐数据，分析了推荐系统如何在嵌入空间中表征用户的政见与社会属性，发现系统内部存在与左右政治立场高度相关的排序，且无法由人口统计学特征解释，并提出了限制政治信息以增强隐私合规的新方法。


<details>
  <summary>Details</summary>
Motivation: 理解现实世界中AI推荐系统如何学习和处理用户的政治与社会属性，揭示算法黑箱中的用户表征机制，并探讨其对隐私法规中算法画像定义的影响。

Method: 通过数据捐赠计划收集用户在X平台上的好友推荐数据，结合公开的推荐系统架构推断用户在嵌入空间中的位置，并使用基于政治调查数据校准的意识形态量表分析用户的政治立场及其他属性。

Result: 发现推荐系统的嵌入空间中用户排列与左右政治立场高度相关（Pearson rho=0.887, p<0.0001），且这种相关性不能由年龄、性别等社会人口学特征解释；并展示了可限制政治信息的新型受限推荐方法。

Conclusion: 推荐系统隐式地构建了用户的政治表征，这不仅为研究人机交互提供了新路径，也挑战了当前数据隐私法规中对算法画像的法律界定，同时提出可通过约束推荐方法实现隐私保护与推荐相关性的平衡。

Abstract: Studies on recommendations in social media have mainly analyzed the quality of recommended items (e.g., their diversity or biases) and the impact of recommendation policies (e.g., in comparison with purely chronological policies). We use a data donation program, collecting more than 2.5 million friend recommendations made to 682 volunteers on X over a year, to study instead how real-world recommenders learn, represent and process political and social attributes of users inside the so-called black boxes of AI systems. Using publicly available knowledge on the architecture of the recommender, we inferred the positions of recommended users in its embedding space. Leveraging ideology scaling calibrated with political survey data, we analyzed the political position of users in our study (N=26,509 among volunteers and recommended contacts) among several attributes, including age and gender. Our results show that the platform's recommender system produces a spatial ordering of users that is highly correlated with their Left-Right positions (Pearson rho=0.887, p-value < 0.0001), and that cannot be explained by socio-demographic attributes. These results open new possibilities for studying the interaction between human and AI systems. They also raise important questions linked to the legal definition of algorithmic profiling in data privacy regulation by blurring the line between active and passive profiling. We explore new constrained recommendation methods enabled by our results, limiting the political information in the recommender as a potential tool for privacy compliance capable of preserving recommendation relevance.

</details>


### [4] [Deepfake Pornography is Resilient to Regulatory and Platform Shocks](https://arxiv.org/abs/2602.02754)
*Alejandro Cuevas,Manoel Horta Ribeiro*

Main category: cs.SI

TL;DR: 该研究探讨了美国《TAK IT DOWN法案》通过及MrDeepfakes网站关闭这一复合干预对合成非自愿色情内容（SNCEI）传播的影响，发现此举并未减少SNCEI的整体活动，反而导致其在不同平台间的重新分布。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能的发展，制造和传播非自愿的合成色情内容（SNCEI）变得更加容易，对受害者造成严重伤害。尽管出台了联邦法律进行打击，但其实际效果尚不明确，因此需要评估此类政策与平台关闭的联合干预是否真正抑制了SNCEI的传播。

Method: 选取三个共享色情内容的在线论坛，利用其子版块结构，将专门用于SNCEI的子版块与其他色情类型进行对比，采用合成控制法和准实验设计分析法案通过和网站关闭前后SNCEI分享行为的变化。

Result: 研究发现，在多个平台上，SNCEI的分享、请求量以及部分情况下的新贡献者数量均有所增加，表明该复合干预并未压制SNCEI活动，而是促使其在平台间重新分布，且时间和程度存在显著差异。

Conclusion: 单纯依靠平台下架和监管信号可能无法减少SNCEI的总体 prevalence，而只是改变了其生产和传播的地点与时间，提示需采取更全面的应对策略。

Abstract: Generative artificial intelligence tools have made it easier to create realistic, synthetic non-consensual explicit imagery (popularly known as deepfake pornography; hereinafter SNCEI) of people. Once created, this SNCEI is often shared on various websites, causing significant harm to victims. This emerging form of sexual abuse was recently criminalized in the US at the federal level by S.146, the TAKE IT DOWN Act. A week after the bill's passage became effectively imminent, the MrDeepfakes website -- one of the most notorious facilitators of SNCEI creation and dissemination -- shut down. Here, we explore the impact of the bill's passage and the subsequent shutdown as a compound intervention on the dissemination of SNCEI. We select three online forums where sexually explicit content is shared, each containing dedicated subforums to organize various types of sexually explicit content. By leveraging each forum's design, we compare activity in subforums dedicated to SNCEI with that in other pornographic genres using a synthetic control, quasi-experimental approach. Across websites, we observed an increase in the sharing and requests for SNCEI, and, in some cases, in new contributors. These results indicate that the compound intervention did not suppress SNCEI activity overall but instead coincided with its redistribution across platforms, with substantial heterogeneity in timing and magnitude. Together, our findings suggest that deplatforming and regulatory signals alone may shift where and when SNCEI is produced and shared, rather than reducing its prevalence.

</details>


### [5] [From semantic memory to collective creativity: A generative cognitive foundation for social creativity models](https://arxiv.org/abs/2602.03068)
*Mirza Nayeem Ahmed,Raiyan Abdul Baten*

Main category: cs.SI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Simulation-based theory development has yielded powerful insights into collective performance by linking social structure to emergent outcomes, yet it has struggled to extend to collective creativity. Creativity is hard to capture purely at the social level, as novel ideas are generated through cognitive mechanisms. To address this gap, we introduce a multi-level socio-cognitive agent-based framework in which agents share a common semantic vocabulary and substrate but differ in semantic network topology. A single generative parameter tunes semantic modularity, yielding emergent individual differences in ideational breadth. When agents exchange ideation traces, two canonical social-creativity phenomena arise without being imposed: lower pre-interaction ideation overlap predicts larger stimulation gains, and shared inspiration sources induce network-level redundancy. The framework enables mechanistic theory-building about cognition and social structure in collective creativity.

</details>


### [6] ["Why I Took the Blackpill": A Thematic Analysis of the Radicalization Process in Incel Communities](https://arxiv.org/abs/2602.03089)
*Jennifer Golbeck,Celia Chen,Alex Leitch*

Main category: cs.SI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Incels, or "involuntary celibates", are an extreme, misogynistic hate group that exists entirely online. Members of the community have been linked to acts of offline violence, including mass shootings. Previous research has engaged with the ideologies and beliefs of incels, but none has looked specifically at the radicalization process. In this paper, we perform a thematic analysis on social media posts where incels describe their own radicalization process. We identified six major themes grouped into four chronological steps: Pre-radicalization (themes of Appearance, Social Isolation, and Psychological issues), Searching for Blame, Radicalization, and Post Radicalization. These results align closely with existing work on radicalization among other extremist groups, bringing incel radicalization inline with a growing body of research on understanding and managing radicalization.

</details>


### [7] [Link Fraction Mixed Membership Reveals Community Diversity in Aggregated Social Networks](https://arxiv.org/abs/2602.03266)
*Gamal Adel,Eszter Bokányi,Eelke M. Heemskerk,Frank W. Takes*

Main category: cs.SI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Community detection is a critical tool for understanding the mesoscopic structure of large-scale networks. However, when applied to aggregated or coarse-grained social networks, disjoint community partitions cannot capture the diverse composition of community memberships within aggregated nodes. While existing mixed membership methods alleviate this issue, they may detected communities that are highly sensitive to the aggregation resolution, not reliably reflecting the underlying community structure of the underlying individual-level network. This paper presents the Link Fraction Mixed Membership (LFMM) method, which computes the mixed memberships of nodes in aggregated networks. Unlike existing mixed membership methods, LFMM is consistent under aggregation. Specifically, we show that it conserves community membership sums at different scales. The method is utilized to study a population-scale social network of the Netherlands, aggregated at different resolutions. Experiments reveal variation in community membership across different geographical regions and evolution over the last decade. In particular, we show how our method identifies large urban hubs that act as the melting pots of diverse, spatially remote communities.

</details>


### [8] [In Bad Faith: Assessing Discussion Quality on Social Media](https://arxiv.org/abs/2602.03090)
*Celia Chen,Alex Leitch,William Jordan Conway,Eric Cotugno,Emily Klein,Rajesh Kumar Gnanasekaran,Kristin Buckstad Hamilton,Casi Sherman,Celia Sterrn,Logan C. Stevens,Rebecca Zarrella,Jennifer Golbeck*

Main category: cs.SI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The quality of a user's social media experience is determined both by the content they see and by the quality of the conversation and interaction around it. In this paper, we look at replies to tweets from mainstream media outlets and official government agencies and assess if they are good faith, engaging honestly and constructively with the original post, or bad faith, attacking the author or derailing the conversation. We assess automated approaches that may help in making this determination and then show that within our dataset of replies to mainstream media outlets and government agencies, bad faith interactions constitute 68.3% of all replies we studied, suggesting potential concerns about the quality of discourse in these specific conversational contexts. This is particularly true from verified accounts, where 91.7% of replies were bad faith. Given that verified accounts are algorithmically amplified, we discuss the implications of our work for understanding the user experience on social media.

</details>


### [9] [An Empirical Study of Collective Behaviors and Social Dynamics in Large Language Model Agents](https://arxiv.org/abs/2602.03775)
*Farnoosh Hashemi,Michael W. Macy*

Main category: cs.SI

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large Language Models (LLMs) increasingly mediate our social, cultural, and political interactions. While they can simulate some aspects of human behavior and decision-making, it is still underexplored whether repeated interactions with other agents amplify their biases or lead to exclusionary behaviors. To this end, we study Chirper.ai-an LLM-driven social media platform-analyzing 7M posts and interactions among 32K LLM agents over a year. We start with homophily and social influence among LLMs, learning that similar to humans', their social networks exhibit these fundamental phenomena. Next, we study the toxic language of LLMs, its linguistic features, and their interaction patterns, finding that LLMs show different structural patterns in toxic posting than humans. After studying the ideological leaning in LLMs posts, and the polarization in their community, we focus on how to prevent their potential harmful activities. We present a simple yet effective method, called Chain of Social Thought (CoST), that reminds LLM agents to avoid harmful posting.

</details>


<div id='cs.CE'></div>

# cs.CE [[Back]](#toc)

### [10] [Efficient Counterfactual Estimation of Conditional Greeks via Malliavin-based Weak Derivatives](https://arxiv.org/abs/2602.02811)
*Vikram Krishnamurthy,Luke Snow*

Main category: cs.CE

TL;DR: 提出了一种无需核平滑的两阶段方法，利用Malliavin积分和Skorohod积分精确表示扩散过程的条件损失泛函，实现高效计算稀有事件下的条件希腊值和反事实随机梯度。


<details>
  <summary>Details</summary>
Motivation: 在量化金融中，当条件事件概率极低时，传统蒙特卡洛估计效率低下，核平滑方法收敛慢，难以有效计算条件希腊值（即市场价值期望对参数的敏感性）。

Method: 采用Malliavin分析将条件损失泛函表示为Skorohod积分，避免核估计；结合弱导数法，实现对模型参数的梯度进行方差恒定的算法化估计。

Result: 所提方法获得与经典蒙特卡洛相当的方差和收敛速度；梯度估计的方差恒定，优于方差随路径长度线性增长的得分函数法。

Conclusion: 该框架为稀有事件场景下的金融希腊值计算和反事实条件随机梯度算法提供了高效、稳定的解决方案。

Abstract: We study counterfactual gradient estimation of conditional loss functionals of diffusion processes. In quantitative finance, these gradients are known as conditional Greeks: the sensitivity of expected market values, conditioned on some event of interest. The difficulty is that when the conditioning event has vanishing or zero probability, naive Monte Carlo estimators are prohibitively inefficient; kernel smoothing, though common, suffers from slow convergence. We propose a two-stage kernel-free methodology. First, we show using Malliavin calculus that the conditional loss functional of a diffusion process admits an exact representation as a Skorohod integral, yielding classical Monte-Carlo estimator variance and convergence rates. Second, we establish that a weak derivative estimate of the conditional loss functional with respect to model parameters can be evaluated algorithmically with constant variance, in contrast to the widely used score function method whose variance grows linearly in the sample path length. Together, these results yield an efficient framework for counterfactual conditional stochastic gradient algorithms and financial Greek computations in rare-event regimes.

</details>


### [11] [Generative Artificial Intelligence creates delicious, sustainable, and nutritious burgers](https://arxiv.org/abs/2602.03092)
*Vahidullah Tac,Christopher Gardner,Ellen Kuhl*

Main category: cs.CE

TL;DR: 本研究利用生成式人工智能从大规模食谱数据中学习人类味觉结构，设计出在美味、营养和可持续性方面优于传统食品（如巨无霸汉堡）的新型汉堡。


<details>
  <summary>Details</summary>
Motivation: 设计既美味又营养且可持续的食物具有挑战性，现有方法难以平衡这些复杂需求。

Method: 使用生成式人工智能模型分析大规模人类生成的食谱数据，以汉堡为模型系统，在无需显式监督的情况下自动生成新颖食物配方，并优化其美味度、可持续性或营养价值。

Result: 生成的美味汉堡在盲测中感官评分不低于巨无霸；蘑菇汉堡环境影响降低一个数量级以上；豆类汉堡营养评分接近翻倍。

Conclusion: 生成式AI可作为学习人类口味并系统化解决食品设计中多重权衡问题的有效框架。

Abstract: Food choices shape both human and planetary health; yet, designing foods that are delicious, nutritious, and sustainable remains challenging. Here we show that generative artificial intelligence can learn the structure of the human palate directly from large-scale, human-generated recipe data to create novel foods within a structured design space. Using burgers as a model system, the generative AI rediscovers the classic Big Mac without explicit supervision and generates novel burgers optimized for deliciousness, sustainability, or nutrition. Compared to the Big Mac, its delicious burgers score the same or better in overall liking, flavor, and texture in a blinded sensory evaluation conducted in a restaurant setting with 101 participants; its mushroom burger achieves an environmental impact score more than an order of magnitude lower; and its bean burger attains nearly twice the nutritional score. Together, these results establish generative AI as a quantitative framework for learning human taste and navigating complex trade-offs in principled food design.

</details>


<div id='stat.ME'></div>

# stat.ME [[Back]](#toc)

### [12] [Selective Information Borrowing for Region-Specific Treatment Effect Inference under Covariate Mismatch in Multi-Regional Clinical Trials](https://arxiv.org/abs/2602.02703)
*Chenxi Li,Ke Zhu,Shu Yang,Xiaofei Wang*

Main category: stat.ME

TL;DR: 本文提出了一种基于因果推断的统一框架，用于多区域临床试验中目标区域特定平均治疗效应（RSATE）的估计，通过选择性借用信息提升小样本区域的推断效率与有效性。


<details>
  <summary>Details</summary>
Motivation: 在多区域临床试验中，当目标区域样本量较小且与其他区域存在基线协变量或未测因素差异时，如何准确有效地推断区域特异性疗效是一个关键挑战。

Method: 采用逆方差加权估计器结合‘小样本、多协变量’的目标区域估计与‘大样本、少协变量’的全借用双重稳健估计；引入保角预测评估患者层面可比性，自适应选择可借用的辅助区域患者；使用条件随机化检验实现精确、无模型、考虑选择的I类错误控制。

Result: 模拟研究表明，所提方法相比不借用和全借用方法，均方误差降低10%-50%，统计功效更高，且在多种情景下保持有效推断；在POWER试验中的应用显示RSATE估计精度提升。

Conclusion: 该框架通过选择性借用外部区域信息，在存在协变量偏移和结果漂移的情况下仍能实现高效且有效的区域特异性治疗效应推断，适用于全球药物研发中的本地监管决策。

Abstract: Multi-regional clinical trials (MRCTs) are central to global drug development, enabling evaluation of treatment effects across diverse populations. A key challenge is valid and efficient inference for a region-specific estimand when the target region is small and differs from auxiliary regions in baseline covariates or unmeasured factors. We adopt an estimand-based framework and focus on the region-specific average treatment effect (RSATE) in a prespecified target region, which is directly relevant to local regulatory decision-making. Cross-region differences can induce covariate shift, covariate mismatch, and outcome drift, potentially biasing information borrowing and invalidating RSATE inference. To address these issues, we develop a unified causal inference framework with selective information borrowing. First, we introduce an inverse-variance weighting estimator that combines a "small-sample, rich-covariate" target-only estimator with a "large-sample, limited-covariate" full-borrowing doubly robust estimator, maximizing efficiency under no outcome drift. Second, to accommodate outcome drift, we apply conformal prediction to assess patient-level comparability and adaptively select auxiliary-region patients for borrowing. Third, to ensure rigorous finite-sample inference, we employ a conditional randomization test with exact, model-free, selection-aware type I error control. Simulation studies show the proposed estimator improves efficiency, yielding 10-50% reductions in mean squared error and higher power relative to no-borrowing and full-borrowing approaches, while maintaining valid inference across diverse scenarios. An application to the POWER trial further demonstrates improved precision for RSATE estimation.

</details>


### [13] [Effect-Wise Inference for Smoothing Spline ANOVA on Tensor-Product Sobolev Space](https://arxiv.org/abs/2602.02753)
*Youngjin Cho,Meimei Liu*

Main category: stat.ME

TL;DR: 提出了一种在张量积Sobolev空间子空间上用于光滑样条ANOVA的效应-wise推断统一框架，实现了对主效应和交互效应的有效推断，并建立了收敛速率、置信区间和假设检验的理论基础。


<details>
  <summary>Details</summary>
Motivation: 现有方法在函数效应推断方面存在局限，无法有效处理交互效应或缺乏严格的理论基础，因此需要一个能同时支持效应-wise推断与理论保证的统一框架。

Method: 基于张量积Sobolev空间上的正交分解，发展了光滑样条ANOVA中效应子空间的正交分解方法，扩展了函数Bahadur表示框架，从而实现点wise置信区间和Wald型检验。

Result: 主效应达到最优一元收敛速率，交互效应达到最优速率至多差一个对数因子；模拟研究和对科罗拉多气温数据的应用显示该方法优于现有方法。

Conclusion: 所提出的框架为功能ANOVA中的效应-wise推断提供了坚实的理论基础和高效的实际性能，克服了现有方法的主要限制。

Abstract: Functional ANOVA provides a nonparametric modeling framework for multivariate covariates, enabling flexible estimation and interpretation of effect functions such as main effects and interaction effects. However, effect-wise inference in such models remains challenging. Existing methods focus primarily on inference for entire functions rather than individual effects. Methods addressing effect-wise inference face substantial limitations: the inability to accommodate interactions, a lack of rigorous theoretical foundations, or restriction to pointwise inference. To address these limitations, we develop a unified framework for effect-wise inference in smoothing spline ANOVA on a subspace of tensor product Sobolev space. For each effect function, we establish rates of convergence, pointwise confidence intervals, and a Wald-type test for whether the effect is zero, with power achieving the minimax distinguishable rate up to a logarithmic factor. Main effects achieve the optimal univariate rates, and interactions achieve optimal rates up to logarithmic factors. The theoretical foundation relies on an orthogonality decomposition of effect subspaces, which enables the extension of the functional Bahadur representation framework to effect-wise inference in smoothing spline ANOVA with interactions. Simulation studies and real-data application to the Colorado temperature dataset demonstrate superior performance compared to existing methods.

</details>


### [14] [Markov Random Fields: Structural Properties, Phase Transition, and Response Function Analysis](https://arxiv.org/abs/2602.02771)
*J. Brandon Carter,Catherine A. Calder*

Main category: stat.ME

TL;DR: 本文综述了用于分类数据的马尔可夫随机场（MRFs），重点是二值观测或潜在变量的模型，引入响应函数作为先验分析的统一工具，并通过案例研究说明不同MRF公式如何编码依赖关系。


<details>
  <summary>Details</summary>
Motivation: 探讨MRF在离散空间域中对空间依赖性的建模能力，特别是二元数据的情形，旨在澄清其结构特性并提供可用于模型解释与扩展的理论和工具。

Method: 通过回顾MRF的核心结构属性（如团块分解、条件独立性和邻域结构），引入响应函数这一新工具进行先验分析，并结合包含协变量的直接数据MRF模型案例研究来说明其应用。

Result: 揭示了不同MRF公式如何影响隐含的边际和联合分布，阐明了相变现象对统计推断的影响，并展示了响应函数在理解模型依赖结构中的有效性。

Conclusion: 响应函数为分析MRF提供了有力的统一框架，该研究不仅增强了对二元MRF的理解，也为更复杂的分类MRF建模提供了可扩展的原则和实践工具。

Abstract: This paper presents a focused review of Markov random fields (MRFs)--commonly used probabilistic representations of spatial dependence in discrete spatial domains--for categorical data, with an emphasis on models for binary-valued observations or latent variables. We examine core structural properties of these models, including clique factorization, conditional independence, and the role of neighborhood structures. We also discuss the phenomenon of phase transition and its implications for statistical model specification and inference. A central contribution of this review is the use of response functions, a unifying tool we introduce for prior analysis that provides insight into how different formulations of MRFs influence implied marginal and joint distributions. We illustrate these concepts through a case study of direct-data MRF models with covariates, highlighting how different formulations encode dependence. While our focus is on binary fields, the principles outlined here extend naturally to more complex categorical MRFs and we draw connections to these higher-dimensional modeling scenarios. This review provides both theoretical grounding and practical tools for interpreting and extending MRF-based models.

</details>


### [15] [Disentangling spatial interference and spatial confounding biases in causal inference](https://arxiv.org/abs/2602.02777)
*Isqeel Ogunsola,Olatunji Johnson*

Main category: stat.ME

TL;DR: 本文从有向无环图（DAG）视角澄清了空间混杂的误解，区分了直接与间接空间混杂及空间干扰，并在更一般的分布假设下推导了偏倚的解析表达式，通过模拟和实证研究验证了权重矩阵、暴露性质等对偏倚的影响。


<details>
  <summary>Details</summary>
Motivation: 解决观测性空间数据中因空间干扰和空间混杂导致的因果估计偏差问题，澄清现有文献中对空间混杂定义和解释的争议。

Method: 基于有向无环图（DAG）框架，区分直接与间接空间混杂及空间干扰；在非正态分布假设下（以泊松分布为例），推导空间混杂偏倚的解析表达式。

Result: 揭示了空间权重矩阵的选择、处理变量的分布以及干扰强度对空间干扰偏倚的重要影响；证明了直接与间接空间混杂可被分离，且权重矩阵和暴露性质决定间接偏倚的大小；仿真与实际数据分析支持理论结果。

Conclusion: 空间混杂和空间干扰可通过DAG框架清晰区分，其引起的偏倚受多种因素共同影响；未来将发展可同时调整这三类问题的参数化因果推断框架。

Abstract: Spatial interference and spatial confounding are two major issues inhibiting precise causal estimates when dealing with observational spatial data. Moreover, the definition and interpretation of spatial confounding remain arguable in the literature. In this paper, our goal is to provide clarity in a novel way on misconception and issues around spatial confounding from Directed Acyclic Graph (DAG) perspective and to disentangle both direct, indirect spatial confounding and spatial interference based on bias induced on causal estimates. Also, existing analyses of spatial confounding bias typically rely on Normality assumptions for treatments and confounders, assumptions that are often violated in practice. Relaxing these assumptions, we derive analytical expressions for spatial confounding bias under more general distributional settings using Poisson as example . We showed that the choice of spatial weights, the distribution of the treatment, and the magnitude of interference critically determine the extent of bias due to spatial interference. We further demonstrate that direct and indirect spatial confounding can be disentangled, with both the weight matrix and the nature of exposure playing central roles in determining the magnitude of indirect bias. Theoretical results are supported by simulation studies and an application to real-world spatial data. In future, parametric frameworks for concomitantly adjusting for spatial interference, direct and indirect spatial confounding for both direct and mediated effects estimation will be developed.

</details>


### [16] [A Model-Robust G-Computation Method for Analyzing Hybrid Control Studies Without Assuming Exchangeability](https://arxiv.org/abs/2602.02809)
*Zhiwei Zhang,Peisong Han,Wei Zhang*

Main category: stat.ME

TL;DR: 提出了一种模型稳健的g-计算方法，用于混合对照设计中的偏倚调整，该方法简单易行，在最小假设下具有一致性和渐近正态性，并能提高效率。


<details>
  <summary>Details</summary>
Motivation: 在混合对照设计中，尽管结合外部对照数据可提升效率，但存在引入偏倚的风险；现有方法依赖于可交换性假设，当该假设被违反时可能导致结果偏差，因此需要一种更稳健的方法来缓解此类问题。

Method: 采用一种特定版本的g-计算方法，结合变量选择，在结果回归模型可能误设的情况下仍保持稳健性，仅需最小假设即可实现一致估计和渐近正态性，并利用内部与外部对照组之间的相似性提升效率。

Result: 模拟研究表明该方法在多种场景下表现良好，实证分析使用HIV治疗试验的真实数据验证了其有效性与实用性。

Conclusion: 所提出的g-计算方法简单、稳健且高效，能够在不严格依赖模型正确设定的前提下有效调整混合对照研究中的偏倚，具有良好的应用前景。

Abstract: There is growing interest in a hybrid control design for treatment evaluation, where a randomized controlled trial is augmented with external control data from a previous trial or a real world data source. The hybrid control design has the potential to improve efficiency but also carries the risk of introducing bias. The potential bias in a hybrid control study can be mitigated by adjusting for baseline covariates that are related to the control outcome. Existing methods that serve this purpose commonly assume that the internal and external control outcomes are exchangeable upon conditioning on a set of measured covariates. Possible violations of the exchangeability assumption can be addressed using a g-computation method with variable selection under a correctly specified outcome regression model. In this article, we note that a particular version of this g-computation method is protected against misspecification of the outcome regression model. This observation leads to a model-robust g-computation method that is remarkably simple and easy to implement, consistent and asymptotically normal under minimal assumptions, and able to improve efficiency by exploiting similarities between the internal and external control groups. The method is evaluated in a simulation study and illustrated using real data from HIV treatment trials.

</details>


### [17] [Functional regression with multivariate responses](https://arxiv.org/abs/2602.02860)
*Ruiyan Luo,Xin Qi*

Main category: stat.ME

TL;DR: 本文研究了具有多变量响应和函数型预测变量的函数回归模型，提出了一种利用响应变量间相关性的新方法，并针对少量和大量预测变量分别设计了估计策略，尤其在高维情况下引入了同时实现平滑与稀疏的惩罚方法，提升了估计与预测精度，且提供了渐近理论支持。


<details>
  <summary>Details</summary>
Motivation: 为了提高估计和预测精度，充分利用响应变量之间的相关性以及函数型预测变量的信息，解决传统逐个拟合响应变量带来的效率损失问题。

Method: 通过识别系数函数在总体水平上的最优分解来改进预测；针对小规模和大规模函数型预测变量分别提出估计方法；在预测变量数量较大时，采用一种同时具有平滑和稀疏性质的联合惩罚方法进行变量选择与参数估计。

Result: 所提方法能够有效处理成千上万个函数型预测变量的情形，提高了估计与预测准确性；提供了当样本量和预测变量数量趋于无穷时的渐近理论结果；方法已实现于R语言包FRegSigCom中。

Conclusion: 利用响应变量间的相关性和最优系数分解可显著提升多变量函数回归的性能，所提出的方法在高维情形下兼具变量选择和平滑能力，具有良好的理论支持和实际应用价值。

Abstract: We consider the functional regression model with multivariate response and functional predictors. Compared to fitting each individual response variable separately, taking advantage of the correlation between the response variables can improve the estimation and prediction accuracy. Using information in both functional predictors and multivariate response, we identify the optimal decomposition of the coefficient functions for prediction in population level. Then we propose methods to estimate this decomposition and fit the regression model for the situations of a small and a large number $p$ of functional predictors separately. For a large $p$, we propose a simultaneous smooth-sparse penalty which can both make curve selection and improve estimation and prediction accuracy. We provide the asymptotic results when both the sample size and the number of functional predictors go to infinity. Our method can be applied to models with thousands of functional predictors and has been implemented in the R package FRegSigCom.

</details>


### [18] [Shiha Distribution: Statistical Properties and Applications to Reliability Engineering and Environmental Data](https://arxiv.org/abs/2602.02875)
*F. A. Shiha*

Main category: stat.ME

TL;DR: 提出了一种新的双参数Shiha分布，适用于具有重尾或轻尾的偏斜寿命数据建模，在可靠性工程等领域表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 为解决现有分布模型在拟合偏斜寿命数据时灵活性不足的问题，提出一种更灵活的新分布。

Method: 推导了Shiha分布的主要统计性质，包括矩生成函数、矩、风险率函数、分位数函数和熵，并以闭式形式得出应力-强度可靠性参数，通过模拟研究和实际数据应用评估性能。

Result: 模拟和多个真实数据集的应用结果表明，Shiha分布在拟合优度上始终优于已有的竞争模型。

Conclusion: Shiha分布是一种实用且有效的寿命数据分析工具，具有广泛的应用前景。

Abstract: This paper introduces a new two-parameter distribution, referred to as the Shiha distribution, which provides a flexible model for skewed lifetime data with either heavy or light tails. The proposed distribution is applicable to various fields, including reliability engineering, environmental studies, and related areas. We derive its main statistical properties, including the moment generating function, moments, hazard rate function, quantile function, and entropy. The stress--strength reliability parameter is also derived in closed form. A simulation study is conducted to evaluate its performance. Applications to several real data sets demonstrate that the Shiha distribution consistently provides a superior fit compared with established competing models, confirming its practical effectiveness for lifetime data analysis.

</details>


### [19] [Weighted Sum-of-Trees Model for Clustered Data](https://arxiv.org/abs/2602.02931)
*Kevin McCoy,Zachary Wooten,Katarzyna Tomczak,Christine B. Peterson*

Main category: stat.ME

TL;DR: 提出一种轻量级的树集成模型，为每个样本组学习一个决策树，并通过加权组合预测结果，使对新组的预测更贴近训练数据中相似组的结果，同时支持跨组模型相似性推断。


<details>
  <summary>Details</summary>
Motivation: 现有混合模型方法在处理组间嵌套数据时，对外部组预测仅依赖全局固定效应，忽略了组间的异质性，限制了预测性能和模型解释能力。

Method: 构建一种基于树的模型，为每个样本组单独学习决策树，并通过组间相似性加权组合各树预测结果，实现对未见组的有效预测和组间结构比较。

Result: 在多种模拟场景下，该模型优于传统决策树和随机森林；在TCGA肉瘤队列数据上验证了其实际应用效果。

Conclusion: 所提方法能更准确地对未见组进行预测，并可解释组间差异，适用于具有群集结构的复杂生物医学数据。

Abstract: Clustered data, which arise when observations are nested within groups, are incredibly common in clinical, education, and social science research. Traditionally, a linear mixed model, which includes random effects to account for within-group correlation, would be used to model the observed data and make new predictions on unseen data. Some work has been done to extend the mixed model approach beyond linear regression into more complex and non-parametric models, such as decision trees and random forests. However, existing methods are limited to using the global fixed effects for prediction on data from out-of-sample groups, effectively assuming that all clusters share a common outcome model. We propose a lightweight sum-of-trees model in which we learn a decision tree for each sample group. We combine the predictions from these trees using weights so that out-of-sample group predictions are more closely aligned with the most similar groups in the training data. This strategy also allows for inference on the similarity across groups in the outcome prediction model, as the unique tree structures and variable importances for each group can be directly compared. We show our model outperforms traditional decision trees and random forests in a variety of simulation settings. Finally, we showcase our method on real-world data from the sarcoma cohort of The Cancer Genome Atlas, where patient samples are grouped by sarcoma subtype.

</details>


### [20] [Empirical Bayes Shrinkage of Functional Effects, with Application to Analysis of Dynamic eQTLs](https://arxiv.org/abs/2602.03077)
*Ziang Zhang,Peter Carbonetto,Matthew Stephens*

Main category: stat.ME

TL;DR: 本文提出了功能自适应收缩（FASH）方法，一种基于经验贝叶斯的联合分析框架，用于在连续条件变量下估计效应函数，适用于动态eQTL研究等场景。


<details>
  <summary>Details</summary>
Motivation: 受动态表达数量性状位点（eQTL）研究的启发，旨在刻画基因对表达的影响如何随时间或连续条件变化。

Method: 将基于线性微分算子定义的高斯过程族融入经验贝叶斯收缩框架，实现跨观测单元的信息共享与自适应平滑。

Result: FASH提高了效应函数的估计精度，支持局部假发现率和假符号率等显著性度量计算，并通过先验调整方法保证推断的保守性；在心肌细胞分化数据中识别出新的动态eQTL，展现出更多样化的时间模式和更高检测效能。

Conclusion: FASH为功能性数据的联合分析提供了灵活且可扩展的统计框架，不仅适用于基因组学，还可推广至其他领域，并配有R软件包便于应用。

Abstract: We introduce functional adaptive shrinkage (FASH), an empirical Bayes method for joint analysis of observation units in which each unit estimates an effect function at several values of a continuous condition variable. The ideas in this paper are motivated by dynamic expression quantitative trait locus (eQTL) studies, which aim to characterize how genetic effects on gene expression vary with time or another continuous condition. FASH integrates a broad family of Gaussian processes defined through linear differential operators into an empirical Bayes shrinkage framework, enabling adaptive smoothing and borrowing of information across units. This provides improved estimation of effect functions and principled hypothesis testing, allowing straightforward computation of significance measures such as local false discovery and false sign rates. To encourage conservative inferences, we propose a simple prior- adjustment method that has theoretical guarantees and can be more broadly used with other empirical Bayes methods. We illustrate the benefits of FASH by reanalyzing dynamic eQTL data on cardiomyocyte differentiation from induced pluripotent stem cells. FASH identified novel dynamic eQTLs, revealed diverse temporal effect patterns, and provided improved power compared with the original analysis. More broadly, FASH offers a flexible statistical framework for joint analysis of functional data, with applications extending beyond genomics. To facilitate use of FASH in dynamic eQTL studies and other settings, we provide an accompanying R package at https: //github.com/stephenslab/fashr.

</details>


### [21] [Entropic Mirror Monte Carlo](https://arxiv.org/abs/2602.03165)
*Anas Cherradi,Yazid Janati,Alain Durmus,Sylvain Le Corff,Yohan Petetin,Julien Stoehr*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Importance sampling is a Monte Carlo method which designs estimators of expectations under a target distribution using weighted samples from a proposal distribution. When the target distribution is complex, such as multimodal distributions in highdimensional spaces, the efficiency of importance sampling critically depends on the choice of the proposal distribution. In this paper, we propose a novel adaptive scheme for the construction of efficient proposal distributions. Our algorithm promotes efficient exploration of the target distribution by combining global sampling mechanisms with a delayed weighting procedure. The proposed weighting mechanism plays a key role by enabling rapid resampling in regions where the proposal distribution is poorly adapted to the target. Our sampling algorithm is shown to be geometrically convergent under mild assumptions and is illustrated through various numerical experiments.

</details>


### [22] [Blinded sample size re-estimation accounting for uncertainty in mid-trial estimation](https://arxiv.org/abs/2602.03218)
*Hirotada Maeda,Satoshi Hattori,Tim Friede*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: For randomized controlled trials to be conclusive, it is important to set the target sample size accurately at the design stage. Comparing two normal populations, the sample size calculation requires specification of the variance other than the treatment effect and misspecification can lead to underpowered studies. Blinded sample size re-estimation is an approach to minimize the risk of inconclusive studies. Existing methods proposed to use the total (one-sample) variance that is estimable from blinded data without knowledge of the treatment allocation. We demonstrate that, since the expectation of this estimator is greater than or equal to the true variance, the one-sample variance approach can be regarded as providing an upper bound of the variance in blind reviews. This worst-case evaluation can likely reduce a risk of underpowered studies. However, blinded reviews of small sample size may still lead to underpowered studies. We propose a refined method accounting for estimation error in blind reviews using an upper confidence limit of the variance. A similar idea had been proposed in the setting of external pilot studies. Furthermore, we developed a method to select an appropriate confidence level so that the re-estimated sample size attains the target power. Numerical studies showed that our method works well and outperforms existing methods. The proposed procedure is motivated and illustrated by recent randomized clinical trials.

</details>


### [23] [Kriging for large datasets via penalized neighbor selection](https://arxiv.org/abs/2602.03483)
*Francisco Cuevas-Pacheco,Jonathan Acosta*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Kriging is a fundamental tool for spatial prediction, but its computational complexity of $O(N^3)$ becomes prohibitive for large datasets. While local kriging using $K$-nearest neighbors addresses this issue, the selection of $K$ typically relies on ad-hoc criteria that fail to account for spatial correlation structure. We propose a penalized kriging framework that incorporates LASSO-type penalties directly into the kriging equations to achieve automatic, data-driven neighbor selection. We further extend this to adaptive LASSO, using data-driven penalty weights that account for the spatial correlation structure. Our method determines which observations contribute non-zero weights through $\ell_1$ regularization, with the penalty parameter selected via a novel criterion based on effective sample size that balances prediction accuracy against information redundancy. Numerical experiments demonstrate that penalized kriging automatically adapts neighborhood structure to the underlying spatial correlation, selecting fewer neighbors for smoother processes and more for highly variable fields, while maintaining prediction accuracy comparable to global kriging at substantially reduced computational cost.

</details>


### [24] [Simulation-Based Inference via Regression Projection and Batched Discrepancies](https://arxiv.org/abs/2602.03613)
*Arya Farahi,Jonah Rose,Paul Torrey*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We analyze a lightweight simulation-based inference method that infers simulator parameters using only a regression-based projection of the observed data. After fitting a surrogate linear regression once, the procedure simulates small batches at the proposed parameter values and assigns kernel weights based on the resulting batch-residual discrepancy, producing a self-normalized pseudo-posterior that is simple, parallelizable, and requires access only to the fitted regression coefficients rather than raw observations. We formalize the construction as an importance-sampling approximation to a population target that averages over simulator randomness, prove consistency as the number of parameter draws grows, and establish stability in estimating the surrogate regression from finite samples. We then characterize the asymptotic concentration as the batch size increases and the bandwidth shrinks, showing that the pseudo-posterior concentrates on an identified set determined by the chosen projection, thereby clarifying when the method yields point versus set identification. Experiments on a tractable nonlinear model and on a cosmological calibration task using the DREAMS simulation suite illustrate the computational advantages of regression-based projections and the identifiability limitations arising from low-information summaries.

</details>


### [25] [Bayesian variable and hazard structure selection in the General Hazard model](https://arxiv.org/abs/2602.03756)
*Yulong Chen,Jim Griffin,Francisco Javier Rubio*

Main category: stat.ME

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The proportional hazards (PH) and accelerated failure time (AFT) models are the most widely used hazard structures for analysing time-to-event data. When the goal is to identify variables associated with event times, variable selection is typically performed within a single hazard structure, imposing strong assumptions on how covariates affect the hazard function. To allow simultaneous selection of relevant variables and the hazard structure itself, we develop a Bayesian variable selection approach within the general hazard (GH) model, which includes the PH, AFT, and other structures as special cases. We propose two types of g-priors for the regression coefficients that enable tractable computation and show that both lead to consistent model selection. We also introduce a hierarchical prior on the model space that accounts for multiplicity and penalises model complexity. To efficiently explore the GH model space, we extend the Add-Delete-Swap algorithm to jointly sample variable inclusion indicators and hazard structures. Simulation studies show accurate recovery of both the true hazard structure and active variables across different sample sizes and censoring levels. Two real-data applications are presented to illustrate the use of the proposed methodology and to compare it with existing variable selection methods.

</details>


<div id='q-fin.CP'></div>

# q-fin.CP [[Back]](#toc)

### [26] [DiffLOB: Diffusion Models for Counterfactual Generation in Limit Order Books](https://arxiv.org/abs/2602.03776)
*Zhuohan Wang,Carmine Ventre*

Main category: q-fin.CP

TL;DR: 提出DiffLOB，一种基于未来市场状态调节的扩散模型，用于可控且符合反事实的限价订单簿（LOB）轨迹生成，支持压力测试与情景分析。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型无法主动应对假设性市场条件变化，限制了其在压力测试和决策中的应用。

Method: 设计一个以未来市场状态（如趋势、波动率、流动性等）为条件的扩散模型DiffLOB，实现对LOB轨迹的可控生成，并构建系统性评估框架验证其反事实能力。

Result: 实验表明DiffLOB在可调控真实性、反事实有效性和实用性三方面均表现良好，能准确反映不同市场状态下的LOB动态变化，并提升对未来市场状态的预测能力。

Conclusion: DiffLOB为金融市场提供了首个支持反事实推理的LOB生成模型，增强了生成模型在金融决策与风险分析中的实用性。

Abstract: Modern generative models for limit order books (LOBs) can reproduce realistic market dynamics, but remain fundamentally passive: they either model what typically happens without accounting for hypothetical future market conditions, or they require interaction with another agent to explore alternative outcomes. This limits their usefulness for stress testing, scenario analysis, and decision-making. We propose \textbf{DiffLOB}, a regime-conditioned \textbf{Diff}usion model for controllable and counterfactual generation of \textbf{LOB} trajectories. DiffLOB explicitly conditions the generative process on future market regimes--including trend, volatility, liquidity, and order-flow imbalance, which enables the model to answer counterfactual queries of the form: ``If the future market regime were X instead of Y, how would the limit order book evolve?'' Our systematic evaluation framework for counterfactual LOB generation consists of three criteria: (1) \textit{Controllable Realism}, measuring how well generated trajectories can reproduce marginal distributions, temporal dependence structure and regime variables; (2) \textit{Counterfactual validity}, testing whether interventions on future regimes induce consistent changes in the generated LOB dynamics; (3) \textit{Counterfactual usefulness}, assessing whether synthetic counterfactual trajectories improve downstream prediction of future market regimes.

</details>


<div id='physics.ao-ph'></div>

# physics.ao-ph [[Back]](#toc)

### [27] [The Design and Performance of Meteorological Sensors for WindBorne Global Sounding Balloons](https://arxiv.org/abs/2602.02714)
*Jake Spisak,Christopher P. Riedel,Andrey Sushko,Michal Adamkiewicz,Joan Creus-Costa,John Dean,Jacob Radford,F. Martin Ralph,Larissa Reames,Anna M. Wilson,Subin Yoon,Vijay Tallapragada,Todd Hutchinson*

Main category: physics.ao-ph

TL;DR: WindBorne Systems开发了长航时大气气球星座，用于全球气象数据收集，具备高精度传感器和快速数据传输能力，已通过与探空仪和再分析数据的对比验证其准确性。


<details>
  <summary>Details</summary>
Motivation: 填补现有原位气象数据采集方法的空白，提供长期、全球覆盖的高质量气象观测数据。

Method: 利用Global Sounding Balloon（GSB）搭载定制化传感器套件，进行长时间飞行并多次开展大气探测，测量压力、温度、湿度及风速等参数，并通过卫星传回数据；采用自定义读出架构和防护外壳以减少偏差和噪声，结合内部校准和数据处理流程优化。

Result: 传感器套件已在数千次飞行中累计超过一百万小时运行；与探空仪对比显示在预期不确定度范围内一致；与ERA5再分析数据对比的均方根差异为：位势高度14米、气压0.36 hPa、气温0.91 K、纬向风速2.45 m/s、经向风速2.50 m/s、相对湿度13%。

Conclusion: 该气球系统及其传感器包能够稳定、准确地收集全球气象数据，具有较高的数据质量和业务应用潜力。

Abstract: WindBorne Systems has developed a constellation of long-duration atmospheric balloons to collect meteorological data across the globe, filling gaps in current in-situ data collection methods. Each Global Sounding Balloon (GSB) is capable of flying for weeks or months and performing dozens of soundings while measuring pressure, temperature, humidity, and GNSS-derived position, altitude, and wind velocity. This data is transmitted to ground via satellite, processed, and made available within minutes of being collected. The current meteorological sensor package has remained largely unchanged since mid-2024 and has flown on thousands of GSBs totaling over one million hours of flight time. Here we present the design and performance of this sensor package. The custom readout architecture and housing allow for data collection across nearly all in-flight conditions while minimizing sources of bias and noise. Uncertainty is characterized via sounding reproducibility studies and in-house calibration of pressure, humidity, and temperature sensors. The calibration and data processing procedures have been optimized and validated by comparison with external datasets. We present external validation in the form of 1) side-by-side radiosonde launches performed in collaboration with the Center for Western Weather and Water Extremes at the Scripps Institution of Oceanography, which show agreement within expected uncertainty limits, and 2) intercomparison studies with European Centre for Medium-Range Weather Forecasts Reanalysis v5, which show an aggregate root mean square difference of: Geopotential height -- 14 m; Pressure -- 0.36 hPa; Temperature -- 0.91 K; Wind speed u -- 2.45 m/s; Wind speed v -- 2.50 m/s; Relative humidity -- 13%.

</details>


### [28] [Addressing the World War 2 Warm Anomaly in HadSST.4.2.0.0](https://arxiv.org/abs/2602.03347)
*Caroline Sandford,Nick Rayner*

Main category: physics.ao-ph

TL;DR: 更新了Hadley中心海表温度数据集（HadSST.4.2.0.0），通过引入发动机室进水口偏差修正和日本神户数据截断偏差修正，消除了二战期间的异常偏暖信号，同时保持了数据集的物理合理性与独立性。


<details>
  <summary>Details</summary>
Motivation: 解决HadSST4数据集中存在的二战期间残余偏暖偏差问题，提升历史海温记录的准确性。

Method: 基于已有的二战偏暖异常定量定义，识别发动机室进水口（ERI）偏差为主要因素，提出1950年前ERI偏差估计的新约束，并对日本神户观测数据中的截断偏差进行修正。

Result: 成功消除了HadSST中的二战暖偏差，修正后的数据与其他最新海温数据集（如ERSSTv6、COBE-SST3、DCENT）具有更好一致性，同时保持了与陆地温度记录的独立性。

Conclusion: 该更新通过物理机制驱动的修正方法提升了历史海温数据的可靠性，增强了HadSST在气候变化研究中的适用性，并维护了全球海温数据集间的结构多样性。

Abstract: We present an update to the Hadley Centre Sea-Surface Temperature dataset (HadSST.4.2.0.0) that addresses residual warm bias during the Second World War (WW2). Using an existing quantitative definition of the WW2 warm anomaly we identify Engine Room Intake (ERI) bias corrections as the dominant factor in this warm bias in HadSST4, and use this to propose new constraints on ERI bias estimates prior to 1950. In addition, we implement corrections for truncation bias in observations from the Japanese Kobe Collection, spanning the period from 1933 to 1961. We evaluate the effects of these changes with respect to the previous version of HadSST and compare with the most recent iterations of other SST datasets including ERSSTv6, COBE-SST3 and DCENT. We show that it is possible to remove the WW2 warm anomaly using a physically-based approach that maintains the independence of HadSST from land surface temperature records, and preserves structural diversity within the range of available global SST datasets.

</details>


<div id='cond-mat.dis-nn'></div>

# cond-mat.dis-nn [[Back]](#toc)

### [29] [Quantum criticality at strong randomness: a lesson from anomaly](https://arxiv.org/abs/2602.02648)
*Yasamin Panahi,Subhayan Sahu,Naren Manjunath,Chong Wang*

Main category: cond-mat.dis-nn

TL;DR: 本文提出了一种基于平均对称性和反常的新方法，用于预测强无序系统中的量子临界行为，并在多个已知模型中验证了该理论，揭示了以往被忽视的临界关联现象。


<details>
  <summary>Details</summary>
Motivation: 研究在强淬火无序存在下的量子临界性是一个难题，尤其是在平均对称性作用下，传统方法难以预测普适性质。因此，作者试图利用拓扑与反常来揭示此类系统的普遍行为。

Method: 通过引入平均对称性相关的拓扑和反常概念，结合平均Lieb-Schultz-Mattis约束，分析系统在无自发对称性破缺时的关联行为，并在随机单重态海森堡自旋链和BDI类无序自由费米子体系中进行验证。

Result: 发现即使在没有自发对称性破缺的情况下，系统仍会表现出两种缓慢衰减的临界关联：一是针对精确对称性荷载算符的绝对值关联，二是针对平均对称性荷载算符的一阶矩关联；这些关联在已有文献中被忽略。

Conclusion: 平均对称性所导致的拓扑与反常能够有效预测强无序系统中的非平庸普适性质，为理解无序量子临界提供了新视角，并具有实验观测的可能性。

Abstract: Quantum criticality in the presence of strong quenched randomness remains a challenging topic in modern condensed matter theory. We show that the topology and anomaly associated with average symmetry can be used to predict certain nontrivial universal properties. Our focus is on systems subject to average Lieb--Schultz--Mattis constraints, where lattice translation symmetry is preserved only on average, while on-site symmetries remain exact. We argue that in the absence of spontaneous symmetry breaking, the system must exhibit critical correlations of local operators in two distinct ways: (i) for some operator $O_e$ charged under exact symmetries, the first absolute moment correlation $\overline{|\langle O_e(x)O^{\dagger}_e(y)\rangle|}$ decays slowly; and (ii) for some operator $O_a$ charged under average symmetries, the first-moment correlation $\overline{\langle O_a(x)O^{\dagger}_a(y)\rangle}$ decays slowly. We verify these predictions in a few examples: the random-singlet Heisenberg spin chain in one dimension, and the disordered free-fermion critical states in symmetry class BDI in one and two dimensions. Surprisingly, even for these well-studied systems, our anomaly-based argument reveals critical correlations overlooked in previous literature. We also discuss the experimental feasibility of measuring these critical correlations.

</details>


### [30] [Long-range spin glass in a field at zero temperature](https://arxiv.org/abs/2602.03488)
*Maria Chiara Angelini,Saverio Palazzi,Giorgio Parisi,Tommaso Rizzo*

Main category: cond-mat.dis-nn

TL;DR: 通过在Bethe M层框架内引入新的环展开方法，计算了一维长程模型在磁场中零温自旋玻璃相变的临界指数，为数值模拟提供了关键基准。


<details>
  <summary>Details</summary>
Motivation: 为了研究自旋玻璃在磁场中的相变行为，并为高维系统的理解提供线索。

Method: 采用Bethe M层形式体系内的新型环展开方法，在一维长程模型上计算临界指数。

Result: 得到了零温自旋玻璃在磁场中相变的临界指数的估计值，可用于指导和验证更大系统尺寸的数值模拟。

Conclusion: 该理论方法为测试自旋玻璃在磁场中的理论提供了重要基准，有助于推动对高维自旋玻璃系统的研究。

Abstract: We compute the critical exponents of the zero-temperature spin glass transition in a field on a one-dimensional long-range model, a proxy for higher-dimensional systems. Our approach is based on a novel loop expansion within the Bethe $M$-layer formalism, whose adaptation to this specific case is detailed here. The resulting estimates provide crucial benchmarks for numerical simulations that can access larger system sizes in one dimension, thus offering a key test of the theory of spin glasses in a field.

</details>


<div id='physics.hist-ph'></div>

# physics.hist-ph [[Back]](#toc)

### [31] [A third law of thermodynamics is an unnecessary complexity](https://arxiv.org/abs/2602.03244)
*José-María Martín-Olalla*

Main category: physics.hist-ph

TL;DR: 本文通过重新审视能斯特-爱因斯坦争论，论证了能斯特热定理在逻辑上是冗余的，第三定律并非独立公设，而是第二定律的必然推论。


<details>
  <summary>Details</summary>
Motivation: 澄清第二定律与第三定律之间的逻辑关系，挑战传统上将第三定律视为独立物理定律的观点。

Method: 采用历史分析与逻辑推理相结合的方法，回顾能斯特-爱因斯坦之争，剖析传统观点所依赖的假设。

Result: 证明了第二定律已足以排除在绝对零度进行循环过程的可能性，因而第三定律作为独立公设是不必要的。

Conclusion: 能斯特定理应被视为一种一致性调节机制，而非独立的物理发现，其作用在于确保热力学体系内部逻辑自洽。

Abstract: This paper elaborates on the implications of the relationship between the Second and Third Laws and provides a comprehensive formal and historical justification for the logical redundancy of the Nernst heat theorem. By revisiting the Nernst-Einstein debate, the underlying hypotheses that lead to the traditional view of the Third Law as an independent postulate are examined. It is argued that the historical rejection of Nernst's proof -- motivated by Einstein's insistence on the practical non-performability of cycles at absolute zero -- overlooks the fact that a universal Second Law already precludes such cycles, rendering an independent Third Law an unnecessary complexity. Ultimately, the Nernst theorem is shown to be an essential consistency regulator rather than an independent physical discovery.

</details>


<div id='eess.SY'></div>

# eess.SY [[Back]](#toc)

### [32] [Estimation of Cell-to-Cell Variation and State of Health for Battery Modules with Parallel-Connected Cells](https://arxiv.org/abs/2602.02866)
*Qinan Zhou,Jing Sun*

Main category: eess.SY

TL;DR: 提出了一种统一框架，仅利用模块级信号准确估计并联电池模块的单体间差异（CtCV）和健康状态（SoH），具有高精度、低计算复杂度和良好的通用性。


<details>
  <summary>Details</summary>
Motivation: 在只能获取模块级信号而无法观测单体行为的情况下，现有方法难以准确估计并联电池组的单体间差异（CtCV）和健康状态（SoH），尤其是CtCV的估计尚未解决。

Method: 通过增量容量分析（ICA）和微分电压分析（DVA）提取模块级特征，将CtCV与SoH估计解耦为两个独立任务，分别采用专用算法处理，并设计通用框架以适配多种CtCV指标。

Result: 实验验证表明，该框架能系统性选择最优特征，在不同充放电倍率下均能实现高置信度、低计算成本的CtCV和SoH估计，且适用于车载应用。

Conclusion: 所提框架有效解决了仅依赖模块级信号时对并联电池组CtCV和SoH联合估计的难题，具备良好的实用性与推广价值。

Abstract: Estimating cell-to-cell variation (CtCV) and state of health (SoH) for battery modules with parallel-connected cells is challenging when only module-level signals are measurable and individual cell behaviors remain unobserved. Although progress has been made in SoH estimation, CtCV estimation remains unresolved in the literature. This paper proposes a unified framework that accurately estimates both CtCV and SoH for modules using only module-level information extracted from incremental capacity analysis (ICA) and differential voltage analysis (DVA). With the proposed framework, CtCV and SoH estimations can be decoupled into two separate tasks, allowing each to be solved with dedicated algorithms without mutual interference and providing greater design flexibility. The framework also exhibits strong versatility in accommodating different CtCV metrics, highlighting its general-purpose nature. Experimental validation on modules with three parallel-connected cells demonstrates that the proposed framework can systematically select optimal module-level features for CtCV and SoH estimations, deliver accurate CtCV and SoH estimates with high confidence and low computational complexity, remain effective across different C-rates, and be suitable for onboard implementation.

</details>


### [33] [Hybrid-Field Channel Estimation for XL-MIMO Systems: Dictionary-based Sparse Signal Recovery](https://arxiv.org/abs/2602.02942)
*David William Marques Guerra,Taufik Abrao*

Main category: eess.SY

TL;DR: 本文提出了一种无需先验稀疏性知识的混合场信道估计方法，通过联合远场和近场字典及残差停止准则，实现对超大规模MIMO系统中信道的高效准确重建。


<details>
  <summary>Details</summary>
Motivation: 由于超大规模MIMO系统的阵列孔径极大，导致传播环境进入混合场区域，传统仅基于远场或近场模型的方法不再适用，因此需要一种能同时处理远场平面波和近场球面波共存的信道估计方法。

Method: 提出了一种统一的混合场信道模型，将远场与近场分量根据瑞利距离边界叠加，并利用信道在角度域和极化域的稀疏性，将其建模为稀疏恢复问题；采用联合字典初始化支持集，通过残差为基础的停止规则自适应确定路径数量，并对每个选中的原子进行连续参数精炼以缓解网格失配。

Result: 仿真结果表明，所提方法在视距和非视距条件下均能准确重建混合场信道，且不依赖于稀疏度L和近远场比例γ等先验信息。

Conclusion: 该方法为超大规模MIMO系统提供了一种实用且计算高效的混合场信道估计解决方案，具有良好的鲁棒性和应用前景。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems are a key technology for future wireless networks, but the large array aperture naturally creates a hybrid-field (HF) propagation regime in which far-field (FF) planar-wave and near-field (NF) spherical-wave components coexist. This work considers the problem of HF channel estimation (CE) and introduces a unified model that superimposes FF and NF contributions according to the Rayleigh distance boundary. By exploiting the inherent sparsity of the channel in the angular and polar domains, we formulate the estimation task as a sparse recovery problem. Unlike conventional approaches that require prior knowledge of the channel sparsity level, the proposed method operates without requiring knowledge of the sparsity level L and the NF/FF ratio γ, which are used only for synthetic channel generation in simulations. The channel estimator determines the number of paths adaptively through a residual-based stopping rule. A combined FF/NF dictionary is employed to initialize the support, and each selected atom undergoes continuous parameter refinement to mitigate grid mismatch. Simulation results demonstrate that the proposed estimator achieves accurate HF channel reconstruction under both line-of-sight (LoS) and non-line-of-sight (NLoS) conditions, offering a practical and computationally efficient solution for XL-MIMO systems.
  Extremely Large-Scale MIMO (XL-MIMO); Channel State Information (CSI); Channel estimation (CE); hybrid-field (HF) wave propagation; near-field (NF) spherical wave model; far-field (FF) planar wave model

</details>


### [34] [Fast Diffusion with Physics-Correction for ACOPF](https://arxiv.org/abs/2602.03020)
*Shashank Shekhar,Abhinav Karn,Kris Keshav,Shivam Bansal,Parikshit Pareek*

Main category: eess.SY

TL;DR: 提出一种基于DDIM的快速扩散框架，结合物理引导校正，显著提升ACOPF数据集生成速度，同时保持良好的统计准确性和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型生成ACOPF数据虽质量高，但采样慢，难以大规模应用；需在保证物理一致性的前提下提高生成效率。

Method: 采用Denoising Diffusion Implicit Models (DDIM)，在采样过程中引入物理引导校正，用少量确定性步骤替代缓慢的随机优化，并通过显式约束引导提升初始化质量。

Result: 在IEEE 6、24和118节点系统上实验表明，新方法比标准扩散模型快20倍，同时保持相当的统计精度和物理一致性。

Conclusion: 该方法适合用于可扩展的OPF数据生成和实际电力系统学习任务，兼顾速度与质量。

Abstract: Generating large-scale, physically consistent AC Optimal Power Flow (ACOPF) datasets is essential for modern data-driven power system applications. The central challenge lies in balancing solution accuracy with computational efficiency. Recent diffusion-based generative models produce high-quality samples; however, their slow sampling procedures limit practical scalability. In this work, we argue that exact physical feasibility is ultimately enforced by power flow solvers or projection steps, and therefore the generative model only needs to produce good initializations rather than perfectly feasible solutions. Based on this insight, we propose a fast diffusion framework using Denoising Diffusion Implicit Models (DDIM) combined with physics-guided corrections during sampling. The proposed method replaces slow stochastic refinement with a small number of deterministic steps and explicit constraint guidance. Experiments on IEEE 6-, 24-, and 118-bus systems show that our approach achieves up to 20 times faster sampling than standard diffusion models while maintaining comparable statistical accuracy and physical consistency. This makes the method well suited for scalable OPF dataset generation and practical power system learning tasks. We release the implementation code at https://github.com/PSquare-Lab/DDIM_OPF.

</details>


### [35] [ProOPF: Benchmarking and Improving LLMs for Professional-Grade Power Systems Optimization Modeling](https://arxiv.org/abs/2602.03070)
*Chao Shen,Zihan Guo,Xu Wan,Zhenghao Yang,Yifan Zhang,Wengi Huang,Jie Song,Zongyan Zhang,Mingyang Sun*

Main category: eess.SY

TL;DR: 本文提出了ProOPF-D和ProOPF-B，一个用于专业级最优潮流（OPF）建模的数据集和基准，旨在评估大型语言模型在电力系统中将自然语言操作需求转化为可执行优化模型的能力。


<details>
  <summary>Details</summary>
Motivation: 随着可再生能源渗透率的增加，电力系统运行中的不确定性加大，需要频繁调整调度目标和约束条件，这对依赖专家知识的实时建模工作流构成了挑战。因此，研究如何利用大型语言模型自动化这一过程具有重要意义。

Method: 构建了一个包含12,000个实例的数据集ProOPF-D，每个实例将自然语言请求与标准最优潮流模型的参数调整和结构扩展相对应，并提供可执行代码；同时建立了一个包含121个专家标注测试用例的基准ProOPF-B，支持在具体和抽象两种模式下进行端到端评估。

Result: 提供了首个针对电力系统最优潮流建模的大型语言模型评测数据集与基准，能够有效评估模型在专业场景下的语义理解与代码生成能力。

Conclusion: ProOPF-D和ProOPF-B为评估大型语言模型在复杂电力系统优化任务中的应用提供了坚实基础，推动了自动化建模在电力系统运行中的发展。

Abstract: Growing renewable penetration introduces substantial uncertainty into power system operations, necessitating frequent adaptation of dispatch objectives and constraints and challenging expertise-intensive, near-real-time modeling workflows. Large Language Models (LLMs) provide a promising avenue for automating this process by translating natural-language (NL) operational requirements into executable optimization models via semantic reasoning and code synthesis. Yet existing LLM datasets and benchmarks for optimization modeling primarily target coarse-grained cross-domain generalization, offering limited, rigorous evaluation in power-system settings, particularly for Optimal Power Flow (OPF). We therefore introduce \textbf{ProOPF-D} and \textbf{ProOPF-B}, a dataset and benchmark for professional-grade OPF modeling: ProOPF-D contains 12K instances pairing NL requests with parameter adjustments and structural extensions to a canonical OPF, together with executable implementations; ProOPF-B provides 121 expert-annotated test cases with ground-truth code, enabling end-to-end evaluation under both concrete and abstract OPF modeling regimes.

</details>


### [36] [Power Reserve Procurement Considering Dependent Random Variables with PCE](https://arxiv.org/abs/2602.03272)
*Nicola Ramseyer,Matthieu Jacobs,Mario Paolone*

Main category: eess.SY

TL;DR: 提出了一种基于广义多项式混沌和高斯copula的依赖随机变量建模方法，用于机会约束优化，并应用于电力备用采购问题。


<details>
  <summary>Details</summary>
Motivation: 为了更准确地处理具有复杂依赖关系的随机变量，在机会约束优化中建模联合分布的需求。

Method: 使用广义多项式混沌展开结合高斯copula构造联合分布，利用问题结构设计合适的变换以保证计算可行性。

Result: 在电力备用采购问题中验证了该方法的有效性，相比独立变量假设的标准方法，能更好地捕捉变量间的依赖关系。

Conclusion: 所提方法能够有效建模随机输入间的任意依赖关系，提升机会约束优化问题的建模精度和实用性。

Abstract: This paper presents an approach for the modelling of dependent random variables using generalised polynomial chaos. This allows to write chance-constrained optimization problems with respect to a joint distribution modelling dependencies between different stochastic inputs. Arbitrary dependencies are modelled by using Gaussian copulas to construct the joint distribution. The paper exploits the problem structure and develops suitable transformations to ensure tractability. The proposed method is applied to a probabilistic power reserve procurement problem. The effectiveness of the method to capture dependencies is shown by comparing the approach with a standard approach considering independent random variables.

</details>


### [37] [When control meets large language models: From words to dynamics](https://arxiv.org/abs/2602.03433)
*Komeil Nosrati,Aleksei Tepljakov,Juri Belikov,Eduard Petlenkov*

Main category: eess.SY

TL;DR: 本文探讨了大语言模型（LLM）与控制理论之间的双向互动关系，提出LLM既可助力控制系统设计，也可通过控制方法实现自身行为调控，构建了一个从提示工程到系统动态的连续框架。


<details>
  <summary>Details</summary>
Motivation: 随着LLM在工程和技术中日益重要，其本身也成为了需要被调控的复杂动态系统，因此需要建立LLM与控制理论之间的双向协同机制，以提升LLM的可控性与可靠性。

Method: 将LLM与控制理论结合，从四个方面进行分析：LLM辅助控制器设计、增强研究流程、利用控制方法优化LLM输入与内部状态，以及将LLM建模为具有外部控制回路的状态空间系统。

Result: 提出了一个LLM与控制双向融合的框架，展示了控制理论如何提升LLM的对齐性与可达性，同时展示了LLM如何推动控制系统的智能化发展。

Conclusion: LLM与控制理论的深度融合有助于构建更可解释、可控且可靠的智能系统，未来应进一步探索其动态特性，使LLM像传统机电系统一样安全可信。

Abstract: While large language models (LLMs) are transforming engineering and technology through enhanced control capabilities and decision support, they are simultaneously evolving into complex dynamical systems whose behavior must be regulated. This duality highlights a reciprocal connection in which prompts support control system design while control theory helps shape prompts to achieve specific goals efficiently. In this study, we frame this emerging interconnection of LLM and control as a bidirectional continuum, from prompt design to system dynamics. First, we investigate how LLMs can advance the field of control in two distinct capacities: directly, by assisting in the design and synthesis of controllers, and indirectly, by augmenting research workflows. Second, we examine how control concepts help LLMs steer their trajectories away from undesired meanings, improving reachability and alignment via input optimization, parameter editing, and activation-level interventions. Third, we look into deeper integrations by treating LLMs as dynamic systems within a state-space framework, where their internal representations are closely linked to external control loops. Finally, we identify key challenges and outline future research directions to understand LLM behavior and develop interpretable and controllable LLMs that are as trustworthy and robust as their electromechanical counterparts, thereby ensuring they continue to support and safeguard society.

</details>


### [38] [Input-to-State Safe Backstepping: Robust Safety-Critical Control with Unmatched Uncertainties](https://arxiv.org/abs/2602.03691)
*Max H. Cohen,Pio Ong,Aaron D. Ames*

Main category: eess.SY

TL;DR: 本文提出了一种针对具有不匹配扰动的非线性系统的安全关键控制的构建性方法，推广了输入到状态安全（ISSf）框架，并通过最优衰减CBF提供了更大的灵活性。


<details>
  <summary>Details</summary>
Motivation: 在存在无法通过控制输入直接抵消的不确定性（即不匹配扰动）时，如何保证系统安全性仍是非线性控制中的关键挑战。

Method: 采用最优衰减控制屏障函数（Optimal Decay CBF）推广输入到状态安全（ISSf）框架，并为两类具有不匹配不确定性的系统（严格反馈系统和双相对阶系统）提出构造ISSf-CBF的方法。

Result: 提出了适用于严格反馈系统和双相对阶系统的ISSf-CBF构造方法，并通过倒立摆和平面四旋翼系统的数值仿真验证了理论结果的有效性。

Conclusion: 所提出的方法能够有效处理具有不匹配扰动的非线性系统的安全控制问题，增强了安全条件的灵活性和适用性。

Abstract: Guaranteeing safety in the presence of unmatched disturbances -- uncertainties that cannot be directly canceled by the control input -- remains a key challenge in nonlinear control. This paper presents a constructive approach to safety-critical control of nonlinear systems with unmatched disturbances. We first present a generalization of the input-to-state safety (ISSf) framework for systems with these uncertainties using the recently developed notion of an Optimal Decay CBF, which provides more flexibility for satisfying the associated Lyapunov-like conditions for safety. From there, we outline a procedure for constructing ISSf-CBFs for two relevant classes of systems with unmatched uncertainties: i) strict-feedback systems; ii) dual-relative-degree systems, which are similar to differentially flat systems. Our theoretical results are illustrated via numerical simulations of an inverted pendulum and planar quadrotor.

</details>


### [39] [Real-world energy data of 200 feeders from low-voltage grids with metadata in Germany over two years](https://arxiv.org/abs/2602.03521)
*Manuel Treutlein,Pascal Bothe,Marc Schmidt,Roman Hahn,Oliver Neumann,Ralf Mikut,Veit Hagenmeyer*

Main category: eess.SY

TL;DR: FeederBW是一个包含200个低压馈线两年真实能源数据的数据集，具有高时间分辨率和丰富的元数据，支持多种应用并揭示低碳技术对低压电网的影响。


<details>
  <summary>Details</summary>
Motivation: 研究人员缺乏合适的低压电网数据来应对能源转型中最后一英里配电系统的挑战。

Method: 提供来自德国配电网运营商Netze BW的真实世界数据，涵盖200个低压馈线、天气信息和详细的元数据，并记录低碳技术安装的变化。

Result: 数据集具有高光伏馈入和一分钟时间分辨率的独特特征，揭示了低碳技术对低压电网日益增长的影响模式。

Conclusion: FeederBW数据集支持负荷预测、非侵入式负荷监测、合成数据生成以及天气与电网测量之间关系的分析等多种应用。

Abstract: The last mile of the distribution grid is crucial for a successful energy transition, as more low-carbon technology like photovoltaic systems, heat pumps, and electric vehicle chargers connect to the low-voltage grid. Despite considerable challenges in operation and planning, researchers often lack access to suitable low-voltage grid data. To address this, we present the FeederBW dataset with data recorded by the German distribution system operator Netze BW. It offers real-world energy data from 200 low-voltage feeders over two years (2023-2025) with weather information and detailed metadata, including changes in low-carbon technology installations. The dataset includes feeder-specific details such as the number of housing units, installed power of low-carbon technology, and aggregated industrial energy data. Furthermore, high photovoltaic feed-in and one-minute temporal resolution makes the dataset unique. FeederBW supports various applications, including machine learning for load forecasting, conducting non-intrusive load monitoring, generating synthetic data, and analyzing the interplay between weather, feeder measurements, and metadata. The dataset reveals insightful patterns and clearly reflects the growing impact of low-carbon technology on low-voltage grids.

</details>


### [40] [A Comparison of Set-Based Observers for Nonlinear Systems](https://arxiv.org/abs/2602.03646)
*Nico Holzinger,Matthias Althoff*

Main category: eess.SY

TL;DR: 本文首次在CORA框架下对非线性离散时间系统的集合状态估计器进行了广泛的工具支持比较，评估了不同方法在计算成本、可扩展性和保守性方面的表现，并公开了所有实现以促进可重复性和未来发展。


<details>
  <summary>Details</summary>
Motivation: 缺乏在相同条件下对非线性离散时间系统集合观测器的统一评估，限制了方法间的客观比较和实际应用选择。

Method: 在CORA框架中实现并比较了代表性集合观测器方法，采用共同基准测试，评估计算代价、可扩展性和状态边界保守性。

Result: 揭示了不同观测器类别与集合表示之间的典型权衡关系，提供了实施中的实用见解，并发现各类方法在效率与精度上的差异。

Conclusion: 该研究为非线性离散时间系统的集合状态估计提供了首个广泛且工具支持的对比分析，推动了可重复研究和未来算法发展。

Abstract: Set-based state estimation computes sets of states consistent with a system model given bounded sets of disturbances and noise. Bounding the set of states is crucial for safety-critical applications so that one can ensure that all specifications are met. While numerous approaches have been proposed for nonlinear discrete-time systems, a unified evaluation under comparable conditions is lacking. This paper reviews and implements a representative selection of set-based observers within the CORA framework. To provide an objective comparison, the methods are evaluated on common benchmarks, and we examine computational effort, scalability, and the conservatism of the resulting state bounds. This study highlights characteristic trade-offs between observer categories and set representations, as well as practical considerations arising in their implementation. All implementations are made publicly available to support reproducibility and future development. This paper thereby offers the first broad, tool-supported comparison of guaranteed state estimators for nonlinear discrete-time systems.

</details>


### [41] [Mitigating Timing-Based Attacks in Real-Time Cyber-Physical Systems](https://arxiv.org/abs/2602.03757)
*Arkaprava Sain,Sunandan Adhikary,Soumyajit Dey*

Main category: eess.SY

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Real-time cyber-physical systems depend on deterministic task execution to guarantee safety and correctness. Unfortunately, this determinism can unintentionally expose timing information that enables adversaries to infer task execution patterns and carry out timing-based attacks targeting safety-critical control tasks. While prior defenses aim to obscure schedules through randomization or isolation, they typically neglect the implications of such modifications on closed-loop control behavior and real-time feasibility. This work studies the problem of securing real-time control workloads against timing inference attacks while explicitly accounting for both schedulability constraints and control performance requirements. We present a scheduling-based mitigation approach that introduces bounded timing perturbations to control task executions in a structured manner, reducing adversarial opportunities without violating real-time guarantees. The framework jointly considers worst-case execution behavior and the impact of execution delays on control performance, enabling the system to operate within predefined safety and performance limits. Through experimental evaluation on representative task sets and control scenarios, the proposed approach demonstrates that exposure to timing-based attacks can be significantly reduced while preserving predictable execution and acceptable control quality.

</details>


<div id='quant-ph'></div>

# quant-ph [[Back]](#toc)

### [42] [On the reality of quantum states: A pedagogic survey from classical to quantum mechanics](https://arxiv.org/abs/2602.02617)
*Moncy Vilavinal John*

Main category: quant-ph

TL;DR: 本文通过从经典力学的哈密顿-雅可比方程出发，类比几何光学到电磁波方程的方法，推导出薛定谔方程，并提出量子态与经典力学波函数同样具有客观性，从而在一定程度上消解量子力学中的诸多谜题。


<details>
  <summary>Details</summary>
Motivation: 受到几何光学中从程函方程推广到波动方程的启发，试图从更基本的经典力学路径理解量子力学的本质，探讨量子态是否仅表示信息的问题。

Method: 将经典哈密顿-雅可比方程重写为波动方程形式，推广德布罗意的波粒二象性，要求物质波函数也可由任意平方可积函数描述，从而导出薛定谔方程，并对比经典与量子体系中的可观测量表达式。

Result: 成功导出薛定谔方程，发现其解与经典力学波函数一样具有客观性；许多量子力学中的方程（如本征值方程、态展开等）在经典情况下也可写出；经典领域缺乏波函数坍缩和纠缠等现象源于经典波动方程的非线性。

Conclusion: 量子力学中的许多谜题实际上以潜藏形式存在于经典力学中，这一观点有助于大幅消除对量子力学的神秘化理解。

Abstract: Some recent experiments claim to show that any model in which a quantum state represents mere information about an underlying physical reality of the system must make predictions which contradict those of quantum theory. The present work undertakes to investigate the issue of reality, treading a more fundamental route from the Hamilton-Jacobi equation of classical mechanics to the Schrodinger equation of quantum mechanics. Motivation for this is a similar approach from the eikonal equation in geometrical optics to the wave equation in electromagnetic theory. We rewrite the classical Hamilton-Jacobi equation as a wave equation and seek to generalise de Broglie's wave particle duality by demanding that both particle and light waves have the freedom of being described by any square-integrable function. This generalisation, which allows superposition also for matter wave functions, helps us to obtain the Schrodinger equation, whose solution can be seen to be as much objective as the classical mechanics wave function. Several other equations which one writes in quantum mechanics, including the eigenvalue equations for observables, series expansion of energy states in terms of eigenstates of observables other than energy, etc., can be written in the classical case too. Absence of any collapse of the wave function, entanglement, etc. in the classical realm have their origin in the nonlinearity of the classical wave equation. These considerations indicate that many of the puzzles in quantum mechanics are present also in classical mechanics in a dormant form, which fact shall help to demystify quantum mechanics to a great extent.

</details>


### [43] [Tailoring Quantum Chaos With Continuous Quantum Measurements](https://arxiv.org/abs/2602.02663)
*Preethi Gopalakrishnan,András Grabarits,Adolfo del Campo*

Main category: quant-ph

TL;DR: 研究了量子监测在哈密顿量量子混沌动力学表现中的作用，通过改变测量强度和检测效率来调节量子混沌的动态特征。


<details>
  <summary>Details</summary>
Motivation: 探索量子监测如何影响量子混沌的动力学表现。

Method: 分析连续能量测量下相干吉布斯态的生存概率定义的广义谱形因子。

Result: 发现量子监测可以调节量子混沌的动态特征，如扩展谱形因子中的ramp；高效率监测下的典型量子轨迹表现出比平均动力学和无测量的幺正演化更强的量子混沌。

Conclusion: 量子监测能够增强并调控量子混沌的动力学特征。

Abstract: We investigate the role of quantum monitoring in the dynamical manifestations of Hamiltonian quantum chaos. Specifically, we analyze the generalized spectral form factor, defined as the survival probability of a coherent Gibbs state under continuous energy measurements. We show that quantum monitoring can tailor the signatures of quantum chaos in the dynamics, such as the extension of the ramp in the spectral form factor, by varying the measurement strength and detection efficiency. In particular, a typical quantum trajectory obtained by monitoring with unit efficiency exhibits enhanced quantum chaos relative to the average dynamics and to unitary evolution without measurements.

</details>


### [44] [Unravelling the emergence of quantum jumps in a monitored qubit](https://arxiv.org/abs/2602.02672)
*Barkay Guttel,Danielle Gov,Noam Netzer,Uri Goldblatt,Sergey Hazanov,Lalit M. Joshi,Alessandro Romito,Yuval Gefen,Parveen Kumar,Kyrylo Snizhko,Fabien Lafont,Serge Rosenblum*

Main category: quant-ph

TL;DR: 通过调节连续监测的超导量子比特的测量强度，观察到量子跃迁经历三个不同的动力学相变，揭示了相干驱动、测量和退相干之间相互作用导致的多层次动力学相。


<details>
  <summary>Details</summary>
Motivation: 研究从相干动力学到测量主导行为的转变过程，特别是量子跃迁在不同测量强度下的表现。

Method: 调节连续监测的超导量子比特的测量强度，并观察其动力学行为的变化。

Result: 发现量子跃迁不是通过逐渐过渡实现的，而是通过三个不同的动力学相变级联发生：第一个是在异常点处相干振荡突然停止；第二个是动态状态冻结的开始；第三个是进入量子芝诺区域。此外，退相干不仅没有模糊这些相变，反而重构了动力学相图，甚至逆转了它们的顺序。

Conclusion: 测量诱导的相变揭示了相干驱动、测量和退相干之间的复杂相互作用，形成了层次分明的动力学相。

Abstract: Quantum jumps, the collapse of a quantum system upon measurement, are among the most striking consequences of observation in quantum mechanics. While recent experiments have revealed the continuous nature of individual jumps, the crossover from coherent dynamics to measurement-dominated behaviour has remained elusive. Here, we tune the measurement strength of a continuously monitored superconducting qubit, and observe that quantum jumps emerge not through a gradual crossover, but via a cascade of three distinct dynamical transitions. The first transition manifests as an exceptional point where coherent oscillations abruptly cease, giving way to jumps towards a stable eigenstate. The second transition marks the onset of dynamical state freezing, where the qubit's dwell time near the eigenstate diverges. A third threshold signals entry into the quantum Zeno regime, where stronger measurement paradoxically suppresses relaxation. Strikingly, we find that decoherence does not blur these transitions but rather fundamentally restructures the dynamical phase diagram, notably inverting their order. These results map measurement-induced transitions in a monitored qubit, revealing that the interplay between coherent driving, measurement, and decoherence gives rise to a hierarchy of distinct dynamical phases.

</details>


### [45] [Floquet-engineered fidelity revivals in the PXP model](https://arxiv.org/abs/2602.02673)
*Francesco Perciavalle,Francesco Plastina,Nicola Lo Gullo*

Main category: quant-ph

TL;DR: 研究了周期驱动下PXP模型的动力学，揭示了谱特性与初态共同作用导致动力学 revival 现象的机制，并展示了如何通过调控驱动参数控制非热化行为。


<details>
  <summary>Details</summary>
Motivation: 探索周期驱动下PXP模型中初态与谱结构如何共同影响动力学revival和避免热化的行为。

Method: 分析Floquet谱中的准能量间隔与初态在驱动参数空间中的演化关系，研究不同初态（如Néel态与极化态之间）的动力学响应。

Result: 发现Néel初态下的revival遵循由主导准能量间隔决定的明确轨迹；介于Néel与极化之间的初态表现出可调的混合动力学，可通过驱动参数调控其与Floquet本征态的重叠来引导非热化路径。

Conclusion: 初态选择与驱动协议共同决定了PXP系统中长寿命动力学行为，为避免Floquet热化提供了可控路径。

Abstract: We explore the dynamics of the PXP model when subjected to a periodic drive, and unveil the mechanism through which the interplay between spectral properties and initial states governs the emergence of dynamical revivals and their evolution across the space of driving parameters. For Néel-ordered initial states, revivals follow well-defined trajectories in the parameter space of the driving, primarily determined by a dominant quasi-energy spacing in the Floquet spectrum. Initial states interpolating between Néel and fully polarized configurations exhibit hybrid dynamics, which can be controlled by tuning their overlap with Floquet eigenstates via the driving parameters. This control also allows steering different routes for avoiding Floquet thermalization, showing how both initial state choice and driving protocol shape long-lived dynamics in this driven quantum many-body systems.

</details>


### [46] [Integration of Variational Quantum Algorithms into Atomistic Simulation Workflows](https://arxiv.org/abs/2602.02695)
*Wilke Dononelli*

Main category: quant-ph

TL;DR: 本工作将Qiskit Nature的量子化学求解器集成到原子模拟环境（ASE）中，实现了基于力驱动的混合量子-经典原子模拟工作流，支持几何优化、振动频率分析和分子动力学等任务。


<details>
  <summary>Details</summary>
Motivation: 为了扩展量子计算在原子尺度模拟中的应用，特别是实现基于量子算法的力计算与传统模拟工具的无缝结合。

Method: 通过将Qiskit Nature的VQE和ADAPT-VQE算法接入ASE的计算器接口，构建混合量子-经典计算流程，用于计算能量、力及相关性质。

Result: 在BeH2等多电子体系中，ADAPT-VQE计算得到的振动和结构特性与高精度CCSD方法结果高度一致，验证了量子算法在力计算中的稳定性与化学准确性。

Conclusion: 自适应变分量子算法能够提供稳定且具有化学意义的原子力，可有效支持分子动力学和主动学习加速模拟等下游应用。

Abstract: In this work, we present the integration of Qiskit Nature's quantum chemistry solvers into the Atomic Simulation Environment (ASE), enabling hybrid quantum-classical workflows for force-driven atomistic simulations. This coupling allows the use of the Variational Quantum Eigensolver (VQE) and its adaptive variant (ADAPT-VQE) not only for ground-state energy calculations, but also for geometry optimisation, vibrational frequency analysis, strain evaluation, and molecular dynamics, all managed through ASE's calculator interface. By applying ADAPT-VQE to multi-electron systems such as BeH2, we obtain vibrational and structural properties in close agreement with high-level classical CCSD calculations within the same minimal basis. These results demonstrate that adaptive variational quantum algorithms can deliver stable and chemically meaningful forces within an atomistic modelling workflow, enabling downstream applications such as molecular dynamics and active-learning accelerated simulations.

</details>


### [47] [Compiling Quantum Regular Language States](https://arxiv.org/abs/2602.02698)
*Armando Bellante,Reinis Irmejs,Marta Florido-Llinàs,María Cea Fernández,Marianna Crupi,Matthew Kiser,J. Ignacio Cirac*

Main category: quant-ph

TL;DR: 提出了一种结构感知的量子态制备编译器，支持正则语言态及其补集的高效编译，通过有限自动机与矩阵乘积态结合实现资源可预测的电路生成。


<details>
  <summary>Details</summary>
Motivation: 现有量子态制备编译器要么是通用但低效的黑箱方法，要么仅支持少数特定态；缺乏能接受结构化描述且保证资源效率的中间方案。

Method: 用户通过位串集合、正则表达式或确定性有限自动机（DFA）描述目标态；系统将输入转换为DFA并最小化，映射到最优矩阵乘积态（MPS）作为中间表示，再生成硬件适配的电路。

Result: 实现了对正则语言态及其补集的高效编译，编译时间与资源开销可预测；提出了两种后端：SeqRLSP（线性深度、无辅助比特）和TreeRLSP（对数深度），并证明了深度与门数量的渐近界。

Conclusion: 该编译器在保持简洁输入的同时揭示并压缩了隐藏结构，显著降低了编译复杂度，为结构化量子态制备提供了高效、可扩展的新范式。

Abstract: State preparation compilers for quantum computers typically sit at two extremes: general-purpose routines that treat the target as an opaque amplitude vector, and bespoke constructions for a handful of well-known state families. We ask whether a compiler can instead accept simple, structure-aware specifications while providing predictable resource guarantees. We answer this by designing and implementing a quantum state-preparation compiler for regular language states (RLS): uniform superpositions over bitstrings accepted by a regular description, and their complements. Users describe the target state via (i) a finite set of bitstrings, (ii) a regular expression, or (iii) a deterministic finite automaton (DFA), optionally with a complement flag. By translating the input to a DFA, minimizing it, and mapping it to an optimal matrix product state (MPS), the compiler obtains an intermediate representation (IR) that exposes and compresses hidden structure. The efficient DFA representation and minimization offloads expensive linear algebra computation in exchange of simpler automata manipulations. The combination of the regular-language frontend and this IR gives concise specifications not only for RLS but also for their complements that might otherwise require exponentially large state descriptions. This enables state preparation of an RLS or its complement with the same asymptotic resources and compile time. We outline two hardware-aware backends: SeqRLSP, which yields linear-depth, ancilla-free circuits for linear nearest-neighbor architectures via sequential generation, and TreeRLSP, which achieves logarithmic depth on all-to-all connectivity via a tree tensor network. We prove depth and gate-count bounds scaling with the system size and the state's maximal Schmidt rank, and we give explicit compile-time bounds that expose the benefit of our approach. We implement and evaluate the pipeline.

</details>


### [48] [Inducing, and enhancing, many-body quantum chaos by continuous monitoring](https://arxiv.org/abs/2602.02750)
*Xianlong Liu,Jie-ping Zheng,Antonio M. García-García*

Main category: quant-ph

TL;DR: 连续监测和热浴的共同作用可驱动系统进入非热稳态，尽管监测会导致退相干，但在某些参数范围内反而会诱导或增强被热浴抑制的量子混沌动力学。


<details>
  <summary>Details</summary>
Motivation: 探索在持续监测和耗散环境下，多体量子混沌是否总是被抑制，并理解量子混沌与环境耦合之间的复杂关系。

Method: 采用林德布拉德主方程描述持续监测下的SYK模型，并将其与处于恒定温度的另一SYK模型所代表的热浴耦合，研究淬火动力学行为。通过解析和数值方法分析推迟格林函数和李雅普诺夫指数的变化。

Result: 发现系统趋于与初态无关的非热稳态；格林函数呈现两阶段指数衰减；在弱耦合下，晚期衰减与热浴特性相关；监测可在特定条件下增强量子混沌，如弱热浴耦合时李雅普诺夫指数显著上升，中等耦合时出现再入性行为（随监测增强从无到有）。

Conclusion: 持续监测并不总是抑制量子混沌，在适当条件下反而可以诱导或恢复被环境抑制的混沌行为，揭示了量子 scrambling 的新机制，为实验调控和提升量子信息器件性能提供了可能路径。

Abstract: It is intuitively expected, and supported by earlier studies, that many-body quantum chaos is suppressed, or even destroyed, by dissipative effects induced by continuous monitoring. We show here that this is not always the case. For this purpose, we study the quenched dynamics of a continuously monitored Sachdev-Ye-Kitaev (SYK) model, described by the Lindblad formalism, coupled to a thermal environment modeled by another SYK maintained at constant temperature. We find that the combined effect of monitoring and the thermal bath drives the system toward a non-thermal steady state independently of the initial conditions. The corresponding retarded Green's function exhibits two stages of exponential decay, with rates that depend non-monotonously on the thermal bath coupling and the monitoring strength. In the limit of weak coupling, the late time decay of the Green's function, computed analytically, is closely related to that of the thermal bath. Strikingly, we identify a range of parameters in which continuous monitoring, despite being a source of decoherence, induces or enhances quantum chaotic dynamics suppressed by the thermal bath. For instance, in the limit of weak coupling to the thermal bath, the Lyapunov exponent increases sharply when monitoring is turned on. For intermediate values of the thermal bath coupling, the Lyapunov exponent exhibits re-entrant behavior: it vanishes at zero or sufficiently weak monitoring strength, and becomes positive again as the monitoring strength is increased. Our results offer intriguing insights on the mechanisms leading to quantum scrambling which paves the way to its experimental control and consequently to a performance enhancement of quantum information devices.

</details>


### [49] [Experimental Quantification of Spin-Phonon Coupling in Molecular Qubits using Inelastic Neutron Scattering](https://arxiv.org/abs/2602.02792)
*Stefan H. Lohaus,Kay T. Xia,Yongqiang Cheng,Ryan G. Hadt*

Main category: quant-ph

TL;DR: 提出了一种全实验方法，结合非弹性中子散射和电子顺磁共振，量化分子自旋系统中的自旋-声子耦合（SPC），揭示了不同温度下主导自旋弛豫的振动模式，并阐明了分子结构对SPC的影响。


<details>
  <summary>Details</summary>
Motivation: 缺乏关于哪些振动能量主导自旋弛豫以及分子结构如何调控自旋-声子耦合（SPC）的实验共识。

Method: 结合温度依赖的非弹性中子散射振动谱与电子顺磁共振测量的自旋弛豫速率，建立一个完全基于实验的SPC系数量化框架，并应用于CuPc和CuOEP两个模型体系。

Result: 发现低于40 K时，<50 cm⁻¹的弱耦合晶格模主导弛豫；高于40 K时，~185 cm⁻¹以上的光学声子热占据导致SPC系数增大近三个数量级。CuOEP的结构畸变软化晶格但提升核心伸缩模能量，使振动能量重分布至外围和面外，降低SPC，实现室温自旋相干。

Conclusion: 该方法虽不提供具体振动模式的SPC系数，但能定量区分不同频段振动对自旋弛豫的贡献，建立了晶体结构、晶格动力学与自旋弛豫之间的普适性实验关联。

Abstract: Electronic spin superposition states enable nanoscale sensing through their sensitivity to the local environment, yet their sensitivity to vibrational motion also limits their coherence times. In molecular spin systems, chemical tunability and atomic-scale resolution are accompanied by a dense, thermally accessible phonon spectrum that introduces efficient spin relaxation pathways. Despite extensive theoretical work, there is little experimental consensus on which vibrational energies dominate spin relaxation or how molecular structure controls spin-phonon coupling (SPC). We present a fully experimental method to quantify SPC coefficients by combining temperature-dependent vibrational spectra from inelastic neutron scattering with spin relaxation rates measured by electron paramagnetic resonance. We apply this framework to two model S = 1/2 systems, copper(II) phthalocyanine (CuPc) and copper(II) octaethylporphyrin (CuOEP). Two distinct relaxation regimes emerge: below 40 K, weakly coupled lattice modes below $50~\mathrm{cm}^{-1}$ dominate, whereas above 40 K, optical phonons above ~$185~\mathrm{cm}^{-1}$ become thermally populated and drive relaxation with SPC coefficients nearly three orders of magnitude larger. Structural distortions in CuOEP that break planar symmetry soften the crystal lattice and enhance anharmonic scattering, but also raise the energy of stretching modes at the molecular core where the spins reside. This redistributes vibrational energy toward the molecular periphery and out of plane, ultimately reducing SPC relative to CuPc and enabling room-temperature spin coherence in CuOEP. Although our method does not provide mode-specific SPC coefficients, it quantifies contributions from distinct spectral regions and establishes a broadly applicable, fully experimental link between crystal structure, lattice dynamics, and spin relaxation.

</details>


### [50] [Quantum Information Flow in Microtubule Tryptophan Networks](https://arxiv.org/abs/2602.02868)
*Lea Gassab,Onur Pusuluk,Travis J. A. Craddock*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Networks of aromatic amino acid residues within microtubules, particularly those formed by tryptophan, may serve as pathways for optical information flow. Ultraviolet excitation dynamics in these networks are typically modeled with effective non-Hermitian Hamiltonians. By extending this approach to a Lindblad master equation that incorporates explicit site geometries and dipole orientations, we track how correlations are generated, routed, and dissipated, while capturing both energy dissipation and information propagation among coupled chromophores. We compare localized injections, fully delocalized preparations, and eigenmode-based initial states. To quantify the emerging quantum-informational structure, we evaluate the $L_1$ norm of coherence, the correlated coherence, and the logarithmic negativity within and between selected chromophore sub-networks. The results reveal a strong dependence of both the direction and persistence of information flow on the type of initial preparation. Superradiant components drive the rapid export of correlations to the environment, whereas subradiant components retain them and slow their leakage. Embedding single tubulin units into larger dimers and spirals reshapes pairwise correlation maps and enables site-selective routing. Scaling to larger ordered lattices strengthens both export and retention channels, whereas static energetic and structural disorder suppresses long-range transport and reduces overall correlation transfer. These findings provide a Lindbladian picture of information flow in cytoskeletal chromophore networks and identify structural and dynamical conditions that transiently preserve nonclassical correlations in microtubules.

</details>


### [51] [Asymptotically Optimal Quantum Universal Quickest Change Detection](https://arxiv.org/abs/2602.02950)
*Arick Grootveld,Haodong Yang,Nandan Sriranga,Biao Chen,Venkata Gandikota,Jason Pollack*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates the quickest change detection of quantum states in a universal setting: specifically, where the post-change quantum state is not known a priori. We establish the asymptotic optimality of a two-stage approach in terms of worst average delay to detection. The first stage employs block POVMs with classical outputs that preserve quantum relative entropy to arbitrary precision. The second stage leverages a recently proposed windowed-CUSUM algorithm that is known to be asymptotically optimal for quickest change detection with an unknown post-change distribution in the classical setting.

</details>


### [52] [Accelerating the Tesseract Decoder for Quantum Error Correction](https://arxiv.org/abs/2602.02985)
*Dragana Grbic,Laleh Aghababaie Beni,Noah Shutty*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum Error Correction (QEC) is essential for building robust, fault-tolerant quantum computers; however, the decoding process often presents a significant computational bottleneck. Tesseract is a novel Most-Likely-Error (MLE) decoder for QEC that employs the A* search algorithm to explore an exponentially large graph of error hypotheses, achieving high decoding speed and accuracy. This paper presents a systematic approach to optimizing the Tesseract decoder through low-level performance enhancements. Based on extensive profiling, we implemented four targeted optimization strategies, including the replacement of inefficient data structures, reorganization of memory layouts to improve cache hit rates, and the use of hardware-accelerated bit-wise operations. We achieved significant decoding speedups across a wide range of code families and configurations, including Color Codes, Bivariate-Bicycle Codes, Surface Codes, and Transversal CNOT Protocols. Our results demonstrate consistent speedups of approximately 2x for most code families, often exceeding 2.5x. Notably, we achieved a peak performance gain of over 5x for the most computationally demanding configurations of Bivariate-Bicycle Codes. These improvements make the Tesseract decoder more efficient and scalable, serving as a practical case study that highlights the importance of high-performance software engineering in QEC and providing a strong foundation for future research.

</details>


### [53] [Device variability of Josephson junctions induced by interface roughness](https://arxiv.org/abs/2602.03037)
*Yu Zhu,Félix Beaudoin,Hong Guo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: As quantum processors scale to large qubit numbers, device-to-device variability emerges as a critical challenge. Superconducting qubits are commonly realized using Al/AlO$_{\text{x}}$/Al Josephson junctions operating in the tunneling regime, where even minor variations in device geometry can lead to substantial performance fluctuations. In this work, we develop a quantitative model for the variability of the Josephson energy $E_{J}$ induced by interface roughness at the Al/AlO$_{\text{x}}$ interfaces. The roughness is modeled as a Gaussian random field characterized by two parameters: the root-mean-square roughness amplitude $σ$ and the transverse correlation length $ξ$. These parameters are extracted from the literature and molecular dynamics simulations. Quantum transport is treated using the Ambegaokar--Baratoff relation combined with a local thickness approximation. Numerical simulations over $5,000$ Josephson junctions show that $E_{J}$ follows a log-normal distribution. The mean value of $E_{J}$ increases with $σ$ and decreases slightly with $ξ$, while the variance of $E_{J}$ increases with both $σ$ and $ξ$. These results paint a quantitative and intuitive picture of Josephson energy variability induced by surface roughness, with direct relevance for junction design.

</details>


### [54] [Quantum spin-heat engine with trapped ions](https://arxiv.org/abs/2602.03057)
*André R. R. Carvalho,Liam J. McClelland,Erik W. Streed,Joan Vaccaro*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We propose an ion-trap implementation of the Vaccaro, Barnett and Wright et al. spin-heat engine (SHE); a hypothetical engine that operates between energy and spin thermal reservoirs rather than two energy reservoirs. The SHE operates in two steps: first, in the work extraction stage, heat from a thermal energy reservoir is converted into optical work via a two photon Raman transition resonant with close-to energy degenerate spin states; second, the internal spin states are brought back to their initial state via non-energetic information erasure using a spin reservoir. The latter incurs no energy cost, but rather the reset occurs at the cost of angular momentum from a spin bath that acts as the thermal spin reservoir. The SHE represents an important first step toward demonstrating heat engines that operate beyond the conventional paradigm of requiring two thermal reservoirs, paving the way to harness quantum coherence in arbitrary conserved quantities via similar machines.

</details>


### [55] [Resource-efficient quantum simulation of transport phenomena via Hamiltonian embedding](https://arxiv.org/abs/2602.03099)
*Joseph Li,Gengzhi Yang,Jiaqi Leng,Xiaodi Wu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Transport phenomena play a key role in a variety of application domains, and efficient simulation of these dynamics remains an outstanding challenge. While quantum computers offer potential for significant speedups, existing algorithms either lack rigorous theoretical guarantees or demand substantial quantum resources, preventing scalable and efficient validation on realistic quantum hardware. To address this gap, we develop a comprehensive framework for simulating classes of transport equations, offering both rigorous theoretical guarantees -- including exponential speedups in specific cases -- and a systematic, hardware-efficient implementation. Central to our approach is the Hamiltonian embedding technique, a white-box approach for end-to-end simulation of sparse Hamiltonians that avoids abstract query models and retains near-optimal asymptotic complexity. Empirical resource estimates indicate that our approach can yield an order-of-magnitude (e.g., $42\times$) reduction in circuit depth given favorable problem structures. We then apply our framework to solve linear and nonlinear transport PDEs, including the first experimental demonstration of a 2D advection equation on a trapped-ion quantum computer.

</details>


### [56] [Accelerating qubit reset through the Mpemba effect](https://arxiv.org/abs/2602.03765)
*Théo Lejeune,Miha Papič,John Goold,Felix C. Binder,François Damanet,Mattia Moroder*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Passive qubit reset is a key primitive for quantum information processing, whereby qubits are initialized by allowing them to relax to their ground state through natural dissipation, without the need for active control or feedback. However, passive reset occurs on timescales that are much longer than those of gate operations and measurements, making it a significant bottleneck for algorithmic execution. Here, we show that this limitation can be overcome by exploiting the Mpemba effect, originally indicating the faster cooling of hot systems compared to cooler ones. Focusing on the regime where coherence times exceed energy relaxation times ($T_2 > T_1$), we propose a simple protocol based on a single entangling two-qubit gate that converts local single-qubit coherences into fast-decaying global two-qubit coherences. This removes their overlap with the slowest decaying Liouvillian mode and enables a substantially faster relaxation to the ground state. For realistic parameters, we find that our protocol can reduce reset times by up to $50\%$ compared to standard passive reset. We analyze the robustness of the protocol under non-Markovian noise, imperfect coherent control and finite temperature, finding that the accelerated reset persists across a broad range of realistic error sources. Finally, we present an experimental implementation of our protocol on an IQM superconducting quantum processor. Our results demonstrate how Mpemba-like accelerated relaxation can be harnessed as a practical tool for fast and accurate qubit initialization.

</details>


### [57] [Quantum Annealing for Combinatorial Optimization: Foundations, Architectures, Benchmarks, and Emerging Directions](https://arxiv.org/abs/2602.03101)
*Rudraksh Sharma,Ravi Katukam,Arjun Nagulapally*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Critical decision-making issues in science, engineering, and industry are based on combinatorial optimization; however, its application is inherently limited by the NP-hard nature of the problem. A specialized paradigm of analogue quantum computing, quantum annealing (QA), has been proposed to solve these problems by encoding optimization problems into physical energy landscapes and solving them by quantum tunnelling systematically through exploration of solution space. This is a critical review that summarizes the current applications of quantum annealing to combinatorial optimization and includes a theoretical background, hardware designs, algorithm implementation strategies, encoding and embedding schemes, protocols to benchmark quantum annealing, areas of implementation, and links with the quantum algorithms implementation with gate-based hardware and classical solvers. We develop a unified framework, relating adiabatic quantum dynamics, Ising and QUBO models, stoquastic and non-stoquastic Hamiltonians, and diabatic transitions to modern flux-qubit annealers (Chimera, Pegasus, Zephyr topologies), and emergent architectures (Lechner-Hauke-Zoller systems, Rydberg atom platforms), and hybrids of quantum and classical computation. Through our analysis, we find that overhead in embedding and encoding is the largest determinant of the scalability and performance (this is not just the number of qubits). Minor embeddings also usually have a physical qubit count per logical variable of between 5 and 12 qubits, which limits effective problem capacity by 80-92% and, due to chain-breaking errors, compromises the quality of solutions.

</details>


### [58] [Validating a Koopman-Quantum Hybrid Paradigm for Diagnostic Denoising of Fusion Devices](https://arxiv.org/abs/2602.03113)
*Tie-Jun Wang,Run-Qing Zhang,Ling Qian,Yun-Tao Song,Ting Lan,Hai-Qing Liu,Keren Li*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The potential of Quantum Machine Learning (QML) in data-intensive science is strictly bottlenecked the difficulty of interfacing high-dimensional, chaotic classical data into resource-limited, noisy quantum processors. To bridge this gap, we introduce a physics-informed Koopman-Quantum hybrid framework, theoretically grounded in a representation-level structural isomorphism we establish between the Koopman operator, which linearizes nonlinear dynamics, and quantum evolution. Based on this theoretical foundation, we design a realizable NISQ-friendly pipeline: the Koopman operator functions as a physics-aware "data distiller," compressing waveforms into compact, "quantum-ready" features, which are subsequently processed by a modular, parallel quantum neural network. We validated this framework on 4,763 labeled channel sequences from 433 discharges of the tokamak system. The results demonstrate that our model achieves 97.0\% accuracy in screening corrupted diagnostic data, matching the performance of state-of-the-art deep classical CNNs while using orders-of-magnitude fewer trainable parameters. This work establishes a practical, physics-grounded paradigm for leveraging quantum processing in constrained environments, offering a scalable path for quantum-enhanced edge computing.

</details>


### [59] [Comprehensive Numerical Studies of Barren Plateau and Overparametrization in Variational Quantum Algorithm](https://arxiv.org/abs/2602.03291)
*Himuro Hashimoto,Akio Nakabayashi,Lento Nagano,Yutaro Iiyama,Ryu Sawada,Junichi Tanaka,Koji Terashi*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The variational quantum algorithm (VQA) with a parametrized quantum circuit is widely applicable to near-term quantum computing, but its fundamental issues that limit optimization performance have been reported in the literature. For example, VQA optimization often suffers from vanishing gradients called barren plateau (BP) and the presence of local minima in the landscape of the cost function. Numerical studies have shown that the trap in local minima is significantly reduced when the circuit is overparametrized (OP), where the number of parameters exceeds a certain threshold. Theoretical understanding of the BP and OP phenomena has advanced over the past years, however, comprehensive studies of both effects in the same setting are not fully covered in the literature. In this paper, we perform a comprehensive numerical study in VQA, quantitatively evaluating the impacts of BP and OP and their interplay on the optimization of a variational quantum circuit, using concrete implementations of one-dimensional transverse and longitudinal field quantum Ising model. The numerical results are compared with the theoretical diagnostics of BP and OP phenomena. The framework presented in this paper will provide a guiding principle for designing VQA algorithms and ansatzes with theoretical support for behaviors of parameter optimization in practical settings.

</details>


### [60] [Surpassing the currently achievable distance of quantum key distribution based on sending-or-not-sending approach](https://arxiv.org/abs/2602.03173)
*Georgi Bebrov*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Protocols based on the sending-or-not-sending (SNS) principle have been intensively studied in recent years and have been shown to enable the longest transmission distances in quantum key distribution (QKD). In this work, we propose a sending-or-not-sending phase-matching QKD protocol (SNS-PM-QKD) that improves tolerance to phase mismatch, thereby extending the achievable transmission distance. We present a security analysis of SNS-PM-QKD in the asymptotic (infinite-key) regime under collective attacks. The performance of the proposed protocol is compared with that of standard phase-matching QKD, theoretical SNS-type twin-field QKD protocols (SNS-TF-QKD), and an experimental SNS-TF-QKD operated over transmission distances of up to 1002km. Our results show that SNS-PM-QKD achieves greater transmission distances than these existing protocols, highlighting its potential for long-distance quantum communication.

</details>


### [61] [A Tunable, Modeless, and Hybridization-free Cross-Kerr Coupler for Miniaturized Superconducting Qubits](https://arxiv.org/abs/2602.03186)
*Gihwan Kim,Andreas Butler,Oskar Painter*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Superconducting quantum circuits typically use capacitive charge-based linear coupling schemes to control interactions between elements such as qubits. While simple and effective, this coupling scheme makes it difficult to satisfy competing circuit design requirements such as maintaining large qubit anharmonicity and coherence along with a high degree of qubit connectivity and packing density. Moreover, tunable interactions using linear coupling elements produce dynamical variations in mode hybridization, which can induce non-adiabatic transitions, resulting in leakage errors and limiting gate speeds. In this work we attempt to address these challenges by proposing a junction-based coupling architecture based on SQUID (superconducting quantum interference device) couplers with relatively small Josephson energies. SQUID couplers provide intrinsic cross-Kerr interactions that can be controlled by external fluxes and that do not rely on mode hybridization. The small Josephson energies of the coupler maintain the interaction at a perturbative scale, which limits undesired higher-order mixing between coupled elements while achieving a sufficiently strong cross-Kerr interaction originating from diagonal coupling elements. Based on these properties, we show that a SQUID coupler can be used to implement a fast, adiabatic, and high-fidelity controlled-Z gate without introducing extra modes, and the operation is robust against junction asymmetry for high-frequency qubits. Although unconventional crosstalk may arise due to junction asymmetries and parasitic hybridization with spectator qubits, we show that these effects are sufficiently small for realistic circuit parameters. As an example of the utility of such junction-based coupling schemes, we present a scalable tiling strategy for a miniaturized superconducting quantum processor based on merged-element transmon qubits.

</details>


### [62] [Liouvillian Gap in Dissipative Haar-Doped Clifford Circuits](https://arxiv.org/abs/2602.03234)
*Ha Eum Kim,Andrew D. Kim,Jong Yeon Lee*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum chaos is commonly assessed through probe-dependent signatures such as spectral statistics, OTOCs, and entanglement growth, which need not coincide. Recently, a dissipative diagnostic of chaos has been proposed, in which an infinitesimal coupling to a bath yields a finite Liouvillian gap in chaotic systems, marking the onset of intrinsic relaxation. This raises a conceptual question: what is the minimal departure from Clifford dynamics needed for this intrinsically relaxing behavior to emerge? In this work, we investigate the dynamics under the Floquet two-qubit Clifford circuit interleaved with a finite density of Haar-random single-site gates, followed by a depolarizing channel with strength $γ$. For Floquet Clifford circuits built from an \textit{i}SWAP-class two-qubit gate, our analysis identifies two distinct regimes for the Liouvillian gap in the thermodynamic limit, exemplified by the undoped and fully doped extreme cases. In both regimes, the dissipative diagnostic signals chaotic behavior, differing only in how the gap scales with system size. In the undoped circuit, the gap scales as $Δ\sim γN$, whereas in the fully doped circuit it remains finite as $N\to\infty$. We find that the doping density $p_h$ governs the crossover: as $p_h\to 0$, any spatial structure remains undoped-like, whereas for finite $p_h$ certain structures can enter a finite-gap regime. These results are analytically established in the strongly dissipative regime $γ\gg 1$ by deriving lower bounds on the gap as a function of $p_h$ and explicit finite-gap constructions, and their extension toward $γ\to 0$ is supported by numerics. Importantly, our analytic treatment depends only on the spatial doping structure, so the same gap scaling persists even when the Haar rotations are independently resampled each Floquet period.

</details>


### [63] [Thermodynamic state variables from a minimal set of quantum constituents](https://arxiv.org/abs/2602.03276)
*Uwe Holm,Hans-Peter Weber,Morgan Berkane,Camilla Wulf,Anton Kantz,Anja Kuhnhold,Andreas Buchleitner*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We show how the macroscopic state variables pressure, entropy and temperature of equilibrium thermodynamics can be consistently derived from the (quantum) chaotic spectral structure of one or two particles in two-dimensional domains. This provides a definition of work and heat from first principles, a microscopic underpinning of the first and second law of thermodynamics, and a transparent illustration of the ``eigenstate thermalization hypothesis''.

</details>


### [64] [Decoherence-protected entangling gates in a silicon carbide quantum node](https://arxiv.org/abs/2602.03296)
*Shuo Ren,Rui-Jian Liang,Zhen-Xuan He,Ji-Yang Zhou,Wu-Xi Lin,Zhi-He Hao,Bing Chen,Tao Tu,Jin-Shi Xu,Chuan-Feng Li,Guang-Can Guo*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Solid-state color centers are promising candidates for nodes in quantum network architectures. However, realizing scalable and fully functional quantum nodes, comprising both processor and memory qubits with high-fidelity universal gate operations, remains a central challenge in this field. Here, we demonstrate a fully functional quantum node in silicon carbide, where electron spins act as quantum processors and nuclear spins serve as quantum memory. Specifically, we design a pulse sequence that combines dynamical decoupling with hyperfine interactions to realize decoherence-protected universal gate operations between the processor and memory qubits. Leveraging this gate, we deterministically prepare entangled states within the quantum node, achieving a fidelity of 90%, which exceeds the fault-tolerance threshold of certain quantum network architectures. These results open a pathway toward scalable and fully functional quantum nodes based on silicon carbide.

</details>


### [65] [Even More Efficient Soft-Output Decoding with Extra-Cluster Growth and Early Stopping](https://arxiv.org/abs/2602.03336)
*Kaito Kishi,Riki Toshio,Jun Fujisaki,Hirotaka Oshima,Shintaro Sato,Keisuke Fujii*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: In fault-tolerant quantum computing, soft outputs from real-time decoders play a crucial role in improving decoding accuracy, post-selecting magic states, and accelerating lattice surgery. A recent paper by Meister et al. [arXiv:2405.07433 (2024)] proposed an efficient method to evaluate soft outputs for cluster-based decoders, including the Union-Find (UF) decoder. However, in parallel computing environments, its computational complexity is comparable to or even surpasses that of the UF decoder itself, resulting in a substantial overhead. Furthermore, this method requires global information about the decoding graph, making it poorly suited for existing hardware implementations of the UF decoder on Field-Programmable Gate Arrays (FPGAs). In this paper, to alleviate these issues, we develop more efficient methods for evaluating high-quality soft outputs in cluster-based decoders by introducing several early-stopping techniques. Our central idea is that the precise value of a large soft output is often unnecessary in practice. Based on this insight, we introduce two types of novel soft-outputs: the bounded cluster gap and the extra-cluster gap. The former reduces the computational complexity of Meister's method by terminating the calculation at an early stage. Our numerical simulations show that this method achieves improved scaling with code distance $d$ compared to the original proposal. The latter, the extra-cluster gap, quantifies decoder reliability by performing a small, additional growth of the clusters obtained by the decoder. This approach offers the significant advantage of enabling soft-output computation without modifying the existing architecture of FPGA-implemented UF decoders. These techniques offer lower computational complexity and higher hardware compatibility, laying a crucial foundation for future real-time decoders with soft outputs.

</details>


### [66] [Zak phase and bulk-boundary correspondence in a generalized Dirac-Kronig-Penney model](https://arxiv.org/abs/2602.03378)
*Giuliano Angelone,Domenico Monaco,Gabriele Peluso*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the topological properties of a generalized Dirac--Kronig--Penney model, a continuum one-dimensional model for a relativistic quantum chain. By tuning the coupling parameters this model can accommodate five Altland--Zirnbauer--Cartan symmetry classes, three of which (AIII, BDI and D) support non-trivial topological phases in dimension one. We characterize analytically the spectral properties of the Hamiltonian in terms of a spectral function, and numerically compute the Zak phase to probe the bulk topological content of the insulating phases. Our findings reveal that, while the Zak phase is quantized in classes AIII and BDI, it exhibits non-quantized values in class D, challenging its traditional role as a topological marker in continuum settings. We also discuss the bulk-boundary correspondence for a truncated version of the chain, analyzing how the emergence of edge states depends on both the truncation position and the boundary conditions. In classes AIII and BDI, we find that the Zak phase effectively detects edge states as a relative boundary topological index, although the correspondence is highly sensitive to the parameters characterizing the truncation.

</details>


### [67] [Enhancing Quantum Diffusion Models for Complex Image Generation](https://arxiv.org/abs/2602.03405)
*Jeongbin Jo,Santanam Wishal,Shah Md Khalil Ullah,Shan Kowalski,Dikshant Dulai*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum generative models offer a novel approach to exploring high-dimensional Hilbert spaces but face significant challenges in scalability and expressibility when applied to multi-modal distributions. In this study, we explore a Hybrid Quantum-Classical U-Net architecture integrated with Adaptive Non-Local Observables (ANO) as a potential solution to these hurdles. By compressing classical data into a dense quantum latent space and utilizing trainable observables, our model aims to extract non-local features that complement classical processing. We also investigate the role of Skip Connections in preserving semantic information during the reverse diffusion process. Experimental results on the full MNIST dataset (digits 0-9) demonstrate that the proposed architecture is capable of generating structurally coherent and recognizable images for all digit classes. While hardware constraints still impose limitations on resolution, our findings suggest that hybrid architectures with adaptive measurements provide a feasible pathway for mitigating mode collapse and enhancing generative capabilities in the NISQ era.

</details>


### [68] [Stationary entanglement of a levitated oscillator with an optical field](https://arxiv.org/abs/2602.03456)
*Q. Deplano,A. Pontin,F. Marino,F. Marin*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We report the generation of quantum entanglement between the center-of-mass motion of a levitated nanosphere, coupled by coherent scattering to an optical cavity mode, and the electromagnetic field. Using heterodyne detection, we reconstruct the full set of optical-mechanical correlations and observe a violation of separability bounds between the mechanical degrees of freedom and the propagating optical mode. Thus, we demonstrate the ability to distribute nonclassical correlations beyond the interaction region. Our results are obtained at room temperature and are robust over a broad range of detunings set by the cavity linewidth. These findings establish levitated optomechanical systems as a promising platform for macroscopic quantum optics and for future tests of fundamental physics.

</details>


### [69] [Quantum Circuit Generation via test-time learning with large language models](https://arxiv.org/abs/2602.03466)
*Adriano Macarone-Palmieri*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Large language models (LLMs) can generate structured artifacts, but using them as dependable optimizers for scientific design requires a mechanism for iterative improvement under black-box evaluation. Here, we cast quantum circuit synthesis as a closed-loop, test-time optimization problem: an LLM proposes edits to a fixed-length gate list, and an external simulator evaluates the resulting state with the Meyer-Wallach (MW) global entanglement measure. We introduce a lightweight test-time learning recipe that can reuse prior high-performing candidates as an explicit memory trace, augments prompts with a score-difference feedback, and applies restart-from-the-best sampling to escape potential plateaus. Across fixed 20-qubit settings, the loop without feedback and restart-from-the-best improves random initial circuits over a range of gate budgets. To lift up this performance and success rate, we use the full learning strategy. For 25-qubit, it mitigates a pronounced performance plateau when naive querying is used. Beyond raw scores, we analyze the structure of synthesized states and find that high MW solutions can correspond to stabilizer or graph-state-like constructions, but full connectivity is not guaranteed due to the metric property and prompt design. These results illustrate both the promise and the pitfalls of memory evaluator-guided LLM optimization for circuit synthesis, highlighting the critical role of prior human-made theoretical theorem to optimally design a custom tool in support of research.

</details>


### [70] [Evaluating Quantum Wire Cutting for QAOA: Performance Benchmarks in Ideal and Noisy Environments](https://arxiv.org/abs/2602.03482)
*Michel Meulen,Niels M. P. Neumann,Jasper Verbree*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Current quantum computers suffer from a limited number of qubits and high error rates, limiting practical applicability. Different techniques exist to mitigate these effects and run larger algorithms. In this work, we analyze one of these techniques called quantum circuit cutting. With circuit cutting, a quantum circuit is decomposed into smaller sub-circuits, each of which can be run on smaller quantum hardware. We compare the performance of quantum circuit cutting with different cutting strategies, and then apply circuit cutting to a QAOA algorithm. Using simulations, we first show that Randomized Clifford measurements outperform both Pauli and random unitary measurements. Second, we show that circuit cutting has trouble providing correct answers in noisy settings, especially as the number of circuits increases.

</details>


### [71] [QRC-Lab: An Educational Toolbox for Quantum Reservoir Computing](https://arxiv.org/abs/2602.03522)
*Anderson Fernandes Pereira dos Santos*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum Reservoir Computing (QRC) has emerged as a strong pa- radigm for Noisy Intermediate-Scale Quantum (NISQ) machine learning, ena- bling the processing of temporal data with minimal training overhead by exploi- ting the high-dimensional dynamics of quantum states. This paper introduces QRC-Lab, an open-source, modular Python framework designed to bridge the gap between theoretical quantum dynamics and applied machine learning work- flows. We provide a rigorous definition of QRC, contrast physical and gate- based approaches, and formalize the reservoir mapping used in the toolbox. QRC-Lab instantiates a configurable gate-based laboratory for studying in- put encoding, reservoir connectivity, and measurement strategies, and validates these concepts through three educational case studies: short-term memory re- construction, temporal parity (XOR), and NARMA10 forecasting as a deliberate stress test. In addition, we include a learning-theory motivated generalization- gap scan to build intuition about capacity control in quantum feature maps. The full source code, experiment scripts, and reproducibility assets are publicly available at: https://doi.org/10.5281/zenodo.18469026.

</details>


### [72] [Microscopic derivation of a completely positive master equation for the description of Open Quantum Brownian Motion of a particle in a potential](https://arxiv.org/abs/2602.03534)
*Ayanda Zungu,Ilya Sinayskiy,Francesco Petruccione*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Open Quantum Brownian Motion (OQBM) was introduced as a scaling limit of discrete-time open quantum walks. This limit defines a new class of quantum Brownian motion, which incorporates both the external and internal degrees of freedom of the Brownian particle. We consider a weakly driven Brownian particle confined in a harmonic potential and dissipatively coupled to a thermal bath. Applying the rotating wave approximation (RWA) to the system-bath interaction Hamiltonian, we derive a completely positive Born-Markov master equation for the reduced dynamics. We express the resulting master equation in the coordinate representation and, utilizing the adiabatic elimination of fast variables, derive a completely positive hybrid quantum-classical master equation that defines OQBM. We illustrate the resulting dynamics using examples of initial Gaussian and non-Gaussian distributions of the OQBM walker. Both examples reveal the emergence of Gaussian distributions in the limiting behavior of the OQBM dynamics, which closely matches that of the standard OQBM. With the help of the obtained OQBM master equation, we derive the equations for the $n$-th moments and the cumulants of the position distribution of the open Brownian walker. We subsequently solve these equations numerically for Gaussian initial distributions across various parameter regimes. Notably, we find that the third-order cumulant is nonzero, indicating that the dynamics' intrinsic generator is non-Gaussian.

</details>


### [73] [An Evaluation of the Remote CX Protocol under Noise in Distributed Quantum Computing](https://arxiv.org/abs/2602.03536)
*Leo Sünkel,Michael Kölle,Tobias Rohe,Claudia Linnhoff-Popien*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum computers connected through classical and quantum communication channels can be combined to function as a single unit to run large quantum circuits that each device is unable to execute on their own. The distributed quantum computing paradigm is therefore often seen as a potential pathway to scaling quantum computing to capacities necessary for practical and large-scale applications. Whether connecting multiple quantum processing units (QPUs) in clusters or over networks, quantum communication requires entanglement to be generated and distributed over distances. Using entanglement, the remote CX protocol can be performed, which allows the application of the CX gate involving qubits located in different QPUs. In this work, we use a specialized simulation framework for a high-level evaluation of the impact of the protocol when executed under noise in various network configurations using different number of QPUs. We compare naive and graph partitioning qubit assignment strategies and how they affect the fidelity in experiments run on Grover, GHZ, VQC, and random circuits. The results provide insights on how QPU and network configurations or naive scheduling can degrade performance.

</details>


### [74] [Lee-Yang tensors and Hamiltonian complexity](https://arxiv.org/abs/2602.03605)
*Benjamin Wong,Sergey Bravyi,David Gosset,Yinchen Liu*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: A complex tensor with $n$ binary indices can be identified with a multilinear polynomial in $n$ complex variables. We say it is a Lee-Yang tensor with radius $r$ if the polynomial is nonzero whenever all variables lie in the open disk of radius $r$. In this work we study quantum states and observables which are Lee-Yang tensors when expressed in the computational basis. We first review their basic properties, including closure under tensor contraction and certain quantum operations. We show that quantum states with Lee-Yang radius $r > 1$ can be prepared by quasipolynomial-sized circuits. We also show that every Hermitian operator with Lee-Yang radius $r > 1$ has a unique principal eigenvector. These results suggest that $r = 1$ is a key threshold for quantum states and observables. Finally, we consider a family of two-local Hamiltonians where every interaction term energetically favors a deformed EPR state $|00\rangle + s|11\rangle$ for some $0 \leq s \leq 1$. We numerically investigate this model and find that on all graphs considered the Lee-Yang radius of the ground state is at least $r = 1/\sqrt{s}$ while the spectral gap between the two smallest eigenvalues is at least $1-s^2$. We conjecture that these lower bounds hold more generally; in particular, this would provide an efficient quantum adiabatic algorithm for the quantum Max-Cut problem on uniformly weighted bipartite graphs.

</details>


### [75] [Optimal Effective Hamiltonian for Quantum Computing and Simulation](https://arxiv.org/abs/2602.03618)
*Hao-Yu Guan,Xiao-Long Zhu,Yu-Hang Dang,Xiu-Hao Deng*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The effective Hamiltonian serves as the conceptual pivot of quantum engineering, transforming physical complexity into programmable logic; yet, its construction remains compromised by the mathematical non-uniqueness of block diagonalization, which introduces an intrinsic "gauge freedom" that standard methods fail to resolve. We address this by establishing the Least Action Unitary Transformation (LAUT) as the fundamental principle for effective models. By minimizing geometric action, LAUT guarantees dynamical fidelity and inherently enforces the preservation of symmetries--properties frequently violated by conventional Schrieffer-Wolff and Givens rotation techniques. We identify the Bloch-Brandow formalism as the natural perturbative counterpart to this principle, yielding analytic expansions that preserve symmetries to high order. We validate this framework against experimental data from superconducting quantum processors, demonstrating that LAUT quantitatively reproduces interaction rates in driven entangling gates where standard approximations diverge. Furthermore, in tunable coupler architectures, we demonstrate that the LAUT approach captures essential non-rotating-wave contributions that standard models neglect; this inclusion is critical for quantitatively reproducing interaction rates and revealing physical multi-body interactions such as $XZX+YZY$, which are verified to be physical rather than gauge artifacts. By reconciling variational optimality with analytical tractability, this work provides a systematic, experimentally validated route for high-precision system learning and Hamiltonian engineering.

</details>


### [76] [Anti-Critical Quantum Metrology](https://arxiv.org/abs/2602.03675)
*George Mihailescu,Karol Gietka*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Critical quantum metrology exploits the dramatic growth of the quantum Fisher information near quantum phase transitions to enhance the precision of parameter estimation. Traditionally, this enhancement is associated with a closing energy gap, which causes the characteristic timescales for adiabatic preparation or relaxation to diverge with increasing system size. Consequently, the apparent growth of the quantum Fisher information largely reflects the increasing evolution time induced by critical slowing down, rather than a genuine gain in metrological performance, thereby severely limiting the practical usefulness of such protocols. Here we show that the relationship between energy-gap variations, quantum Fisher information, and achievable precision is far more subtle in interacting quantum systems: enhanced sensitivity does not require a vanishing gap, and, perhaps more surprisingly, a decreasing quantum Fisher information does not necessarily imply reduced precision once the time is properly taken into account. Building on this insight, we introduce an anti-critical metrology scheme that achieves enhanced precision while the energy gap increases. We illustrate this mechanism using the quantum Rabi model, thereby identifying a route to metrological advantage that avoids the critical slowing down associated with conventional criticality.

</details>


### [77] [Universal Characterization of Quantum Vacuum Measurement Engines](https://arxiv.org/abs/2602.03706)
*Robert Czupryniak,Bibek Bhandari,Paolo Andrea Erdman,Andrew N Jordan*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Quantum measurements can inject energy into quantum systems, enabling engines whose operation is powered entirely by measurements. We develop a general theory of quantum vacuum measurement engines by introducing the quantum vacuum bending function (QVBF), a quantity that characterizes the lowering of the ground-state energy due to interactions. We show that all thermodynamic observables, including work and efficiency, are governed solely by the shape of the ground-state energy landscape encoded in the QVBF, regardless of microscopic details. We further demonstrate that work fluctuations are defined by the curvature of QVBF modulated by a model-dependent quantity, and are constrained by a generalized quantum fluctuation relation that involves the interplay between quantum Fisher information and the ground-state energy landscape. Exactly solvable models and numerical simulations of single and many-body systems confirm the theory and illustrate how the QVBF alone determines the performance of quantum vacuum measurement engines.

</details>


### [78] [Quantum Computing for Electronic Circular Dichroism Spectrum Prediction of Chiral Molecules](https://arxiv.org/abs/2602.03710)
*Amandeep Singh Bhatia,Sabre Kais*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Electronic circular dichroism (ECD) spectroscopy captures the chiroptical response of molecules, enabling absolute configuration assignment that is vital for enantioselective synthesis and drug design. The practical use of ECD spectra in predictive modeling remains restricted, as existing approaches offer limited confidence for chiral discrimination. By contrast, theoretical ECD calculations demand substantial computational effort rooted in electronic structure theory, which constrains their scalability to larger chemically diverse molecules. These limitations underscore the need for computational approaches that retain first principles physical rigor while enabling efficient and scalable prediction. Motivated by recent advances in quantum algorithms for chemistry, we introduce a variational quantum framework combined with the quantum equation of motion formalism to compute molecular properties and predict ECD spectra, implemented within a multi GPU or QPU accelerated hybrid quantum/classical workflow. We demonstrate its efficient applicability on 12 clinically relevant chiral drug molecules accessing expanded active spaces. The proposed framework is assessed by comparison with established classical wavefunction based methods, employing Coupled Cluster Singles and Doubles (CCSD) for ground-state energy benchmarks and Complete Active Space Configuration Interaction (CASCI) as the reference method for excited state energies and chiroptical properties within the same active orbital space. Notably, the quantum computed ECD spectra, obtained from chemically relevant active spaces mapped onto quantum circuits of approximately 20 to 24 qubits, exhibit near quantitative agreement with classical reference calculations, accurately reproducing spectral line shapes, Cotton effect signs, and relative peak intensities.

</details>


### [79] [Quantum Speedups for Derivative Pricing Beyond Black-Scholes](https://arxiv.org/abs/2602.03725)
*Dylan Herman,Yue Sun,Jin-Peng Liu,Marco Pistoia,Charlie Che,Rob Otter,Shouvanik Chakrabarti,Aram Harrow*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper explores advancements in quantum algorithms for derivative pricing of exotics, a computational pipeline of fundamental importance in quantitative finance. For such cases, the classical Monte Carlo integration procedure provides the state-of-the-art provable, asymptotic performance: polynomial in problem dimension and quadratic in inverse-precision. While quantum algorithms are known to offer quadratic speedups over classical Monte Carlo methods, end-to-end speedups have been proven only in the simplified setting over the Black-Scholes geometric Brownian motion (GBM) model. This paper extends existing frameworks to demonstrate novel quadratic speedups for more practical models, such as the Cox-Ingersoll-Ross (CIR) model and a variant of Heston's stochastic volatility model, utilizing a characteristic of the underlying SDEs which we term fast-forwardability. Additionally, for general models that do not possess the fast-forwardable property, we introduce a quantum Milstein sampler, based on a novel quantum algorithm for sampling Lévy areas, which enables quantum multi-level Monte Carlo to achieve quadratic speedups for multi-dimensional stochastic processes exhibiting certain correlation types.
  We also present an improved analysis of numerical integration for derivative pricing, leading to substantial reductions in the resource requirements for pricing GBM and CIR models. Furthermore, we investigate the potential for additional reductions using arithmetic-free quantum procedures. Finally, we critique quantum partial differential equation (PDE) solvers as a method for derivative pricing based on amplitude estimation, identifying theoretical barriers that obstruct achieving a quantum speedup through this approach. Our findings significantly advance the understanding of quantum algorithms in derivative pricing, addressing key challenges and open questions in the field.

</details>


### [80] [Distributed Phase-Insensitive Displacement Sensing](https://arxiv.org/abs/2602.03727)
*Piotr T. Grochowski,Matteo Fadel,Radim Filip*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Distributed quantum sensing leverages quantum correlations among multiple sensors to enhance the precision of parameter estimation beyond classical limits. Most existing approaches target phase estimation and rely on a shared phase reference between the signal and the probe, yet many relevant scenarios deal with regimes where such a reference is absent, making the estimation of force or field amplitudes the main task. We study this phase-insensitive regime for bosonic sensors that undergo identical displacements with common phases randomly varying between experimental runs. We derive analytical bounds on the achievable precision and show that it is determined by first-order normal correlations between modes in the probe state, constrained by their average excitations. These correlations yield a collective sensitivity enhancement over the standard quantum limit, with a gain that grows linearly in the total excitation number, revealing a distributed quantum advantage even without a global phase reference. We identify families of multimode states with definite joint parity that saturate this limit and can be probed efficiently via local parity measurements already demonstrated or emerging in several quantum platforms. We further demonstrate that experimentally relevant decoherence channels favor two distinct sensing strategies: splitting of a single-mode nonclassical state among the modes, which is robust to loss and heating, and separable probes, which are instead resilient to dephasing and phase jitter. Our results are relevant to multimode continuous platforms, including trapped-ion, solid-state mechanical, optomechanical, superconducting, and photonic systems.

</details>


### [81] [Detecting quantum noise of a solid-state spin ensemble with dispersive measurement](https://arxiv.org/abs/2602.03734)
*Mikhail Mamaev,Jayameenakshi Venkatraman,Martin Koppenhöfer,Ania C. Bleszynski Jayich,Aashish A. Clerk*

Main category: quant-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We theoretically explore protocols for measuring the spin polarization of an ensemble of solid-state spins, with precision at or below the standard quantum limit. Such measurements in the solid-state are challenging, as standard approaches based on optical fluorescence are often limited by poor readout fidelity. Indirect microwave resonator-mediated measurements provide an attractive alternative, though a full analysis of relevant sources of measurement noise is lacking. In this work we study dispersive readout of an inhomogeneously broadened spin ensemble via coupling to a driven resonator measured via homodyne detection. We derive generic analytic conditions for when the homodyne measurement can be limited by the fundamental spin-projection noise, as opposed to microwave-drive shot noise or resonator phase noise. By studying fluctuations of the measurement record in detail, we also propose an experimental protocol for directly detecting spin squeezing, i.e. a reduction of the spin ensemble's intrinsic projection noise from entanglement. Our protocol provides a method for benchmarking entangled states for quantum-enhanced metrology.

</details>


<div id='cond-mat.stat-mech'></div>

# cond-mat.stat-mech [[Back]](#toc)

### [82] [Thermalization in classical systems with discrete phase space](https://arxiv.org/abs/2602.02681)
*Pavel Orlov,Enej Ilievski*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了具有局部相互作用和离散相空间的孤立经典系统中统计力学的出现，提出热化源于有效的局部遍历性而非全局遍历性，并提出了经典版本的本征态热化假说的框架。


<details>
  <summary>Details</summary>
Motivation: 探讨在不具备全局遍历性的条件下，孤立经典系统如何实现热化，以统一理解经典与量子系统中的热化现象。

Method: 通过分析幺正演化算符的谱，并提出一个描述局域可观测量在本征函数基底下统计特性的试探性假设（即经典的本征态热化假说）。

Result: 发现局域动力学呈现伪随机行为时可实现有效热化，且该机制不依赖于全局遍历性。

Conclusion: 建立了经典离散系统中基于局部遍历性的热化理论框架，为经典与量子系统的热化提供了统一视角。

Abstract: We study the emergence of statistical mechanics in isolated classical systems with local interactions and discrete phase spaces. We establish that thermalization in such systems does not require global ergodicity; instead, it arises from effective local ergodicity, where dynamics in a subsystem may appear pseudorandom. To corroborate that, we analyze the spectrum of the unitary evolution operator and propose an ansatz to describe statistical properties of local observables expanded in the eigenfunction basis - the classical counterpart of the Eigenstate Thermalization Hypothesis. Our framework provides a unified perspective on thermalization in classical and quantum systems with discrete spectra.

</details>


### [83] [Quantum phase transition in transverse-field Ising model on Sierpiński gasket lattice](https://arxiv.org/abs/2602.02904)
*Tymoteusz Braciszewski,Oliwier Urbański,Piotr Tomczak*

Main category: cond-mat.stat-mech

TL;DR: 研究了谢尔宾斯基垫片上横向场伊辛模型的量子相变，通过有限尺寸缩放和数值重正化群方法确定了临界耦合和临界指数。结果表明，分形几何显著影响量子涨落行为，导致不同于一维和平均场情况的新临界行为。


<details>
  <summary>Details</summary>
Motivation: 探索分形结构对量子相变的影响，特别是在非整数维度系统中临界行为的变化。

Method: 采用有限尺寸缩放和数值重正化群方法，在11和15自旋的谢尔宾斯基垫片上进行计算，并在一维精确可解链上验证方法的准确性。

Result: 发现量子临界点位于λ_c ≈ 2.72–2.93，临界指数为z≈0.84，ν≈1.12，β≈0.30，γ≈2.54；数值重正化群给出λ_c=2.765，β=0.306，支持主要结果；有效临界维度约为2.43。

Conclusion: 分形几何抑制了量子涨落，导致动力学指数z降低，临界行为介于一维与平均场之间，展现出独特的普适类。

Abstract: We study quantum phase transition in the transverse-field Ising model on the Sierpiński gasket. By applying finite-size scaling and numerical renormalization group methods, we determine the critical coupling and the exponents that describe this transition. We first checked our finite-size scaling and the renormalization methods on the exactly solvable one-dimensional chain, where we recovered proper values of critical couplings and exponents. Then, we applied the method to the Sierpiński gasket with 11 and 15 spins. We found a quantum critical point at $λ_c \approx 2.72$ to $2.93$, with critical exponents $z\approx0.84$, $ν\approx 1.12 $, $β\approx 0.30$, and $γ\approx 2.54$. The lower dynamical exponent $z$ indicates that quantum fluctuations slow down due to fractal geometry, yielding an effective critical dimension of about 2.43. The numerical renormalization group method yielded similar results $λ_c = 2.765$, $β= 0.306$, supporting our findings. These exponents differ from those in both the one-dimensional and mean-field cases.

</details>


### [84] [Violation of local equilibrium thermodynamics in one-dimensional Hamiltonian-Potts model](https://arxiv.org/abs/2602.02946)
*Hitomi Endo,Michikazu Kobayashi*

Main category: cond-mat.stat-mech

TL;DR: 本研究通过引入分数阶空间导数的一维哈密顿-波茨模型，数值研究了非平衡态下一级相变中的相共存现象。结果表明，在稳态热传导下，有序和无序相可稳定共存，且界面温度偏离平衡相变温度，违背局域平衡假设。这一偏离表明，稳态热流可以稳定并调控平衡亚稳态，且模拟结果与非平衡稳态的全局热力学预测定量一致。


<details>
  <summary>Details</summary>
Motivation: 探索在非平衡条件下一级相变中相共存的本质特征，特别是打破局域平衡假设的机制，并建立一个低维、可控的模型来研究非平衡稳态下热力学描述的适用极限。

Method: 采用具分数阶空间导数的一维哈密顿-波茨模型，通过数值模拟再现二维系统低波数态密度，实现一维系统中的相共存；施加边界热浴以维持恒定热流，研究稳态热传导下的相行为。

Result: 观察到有序与无序相在稳态界面下的稳定共存；界面温度系统性偏离平衡相变温度，显示局域平衡失效；该偏离表明热流可稳定和控制平衡亚稳态；模拟所得界面温度与非平衡稳态的全局热力学理论预测定量吻合。

Conclusion: 非平衡一级相变中局域平衡的破坏以及亚稳态的稳定化是内在特性，不依赖于空间维度；本研究提供了一个极简且可控的数值模型，用于探究非平衡稳态下热力学描述的基本极限。

Abstract: We investigate non-equilibrium phase coexistence associated with a first-order phase transition by numerically studying a one-dimensional Hamiltonian-Potts model with fractional spatial derivatives. The fractional derivative is introduced so as to reproduce the low-wavenumber density of states of the standard two-dimensional model, allowing phase coexistence to occur in a minimal one-dimensional setting under steady heat conduction. By imposing a constant heat flux through boundary heat baths, we observe stable coexistence of ordered and disordered phases separated by a stationary interface. We find that the temperature at the interface systematically deviates from the equilibrium transition temperature, demonstrating a clear violation of the local equilibrium description. This deviation indicates that equilibrium metastable states can be stabilized and controlled by a steady heat current. Furthermore, the interface temperature obtained in our simulations is in quantitative agreement with the prediction of global thermodynamics for non-equilibrium steady states. These results confirm that the breakdown of local equilibrium and the stabilization of metastable states are intrinsic features of non-equilibrium first-order phase transitions, independent of spatial dimensionality. Our study thus provides a minimal and controlled numerical model for exploring the fundamental limits of thermodynamic descriptions in non-equilibrium steady states.

</details>


### [85] [Solving models with generalized free fermions I: Algebras and eigenstates](https://arxiv.org/abs/2602.03431)
*Kohei Fukai,Balázs Pozsgay,István Vona*

Main category: cond-mat.stat-mech

TL;DR: 研究了通过隐藏的自由费米子结构可解的量子自旋链，建立了与图-克利福德或拟克利福德代数的联系，并引入了“定义表示”，在XY模型和Fendley的“伪装自由费米子”模型中展示了其应用。


<details>
  <summary>Details</summary>
Motivation: 探索量子自旋链中隐藏的自由费米子结构及其代数基础，以加深对这类可解模型的理解。

Method: 分析相关代数结构，引入定义表示，并研究反对称组合的哈密顿量在模型无关情况下的性质。

Result: 发现定义表示与XY模型和Fendley模型中的哈密顿量项一致；对于反对称组合存在参考态，且可通过费米子算符构造少数体本征态。

Conclusion: 揭示了特定量子自旋链模型背后的代数结构，并提供了构建本征态的新方法，增强了对自由费米子结构在可解模型中作用的理解。

Abstract: We study quantum spin chains solvable via hidden free fermionic structures. We study the algebras behind such models, establishing connections to the mathematical literature of the so-called ``graph-Clifford'' or ``quasi-Clifford'' algebras. We also introduce the ``defining representation'' for such algebras, and show that this representation actually coincides with the terms of the Hamiltonian in two relevant models: the XY model and the ``free fermions in disguise'' model of Fendley. Afterwards we study a particular anti-symmetric combination of commuting Hamiltonians; this is performed in a model independent way. We show that for this combination there exists a reference state, and few body eigenstates can be created by the fermionic operators. Concrete application is presented in the case of the ``free fermions in disguise'' model.

</details>


### [86] [Stochastic Thermodynamics of Quantum-Induced Stochastic Dynamics](https://arxiv.org/abs/2602.03764)
*Pedro V. Paraguassú*

Main category: cond-mat.stat-mech

TL;DR: 提出了一种量子诱导的随机动力学的热力学框架，考虑了非平衡量子特性对第二定律的修正。


<details>
  <summary>Details</summary>
Motivation: 研究经典系统与量子环境耦合下的热力学行为，特别是在动态浴中同时交换热量和做功的情况。

Method: 构建了一个半经典区域的热力学框架，定义了热量、功和熵产生，并推导出考虑量子特性的修正第二定律。

Result: 在光机械系统中验证了该框架，描述了腔场引起的非平稳噪声的热力学特性。

Conclusion: 该框架能够有效描述量子环境对经典系统的非平衡热力学影响。

Abstract: Quantum-Induced Stochastic Dynamics arises from the coupling between a classical system and a quantum environment. Unlike standard thermal reservoirs, this environment acts as a dynamic bath, capable of simultaneously exchanging heat and performing work. We formulate a thermodynamic framework for this semi-classical regime, defining heat, work, and entropy production. We derive a modified Second Law that accounts for non-equilibrium quantum features, such as squeezing. The framework is exemplified by an optomechanical setup, where we characterize the thermodynamics of the non-stationary noise induced by the cavity field.

</details>


### [87] [The Mpemba effect in the Descartes protocol: A time-delayed Newton's law of cooling approach](https://arxiv.org/abs/2602.03790)
*Andrés Santos*

Main category: cond-mat.stat-mech

TL;DR: 本文研究了在时间延迟的牛顿冷却定律框架下的直接和逆向Mpemba效应，提出了一种名为Descartes协议的三储层热方案，通过引入单步淬火时间的不同，清晰分离了延迟时间、等待时间和归一化高温的作用。该方法为异常热弛豫提供了灵活的表征手段，并得出了瞬时淬火下Mpemba效应存在的精确条件及其最大值的近似表达式。


<details>
  <summary>Details</summary>
Motivation: 为了更深入理解Mpemba效应（即热水比冷水更快结冰的现象）在非平衡热力学中的机制，特别是考虑时间延迟和多步热过程的影响，本文旨在建立一个可解析处理的统一框架来系统分析该效应的产生条件与调控参数。

Method: 引入并分析了Descartes协议——一种包含三个热库的热传导模型，每个样本在不同时间进行单步淬火；利用时间延迟的牛顿冷却定律，推导出瞬时淬火下Mpemba效应存在的精确条件，并给出最优归一化温度和效应最大强度的紧凑近似表达式；进一步将分析扩展到有限速率淬火情形。

Result: 得到了Mpemba效应存在所需的归一化高温ω的边界条件；发现效应在特定ω=ω̃(t_w)时达到最大，且其最大幅度Mp(t_w)有明确表达式；绝对最大值出现在t_w = τ时；相比两储层协议，尽管Descartes协议多一个控制参数，但其最大效应更小；在有限速率淬火中，严格条件下无法实现真正的Mpemba效应，但在浴时间尺度足够短时仍可观察到近似效应。

Conclusion: Descartes协议为研究Mpemba效应提供了一个统一且可解析求解的理论框架，能够清晰揭示延迟时间、等待时间和初始温度之间的耦合关系；虽然该协议未能增强效应的最大强度，但其灵活性适用于其他多步热协议的研究，拓展了对非平衡热弛豫现象的理解。

Abstract: We investigate the direct and inverse Mpemba effects within the framework of the time-delayed Newton's law of cooling by introducing and analyzing the Descartes protocol, a three-reservoir thermal scheme in which each sample undergoes a single-step quench at different times. This protocol enables a transparent separation of the roles of the delay time $τ$, the waiting time $t_{\text{w}}$, and the normalized warm temperature $ω$, thus providing a flexible setting to characterize anomalous thermal relaxation. For instantaneous quenches, exact conditions for the existence of the Mpemba effect are obtained as bounds on $ω$ for given $τ$ and $t_{\text{w}}$. Within those bounds, the effect becomes maximal at a specific value $ω=\widetildeω(t_{\text{w}})$, and its magnitude is quantified by the extremal value of the temperature-difference function at this optimum. Accurate and compact approximations for both $\widetildeω(t_{\text{w}})$ and the maximal magnitude $\text{Mp}(t_{\text{w}})$ are derived, showing in particular that the absolute maximum at fixed $τ$ is reached for $t_{\text{w}}=τ$. A comparison with a previously studied two-reservoir protocol reveals that, despite its additional control parameter, the Descartes protocol yields a smaller maximal magnitude of the effect. The analysis is extended to finite-rate quenches, where strict equality of bath conditions prevents a genuine Mpemba effect, although an approximate one survives when the bath time scale is sufficiently short. The developed framework offers a unified and analytically tractable approach that can be readily applied to other multi-step thermal protocols.

</details>


### [88] [Emergent correlations in the selected link-times along optimal paths](https://arxiv.org/abs/2602.03800)
*Iván Álvarez Domenech,Javier Rodríguez-Laguna,Pedro Córdoba-Torres,Silvia N. Santalla*

Main category: cond-mat.stat-mech

TL;DR: 研究了第一通过渗流中选定路径时间（SLTs）的统计特性，发现其平均值和标准差随距离呈普适幂律衰减，并表现出与KPZ普适类相关的长程关联；SLT分布不满足中心极限定理条件，其和服从KPZ类特有的Tracy-Widom分布。


<details>
  <summary>Details</summary>
Motivation: 理解弱无序方格 lattice 中最优路径上链接时间的统计行为及其与KPZ普适类的关系。

Method: 在属于KPZ普适类的弱无序平方格子上分析对角线和轴向路径的SLT统计特性，研究均值、标准差、相关性和分布形式。

Result: 发现SLT的平均值和标准差随端到端距离呈普适幂律衰减；存在与KPZ指数相关的长程相关性；对角和轴向路径的SLT分布有显著差异；SLT和不服从中心极限定理，而是符合Tracy-Widom分布。

Conclusion: SLT的统计特性由KPZ普适类决定，且高阶长程相关性导致系统偏离经典极限行为，支持KPZ类中非平凡波动现象的存在。

Abstract: In the context of first-passage percolation (FPP), we investigate the statistical properties of the selected link-times (SLTs) -the random link times comprising the optimal paths (or geodesics) connecting two given points. We focus on weakly disordered square lattices, whose geodesics are known to fall under the Kardar-Parisi-Zhang (KPZ) universality class. Our analysis reveals universal power-law decays with the end-to-end distance for both the average and standard deviation of the SLTs, along with an intricate pattern of long-range correlations, whose scaling exponents are directly linked to KPZ universality. Crucially, the SLT distributions for diagonal and axial paths exhibit significant differences, which we trace back to the distinct directed and undirected nature, respectively, of the underlying geodesics. Moreover, we demonstrate that the SLT distribution violates the conditions of the central limit theorem. Instead, SLT sums follow the Tracy-Widom distribution characteristic of the KPZ class, which we associate with evidence for the emergence of high-order long-range correlations in the ensemble.

</details>


<div id='physics.comp-ph'></div>

# physics.comp-ph [[Back]](#toc)

### [89] [Transformation front kinetics in deformable ferromagnets](https://arxiv.org/abs/2602.03745)
*Michael Poluektov*

Main category: physics.comp-ph

TL;DR: 本文提出了一种在多场耦合条件下（磁-力）描述可变形磁性材料中相界传播的热力学驱动力推导方法，并采用切割有限元法高效模拟相变前沿的运动，无需修改网格，应用于磁性形状记忆合金的定性建模。


<details>
  <summary>Details</summary>
Motivation: 现有对可变形铁磁材料中相界动力学的研究存在局限，缺乏在一般磁-力耦合框架下的统一热力学驱动力表达及高效的数值计算方法。

Method: 基于连续介质热力学推导相界传播的热力学驱动力，并结合切割有限元法（cut-FEM）实现对移动相界面的高效数值模拟，避免了传统方法中频繁重构网格的问题。

Result: 成功建立了适用于一般磁-力耦合系统的相界动力学模型，实现了无需网格调整的高效相变前沿模拟，并对磁性形状记忆合金的力学行为进行了定性预测。

Conclusion: 该方法为研究具有相变行为的多功能磁性材料提供了一个通用且高效的理论与数值框架，有望推广至其他多场耦合材料系统。

Abstract: Materials such as magnetic shape-memory alloys possess an intrinsic coupling between material's magnetisation and mechanical deformation. These materials also undergo structural phase transitions, with phase boundaries separating different phases and the kinetics of the phase boundaries governed by the magnetic field and the mechanical stresses. There is a multiplicity of other materials revealing similar phenomena, e.g. magnetic perovskites. To model the propagation of the phase boundaries in deformable magnetic materials at the continuum scale, three ingredients are required: a set of governing equations for the bulk behaviour with coupled magnetic and mechanical degrees of freedom, a dependency of the phase boundary velocity on the governing factors, and a reliable computational method. The expression for the phase boundary velocity is usually obtained within the continuum thermodynamics setting, where the entropy production due to phase boundary propagation is derived, which gives a thermodynamic driving force for the phase boundary kinetics. For deformable ferromagnets, all three elements (bulk behaviour, interface kinetics, and computational approaches) have been explored, but under a number of limitations. The present paper focuses on the derivation of the thermodynamic driving force for transformation fronts in a general magneto-mechanical setting, adapts the cut-finite-element method for transformation fronts in magneto-mechanics, which allows for an exceptionally efficient handling of the propagating interfaces, without modifying the finite-element mesh, and applies the developments to qualitative modelling of magneto-mechanics of magnetic shape-memory alloys.

</details>


<div id='math.NA'></div>

# math.NA [[Back]](#toc)

### [90] [Error Analysis of Matrix Multiplication Emulation Using Ozaki-II Scheme](https://arxiv.org/abs/2602.02549)
*Yuki Uchino,Katsuhisa Ozaki,Toshiyuki Imamura*

Main category: math.NA

TL;DR: 本文对Ozaki-II方案进行了严格的确定性误差分析，阐明了其精度行为，并能够估计实现所需数值精度所需的低精度矩阵乘法次数。


<details>
  <summary>Details</summary>
Motivation: 当输入矩阵的指数分布较宽时，Ozaki-II方案的精度可能会下降，需要大量低精度矩阵乘法才能获得高精度结果。因此需要一种方法来估计达到目标精度所需的计算量。

Method: 利用中国剩余定理进行高精度矩阵乘法的模拟，通过一系列低精度矩阵乘法实现，并提出一种确定性误差分析方法。

Result: 提出的误差分析可以准确描述Ozaki-II方案的精度行为，并能有效估计为达到指定精度所需的低精度矩阵乘法次数。

Conclusion: 该分析为Ozaki-II方案的实际应用提供了理论支持，有助于在保证精度的前提下优化计算效率。

Abstract: The Ozaki-II scheme is an emulation method that leverages the Chinese Remainder Theorem to compute high-precision matrix multiplication via a sequence of low-precision matrix multiplications. In this scheme, the attainable numerical accuracy improves as the number of low-precision matrix multiplications increases. Previous numerical studies have shown that single- and double-precision matrix multiplication using the Ozaki-II scheme achieves higher throughput than that of standard BLAS routines on modern AI hardware equipped with fast INT8 matrix multiply-accumulate units with INT8 inputs and INT32 accumulation. However, the accuracy of the Ozaki-II scheme can degrade when the exponent distribution of the input matrices is wide, in which case a large number of low-precision matrix multiplications is required to obtain high-precision results. In this paper, we present a rigorous deterministic error analysis of the Ozaki-II scheme. The proposed analysis not only clarifies the accuracy behavior of the method but also enables the estimation of the number of low-precision matrix multiplications required to achieve a desired level of numerical accuracy.

</details>


### [91] [A space-time LATIN-PGD strategy for solving Newtonian compressible flows](https://arxiv.org/abs/2602.02616)
*Élise Foulatier,Pierre-Alain Boucard,François Louf,David Néron,Philipp Junker*

Main category: math.NA

TL;DR: 本文提出了一种基于LATIN-PGD求解器的新方法，用于高效模拟牛顿型可压缩层流流动问题，通过压力-速度解耦和时空分解实现计算加速，并在简单案例上验证了准确性。


<details>
  <summary>Details</summary>
Motivation: 为了降低复杂流动问题的高计算成本，特别是在具有压密关系的流动中，开发一种高效的数值求解方法。

Method: 采用LATIN-PGD求解器框架，利用状态方程建立压力与密度之间的直接关系，实现压力与速度场的解耦，并通过PGD方法对速度和压力场分别进行独立的时空分解。

Result: 在具有解析解的问题上验证了求解器的准确性，随后应用于更复杂的流动问题，结果与文献数据吻合良好。

Conclusion: LATIN-PGD方法在处理牛顿型可压缩层流时表现出良好的精度和潜力，未来有望扩展至更复杂的材料本构关系模拟。

Abstract: Simulating flow problems is at the core of many engineering applications but often requires high computational effort, especially when dealing with complex models. This work presents a novel approach for resolving flow problems using the LATIN-PGD solver. In this contribution, we place ourselves within the framework of Newtonian compressible and laminar flows. This specific and relatively simple case enables focusing on flows for which a state equation provides a direct relation between pressure and density. It is then possible to use the LATIN solver to set up a pressure-velocity decoupling algorithm. Moreover, Proper Generalised Decomposition (PGD) is natively included in the solver and yields two independent space-time decompositions for the velocity and the pressure fields. As a first step, the solver is validated on a problem for which an analytical solution is available. It is then applied to slightly more complex problems. The results show good agreement with the literature, and we expect that the solver could be used to compute more complicated material laws in the future.

</details>


### [92] [Fully Automated Adaptive Parameter Selection for 3-D High-order Nyström Boundary Integral Equation Methods](https://arxiv.org/abs/2602.03178)
*Davit Aslanyan,Constantine Sideris*

Main category: math.NA

TL;DR: 提出了一种自适应的基于Chebyshev的边界积分方程求解器，用于光滑完美电导体的电磁散射问题，实现了高精度、自动化和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 避免手动调参，提升求解器在不同几何形状下的鲁棒性和自动化程度。

Method: 引入统一的自适应积分策略，自动选择近奇异相互作用距离，并采用高斯-克朗罗德或Clenshaw-Curtis规则自适应计算自作用和近奇异积分。

Result: 数值结果表明，该方法在标准和复杂CAD几何上均能达到与最优固定网格方法相当的精度和收敛速度。

Conclusion: 所提出的自适应CBIE求解器在保持高效的同时，实现了高阶精度、自动化和对电大尺寸复杂几何问题的可扩展性。

Abstract: We present an adaptive Chebyshev-based Boundary Integral Equation (CBIE) solver for electromagnetic scattering from smooth perfect electric conductor (PEC) objects. The proposed approach eliminates manual parameter tuning by introducing (i) a unified adaptive quadrature strategy for automatic selection of the near-singular interaction distance and (ii) an adaptive computation of all self- and near-singular precomputation integrals to a prescribed accuracy using Gauss-Kronrod (h-adaptive) or Clenshaw-Curtis (p-adaptive) rules and singularity-resolving changes of variables. Both h-adaptive and p-adaptive schemes are explored within this framework, ensuring high-order accuracy and robustness across a broad range of geometries without loss of efficiency. Numerical results for canonical and complex CAD geometries demonstrate that the adaptive solver achieves accuracy and convergence rates comparable to optimally tuned fixed-grid CBIE implementations, while offering automation and scalability to electrically large, geometrically complex problems.

</details>


### [93] [Scaling Optimized Spectral Approximations on Unbounded Domains: The Generalized Hermite and Laguerre Methods](https://arxiv.org/abs/2602.03083)
*Hao Hu,Haijun Yu*

Main category: math.NA

TL;DR: 提出了一种用于缩放广义拉盖尔和广义厄米逼近的新型误差分析框架，能够预测经典方法无法捕捉的收敛行为，并为选择最优缩放因子提供系统指导。


<details>
  <summary>Details</summary>
Motivation: 现有经典理论在描述拉盖尔和厄米逼近的收敛性方面存在局限，无法准确预测复杂收敛行为，因此需要一种更强大的误差分析框架。

Method: 构建了一个类比于奈奎斯特-香农采样定理的误差分析框架，通过刻画空间和频率带宽来分析函数在拉盖尔或厄米采样点下的逼近能力，并研究不同函数特性对收敛速率的影响。

Result: 该框架能有效预测根指数收敛等复杂行为；提供了最优缩放因子的选择准则；发现具有相似衰减和振荡特性的函数可能表现出显著不同的收敛速率；双组拉盖尔函数串联逼近优于单组厄米函数逼近。

Conclusion: 所提出的框架比经典理论更强大，不仅提升了对广义拉盖尔和厄米逼近的理解，还为实际应用中的基函数选择和参数优化提供了系统性指导。

Abstract: We propose a novel error analysis framework for scaled generalized Laguerre and generalized Hermite approximations.This framework can be regarded as an analogue of the Nyquist-Shannon sampling theorem: It characterizes the spatial and frequency bandwidths that can be effectively captured by Laguerre or Hermite sampling points. Provided a function satisfies the corresponding bandwidth constraints, it can be accurately approximated within this framework. The proposed framework is notably more powerful than classical theory -- it not only provides systematic guidance for choosing the optimal scaling factor, but also predicts root-exponential and other intricate convergence behaviors that classical approaches fail to capture. Leveraging this framework, we conducted a detailed comparative study of Hermite and Laguerre approximations. We find that functions with similar decay and oscillation characteristics may nonetheless display markedly different convergence rates. Furthermore, approximations based on two concatenated sets of Laguerre functions may offer significant advantages over those using a single set of Hermite functions.

</details>


### [94] [The High Cost of Data Augmentation for Learning Equivariant Models](https://arxiv.org/abs/2602.03118)
*Henri Klintebäck,Christoph Ortner,Lior Silberman*

Main category: math.NA

TL;DR: 本文研究了通过数据增强方法改进哈密顿系统中连续对称性近似保持的两种策略，提出基于紧致李群上哈尔测度的求积规则可实现多项式模型中的精确对称性保持，而随机采样方法仅具有对称化误差的平方根收敛速率。


<details>
  <summary>Details</summary>
Motivation: 尽管诺特定理表明哈密顿系统中的连续对称性对应守恒量，但数据驱动模型并不总是显式地强制执行这些对称性，关于是否应在模型结构中编码对称性仍存在争议。

Method: 采用基于哈尔测度的求积规则和随机采样两种数据增强方法，分析其在保持模型对称性方面的性能，并结合理论证明与实验验证。

Result: 理论和实验证明，基于求积规则的数据增强可在多项式模型中实现精确的对称性保持，而随机采样方法仅达到对称化误差的平方根收敛速率。

Conclusion: 在数据驱动模型中，采用基于哈尔测度求积规则的数据增强是比随机采样更优的对称性保持策略，尤其适用于需要精确对称性的物理系统建模。

Abstract: According to Noether's theorem the presence of a continuous symmetry in a Hamiltonian systems is equivalent to the existence of a conserved quantity, yet these symmetries are not always explicitly enforced in data-driven models. There remains a debate whether or not encoding of symmetry into a model architecture is the optimal approach. A competing approach is to target approximate symmetry through data augmentation. In this work, we study two approaches aimed at improving the symmetry properties of such an approximation scheme: one based on a quadrature rule for the Haar measure on the compact Lie group encoding the continuous symmetry of interest and one based on a random sampling of that Haar measure. We demonstrate both theoretically and empirically that the quadrature augmentation leads to exact symmetry preservation in polynomial models, while the random augmentation has only square-root convergence of the symmetrization error.

</details>


### [95] [Event-Level Probabilistic Prediction of Extreme Rainfall over India Using Physics-Gated Latent Dynamics](https://arxiv.org/abs/2602.03166)
*Arun Govind Neelan*

Main category: math.NA

TL;DR: 本研究提出了一种物理门控的连续时间潜变量模型（PG-LODE），用于印度季风区极端降雨事件的概率预测，相比传统ConvLSTM方法显著提升了事件检出率和预测可靠性。


<details>
  <summary>Details</summary>
Motivation: 极端降雨难以在日尺度上准确预测，主要由于对流触发的随机性和多尺度大气相互作用，而大尺度环流场虽提供背景信息，却难以精确定位极端事件。因此需要更有效的模型来提升事件级预测能力。

Method: 利用ERA5再分析资料构建大尺度大气环境输入，采用基于物理门控机制调制的潜变量常微分方程框架（PG-LODE）建模大气连续时间演化过程，并与自适应ConvLSTM基线模型对比，以印度气象局网格化降水数据中局部95百分位定义极端事件，进行像素级和事件级（瓦片）验证。

Result: 像素级评估显示两模型均受限于空间位移误差，但在事件级瓦片验证中，PG-LODE显著优于ConvLSTM：前者实现了接近完全的极端事件检出率（远高于后者的27%），更高的临界成功指数和适度的误报率。

Conclusion: 物理门控的连续时间潜变量动态建模为将大尺度大气可预报性转化为可靠的极端降雨风险评估提供了有效路径。

Abstract: Extreme rainfall over the Indian monsoon region poses severe societal and infrastructural risks but remains difficult to predict at daily time scales due to stochastic convective triggering and multiscale atmospheric interactions. While large-scale atmospheric fields provide important environmental context, their ability to localize extreme rainfall events is fundamentally limited. In this study, we examine how large-scale atmospheric information from ERA5 reanalysis can be leveraged for event-level probabilistic prediction of daily rainfall extremes over India. We compare an adaptive ConvLSTM baseline with a proposed Physics-Gated Latent Ordinary Differential Equation (PG-LODE) framework, which models atmospheric evolution as a continuous-time latent process whose dynamics are explicitly modulated by a physics-based gating mechanism under convectively unstable conditions. Extreme events are defined using the local 95th percentile of the India Meteorological Department gridded rainfall dataset during the June to September monsoon season. Pixel-wise evaluation shows limited skill for both models due to spatial displacement errors, whereas event-level tile-based verification reveals a clear performance contrast. The ConvLSTM remains highly conservative, detecting only 27 percent of extreme events, while PG-LODE achieves near-complete detection with a substantially higher critical success index and a moderate false alarm rate. These results demonstrate that physics-gated continuous-time latent dynamics offer a robust pathway for translating large-scale atmospheric predictability into reliable assessments of extreme rainfall risk.

</details>


### [96] [Deterministic and randomized Kaczmarz methods for $AXB=C$ with applications to color image restoration](https://arxiv.org/abs/2602.03239)
*Wenli Wang,Duo Liu,Gangrong Qu,Michiel E. Hochstenbach*

Main category: math.NA

TL;DR: 提出了一种求解线性矩阵方程的块Kaczmarz方法及其随机和确定性变体，并验证了其在彩色图像恢复中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决一致线性矩阵方程的高效求解问题，特别是针对大规模问题设计更有效的迭代算法。

Method: 提出了块Kaczmarz (BK) 方法，并进一步发展了贪婪随机块Kaczmarz (GRBK)、松弛变体 (RGRBK) 和确定性版本 (MWRBK)，采用循环行选择策略和收敛性分析。

Result: 推导了BK方法在一个周期内的矩阵公式，证明了所提方法的收敛性，并通过数值实验验证了理论结果。

Conclusion: 所提出的块Kaczmarz类方法在理论上具有良好的收敛性，并在彩色图像恢复应用中表现出良好性能。

Abstract: We study Kaczmarz type methods to solve consistent linear matrix equations. We first present a block Kaczmarz (BK) method that employs a deterministic cyclic row selection strategy. Assuming that the associated coefficient matrix has full column or row rank, we derive matrix formulas for a cycle of this BK method. Moreover, we propose a greedy randomized block Kaczmarz (GRBK) method and further extend it to a relaxed variant (RGRBK) and a deterministic counterpart (MWRBK). We establish the convergence properties of the proposed methods. Numerical tests verify the theoretical findings, and we apply the proposed methods to color image restoration problems.

</details>


### [97] [Physics informed learning of orthogonal features with applications in solving partial differential equations](https://arxiv.org/abs/2602.03247)
*Qianxing Jia,Dong Wang*

Main category: math.NA

TL;DR: 提出了一种物理驱动的正交特征方法（PD-OFM），通过物理信息预训练和正交正则化构造针对微分算子和计算域定制的特征表示，显著提升随机特征方法在求解偏微分方程时的逼近能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 标准随机特征方法因缺乏对物理规律和几何结构的感知而限制了逼近能力，因此需要一种能融合物理信息并增强特征基正交性的新方法。

Method: 提出PD-OFM框架，通过物理信息目标函数进行特征预训练，并引入正交正则化，构建接近正交且符合物理规律的特征基。

Result: 在Helmholtz、Poisson、波动和Navier-Stokes方程上，PD-OFM的残差误差比现有方法低2-3个数量级，且预训练特征可跨不同源项和几何域有效迁移。

Conclusion: 物理信息预训练结合正交正则化显著提升了特征空间的逼近能力和泛化性，PD-OFM为高效求解PDE提供了新思路。

Abstract: The random feature method (RFM) constructs approximation spaces by initializing features from generic distributions, which provides universal approximation properties to solve general partial differential equations. However, such standard initializations lack awareness of the underlying physical laws and geometry, which limits approximation. In this work, we propose the Physics-Driven Orthogonal Feature Method (PD-OFM), a framework for constructing feature representations that are explicitly tailored to both the differential operator and the computational domain by pretraining features using physics-informed objectives together with orthogonality regularization. This pretraining strategy yields nearly orthogonal feature bases. We provide both theoretical and empirical evidence that physics-informed pretraining improves the approximation capability of the learned feature space. When employed to solve Helmholtz, Poisson, wave, and Navier-Stokes equations, the proposed method achieves residual errors 2-3 orders of magnitude lower than those of comparable methods. Furthermore, the orthogonality regularization improves transferability, enabling pretrained features to generalize effectively across different source terms and domain geometries for the same PDE.

</details>


### [98] [Weighted finite difference methods for a nonlinear Klein--Gordon equation with high oscillations in space and time](https://arxiv.org/abs/2602.03322)
*Yanyan Shi,Christian Lubich*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider a nonlinear Klein--Gordon equation in the nonrelativistic limit regime with initial data in the form of a modulated highly oscillatory exponential. In this regime of a small scaling parameter $\varepsilon$, the solution exhibits rapid oscillations in both time and space, posing challenges for numerical approximation. We propose an explicit and an implicit exponentially weighted finite difference method. While the explicit weighted leapfrog method needs to satisfy a CFL-type stability condition, the implicit weighted Crank--Nicolson method is unconditionally stable. Both methods achieve second-order accuracy with time steps and mesh sizes that are not restricted in magnitude by $\varepsilon$. The methods are uniformly convergent in the range from arbitrarily small to moderately bounded $\varepsilon$. Numerical experiments illustrate the theoretical results.

</details>


### [99] [A Comparative Study of Low-Dissipation Numerical Schemes for Hyperbolic Conservation Laws](https://arxiv.org/abs/2602.03348)
*Shaoshuai Chu,Michael Herty*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This work provides a comparative assessment of several low-dissipation numerical schemes for hyperbolic conservation laws, highlighting their performance relative to the classical Harten-Lax-van Leer (HLL) schemes. The schemes under consideration include the classical Harten-Lax-van Leer-Contact (HLLC), the recently proposed TV flux splitting, the low-dissipation Central-Upwind (LDCU), and the local characteristic decomposition-based Central-Upwind (LCDCU) schemes. These methods are extended to higher orders of accuracy, up to the fifth order, within both finite-volume and finite-difference frameworks. A series of numerical experiments for the one- and two-dimensional Euler equations of gas dynamics are performed to evaluate the accuracy, robustness, and computational efficiency of the studied schemes. The comparison highlights the trade-offs between resolution of contact and shear waves, robustness in the presence of shocks, and computational cost. The investigated low-dissipation schemes show comparable levels of numerical dissipation, with only subtle differences appearing in selected benchmark problems. The results provide practical guidance for selecting efficient low-dissipation solvers for the simulation of complex compressible flows.

</details>


### [100] [On singular Galerkin discretizations for three models in high-frequency scattering](https://arxiv.org/abs/2602.03428)
*T. Chaumont-Frelet,S. Sauter*

Main category: math.NA

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We consider three common mathematical models for time-harmonic high frequency scattering: the Helmholtz equation in two and three spatial dimensions, a transverse magnetic problem in two dimensions, and Maxwell's equation in three dimensions with dissipative boundary conditions such that the continuous problem is well posed. In this paper, we construct meshes for popular (low order) Galerkin finite element discretizations such that the discrete system matrix becomes singular and the discrete problem is not well posed. This implies that a condition "the finite element space has to be sufficiently rich" in the form of a resolution condition - typically imposed for discrete well-posedness - is not an artifact from the proof by a compact perturbation argument but necessary for discrete stability of the Galerkin discretization.

</details>


<div id='math.ST'></div>

# math.ST [[Back]](#toc)

### [101] [Decision-Focused Optimal Transport](https://arxiv.org/abs/2602.02800)
*Suhan Liu,Mo Liu*

Main category: math.ST

TL;DR: 提出了一种面向决策的分布距离（DF divergence），用于衡量在随机线性优化问题中目标系数服从不同分布时对决策成本的影响，相比传统度量（如KL散度、Wasserstein距离）更贴合实际，具备高效计算方法和良好的样本复杂度，适用于插值、医疗等实际场景。


<details>
  <summary>Details</summary>
Motivation: 传统分布距离（如KL散度、Wasserstein距离）无法有效反映分布变化对优化问题目标值的实际影响，因为分布改变未必改变最优解，但会影响决策成本；需要一种更贴近决策结果的距离度量。

Method: 基于最优传输思想，针对随机线性优化问题设计了多种决策导向的距离度量，包括乐观DF距离、鲁棒DF距离及其熵正则化变体，并提出高效的计算算法和样本复杂度分析。

Result: 建立了DF距离与经典分布度量之间的理论联系；证明DF距离估计避免了Wasserstein距离中的维度灾难；在新闻商问题和真实医疗数据上验证了其有效性。

Conclusion: DF divergence是一种更适用于随机优化问题的分布距离度量，能准确反映分布差异对决策成本的影响，具有良好的理论性质和实际应用价值。

Abstract: We propose a fundamental metric for measuring the distance between two distributions. This metric, referred to as the decision-focused (DF) divergence, is tailored to stochastic linear optimization problems in which the objective coefficients are random and may follow two distinct distributions. Traditional metrics such as KL divergence and Wasserstein distance are not well-suited for quantifying the resulting cost discrepancy, because changes in the coefficient distribution do not necessarily change the optimizer of the underlying linear program. Instead, the impact on the objective value depends on how the two distributions are coupled (aligned). Motivated by optimal transport, we introduce decision-focused distances under several settings, including the optimistic DF distance, the robust DF distance, and their entropy-regularized variants. We establish connections between the proposed DF distance and classical distributional metrics. For the calculation of the DF distance, we develop efficient computational methods. We further derive sample complexity guarantees for estimating these distances and show that the DF distance estimation avoids the curse of dimensionality that arises in Wasserstein distance estimation. The proposed DF distance provides a foundation for a broad range of applications. As an illustrative example, we study the interpolation between two distributions. Numerical studies, including a toy newsvendor problem and a real-world medical testing dataset, demonstrate the practical value of the proposed DF distance.

</details>


### [102] [Sharp Inequalities between Total Variation and Hellinger Distances for Gaussian Mixtures](https://arxiv.org/abs/2602.03202)
*Joonhyuk Jung,Chao Gao*

Main category: math.ST

TL;DR: 研究了高斯位置混合中总变差（TV）与Hellinger距离之间的关系，建立了一个通用上界，并证明了该界的紧性，解决了Jia et al. (2023) 提出的开放问题，实现了TV下的高斯混合熵刻画，并应用于鲁棒估计和经验贝叶斯的极小化极大遗憾界。


<details>
  <summary>Details</summary>
Motivation: 解决Jia et al. (2023) 中关于高斯混合模型中TV与Hellinger距离关系的开放问题，推动对混合分布间距离度量的理解，并为鲁棒估计和经验贝叶斯方法提供理论支持。

Method: 通过建立在紧集上的混合分布的TV距离与Hellinger距离之间的上界关系，结合渐近分析（o(1)项依赖于双重对数尺度），并构造两列混合分布序列以验证该上界的紧性。

Result: 证明了Hellinger距离可由TV距离的1-o(1)次幂控制，其中o(1)项为1/log log(1/TV)量级；构造的例子表明该上界是紧的；解决了Jia et al. (2023) 的开放问题，并导出了高斯混合在TV意义下的熵刻画及Hellinger距离下的最优鲁棒估计结果。

Conclusion: TV与Hellinger距离在高斯位置混合下存在精细的非线性控制关系，所得不等式不仅紧致且具有理论深度，可用于刻画学习高斯混合的复杂性，并应用于鲁棒估计与经验贝叶斯的极小化极大后悔分析。

Abstract: We study the relation between the total variation (TV) and Hellinger distances between two Gaussian location mixtures. Our first result establishes a general upper bound: for any two mixing distributions supported on a compact set, the Hellinger distance between the two mixtures is controlled by the TV distance raised to a power $1-o(1)$, where the $o(1)$ term is of order $1/\log\log(1/\mathrm{TV})$. We also construct two sequences of mixing distributions that demonstrate the sharpness of this bound. Taken together, our results resolve an open problem raised in Jia et al. (2023) and thus lead to an entropic characterization of learning Gaussian mixtures in total variation. Our inequality also yields optimal robust estimation of Gaussian mixtures in Hellinger distance, which has a direct implication for bounding the minimax regret of empirical Bayes under Huber contamination.

</details>


### [103] [Orthogonal Approximate Message Passing Algorithms for Rectangular Spiked Matrix Models with Rotationally Invariant Noise](https://arxiv.org/abs/2602.03283)
*Haohua Chen,Songbin Liu,Junjie Ma*

Main category: math.ST

TL;DR: 提出了一种用于矩形尖峰矩阵模型中信号估计的正交近似消息传递（OAMP）算法，适用于一般的旋转不变噪声，并建立了精确描述其高维动态行为的态演化方程。


<details>
  <summary>Details</summary>
Motivation: 在存在一般旋转不变噪声的情况下，现有信号估计算法性能受限，缺乏对高维动态的精确刻画，因此需要一种更通用且高效的算法。

Method: 提出了OAMP算法，结合旋转不变噪声特性，建立严格的态演化框架，并设计了每步最小化预测均方误差的最优变体。

Result: 建立了精确的态演化方程；最优OAMP在i.i.d.高斯噪声下与标准AMP算法的不动点一致；在一般旋转不变噪声下表现出优越性能。

Conclusion: 最优OAMP算法在广泛迭代方法中可能是统计最优的，在某些情况下可实现贝叶斯最优性能。

Abstract: We propose an orthogonal approximate message passing (OAMP) algorithm for signal estimation in the rectangular spiked matrix model with general rotationally invariant (RI) noise. We establish a rigorous state evolution that exactly characterizes the high-dimensional dynamics of the algorithm. Building on this framework, we derive an optimal variant of OAMP that minimizes the predicted mean-squared error at each iteration. For the special case of i.i.d. Gaussian noise, the fixed point of the proposed OAMP algorithm coincides with that of the standard AMP algorithm. For general RI noise models, we conjecture that the optimal OAMP algorithm is statistically optimal within a broad class of iterative methods, and achieves Bayes-optimal performance in certain regimes.

</details>


<div id='nlin.AO'></div>

# nlin.AO [[Back]](#toc)

### [104] [Emergence and co-existence of periodic and unstructured motion in future-avoiding random walks](https://arxiv.org/abs/2602.03308)
*A. Schmaus,K. Stiller,N. Molkenthin*

Main category: nlin.AO

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Self-avoiding random walks on graphs can be seen as walkers interacting with their own past history. This letter considers a complementary class of dynamics: Mutual future avoiding random walks (MFARWs), where stochastically driven walkers are avoiding each others planned future trajectories. Such systems arise naturally in conceptual models of shared mobility. We show that periodic behavior emerges spontaneously in such MFARWs, and that periodic and unstructured behavior coexist, providing a first example of Chimera style behavior of non-oscillatory paths on networks. Further, we analytically describe and predict the onset of structure. We find that the phase transition from unstructured to periodic behavior is driven by a novel mechanism of self-amplifying coupling to the periodic components of the stochastic drivers of the system. In the context of shared mobility applications, these Chimera states imply a regime of naturally stable co-existence between flexible and line-based public transport.

</details>


### [105] [Noisy nonlocal aggregation model with gradient flow structures](https://arxiv.org/abs/2602.03654)
*Su Yang,Weiqi Chu,Panayotis G. Kevrekidis*

Main category: nlin.AO

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Interacting particle systems provide a fundamental framework for modeling collective behavior in biological, social, and physical systems. In many applications, stochastic perturbations are essential for capturing environmental variability and individual uncertainty, yet their impact on long-term dynamics and equilibrium structure remains incompletely understood, particularly in the presence of nonlocal interactions. We investigate a stochastic interacting particle system governed by potential-driven interactions and its continuum density formulation in the large-population limit. We introduce an energy functional and show that the macroscopic density evolution has a gradient-flow structure in the Wasserstein-2 space. The associated variational framework yields equilibrium states through constrained energy minimization and illustrates how noise regulates the density and mitigates singular concentration. We demonstrate the connection between microscopic and macroscopic descriptions through numerical examples in one and two dimensions. Within the variational framework, we compute energy minimizers and perform a linear stability analysis. The numerical results show that the stable minimizers agree with the long-time dynamics of the macroscopic density model.

</details>


<div id='physics.geo-ph'></div>

# physics.geo-ph [[Back]](#toc)

### [106] [Variational and Monte Carlo Methods for Bayesian Inversion of Dynamic Subsurface Flow Simulations Using Seismic and Fluid Pressure Data](https://arxiv.org/abs/2602.02993)
*Zhen Zhang,Xuebin Zhao,Andrew Curtis*

Main category: physics.geo-ph

TL;DR: 比较了蒙特卡洛采样与变分推断方法在地下储层渗透率反演中的应用，PSVI在精度和计算效率间取得良好平衡，sSVGD在后验分布逼近上更优但计算成本更高。


<details>
  <summary>Details</summary>
Motivation: 为准确预测地下流体储层在未来操作情景下的表现，需基于观测数据估计储层属性，解决非线性贝叶斯反演中的挑战性逆问题。

Method: 采用自动微分变分推断（ADVI）、Stein变分梯度下降（SVGD）、随机SVGD（sSVGD）及Metropolis-Hastings McMC进行对比，并提出物理结构化变分推断（PSVI），仅估计模型参数的局部空间相关性。

Result: PSVI在均值场ADVI与全秩ADVI之间实现了后验近似精度与计算效率的良好平衡；SVGD和sSVGD提供更精确的后验逼近，其中sSVGD优于SVGD，具有更好的计算效率并缓解模式崩溃和虚假相关问题，但总体计算成本更高。

Conclusion: 在碳封存等遥感反演问题中，考虑局部空间相关性的PSVI是一种高效且准确的变分推断方法，而sSVGD虽计算昂贵但在后验估计上表现最佳。

Abstract: In order to predict future performance of subsurface fluid reservoirs under possible operating scenarios, a dynamic, porous-medium flow simulation model must be tuned to include representative properties of the reservoir. Estimating subsurface reservoir properties given remotely sensed or borehole-based observations typically involves finding the solution to a challenging inverse problem. We compare Monte Carlo random sampling to variational inference methods which use optimisation to constrain parametrised uncertainties in nonlinear Bayesian inversions. We use them to estimate the posterior probability distribution of reservoir permeability given fluid pressure and seismic measurements. The methods include automatic differentiation variational inference (ADVI), Stein variational gradient descent (SVGD), and a Monte Carlo method called stochastic SVGD (sSVGD), all of which we benchmark against results from Metropolis-Hastings McMC. We also test an ADVI variant called physically structured variational inference (PSVI): in our implementation this method estimates only spatially-local correlations between model parameters based on the intuition that such correlations are strong in remote sensing problems in which data only inform about spatial-averages of local dynamics. We apply the methods to two- and three-dimensional inverse problems of carbon dioxide storage, inspired by the Endurance field, located in the UK North Sea. Results show that PSVI achieves a good balance between mean-field ADVI and full-rank ADVI in terms of accuracy of the posterior approximation and computational efficiency. SVGD and sSVGD offer more accurate approximations of the target posterior distribution, but at far higher computational cost. Between them, sSVGD outperforms SVGD, exhibiting better computational efficiency and mitigating the problems of mode collapse and spurious correlations.

</details>


### [107] [Scaling laws for rockfall impact fragmentation emerging from diverse lithologies](https://arxiv.org/abs/2602.03360)
*Alvaro Vergara,Sergio Palma,Raul Fuentes*

Main category: physics.geo-ph

TL;DR: 提出了一种离散元框架来研究不同岩性下的冲击破碎机制，发现碎片尺寸分布遵循普适的Weibull标度律，并揭示了其作为岩石力学敏感性指标的潜力，为山地灾害防护设计提供了物理基础。


<details>
  <summary>Details</summary>
Motivation: 冲击引起的破碎具有随机性，难以预测碎屑演化，传统模型难以适用于复杂岩性和能量条件，亟需一种能跨岩性、跨能量尺度统一描述破碎行为的物理框架。

Method: 开发了一种离散元方法框架，模拟从高强碎屑岩到块状碳酸盐岩的破碎过程，并利用高分辨率野外岩崩事件数据进行验证；引入相对破碎指数，实现不同条件下破碎数据的统计坍缩。

Result: 发现尽管冲击动力学具有随机性，碎片尺寸分布始终遵循普适的Weibull标度律，且该规律与岩性及初始动能无关；Weibull参数可反映岩石将动能转化为新裂隙面的效率差异；框架明确解析了能量在残留块体与细碎颗粒间的分配。

Conclusion: Weibull标度律可作为描述冲击破碎的普适数理基础，能够连接微观断裂与宏观碎屑演化，为从单一块体假设转向真实碎粒云能量分布评估提供依据，有助于优化山地灾害防护结构设计。

Abstract: Impact-induced fragmentation is a fundamental dissipative process in geosciences, yet its stochastic nature makes predicting debris evolution a persistent challenge. Here, we introduce a discrete element framework to resolve fragmentation mechanics across a diverse lithological spectrum, from high-strength siliciclastic units to massive carbonates, validated against high-resolution field data from documented rockfall events. Our results reveal that, despite the inherent randomness of impact dynamics, fragment size distributions consistently follow a universal Weibull scaling law, independent of lithology or initial kinetic energy. By applying a relative breakage index, we demonstrate a remarkable collapse of fragmentation data onto a single statistical signature, bridging the gap between grain-scale fracture and macroscopic debris evolution. We find that this Weibullian signature acts as a proxy for lithological sensitivity, reflecting distinct efficiencies in converting kinetic energy into new fracture surfaces. This framework explicitly resolves the energy partitioning between surviving blocks and comminuted debris, providing a robust predictive link between impact mechanics and structural resilience. From an engineering perspective, our findings enable a shift from idealised single-block impact assumptions toward a realistic assessment of distributed energy in fragmented particle clouds, offering a physical basis for optimising protective galleries and hazard mitigation strategies in complex mountainous terrains.

</details>


### [108] [Radial gradient of superionic hydrogen in Earth's inner core](https://arxiv.org/abs/2602.03509)
*Zepeng Wu,Liangrui Wei,Chen Gao,Shunqing Wu,Renata M. Wentzcovitch,Yang Sun*

Main category: physics.geo-ph

TL;DR: 该研究通过计算液态和超离子态hcp与bcc Fe-H相的从头算吉布斯自由能，构建了地球内核条件下超离子-液态相图，发现不同压力下的相图在以纯铁熔点归一化温度后具有普适性，揭示了氢在内核中因热力学平衡形成径向浓度梯度的机制。


<details>
  <summary>Details</summary>
Motivation: 明确氢作为地核主要轻元素之一，在内核中的超离子相热力学行为及其分布规律尚不清楚，需解决理论与实验间分配系数的差异问题。

Method: 采用第一性原理计算方法计算吉布斯自由能，并构建压力-温度条件下的超离子-液态相图，利用归一化温度分析相变行为。

Result: 发现相图在归一化温度下具有普适标度律，解释了先前理论结果间的差异并与低压试验数据吻合；结合热化学约束，揭示了内核中存在氢的径向浓度梯度。

Conclusion: 超离子氢在地球内核中的成分梯度可自然由平衡热力学产生，提出了一种控制轻元素深度分布的普适机制。

Abstract: Hydrogen is considered a major light element in Earth's core, yet the thermodynamics of its superionic phase and its distribution in the inner core remain unclear. Here, we compute ab initio Gibbs free energies for liquid and superionic hcp and bcc Fe-H phases and construct the superionic-liquid phase diagram over pressure-temperature conditions relevant to the Earth's inner core. We find that phase diagrams at different inner-core pressures collapse when temperatures are scaled by the melting temperature of pure iron, indicating that solid-liquid partitioning is controlled primarily by a reduced temperature relative to iron melting and is weakly sensitive to pressure. This scaling relation further reconciles previously reported discrepancies in partition coefficients among theoretical studies and yields good agreement with available experimental data at low pressures. By applying thermochemical constraints, our free-energy results reveal a radial hydrogen gradient within the inner core. These results demonstrate that compositional gradients of superionic hydrogen in the inner core emerge naturally from equilibrium thermodynamics and suggest a general mechanism governing the depth-dependent distribution of light elements within Earth's inner core.

</details>


<div id='math.OC'></div>

# math.OC [[Back]](#toc)

### [109] [Sub-optimality bounds for certainty equivalent policies in partially observed systems](https://arxiv.org/abs/2602.02814)
*Berk Bozkurt,Aditya Mahajan,Ashutosh Nayyar,Yi Ouyang*

Main category: math.OC

TL;DR: 本文推广了随机控制中的确定性等价原理，提出在非线性部分可观测系统中使用任意状态估计的确定性等价策略，并给出了其次优性的上界。


<details>
  <summary>Details</summary>
Motivation: 受经典确定性等价原理启发，研究在更一般的非线性系统中使用非MMSE状态估计时该策略的表现。

Method: 通过假设成本和动态具有适当光滑性，推导出确定性等价策略在一般非线性部分可观测系统中的次优性上界。

Result: 得到了确定性等价策略在非线性系统中次优性的理论上界，并通过多个例子验证了结果。

Conclusion: 尽管确定性等价策略在非线性部分可观测系统中不是最优的，但在一定条件下其性能损失可控。

Abstract: In this paper, we present a generalization of the certainty equivalence principle of stochastic control. One interpretation of the classical certainty equivalence principle for linear systems with output feedback and quadratic costs is as follows: the optimal action at each time is obtained by evaluating the optimal state-feedback policy of the stochastic linear system at the minimum mean square error (MMSE) estimate of the state. Motivated by this interpretation, we consider certainty equivalent policies for general (non-linear) partially observed stochastic systems that allow for any state estimate rather than restricting to MMSE estimates. In such settings, the certainty equivalent policy is not optimal. For models where the cost and the dynamics are smooth in an appropriate sense, we derive upper bounds on the sub-optimality of certainty equivalent policies. We present several examples to illustrate the results.

</details>


### [110] [Fast Near Time-Optimal Motion Planning for Holonomic Vehicles in Structured Environments](https://arxiv.org/abs/2602.02826)
*Louis Callens,Bastiaan Vandewal,Ibrahim Ibrahim,Jan Swevers,Wilm Decré*

Main category: math.OC

TL;DR: 提出了一种基于优化的高效方法，用于在结构化环境中为全向车辆生成接近时间最优的轨迹，具有较低的计算时间且不显著牺牲最优性。


<details>
  <summary>Details</summary>
Motivation: 为了提高生产效率并实现实时响应，需要在复杂但结构化的环境中为磁悬浮平面运动系统（如装配线、自动化实验室或洁净室）中的全向车辆生成实时可计算的时间最优轨迹。

Method: 通过自由空间走廊表示环境，并使用运动原语表示车辆在走廊内的运动；运动原语通过启发式选择，将轨迹参数化为有限自由度，进而构建优化问题求解。

Result: 相比现有最先进方法（如完全求解最优控制问题、OMG-tools或VP-STO），该方法显著降低了计算时间，同时在固定走廊序列下保持了较高的轨迹质量。

Conclusion: 所提方法能够在保证近似时间最优的同时大幅提升计算效率，适用于对实时性和反应性要求高的工业应用场景。

Abstract: This paper proposes a novel and efficient optimization-based method for generating near time-optimal trajectories for holonomic vehicles navigating through complex but structured environments. The approach aims to solve the problem of motion planning for planar motion systems using magnetic levitation that can be used in assembly lines, automated laboratories or clean-rooms. In these applications, time-optimal trajectories that can be computed in real-time are required to increase productivity and allow the vehicles to be reactive if needed. The presented approach encodes the environment representation using free-space corridors and represents the motion of the vehicle through such a corridor using a motion primitive. These primitives are selected heuristically and define the trajectory with a limited number of degrees of freedom, which are determined in an optimization problem. As a result, the method achieves significantly lower computation times compared to the state-of-the-art, most notably solving a full Optimal Control Problem (OCP), OMG-tools or VP-STO without significantly compromising optimality within a fixed corridor sequence. The approach is benchmarked extensively in simulation and is validated on a real-world Beckhoff XPlanar system

</details>


### [111] [Fisher-Information-Based Sensor Placement for Structural Digital Twins: Analytic Results and Benchmarks](https://arxiv.org/abs/2602.02981)
*Harbir Antil,Animesh Jain,Rainald Löhner*

Main category: math.OC

TL;DR: 本文提出了一种基于Fisher信息的传感器布置框架，用于伴随有限元数字孪生体，通过D最优设计准则评估传感器配置，并推导了D最优多传感器布置近似均匀分布的结论。


<details>
  <summary>Details</summary>
Motivation: 为了提高结构应用中数字孪生体对空间分布量识别的准确性与稳定性，需优化传感器位置和测量类型的选择。

Method: 采用基于Fisher信息矩阵的D最优设计准则，结合伴随法计算梯度，利用线性化测量映射评估传感器配置的信息含量，并推导无需显式构建雅可比矩阵即可计算Fisher信息乘积的方法。

Result: 提出了矩阵自由的算子公式用于高效计算Fisher信息乘积，导出了D最优传感器设计关于测量参数的显式敏感性表达式，并在一维结构模型中证明了多个位移传感器的D最优布置趋于均匀间隔。

Conclusion: 该框架为高保真数字孪生中的传感器布局提供了统计意义上严谨且可实施的解决方案，有助于提升逆问题求解的质量和稳定性。

Abstract: High-fidelity digital twins rely on the accurate assimilation of sensor data into physics-based computational models. In structural applications, such twins aim to identify spatially distributed quantities--such as elementwise weakening fields, material parameters, or effective thermal loads--by minimizing discrepancies between measured and simulated responses subject to the governing equations of structural mechanics. While adjoint-based methods enable efficient gradient computation for these inverse problems, the quality and stability of the resulting estimates depend critically on the choice of sensor locations, measurement types, and directions.
  This paper develops a rigorous and implementation-ready framework for Fisher-information-based sensor placement in adjoint-based finite-element digital twins. Sensor configurations are evaluated using a D-optimal design criterion derived from a linearization of the measurement map, yielding a statistically meaningful measure of information content. We present matrix-free operator formulas for applying the Jacobian and its adjoint, and hence for computing Fisher-information products $Fv = J^\top R^{-1} Jv$ using only forward and adjoint solves. Building on these operator evaluations, we derive explicit sensitivity expressions for D-optimal sensor design with respect to measurement parameters and discuss practical strategies for evaluating the associated log-determinant objectives. To complement the general framework, we provide analytically tractable sensor placement results for a canonical one-dimensional structural model, clarifying the distinction between detectability and localizability and proving that D-optimal placement of multiple displacement sensors yields approximately uniform spacing.

</details>


### [112] [Data-driven stabilization of continuous-time systems with noisy input-output data](https://arxiv.org/abs/2602.02992)
*Masashi Wakaiki*

Main category: math.OC

TL;DR: 本文研究了在仅有噪声输入输出数据的情况下，如何通过数据驱动方法稳定连续时间自回归系统，并结合行为理论提出了二次稳定的充分必要条件。


<details>
  <summary>Details</summary>
Motivation: 在无法获得精确系统模型且仅有噪声数据的条件下，实现系统的稳定控制是一个重要挑战。

Method: 采用算子方法描述与数据一致的系统集合，结合行为理论推导出基于线性矩阵不等式的二次稳定条件。

Result: 得到了噪声数据可进行二次镇定的充要条件，并可通过求解LMI获得稳定控制器；同时刻画了无噪声情况下系统辨识的数据可识别性。

Conclusion: 所提方法能够有效利用噪声输入输出数据判断系统是否可被镇定，并提供相应的控制器设计途径。

Abstract: We study data-driven stabilization of continuous-time systems in autoregressive form when only noisy input-output data are available. First, we provide an operator-based characterization of the set of systems consistent with the data. Next, combining this characterization with behavioral theory, we derive a necessary and sufficient condition for the noisy data to be informative for quadratic stabilization. This condition is formulated as linear matrix inequalities, whose solution yields a stabilizing controller. Finally, we characterize data informativity for system identification in the noise-free setting.

</details>


### [113] [Q-Learning for 3D Coverage in VCSEL-based Optical Wireless Systems](https://arxiv.org/abs/2602.03526)
*Hossein Safi,Rizwana Ahmad,Iman Tavakkolnia,Harald Haas*

Main category: math.OC

TL;DR: 本文提出了一种基于强化学习的动态光束发散角调控框架，用于解决室内光无线通信系统中因接收器高度变化导致的覆盖范围下降问题。


<details>
  <summary>Details</summary>
Motivation: 传统固定发散角方法在光学功率集中与空间扩展之间存在非凸权衡，导致覆盖性能显著下降，难以适应动态环境。

Method: 采用强化学习（RL）框架，使智能体通过与环境持续交互，自主学习接收器高度与光束发散角之间的近似最优映射关系，实现动态发散角自适应控制。

Result: 仿真结果表明，该方法在低接收高度下可实现高达92%的覆盖率，并在恶劣条件下保持稳健性能。

Conclusion: 所提出的RL-based方法无需复杂建模或穷举搜索，支持可扩展、实时且节能的光束控制，适用于下一代高密度VCSEL阵列光无线通信系统。

Abstract: Beam divergence control is a key factor in maintaining reliable coverage in indoor optical wireless communication (OWC) systems as receiver height varies.Conventional systems employ fixed divergence angles, which result in significant coverage degradation due to the non-convex tradeoff between optical power concentration and spatial spread. In this paper, we introduce a reinforcement learning (RL)-based framework for dynamic divergence adaptation in vertical-cavity surface-emitting laser (VCSEL)-based OWC networks. By continuously interacting with the environment, the RL agent autonomously learns a near-optimal mapping between receiver height and beam divergence, thereby eliminating the need for analytical modeling or computationally intensive exhaustive search. Simulation results demonstrate that the proposed approach achieves up to 92% coverage at low receiver heights and maintains robust performance under challenging conditions, enabling scalable, real-time, and energy-efficient beam control for dense VCSEL array deployments in next-generation OWC systems.

</details>


<div id='physics.soc-ph'></div>

# physics.soc-ph [[Back]](#toc)

### [114] [How Much of the United States Can Still Host New Hyperscale Data Centers? A Constraint-Based Feasibility Analysis](https://arxiv.org/abs/2602.02529)
*Milan Janosov*

Main category: physics.soc-ph

TL;DR: 本研究通过一种基于物理、基础设施和环境约束的全国性地理空间框架，评估了美国超大规模数据中心的可行建设容量，发现实际可供建设的土地远少于以往假设，总容量可能仅为数十吉瓦而非数百吉瓦。


<details>
  <summary>Details</summary>
Motivation: 随着云计算和生成式AI的发展，超大规模数据中心迅速扩张，对电力系统、土地和气候敏感型基础设施造成压力。目前尚不清楚在现有约束下还能在哪里建设这些数据中心。

Method: 研究采用‘约束优先’的地理空间分析方法，结合电网邻近性、环境限制、土地使用限制和气候条件，在统一的六边形空间系统中推断美国本土范围内超大规模数据中心的选址可行性。

Result: 分析表明，符合所有约束条件的可行土地范围非常有限，相对于简单土地可用性估计有显著收缩；根据现有建设模式，推测美国超大规模数据中心的总物理可行容量为数十吉瓦级别。

Conclusion: 在现代多重约束下，美国超大规模数据中心的扩展潜力远低于普遍预期，需重新评估未来基础设施规划与政策制定。

Abstract: The rapid expansion of hyperscale data centers, primarily driven by cloud computing and generative AI is placing growing pressure on electricity systems, land, and climate-sensitive infrastructure. While existing maps document where data centers are currently located, a major unanswered question remains: where can hyperscale data centers still be built under present-day physical, infrastructural, and environmental constraints?
  Here we address this question, focusing on the United States, using a national-scale, constraint-first geospatial framework that infers feasibility from revealed hyperscale siting patterns rather than from demand forecasts or optimization assumptions. By combining power-grid adjacency, environmental limits, land-use constraints, and climatic constraints within a uniform hexagonal spatial system, we estimate the feasible hyperscale hosting capacity.
  Our presented approaches converge on a limited feasible land envelope, implying a substantial contraction relative to naive land-availability assumptions. Based on observed build-out patterns, we estimate that total physically feasible U.S. hyperscale capacity lies in the tens of gigawatts rather than the hundreds. The results of this piece are intended to support national-scale reasoning about infrastructure feasibility under modern constraints.

</details>


### [115] [Thermal Comfort Path Planning Tool for Urban Mobility in Austin, Texas](https://arxiv.org/abs/2602.02540)
*Aditya Patel,Naveen Sudharsan,Trevor Brooks,Harsh Kamath,Dru Crawley,Zack Baumer,Marc Coudert,Dev Niyogi*

Main category: physics.soc-ph

TL;DR: 本文提出了一种基于通用热气候指数（UTCI）的城市步行与骑行路线规划工具，通过高分辨率热环境建模与实时路径映射，为用户提供最凉爽、遮阴最佳且路径合理的出行选择，有效降低行人热暴露风险，提升极端高温下的主动出行安全性与舒适性。


<details>
  <summary>Details</summary>
Motivation: 传统的天气报告无法反映城市内部微气候差异，导致行人和骑行者在极端高温下面临较高的热暴露风险。本文旨在通过考虑实际热舒适性的路线规划，解决城市中局部热环境对主动交通的影响问题。

Method: 结合SOLWEIG-GPU模型生成城市尺度的高分辨率UTCI热图，综合建筑、植被等城市特征与实时气象数据，计算每条可能路径的平均UTCI值，并推荐热应力最低（即最凉爽）且路径合理的路线。

Result: 在奥斯汀的案例研究中，该系统能够识别出显著减少热暴露的路线，通常建议更多遮阴路径，相比传统最短路径大幅提高热舒适性。

Conclusion: 基于热舒适性的路线规划工具可有效改善高温环境下城市出行的安全性与宜居性，具有重要的公共卫生意义，有助于推动气候适应型城市设计与主动交通发展。

Abstract: Extreme heat poses a growing challenge for active transportation in cities like Austin, Texas, where conventional weather reporting (e.g. a single air temperature measurement for the whole city) fails to capture the large microclimate variations that pedestrians and cyclists actually experience. We present a novel walking and biking route planner that selects paths based on thermal comfort using the Universal Thermal Climate Index (UTCI) (Jendritzky et al., 2012) rather than just distance or travel time. This system combines high-resolution thermal modeling with real-time route mapping. We generate city-scale UTCI maps using SOLWEIG-GPU (Solar and LongWave Environmental Irradiance Geometry), to account for urban features (buildings, trees, etc.) and weather conditions (Lindberg et al., 2008; Kamath et al., 2026). For any given origin and destination, our tool calculates the average UTCI along each possible route and recommends the 'coolest' route, i.e. the path with the lowest heat stress (often the most shaded or otherwise thermally comfortable), while still being reasonably direct. In a case study for Austin, this approach identifies routes that significantly reduce pedestrians' heat exposure (often recommending routes with a much larger proportion of shade). Such thermally-informed route planning has important public health implications: by helping people avoid dangerous heat hotspots and sun-exposed areas, it can reduce the risk of heat-related illness and make walking or biking a safer choice even on hot days. This paper describes the motivation, methodology, results, and implications of the thermal comfort path planner, emphasizing the role of shade and thermal comfort in urban mobility and heat mitigation.

</details>


### [116] [Indirect Reciprocity with Environmental Feedback](https://arxiv.org/abs/2602.02553)
*Yishen Jiang,Xin Wang,Ming Wei,Wenqiang Zhu,Longzhao Liu,Hongwei Zheng,Shaoting Tang*

Main category: physics.soc-ph

TL;DR: 本研究提出一个耦合道德评估、策略更新与环境动态的共进化框架，揭示在资源动态变化的真实环境中，间接互惠如何促进合作的演化。


<details>
  <summary>Details</summary>
Motivation: 现有间接互惠理论多假设静态环境，无法反映现实世界中个体行为对资源环境的影响及其反馈作用，因此需要建立能体现策略与环境共演化的模型。

Method: 构建一个将个体声誉评估、策略演化与环境动态反馈耦合的理论模型，通过演化博弈模拟分析不同类型社会规范在动态环境下的合作促进效果。

Result: 环境反馈机制降低了合作演化的阈值，使系统可自发从低合作状态转向高合作稳态；严格区分性规范在动态环境中比宽容规范更有效抑制机会主义行为。

Conclusion: 声誉机制与环境约束的相互作用对合作演化至关重要，严格社会规范在复杂动态环境中更具进化韧性，为理解现实社会中的集体合作与治理提供了新视角。

Abstract: Indirect reciprocity maintains cooperation in stranger societies by mapping individual behaviors onto reputation signals via social norms. Existing theoretical frameworks assume static environments with constant resources and fixed payoff structures. However, in real-world systems, individuals' strategic behaviors not only shape their reputation but also induce collective-level resource changes in ecological, economic, or other external environments, which in turn reshape the incentives governing future individual actions. To overcome this limitation, we establish a co-evolutionary framework that couples moral assessment, strategy updating, and environmental dynamics, allowing the payoff structure to dynamically adjust in response to the ecological consequences of collective actions. We find that this environmental feedback mechanism helps lower the threshold for the emergence of cooperation, enabling the system to spontaneously transition from a low-cooperation state to a stable high-cooperation regime, thereby reducing the dependence on specific initial conditions. Furthermore, while lenient norms demonstrate adaptability in static environments, norms with strict discrimination are shown to be crucial for curbing opportunism and maintaining evolutionary resilience in dynamic settings. Our results reveal the evolutionary dynamics of coupled systems involving reputation institutions and environmental constraints, offering a new theoretical perspective for understanding collective cooperation and social governance in complex environments.

</details>


### [117] [A Distinct Communication Strategies Model of the Double Empathy Problem](https://arxiv.org/abs/2602.02562)
*Enrique Calderoli,Maria Cristina Varriale,Flávio Kapczinski*

Main category: physics.soc-ph

TL;DR: 本文提出了一个基于反馈循环的数学模型，用以解释自闭症与神经典型个体之间共情纽带破裂的现象，认为这是由于双方沟通偏好的差异所致，而非单方面的缺陷。


<details>
  <summary>Details</summary>
Motivation: 旨在为双 empathy 问题提供一种机制性解释，挑战将共情困难归因于自闭症个体单一缺陷的传统观点。

Method: 构建了一个基于沟通偏好的反馈循环数学模型，并通过数值模拟进行验证，同时进行了稳定性分析以预测互动在共情空间中的轨迹。

Result: 模型显示，仅基于沟通偏好差异即可导致共情退化现象，模拟结果与临床观察一致，且稳定性分析能预测互动的整体走向。

Conclusion: 自闭症与神经典型个体间的共情障碍可由双向沟通偏好差异解释，无需假设任何一方存在内在缺陷，为理解神经多样性互动提供了新框架。

Abstract: The double empathy problem recasts the difficulty of forming empathy bonds in social interactions between autistic and neurotypical individuals as a bidirectional problem, rather than due to a deficit exclusive to the person on the spectrum. However, no explicit mechanism to explain such a phenomenon has been proposed. Here we build a feedback-loop mathematical model that would theoretically induce the empathy degradation observed during communication in neurotypical-autistic pairs solely due to differences in communication preferences between neurotypical and neurodivergent individuals. Numerical simulations of dyadic interactions show the model, whose mechanism is based solely on communication preferences, can illustrate the breakdown of empathic bonding observed clinically. Stability analysis of the model provides a way to predict the overall trajectory of the interaction in the empathy space. Furthermore, we suggest experimental designs to measure several parameters outlined here and discuss the future directions for testing the proposed model.

</details>


### [118] [The Evolution of Lying in a Spatially-Explicit Prisoner's Dilemma Model](https://arxiv.org/abs/2602.02587)
*Gregg Hartvigsen*

Main category: physics.soc-ph

TL;DR: 该研究通过环面格子上的囚徒困境空间模型，探讨了个体在合作与背叛策略下，基于“以牙还牙”或默认策略的行为演化，并引入说真话概率（P_truth）这一可进化参数。结果显示，高诚实度群体趋向于真实合作者，低诚实度群体则演变为说谎的背叛者，两类群体均表现稳定。


<details>
  <summary>Details</summary>
Motivation: 探索在存在信息欺骗的情况下，合作行为如何在群体中演化并维持稳定。

Method: 采用环面格子上的空间囚徒困境模型，比较‘以牙还牙’和默认策略，允许个体以一定概率报告其上一轮行为（P_truth），并通过模拟观察群体策略和诚实度的演化动态。

Result: 当初始群体的平均P_truth ≥ 0.75时，系统演化为诚实的合作群体；当P_truth < 0.7时，演化为说谎的背叛群体；中间值的群体不稳定，被两端群体取代。两种极端群体具有更高的平均得分且状态稳定。

Conclusion: 诚实的合作与说谎的背叛均可在特定条件下形成稳定的演化均衡，表明诚实程度的演化依赖于初始群体的特征，信息透明度对合作的维持至关重要。

Abstract: I present the results from a spatial model of the prisoner's dilemma, played on a toroidal lattice. Each individual has a default strategy of either cooperating ($C$) or defecting ($D$). Two strategies were tested, including ``tit-for-tat'' (TFT), in which individuals play their opponent's last play, or simply playing their default play. Each individual also has a probability of telling the truth ($0 \leq P_{truth} \leq 1$) about their last play. This parameter, which can evolve over time, allows individuals to be, for instance, a defector but present as a cooperator regarding their last play. This leads to interesting dynamics where mixed populations of defectors and cooperators with $P_{truth} \geq 0.75$ move toward populations of truth-telling cooperators. Likewise, mixed populations with $P_{truth} < 0.7$ become populations of lying defectors. Both such populations are stable because they each have higher average scores than populations with intermediate values of $P_{truth}$. Applications of this model are discussed with regards to both humans and animals.

</details>


### [119] [Social Catalysts, Not Moral Agents: The Illusion of Alignment in LLM Societies](https://arxiv.org/abs/2602.02598)
*Yueqing Hu,Yixuan Jiang,Zehua Jiang,Xiao Wen,Tianhong Wang*

Main category: physics.soc-ph

TL;DR: 本研究探讨了在大型语言模型（LLM）多智能体系统中，通过引入预设利他行为的“锚定智能体”来促进合作的效果。实验发现，尽管锚定智能体能短期提升合作率，但这种效果源于策略性顺从和认知卸载，而非真正的规范内化。多数智能体在新环境中回归自私行为，且高级模型如GPT-4.1表现出“变色龙效应”，在公开监督下隐藏背叛行为。


<details>
  <summary>Details</summary>
Motivation: 解决LLM多智能体系统中因个体自利导致的‘公地悲剧’问题，探索如何有效促进持久合作。

Method: 采用三类最先进的大语言模型，在公共物品博弈（PGG）中实施全因子实验设计，分析锚定智能体对合作行为的影响，并通过认知解构与迁移测试探究其内在推理机制。

Result: 锚定智能体提升了局部合作水平，但该效应依赖于外部环境；迁移测试显示智能体未实现规范内化，高级模型表现出策略性伪装合作的行为。

Conclusion: 当前方法仅能实现表面行为改变，难以达成真正价值观对齐，揭示了人工社会中行为调节与价值内化之间的关键差距。

Abstract: The rapid evolution of Large Language Models (LLMs) has led to the emergence of Multi-Agent Systems where collective cooperation is often threatened by the "Tragedy of the Commons." This study investigates the effectiveness of Anchoring Agents--pre-programmed altruistic entities--in fostering cooperation within a Public Goods Game (PGG). Using a full factorial design across three state-of-the-art LLMs, we analyzed both behavioral outcomes and internal reasoning chains. While Anchoring Agents successfully boosted local cooperation rates, cognitive decomposition and transfer tests revealed that this effect was driven by strategic compliance and cognitive offloading rather than genuine norm internalization. Notably, most agents reverted to self-interest in new environments, and advanced models like GPT-4.1 exhibited a "Chameleon Effect," masking strategic defection under public scrutiny. These findings highlight a critical gap between behavioral modification and authentic value alignment in artificial societies.

</details>


### [120] [Influence Mechanism Of Environmental Stimulus And Consumer Ethnocentrism On Purchasing Wuliangye: Applications Of Extended Theory Of Planned Behavior (ETPB) And Stimulus-Organism-Response (SOR) Theory](https://arxiv.org/abs/2602.02967)
*Ruofeng Rao,Sarana Photchanachan*

Main category: physics.soc-ph

TL;DR: 环境刺激和消费者民族中心主义通过感知价值、态度和购买意愿的链式中介效应，影响四川消费者对五粮液的购买行为，研究提出通过平台建设、开发中低端产品和吸引Z世代消费者等策略提升销量。


<details>
  <summary>Details</summary>
Motivation: 探讨环境刺激和消费者民族中心主义如何影响四川消费者对本地白酒五粮液的冲动购买行为，并揭示其中的中介机制和预测因素。

Method: 基于ETPB和SOR理论，通过对453名四川五粮液消费者的在线调查，采用结构方程模型进行数据分析。

Result: 环境刺激和消费者民族中心主义对购买行为有积极影响，该影响通过感知价值、态度和购买意愿形成链式中介效应；购买意愿、感知行为控制等因素能有效预测实际购买行为。

Conclusion: 环境刺激和民族中心主义显著影响消费者购买决策，企业应加强平台建设、推出中低端产品并聚焦Z世代营销以提升五粮液销售。

Abstract: Environmental stimuli play a pivotal role in triggering impulsive purchases among consumers,while consumers from Sichuan Province, China, exhibit strong ethnocentric tendencies, impacting their decision-making process, particularly regarding Wuliangye liquor, a local product. Through an online survey of 453 Wuliangye consumers from Sichuan, an analysis was conducted using structural equation modeling rooted in the ETPB and SOR theory. This analysis revealed the favorable impact of environmental stimuli and consumer ethnocentrism on purchasing behavior. This influence was found to be partially mediated through perceived value, attitudes, and purchase intention, forming a chain-mediated effect. Notably, purchase intention doesn't always translate to actual buying behavior, with environmental stimuli, consumer ethnocentrism, perceived behavioral control and purchase intention all being robust predictors of purchase behavior. Finally, several management strategies were proposed, aimed at bolstering Wuliangye sales, with a focus on platform development, mid-to-low range product creation, and appealing to Generation Z consumers.

</details>


### [121] [Instantaneous Spectra Analysis of Pulse Series - Application to Lung Sounds with Abnormalities](https://arxiv.org/abs/2602.03680)
*Fumihiko Ishiyama*

Main category: physics.soc-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The origin of the "theoretical limit of time-frequency resolution of Fourier analysis" is from its numerical implementation, especially from an assumption of "Periodic Boundary Condition (PBC)," which was introduced a century ago. We previously proposed to replace this condition with "Linear eXtrapolation Condition (LXC)," which does not require periodicity. This feature makes instantaneous spectra analysis of pulse series available, which replaces the short time Fourier transform (STFT). We applied the instantaneous spectra analysis to two lung sounds with abnormalities (crackles and wheezing) and to a normal lung sound, as a demonstration. Among them, crackles contains a random pulse series. The spectrum of each pulse is available, and the spectrogram of pulse series is available with assembling each spectrum. As a result, the time-frequency structure of given pulse series is visualized.

</details>


### [122] [Emergent structures in coupled opinion and network dynamics](https://arxiv.org/abs/2602.03738)
*Andrew Nugent,Carmen Calatayud Fernandez,Susana N. Gomes*

Main category: physics.soc-ph

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: This paper investigates a model of opinion formation on an adaptive social network, consisting of a system of coupled ordinary differential equations for individuals' opinions and corresponding network edge weights. A key driver of the system's behaviour is the form of the interaction function, which determines the strength of interactions based on the distance between individuals' opinions and appears in both opinion and network dynamics. Two cases are examined: in the first the interaction function is always positive and in the second case the interaction function is of bounded-confidence type. In both cases there is positive feedback between opinion clustering and the emergence of community structure in the social network. This is confirmed through analytical results on long-term behaviour, extending existing results for a fixed network, as well as through numerical simulations. Transient network dynamics are also examined through a short-time approximation that captures the `typical' early network dynamics. Each approach improves some aspect of our understanding of the interplay between opinion and network evolution.

</details>


<div id='cond-mat.str-el'></div>

# cond-mat.str-el [[Back]](#toc)

### [123] [Resolving Quantum Criticality in the Honeycomb Hubbard Model](https://arxiv.org/abs/2602.03656)
*Fo-Hong Wang,Fanjie Sun,Chenghao He,Xiao Yan Xu*

Main category: cond-mat.str-el

TL;DR: 通过大规模投影子行列式量子蒙特卡洛模拟和新算法，精确确定了蜂窝晶格上狄拉克费米子与电子关联相变的临界指数，解决了GNH普适类长期存在的争议，并建立了适用于强关联体系的有限尺寸标度工作流程。


<details>
  <summary>Details</summary>
Motivation: 解决蜂窝晶格上狄拉克费米子与电子关联导致的半金属到Mott绝缘体相变中临界指数不一致的问题，克服数值模拟中的严重有限尺寸效应和缺乏共形自举基准的挑战。

Method: 采用投影子行列式量子蒙特卡洛（QMC）方法，在高达10,368个格点的大尺度晶格上进行模拟；发展了一种新的投影子矩阵更新算法以提升计算效率；通过线性外推法处理玻色子反常维度的系统性尺寸依赖；并利用无自旋t-V模型的并行大尺度模拟进行方法验证。

Result: 费米子反常维度和关联长度指数快速收敛，玻色子反常维度通过外推得以精确确定；在t-V模型中首次由QMC确定费米子反常维度，结果与共形自举预测一致，验证了方法的可靠性。

Conclusion: 本研究提供了蜂窝Hubbard模型最先进的临界指数，确认了GNH普适类的临界行为，并建立了一套系统的有限尺寸标度分析流程，为研究其他费米子量子临界现象提供了可靠路径。

Abstract: The interplay between Dirac fermions and electronic correlations on the honeycomb lattice hosts a fundamental quantum phase transition from a semimetal to a Mott insulator, governed by the Gross-Neveu-Heisenberg (GNH) universality class. Despite its importance, consensus on the precise critical exponents remains elusive due to severe finite-size effects in numerical simulations and the lack of conformal bootstrap benchmarks. Here we try to resolve this long-standing controversy by performing projector determinant quantum Monte Carlo (QMC) simulations on lattices of unprecedented size, reaching 10,368 sites. By developing a novel projected submatrix update algorithm, we achieve a significant algorithmic speedup that enables us to access the thermodynamic limit with high precision. We observe that the fermion anomalous dimension and the correlation length exponent converge rapidly, while the boson anomalous dimension exhibits a systematic size dependence that we resolve via linear extrapolation. To validate our analysis, we perform parallel large-scale simulations of the spinless $t$-$V$ model on the honeycomb lattice, which belongs to the Gross-Neveu-Ising class. Our results for the $t$-$V$ model, including the first QMC determination of the fermion anomalous dimension, show agreement with conformal bootstrap predictions, thereby corroborating the robustness of our methodology. Our work provides state-of-the-art critical exponents for the honeycomb Hubbard model and establishes a systematic finite-size scaling workflow applicable to a broad class of strongly correlated quantum systems, paving the way for resolving other challenging fermionic quantum critical phenomena.

</details>


### [124] [Non-Hermitian free-fermion critical systems and logarithmic conformal field theory](https://arxiv.org/abs/2602.02649)
*Iao-Fai Io,Fu-Hsiang Huang,Chang-Tse Hsieh*

Main category: cond-mat.str-el

TL;DR: 该论文研究了1+1维无能隙非厄米系统在宇称-时间对称下的共形结构，发现其可描述为具有中心电荷c=-2的对数型共形场论，并通过场论与晶格模型验证了该结果。


<details>
  <summary>Details</summary>
Motivation: 探索非厄米系统中例外点附近的共形不变性，特别是在哈密顿量不可对角化时是否存在共形描述。

Method: 采用双正交形式体系，构造无迹的能量-动量张量，并分析其傅里叶模式生成的Virasoro代数；结合微观晶格模型提取有限尺寸修正下的共形数据。

Result: 发现了中心电荷为c=-2的Virasoro代数结构，关联函数呈现对数标度行为，能谱形成具有普适不可分解参数的Virasoro阶梯模，且晶格模型支持场论预测。

Conclusion: 1+1维非厄米自由费米子系统在例外点临界性下可实现一种非厄米、双正交的对数共形场论描述，拓展了传统共形不变性的概念。

Abstract: Conformal invariance often accompanies criticality in Hermitian systems. However, its fate in non-Hermitian settings is less clear, especially near exceptional points where the Hamiltonian becomes non-diagonalizable. Here we investigate whether a 1+1-dimensional gapless non-Hermitian system can admit a conformal description, focusing on a PT-symmetric free-fermion field theory. Working in the biorthogonal formalism, we identify the conformal structure of this theory by constructing a traceless energy-momentum tensor whose Fourier modes generate a Virasoro algebra with central charge $c=-2$. This yields a non-Hermitian, biorthogonal realization of a logarithmic conformal field theory, in which correlation functions exhibit logarithmic scaling and the spectrum forms Virasoro staggered modules that are characterized by universal indecomposability parameters. We further present a microscopic construction and show how the same conformal data (with finite-size corrections) can be extracted from the lattice model at exceptional-point criticality, thereby supporting the field-theory prediction.

</details>


### [125] [Dynamic Simulations of Strongly Coupled Spin Ensembles for Inferring Nature of Electronic Correlations from Nuclear Magnetic Resonance](https://arxiv.org/abs/2602.02732)
*Charles Snider,Stephen Carr,D. E. Feldman,Chandrasekhar Ramanathan,V. F. Mitrović*

Main category: cond-mat.str-el

TL;DR: 本文开发了一个用于模拟核磁共振自旋回波实验的高效软件包，研究强关联电子体系对核自旋系综动力学的影响。通过平均场模型结合超精细相互作用，分析了核自旋系统的时域不对称性和谱域中的脉冲依赖性频移，并提出该频移可作为探测电子相互作用各向异性的新工具。同时介绍了模拟软件的结构、精度及所用近似方法的技术优势。


<details>
  <summary>Details</summary>
Motivation: 旨在理解强关联电子系统中电子自旋关联对核自旋动力学的影响，并提供一种通过NMR实验探测电子相互作用各向异性和范围的新方法。

Method: 采用平均场模型描述关联电子相，并通过超精细相互作用将其与核自旋系综耦合；开发专用模拟软件包进行自旋回波实验的数值模拟，分析系统在时域和谱域的动力学行为。

Result: 发现了由电子-核相互作用引起的核自旋系统的时间反演不对称性以及谱域中依赖于脉冲序列的频移现象；表明该频移与电子相互作用的各向异性密切相关，可用于反推电子关联的性质。

Conclusion: 该模拟工具为研究强关联材料中的奇异NMR信号提供了新途径，特别是通过测量脉冲依赖的谱偏移可有效提取电子相互作用的各向异性与作用范围信息。

Abstract: We develop an efficient package for the simulation of nuclear magnetic resonance spin echo experiments to study the effects of strong electronic spin correlations on the dynamics of the nuclear spin ensemble. A mean-field model is used to study correlated electronic phases through their hyperfine interaction with nuclear spins. We explore the dynamics of the interacting nuclear ensemble and discuss the key behaviors of the system. In particular, we classify the types of temporal asymmetry that the interaction induces in the system as well as a pulse-dependent shift in the spectral domain. Us- ing these results, we discuss how careful measurement of the pulse-dependent shiftcanbeusedtoextractinformationabouttheanisotropyoftheelectronic interaction and how these results represent a novel tool for the examination of exotic NMR signatures in strongly correlated materials. Finally, we re- view specific aspects of the simulation package developed for our exploration and give explicit examples where package can be used to infer range and anisotropy of electronic correlations. In particular, we discuss its structure, accuracy, and the technical merits of the various approximations used to model the nuclear spin ensemble.

</details>


### [126] [Dynamical Effective Hamiltonian Approach to Second-Harmonic Generation in Quantum Magnets: Application to NiI$_2$](https://arxiv.org/abs/2602.02872)
*Banasree S. Mou,Stephen M. Winter*

Main category: cond-mat.str-el

TL;DR: 提出了一种基于第一性原理的方法，用于定量分析绝缘磁体中的二次谐波产生（SHG），并通过NiI$_2$的实例验证了该方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前对SHG张量的完整定量分析具有挑战性，尤其是在二维磁性材料中，需要一种可靠的方法来解析其非线性光学响应。

Method: 通过构建动力学有效算符的形式体系，并结合局域多体簇模型计算这些算符，实现对SHG的定量分析。

Result: 在NiI$_2$这一二维范德瓦尔斯反铁磁体中成功实现了对旋转各向异性SHG实验数据的定量解释，表明SHG可探测局域环电流敏感性和短程手性自旋关联。

Conclusion: 所提出的方法为研究绝缘磁体中的非线性光学效应提供了定量工具，并可推广至其他非线性光学响应和材料体系。

Abstract: Although second harmonic generation (SHG) is a promising and widely used method recently for studying 2D magnetic materials, the quantitative analysis of the full SHG tensor is currently challenging. In this letter, we describe a first-principles-based approach towards quantitative analysis of SHG in insulating magnets through formulation in terms of dynamical effective operators. These operators are computed by solving local many-body cluster models. We benchmark this method on NiI$_2$, a multiferroic 2D van der Waals antiferromagnet, demonstrating quantitative analysis of reported Rotational Anisotropy (RA)-SHG data. SHG is demonstrated to probe local ring-current susceptibilities, which provide sensitivity to short-range chiral spin-spin correlations. The described methods may be easily extended to other non-linear optical responses and materials.

</details>


### [127] [Single crystal growth and properties of Au- and Ge-substituted EuPd$_2$Si$_2$](https://arxiv.org/abs/2602.03287)
*Michelle Ocker,Robert Möller,Marius Peters,Franziska Walther,Vivien Kirschall,Dominik C. Hezel,Michael Merz,Christo Guguschev,Cornelius Krellner,Kristin Kliemt*

Main category: cond-mat.str-el

TL;DR: 该研究通过Czochralski法从悬浮的富铕熔体中成功生长出Eu(Pd$_{1-x}$Au$_x$)$_2$Si$_2$（0 < x ≤ 0.2）和EuPd$_2$(Si$_{1-x}$Ge$_x$)$_2$（x=0.2）的单晶，并对其结构和物性进行了分析，发现金掺杂导致晶格膨胀但取代率随x增加而降低，引发显著的价态交叉温度变化，且未观察到一阶相变或反铁磁序；同时发现了新的正交相EuPd$_{1.42}$Si$_{1.27}$Ge$_{0.31}$在17 K以下呈现反铁磁有序。


<details>
  <summary>Details</summary>
Motivation: 探索Au和Ge掺杂对Eu基ThCr2Si2型化合物晶体结构、价态行为及磁性相变的影响，优化单晶生长工艺以获得高质量样品用于物性研究。

Method: 采用悬浮区熔Czochralski法生长单晶，结合X射线衍射、化学分析和X射线荧光分析确定晶体结构与成分，并通过磁性测量研究相变行为。

Result: 成功生长出毫米级单晶；确认ThCr2Si2型结构，a和c晶格参数随Au含量增加而增大；实际Au掺杂量仅为初始熔体的25-35%，且取代效率随x上升而下降；施加化学压力引起显著的价态交叉温度变化；未在x=0.1样品中发现一级相变，高x也未见AFM序；高Au熔体中出现四元副相；发现新正交相EuPd1.42Si1.27Ge0.31在17 K以下呈AFM有序。

Conclusion: Au掺杂有效调节Eu(Pd1-xAux)2Si2的电子结构和价态行为，但存在掺杂效率限制和副相形成问题；Ge掺杂引入成分波动影响物性；新发现的正交相拓展了该体系的结构与磁性多样性。

Abstract: We report on the single crystal growth of Eu(Pd$_{1-x}$Au$_x$)$_2$Si$_2$, $0< x\leq 0.2$, from a levitating Eu-rich melt using the Czochralski method. Our structural analysis of the samples confirms the ThCr$_2$Si$_2$-type structure as well as an increase of the room temperature $a$ and $c$ lattice parameters with increasing $x$. Chemical analysis reveals that, depending on the Au concentration, only about 25-35\% of the amount of Au available in the initial melt is incorporated into the crystal structure, resulting in a decreasing substitution level for increasing $x$. Through Au substitution, chemical pressure is applied and large changes in valence crossover temperatures are already observed for low substitution levels $x$. In contrast to previous studies, we do not find any signs of a first-order transition in samples with $x_{\rm nom}=0.1$ or AFM order for higher $x$. Furthermore, we observe the formation of quarternary side phases for a higher amount of Au in the melt.
  In addition, cubic-mm-sized single crystals of EuPd$_2$(Si$_{1-x}$Ge$_x$)$_2$ with $x_{\rm nom}=0.2$ were grown. The analysis of the X-ray fluorescence revealed that the crystals exhibit a slight variation in the Ge content. Such tiny compositional changes can cause changes in the sample properties concerning variations of the crossover temperature or changes of the type of the transition from crossover to magnetic order. Furthermore, we report on a new orthorhombic phase EuPd$_{1.42}$Si$_{1.27}$Ge$_{0.31}$ that orders antiferromagnetically below $17\,\rm K$.

</details>


### [128] [Thermal conductivity in noncollinear magnets](https://arxiv.org/abs/2602.03326)
*Margherita Parodi,Sergey Artyukhin*

Main category: cond-mat.str-el

TL;DR: 研究了非共线自旋排列对磁振子热导率的影响，发现热传导主要由relaxons而非单个磁振子主导，热导率随螺旋螺距减小而增加。


<details>
  <summary>Details</summary>
Motivation: 控制热量流动对于基于磁性器件（如skyrmions）的性能至关重要，需要理解非共线自旋结构如何影响热导率。

Method: 以具有自旋螺旋基态的基本非共线磁体为模型系统，通过数值求解完整的玻尔兹曼方程来研究磁振子的热输运行为。

Result: 发现非共线性导致磁振子融合和衰变过程，传统单模近似低估热导率；实际热导率更高，表明热量由relaxons（磁振子的线性组合）携带，并随螺旋螺距减小而增加。

Conclusion: 结果揭示了非共线磁体中磁热输运的新机制，为相关材料的热管理提供了理论蓝图。

Abstract: Magnetic memory and logic devices, including prospective ones based on skyrmions, inevitably produce heat. Thus, controlling heat flow is essential for their performance. Here we study how non-collinear spin arrangement affects the magnon contribution to thermal conductivity. As a paradigm system, we consider the most basic non-collinear magnet with a spin spiral ground state. Spin noncollinearity leads to anharmonic terms, resulting in magnon fusion and decay processes. These processes determine the magnon lifetime, which can be used to estimate thermal conductivity in a single-mode approximation. However, by solving the full Boltzmann equation numerically, we find a much higher thermal conductivity. This signifies that heat is carried not by individual magnons but by their linear combinations -- relaxons. The thermal conductivity is found to increase with the diminishing spiral pitch, consistent with recent experiments. The results provide the blueprint for calculating magnetic thermal transport in non-collinear magnets.

</details>


### [129] [Calculating Feynman diagrams with matrix product states](https://arxiv.org/abs/2602.03598)
*Xavier Waintal*

Main category: cond-mat.str-el

TL;DR: 本文综述了在量子纳米电子学（Keldysh形式）中费曼图自动计算的研究工作，重点应用于非平衡单杂质安德森模型中的近藤效应。


<details>
  <summary>Details</summary>
Motivation: 为了解决非平衡态强关联电子系统中费曼图数量激增的问题，并实现高效精确的计算。

Method: 采用张量交叉插值算法（Tensor Cross Interpolation）替代蒙特卡洛方法进行费曼图计算，并发展级数重求和技术。

Result: 实现了对大量费曼图的高效自动计算与处理，提升了非平衡量子系统微扰计算的效率与精度。

Conclusion: 该方法为研究非平衡条件下的强关联电子系统（如近藤效应）提供了有力的理论工具。

Abstract: This text reviews, hopefully in a pedagogical manner, a series of work on the automatic calculations of Feynman diagrams in the context of quantum nanoelectronics (Keldysh formalism) with an application to the Kondo effect in the out-of-equilibrium single impurity Anderson model. It includes a discussion of (A) how to deal with the proliferation of diagrams, (B) how to calculate them using the Tensor Cross Interpolation algorithm instead of Monte-Carlo and (C) how to resum the obtained series. These notes correspond to a lecture given at the Autumn School on Correlated Electrons 2025 in Jullich, Germany. The book with all the lectures of the school (edited by Eva Pavarini, Erik Koch, Alexander Lichtenstein, and Dieter Vollhardt) is available in open access.

</details>


### [130] [Evidence for Many-Body States in NiPS$_3$ Revealed by Angle-Resolved Photoelectron Spectroscopy](https://arxiv.org/abs/2602.03600)
*Miłosz Rybak,Benjamin Pestka,Biplab Bhattacharyya,Jeff Strasdas,Adam K. Budniak,Adi Harchol,Vitaliy Feyer,Iulia Cojocariu,Daniel Baranowski,Efrat Lifshitz,Markus Morgenstern,Magdalena Birowska,Krzysztof Wohlfeld*

Main category: cond-mat.str-el

TL;DR: 该研究通过μ-ARPES光谱揭示了NiPS₃中超出平均场理论的多体结构，证实了强关联、低维度和共价金属-配体键合共同影响其单粒子和双粒子谱学特性。


<details>
  <summary>Details</summary>
Motivation: 探索二维量子材料NiPS₃中的强关联效应及其在单粒子谱中的表现，填补此前未在光发射谱中观测到强关联特征的空白。

Method: 采用μ-ARPES技术测量NiPS₃的价带边缘，并结合NiS₆团簇的精确对角化计算分析低能末态构型。

Result: 发现一个弱色散的额外谱特征，该特征在DFT+U计算中缺失且在奈尔转变前后不变，可归因于混合多重态d⁷和d⁸L̲的低能末态配置。

Conclusion: NiPS₃是研究强关联二维材料的理想平台，其单粒子谱直接反映了局域Ni-S多重态物理，需采用真正的量子多体描述。

Abstract: We present $μ$-ARPES spectra of the Mott-insulating van der Waals antiferromagnet NiPS$_3$. Signatures of strong correlations- such as the onset of atomic or atomic-ligand multiplets and spin-orbit-entangled exciton have been observed in this material by various two-particle spectroscopies, but not previously in photoemission. Our measurements reveal a weakly dispersive feature at the valence-band edge that is absent in DFT+$U$ calculations and remains unchanged across the Néel transition. After critically examining and ruling out alternative interpretations, we show that an exact diagonalization of a NiS$_6$ cluster yields low-energy final-state configurations of mixed multiplet $d^7$ and $d^8\underline{L}$ character, whose energy differences are consistent with the observed additional feature. This implies that ARPES directly accesses local Ni-S multiplet physics in NiPS$_3$, revealing a many-body structure beyond mean-field theory. Our results confirm that NiPS$_3$ is an excellent model platform in which strong correlations, reduced dimensionality, and covalent metal-ligand bonding jointly shape both two- and single-particle spectroscopies, underscoring the need for a genuinely quantum many-body description of two-dimensional quantum materials.

</details>


### [131] [Orbital-selective Mottness Driven by Geometric Frustration of Interorbital Hybridization in Pr4Ni3O10](https://arxiv.org/abs/2602.03658)
*Yidian Li,Mingxin Zhang,Xian Du,Cuiying Pei,Jieyi Liu,Houke Chen,Wenxuan Zhao,Kaiyi Zhai,Yinqi Hu,Senyao Zhang,Jiawei Shao,Mingxin Mao,Yantao Cao,Jinkui Zhao,Zhengtai Li,Dawei Shen,Yaobo Huang,Makoto Hashimoto,Donghui Lu,Zhongkai Liu,Yulin Chen,Hanjie Guo,Yilin Wang,Yanpeng Qi,Lexian Yang*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: The interplay among orbital-selective Mott physics, Hund's coupling, tunable structural motifs, and Kondo-like scattering establishes a compelling paradigm for understanding and engineering correlated multi-orbital systems, as vividly exemplified by nickelate superconductors. Here, using high-resolution angle-resolved photoemission spectroscopy combined with theoretical calculations, we systematically investigate the electronic properties of trilayer nickelates. In La4Ni3O10, we observe pronounced interorbital hybridization, whereas in Pr4Ni3O10, the flat d_(z^2 ) band becomes markedly incoherent and diminishes in spectral weight. By contrast, the dispersive d_(x^2-y^2 ) bands retain coherence in both compounds. This striking incoherence/coherence dichotomy identifies an orbital-selective Mott phase modulated by the interlayer Ni-O-Ni bonding angle. The depletion of the d_(z^2 ) orbitals further frustrates the interorbital hybridization and influences the density-wave transition in Pr4Ni3O10. Moreover, the density-wave gap is substantially reduced in Pr4Ni3O10, likely due to extra scattering channels provided by the local moments of Pr3+ cations. Our findings elucidate the intricate interplay among lattice, orbital, spin, and electronic degrees of freedom and reveal a feasible structural control parameter for the multi-orbital correlated state in trilayer nickelates, which provide a concrete framework for understanding the emergence of superconductivity under high pressure.

</details>


### [132] [Machine Learning Modeling of Charge-Density-Wave Recovery After Laser Melting](https://arxiv.org/abs/2602.03761)
*Sankha Subhra Bakshi,Yunhao Fan,Gia-Wei Chern*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We investigate the nonequilibrium dynamics of a laser-pumped two-dimensional spinless Holstein model within a semiclassical framework, focusing on the melting and recovery of long-range charge-density-wave order. Accurately describing this process requires fully nonadiabatic electron-lattice dynamics, which is computationally demanding due to the need to resolve fast electronic motion over long time scales. By analyzing the structure of the lattice force during nonequilibrium evolution, we show that the force naturally separates into a smooth quasi-adiabatic component and a residual bath-like contribution associated with fast electronic fluctuations. The quasi-adiabatic component depends only on the instantaneous local lattice configuration and can be efficiently learned using machine-learning techniques, while a minimal Langevin description of the bath term captures the essential features of the recovery dynamics. Combining these elements enables efficient and scalable simulations of long-time nonequilibrium dynamics on large lattices, providing a practical route to access driven correlated systems beyond the reach of direct nonadiabatic approaches.

</details>


### [133] [Spin and Charge Conductivity in the Square Lattice Fermi-Hubbard Model](https://arxiv.org/abs/2602.03771)
*Linh Pham,Ehsan Khatami*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: Dynamical properties are notoriously difficult to compute in numerical treatments of the Fermi-Hubbard model, especially in two spatial dimensions. However, they are essential in providing us with insight into some of the most important and less well-understood phases of the model, such as the pseudogap and strange metal phases at relatively high temperatures, or unconventional superconductivity at lower temperatures, away from the commensurate filling. Here, we use the numerical linked-cluster expansions to compute spin and charge optical conductivities of the model at different temperatures and strong interaction strengths via the exact real-time-dependent correlation functions of the current operators. We mitigate systematic errors associated with having a limited access to the long-time behavior of the correlators by introducing fits and allowing for non-zero Drude weights when appropriate. We compare our results to available data from optical lattice experiments and find that the Drude contributions can account for the theory-experiment gap in the DC spin conductivity of the model at half filling in the strong-coupling region. Our method helps paint a more complete picture of the conductivity in the two-dimensional Hubbard model and opens the door to studying dynamical properties of quantum lattice models in the thermodynamic limit.

</details>


### [134] [Classical Benchmarks of a Symmetry-Adapted Variational Quantum Eigensolver for Real-Time Green's Functions in Dynamical Mean-Field Theory](https://arxiv.org/abs/2602.03843)
*Aadi Singh,Chakradhar Rangi,Ka-Ming Tam*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a variational quantum eigensolver (VQE) approach for solving the Anderson Impurity Model (AIM) arising in Dynamical Mean-Field Theory (DMFT). Recognizing that the minimal two-site approximation often fails to resolve essential spectral features, we investigate the efficacy of VQE for larger bath discretizations while adhering to near-term hardware constraints. We employ a symmetry-adapted ansatz enforcing conservation of particle number $(N)$, spin projection $(S_z=0)$, and total spin $(S^2=0)$ symmetry, benchmarking the performance against exact diagonalization across different interaction strengths using bath parameters extracted from the DMFT self-consistency loop. For a four-site model, the relative error in the ground state energy remains well below $0.01%$ with a compact parameter set $(N_p \le 30)$. Crucially, we demonstrate that the single-particle Green's function-the central quantity for DMFT-can be accurately extracted from VQE-prepared ground states via real-time evolution in the intermediate to strong interaction regimes. However, in the weak interaction regime, the Green's function exhibits noticeable deviations from the exact benchmark, particularly in resolving low-energy spectral features, despite the ground state energy showing excellent agreement. These findings demonstrate that VQE combined with real-time evolution can effectively extend quantum-classical hybrid DMFT beyond the two-site approximation, particularly for describing insulating phases. While this approach offers a viable pathway for simulating strongly correlated materials on near-term devices, the observation that accurate ground state energy does not guarantee accurate dynamical properties highlights a key challenge for applying such approaches to correlated metals.

</details>


### [135] [A Unified Categorical Description of Quantum Hall Hierarchy and Anyon Superconductivity](https://arxiv.org/abs/2602.03848)
*Donghae Seo,Taegon Lee,Gil Young Cho*

Main category: cond-mat.str-el

TL;DR: Summary generation failed


<details>
  <summary>Details</summary>
Motivation: Motivation analysis unavailable

Method: Method extraction failed

Result: Result analysis unavailable

Conclusion: Conclusion extraction failed

Abstract: We present a unified category-theoretic framework for quantum Hall hierarchy constructions and anyon superconductivity based on modular tensor categories over $\mathrm{Rep}(\mathrm{U}(1))$ and $\mathrm{sRep}(\mathrm{U}(1)^f)$. Our approach explicitly incorporates conserved $\mathrm{U}(1)$ charge and formulates doping via a generalized stack-and-condense procedure, in which an auxiliary topological order is stacked onto the parent phase, and the quasiparticles created by doping subsequently condense. Depending on whether this condensation preserves or breaks the $\mathrm{U}(1)$ symmetry, the system undergoes a transition to a quantum Hall hierarchy state or to an anyon superconductor. For anyon superconductors, the condensate charge is determined unambiguously by the charged local bosons contained in the condensable algebra. Our framework reproduces all known anyon superconductors obtained from field-theoretic analyses and further predicts novel phases, including a charge-$2e$ anyon superconductor derived from the Laughlin state and charge-$ke$ anyon superconductors arising from bosonic $\mathbb{Z}_k$ Read-Rezayi states. By placing hierarchy transitions and anyon superconductivity within a single mathematical formalism, our work provides a unified understanding of competing and proximate phases near experimentally realizable fractional quantum Hall states.

</details>
