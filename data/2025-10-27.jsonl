{"id": "2510.21041", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2510.21041", "abs": "https://arxiv.org/abs/2510.21041", "authors": ["Yamil Cahuana Medrano", "Hervé Dutrieux", "Joseph Karpie", "Kostas Orginos", "Savvas Zafeiropoulos"], "title": "Gaussian Processes for Inferring Parton Distributions", "comment": null, "summary": "The extraction of parton distribution functions (PDFs) from experimental or\nlattice QCD data is an ill-posed inverse problem, where regularization strongly\nimpacts both systematic uncertainties and the reliability of the results. We\nstudy a framework based on Gaussian Process Regression (GPR) to reconstruct\nPDFs from lattice QCD matrix elements. Within a Bayesian framework, Gaussian\nprocesses serve as flexible priors that encode uncertainties, correlations, and\nconstraints without imposing rigid functional forms. We investigate a wide\nrange of kernel choices, mean functions, and hyperparameter treatments. We\nquantify information gained from the data using the Kullback Leibler\ndivergence. Synthetic data tests demonstrate the consistency and robustness of\nthe method. Our study establishes GPR as a systematic and non-parametric\napproach to PDF reconstruction, offering controlled uncertainty estimates and\nreduced model bias in lattice QCD analyses."}
{"id": "2510.21248", "categories": ["hep-lat", "gr-qc", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.21248", "abs": "https://arxiv.org/abs/2510.21248", "authors": ["Axel Maas", "Simon Plätzer", "Felix Pressler"], "title": "Composite objects in quantum (super)gravity", "comment": "9 pages, 2 figures, submitted to the proceedings of EPHSHEP25", "summary": "It has been a long entertained idea that self-bound gravitons, so-called\ngeons, could be a dark matter candidate or form (primordial) black holes. The\ndevelopment of viable candidates for quantum gravity allows now to investigate\nthese ideas. Analytic methods show that the description of geons needs to be\nbased on composite operators made out of the graviton field. We present results\nfrom a numerical investigation into this idea using causal dynamical\ntriangulations, an ab-initio non-perturbative definition of quantum gravity\nbased on general relativity, and accessible in lattice-gauge-theory-like\nsimulations. Our results suggest an interesting dependence on cosmological time\nand other unexpected features. Finally, we extend the analytic part of the\nsetting to a supergravity scenario. This provides hints which, if confirmed,\ncould explain why supersymmetry may in a realistic universe in principle not be\nobservable at low (collider) energy scales."}
{"id": "2510.20893", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.20893", "abs": "https://arxiv.org/abs/2510.20893", "authors": ["Lei Su"], "title": "$\\mathbb{Z}_2$ lattice gauge theories: fermionic gauging, transmutation, and Kramers-Wannier dualities", "comment": "6+17 pages. This work is dedicated to C. N. Yang", "summary": "We generalize the gauging of $\\mathbb{Z}_2$ symmetries by inserting Majorana\nfermions, establishing parallel duality correspondences for bosonic and\nfermionic lattice systems. Using this fermionic gauging, we construct fermionic\nanalogs of $\\mathbb{Z}_2$ gauge theories dual to the transverse-field Ising\nmodel, interpretable as Majorana stabilizer codes. We demonstrate a unitary\nequivalence between the $\\mathbb{Z}_2$ gauge theory obtained by gauging the\nfermion parity of a free fermionic system and the conventional $\\mathbb{Z}_2$\ngauge theory with potentially nonlocal terms on the square lattice with\ntoroidal geometry. This equivalence is implemented by a linear-depth local\nunitary circuit, connecting the bosonic and fermionic toric codes through a\ndirection-dependent anyonic transmutation. The gauge theory obtained by gauging\nfermion parity is further shown to be equivalent to a folded Ising chain\nobtained via the Jordan--Wigner transformation. We clarify the distinction\nbetween the recently proposed Kramers--Wannier dualities and those obtained by\ngauging the $\\mathbb{Z}_2$ symmetry along a space-covering path. Our results\nextend naturally to higher-dimensional $\\mathbb{Z}_2$ lattice gauge theories,\nproviding a unified framework for bosonic and fermionic dualities and offering\nnew insights for quantum computation and simulation."}
{"id": "2510.21109", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.21109", "abs": "https://arxiv.org/abs/2510.21109", "authors": ["Federico Ghimenti", "Adithya Sriram", "Atsushi Yamamura", "Hideo Mabuchi", "Surya Ganguli"], "title": "The geometry and dynamics of annealed optimization in the coherent Ising machine with hidden and planted solutions", "comment": null, "summary": "The coherent Ising machine (CIM) is a nonconventional hardware architecture\nfor finding approximate solutions to large-scale combinatorial optimization\nproblems.It operates by annealing a laser gain parameter to adiabatically\ndeform a high-dimensional energy landscape over a set of soft spins, going from\na simple convex landscape to the more complex optimization landscape of\ninterest. We address how the evolving energy landscapes guides the optimization\ndynamics against problems with hidden planted solutions. We study the\nSherrington-Kirkpatrick spin-glass with ferromagnetic couplings that favor a\nhidden configuration by combining the replica method, random matrix theory, the\nKac-Rice method and dynamical mean field theory. We characterize energy,\nnumber, location, and Hessian eigenspectra of global minima, local minima, and\ncritical points as the landscape evolves. We find that low energy global minima\ndevelop soft-modes which the optimization dynamics can exploit to descend the\nenergy landscape. Even when these global minima are aligned to the hidden\nconfiguration, there can be exponentially many higher energy local minima that\nare all unaligned with the hidden solution. Nevertheless, the annealed\noptimization dynamics can evade this cloud of unaligned high energy local\nminima and descend near to aligned lower energy global minima. Eventually, as\nthe landscape is further annealed, these global minima become rigid,\nterminating any further optimization gains from annealing. We further consider\na second optimization problem, the Wishart planted ensemble, which contains a\nhidden planted solution in a landscape with tunable ruggedness. We describe CIM\nphase transitions between recoverability and non-recoverability of the hidden\nsolution. Overall, we find intriguing relations between high-dimensional\ngeometry and dynamics in analog machines for combinatorial optimization."}
{"id": "2510.21191", "categories": ["physics.geo-ph", "86A22 (Primary) 68T07, 31A25, 86A20 (Secondary)"], "pdf": "https://arxiv.org/pdf/2510.21191", "abs": "https://arxiv.org/abs/2510.21191", "authors": ["Adarsh Jain", "Pawan Bharadwaj", "Chandra Sekhar Seelamantula"], "title": "Cold-Diffusion Driven Downward Continuation of Gravity Data", "comment": null, "summary": "Gravity data can be better interpreted after enhancing high-frequency\ninformation via downward continuation. Downward continuation is an ill-posed\ndeconvolution problem. It has been tackled using regularization techniques,\nwhich are sensitive to the choice of regularization parameters. More recently,\nconvolutional neural networks such as the U-Net have been trained using\nsynthetic data to potentially learn prior information and perform deconvolution\nwithout the need to adjust the regularization parameters. Our experiments\nreveal that the U-Net is highly sensitive to correlated noise, which is\nubiquitously present in geophysical field data. In this paper, we develop a\nframework based on the $\\textbf{cold-diffusion model}$ using the exponential\nkernel associated with downward continuation. The exponential form of the\nkernel allows us to train the U-Net to tackle multiple concurrent deconvolution\nproblems with varying levels of blur. This allows our framework to be more\nrobust and quantitatively outperform traditional U-Net-based approaches. The\nperformances also closely matches that of $\\textbf{oracle}$ Tikhonov\nreconstruction technique, which has access to the ground truth."}
{"id": "2510.21012", "categories": ["math.NA", "cs.LG", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21012", "abs": "https://arxiv.org/abs/2510.21012", "authors": ["William Lauga", "James Rowbottom", "Alexander Denker", "Željko Kereta", "Moshe Eliasof", "Carola-Bibiane Schönlieb"], "title": "Graph Neural Regularizers for PDE Inverse Problems", "comment": null, "summary": "We present a framework for solving a broad class of ill-posed inverse\nproblems governed by partial differential equations (PDEs), where the target\ncoefficients of the forward operator are recovered through an iterative\nregularization scheme that alternates between FEM-based inversion and learned\ngraph neural regularization. The forward problem is numerically solved using\nthe finite element method (FEM), enabling applicability to a wide range of\ngeometries and PDEs. By leveraging the graph structure inherent to FEM\ndiscretizations, we employ physics-inspired graph neural networks as learned\nregularizers, providing a robust, interpretable, and generalizable alternative\nto standard approaches. Numerical experiments demonstrate that our framework\noutperforms classical regularization techniques and achieves accurate\nreconstructions even in highly ill-posed scenarios."}
{"id": "2510.20826", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.20826", "abs": "https://arxiv.org/abs/2510.20826", "authors": ["Hai Zhu", "Chia-Nan Yeh", "Miguel A. Morales", "Leslie Greengard", "Shidong Jiang", "Jason Kaye"], "title": "Interpolative separable density fitting on adaptive real space grids", "comment": "12 pages, 8 figures", "summary": "We generalize the interpolative separable density fitting (ISDF) method, used\nfor compressing the four-index electron repulsion integral (ERI) tensor, to\nincorporate adaptive real space grids for potentially highly localized\nsingle-particle basis functions. To do so, we employ a fast adaptive algorithm,\nthe recently-introduced dual-space multilevel kernel-splitting method, to solve\nthe Poisson equation for the ISDF auxiliary basis functions. The adaptive grids\nare generated using a high-order accurate, black-box procedure that satisfies a\nuser-specified error tolerance. Our algorithm relies on the observation, which\nwe prove, that an adaptive grid resolving the pair densities appearing in the\nERI tensor can be straightforwardly constructed from one that resolves the\nsingle-particle basis functions, with the number of required grid points\ndiffering only by a constant factor. We find that the ISDF compression\nefficiency for the ERI tensor with highly localized basis sets is comparable to\nthat for smoother basis sets compatible with uniform grids. To demonstrate the\nperformance of our procedure, we consider several molecular systems with\nall-electron basis sets which are intractable using uniform grid-based methods.\nOur work establishes a pathway for scalable many-body electronic structure\nsimulations with arbitrary smooth basis functions, making simulations of\nphenomena like core-level excitations feasible on a large scale."}
{"id": "2510.21688", "categories": ["cond-mat.dis-nn", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2510.21688", "abs": "https://arxiv.org/abs/2510.21688", "authors": ["H. P. Veiga", "D. R. Pinheiro", "J. P. Santos Pires", "J. M. Viana Parente Lopes"], "title": "Markov Inequality as a Tool for Linear-Scaling Estimation of Local Observables", "comment": "5 pages, 4 figures", "summary": "We introduce a linear-scaling stochastic method to compute real-space maps of\nany positive local spectral operator in a tight-binding model. By employing\npositive-definite estimators, the sampling error at each site can be rigorously\nbounded relative to the mean via the Markov inequality, overcoming the lack of\nself-averaging and enabling accurate estimates even under strong spatial\nfluctuations. The approach extends to non-diagonal observables, such as local\ncurrents, through local unitary transformations and its effectiveness is\nshowcased by benchmark calculations in the disordered two-dimensional (2D)\n$\\pi$-flux model, where the LDoS and steady-state current maps are computed.\nThis method will enable simulations of disorder-driven mesoscopic phenomena in\nrealistically large lattices and accelerate real-space self-consistent\nmean-field calculations."}
{"id": "2510.21328", "categories": ["physics.ao-ph", "astro-ph.EP", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.21328", "abs": "https://arxiv.org/abs/2510.21328", "authors": ["Leonard Schulz", "Karl-Heinz Glassmeier", "Moritz Herberhold", "Adam Mitchell", "Daniel M. Murphy", "John M. C. Plane", "Ferdinand Plaschke"], "title": "Space waste: An update of the anthropogenic matter injection into Earth atmosphere", "comment": "Preprint submitted to Advances in Space Research", "summary": "Large satellite constellations are one of the main reasons for an increasing\namount of mass being brought into low Earth orbit in recent years. After end of\nlife, the satellites, as well as rocket stages, reenter Earth's atmosphere.\nThis space waste burns up and thus injects a substantial amount of its matter\ninto the mesosphere and lower thermosphere. A first comprehensive analysis of\nthe anthropogenic injection and a comparison to the natural injection by\nmeteoroids was presented by Schulz & Glassmeier (2021). They found significant\nand even the dominant injection of several metal elements regularly used in\nspacecraft compared to the natural injection. The first observations of space\nwaste remnants in stratospheric aerosol particles (Murphy et al., 2023)\nconfirmed several of these estimates, but also revealed differences and new\ninsights. The current study presents an update to the space waste injection\nestimates of Schulz & Glassmeier (2021), assessing the years from 2015 to 2025\nbut also considering future mass influx scenarios. 43 elements are considered\nand thus a much more detailed comparison to the meteoric injection is possible.\nComparison of estimated elemental fluxes to stratospheric aerosol data shows\nexcellent agreement. From 2020 onward, a strong rise in space waste mass influx\nto the atmosphere can be seen. Future scenarios discussed by Schulz &\nGlassmeier (2021) may already be reached by the end of 2025. In 2024, 24\nelements were dominating the meteoric injection compared to 18 in 2015. Several\nof them are transition metals, which are known for their catalytic activity.\nThis indicates a substantial risk of long-term adverse effects on the\natmosphere such as ozone depletion, radiative effects and changes in cloud\nformation, if no action is taken. Research is urgently needed into the\natmospheric accumulation, chemistry, and general atmospheric effects of\nspecific elements."}
{"id": "2510.21080", "categories": ["math.NA", "cs.NA", "65K05, 65K10, 65M60, 90C25"], "pdf": "https://arxiv.org/pdf/2510.21080", "abs": "https://arxiv.org/abs/2510.21080", "authors": ["Chen Liu", "Dionysis Milesis", "Chi-Wang Shu", "Xiangxiong Zhang"], "title": "Efficient optimization-based invariant-domain-preserving limiters in solving gas dynamics equations", "comment": null, "summary": "We introduce effective splitting methods for implementing optimization-based\nlimiters to enforce the invariant domain in gas dynamics in high order accurate\nnumerical schemes. The key ingredients include an easy and efficient explicit\nformulation of the projection onto the invariant domain set, and also proper\napplications of the classical Douglas-Rachford splitting and its more recent\nextension Davis-Yin splitting. Such an optimization-based approach can be\napplied to many numerical schemes to construct high order accurate, globally\nconservative, and invariant-domain-preserving schemes for compressible flow\nequations. As a demonstration, we apply it to high order discontinuous Galerkin\nschemes and test it on demanding benchmarks to validate the robustness and\nperformance of both $\\ell^1$-norm minimization limiter and $\\ell^2$-norm\nminimization limiter."}
{"id": "2510.21065", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.21065", "abs": "https://arxiv.org/abs/2510.21065", "authors": ["Tianyi Hu", "Thomas J. R. Hughes", "Guglielmo Scovazzi", "Hector Gomez"], "title": "Phase-Field/Discontinuity Capturing operator for direct van der Waals simulation (DVS)", "comment": null, "summary": "Discontinuity capturing (DC) operators are commonly employed to numerically\nsolve problems involving sharp gradients in the solution. Despite their\nsuccess, the application of DC operators to the direct van der Waals simulation\n(DVS) remains challenging. The DVS framework models non-equilibrium phase\ntransitions by admitting interfacial regions in which the derivative of\npressure with respect to density is negative. In these regions, we demonstrate\nthat classical DC operators may violate the free energy dissipation law and\nproduce unphysical wave structures. To address this limitation, we propose the\nphase-field/discontinuity capturing (PF/DC) operator. Numerical results show\nthat PF/DC yields stable and accurate solutions in both bulk fluids and\ninterfacial regions. Finally, we apply the proposed method to simulate\ncavitating flow over a three-dimensional bluff body, obtaining excellent\nagreement with experimental data and significant improvements over results\nproduced using classical DC operators."}
{"id": "2510.20824", "categories": ["nlin.CD", "cond-mat.mtrl-sci", "cond-mat.stat-mech", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.20824", "abs": "https://arxiv.org/abs/2510.20824", "authors": ["Liteng Yang", "Yuliang Liu", "Jing Liu", "Hongxuan Li", "Wei Chen"], "title": "A Probability Space at Inception of Stochastic Process", "comment": "14 pages, 1 figure", "summary": "Recently, progress has been made in the theory of turbulence, which provides\na framework on how a deterministic process changes to a stochastic one owing to\nthe change in thermodynamic states. It is well known that, in the framework of\nNewtonian mechanics, motions are dissipative; however, when subjected to\nperiodic motion, a system can produce nondissipative motions intermittently and\nsubject to resonance. It is in resonance that turbulence occurs in fluid flow,\nsolid vibration, thermal transport, etc. In this, the findings from these\nphysical systems are analyzed in the framework of statistics with their own\nprobability space to establish their compliance to the stochastic process. In\nparticular, a systematic alignment of the inception of the stochastic process\nwith the signed measure theory, signed probability space, and stochastic\nprocess was investigated. It was found that the oscillatory load from the\ndissipative state excited the system and resulted in a quasi-periodic\nprobability density function with the negative probability regimes. In\naddition, the vectorial nature of the random velocity splits the probability\ndensity function along both the positive and negative axes with slight\nasymmetricity. By assuming that a deterministic process has a probability of 1,\nwe can express the inception of a stochastic process, and the subsequent\nbenefit is that a dynamic fractal falls on the probability density function.\nMoreover, we leave some questions of inconsistency between the physical system\nand the measurement theory for future investigation. We believe that the\nestablishment of the probability density function of resonance nondissipative\ndynamics in contemporary statistics should make many mathematical tools\navailable and the analytical formulas for the random velocity and probability\ndensity function can provide a convenient platform for the development of\nstatistics."}
{"id": "2510.20865", "categories": ["physics.hist-ph", "cond-mat.dis-nn", "cond-mat.str-el", "cond-mat.supr-con", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.20865", "abs": "https://arxiv.org/abs/2510.20865", "authors": ["Premala Chandra", "Piers Coleman", "Clare C. Yu"], "title": "Philip Warren Anderson", "comment": "A biographical memoir of P. W. Anderson to be published in\n  Biographical Memoirs of Fellows of the Royal Society. 27 pages, 7\n  figures/photos", "summary": "Philip Warren Anderson was a pioneering theoretical physicist whose work\nfundamentally shaped our understanding of complex systems. Anderson received\nthe Nobel Prize in Physics in 1977 for his groundbreaking research on\nlocalization and magnetism, yet he did so much more. His work on magnetism\nincluded antiferromagnetism, superexchange, the Kondo problem and local\nmagnetic moments in metals. Anderson pointed out the importance of disorder\nthrough his work on localization, non-crystalline solids and spin glasses. In\nsuperconductivity, he is known for the dirty superconductor theorem, showing\nthe gauge-invariance of the BCS theory, his study of flux creep, and for his\ncollaboration with experimentalists to realize the Josephson effect. Anderson's\nresonating valence bond theory may yet play an important role in high\ntemperature superconductivity. Anderson was also fascinated by broken symmetry,\nand he laid the theoretical groundwork for what is now known as the\nAnderson-Higgs mechanism, showing how gauge bosons can acquire mass - an\ninsight that played a foundational role in the Standard Model of particle\nphysics. In his seminal \"More is Different\" paper, Anderson argued that the\ncollective emergent phenomena that arise in complex interacting systems cannot\nbe deduced from their fundamental parts. Anderson's legacy endures not only\nthrough the lasting impact of his scientific work but also through his\ninfluence on generations of physicists who continue to explore the rich\nlandscape of collective behavior in nature."}
{"id": "2510.21018", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.21018", "abs": "https://arxiv.org/abs/2510.21018", "authors": ["Panayiotis Kousoulas", "Rahul Sharma", "Y. B. Guo"], "title": "Integrated physics-informed learning and resonance process signature for the prediction of fatigue crack growth for laser-fused alloys", "comment": "21 pages, 11 figures, 2 tables", "summary": "Fatigue behaviors of metal components by laser fusion suffer from scattering\ndue to random geometrical defects (e.g., porosity, lack of fusion). Monitoring\nfatigue crack initiation and growth is critical, especially for laser-fused\ncomponents with significant inherent fatigue scattering. Conventional\nstatistics-based curve-fitting fatigue models have difficulty incorporating\nsignificant scattering in their fatigue life due to the random geometrical\ndefects. A scattering-informed predictive method is needed for laser-fused\nmaterials' crack size and growth. Current data-driven machine learning could\ncircumvent the issue of deterministic modeling, but results in a black-box\nfunction that lacks interpretability. To address these challenges, this study\nexplores a novel nondimensionalized physics-informed machine learning (PIML)\nmodel to predict fatigue crack growth of laser-fused SS-316L by integrating\nfatigue laws and constraints with small data to ensure a realistic and\ninterpretable prediction. Resonance process signature data were leveraged with\nParis's law to train the PIML model without experimental crack growth data. The\nresults show that Paris's law constants can be learned with good similarity to\ncomparable data from the literature, and the crack growth rate can be predicted\nto compute crack sizes."}
{"id": "2510.21123", "categories": ["physics.ao-ph", "physics.ed-ph"], "pdf": "https://arxiv.org/pdf/2510.21123", "abs": "https://arxiv.org/abs/2510.21123", "authors": ["Gan Zhang", "Zhuo Wang", "Kevin A Reed", "Lucas M Harris"], "title": "Navigating Through Turbulence: Blueprint for the Next Generation of Weather-Climate Scientists", "comment": "Essay for Bulletin of the American Meteorological Society (BAMS).\n  Invited submission to go through peer review", "summary": "The field of weather and climate science is at a pivotal moment, defined by\nthe dual forces of unprecedented technological advancement. While a shifting\nresearch and employment landscape has created career uncertainty, leading to a\nsignificant migration of talent toward the private sector, it has\nsimultaneously spurred an expansion of the ecosystem through the emergence of\nnew computational tools and the growing role of industry innovators and\nstakeholders. This perspective paper argues that this new, expanded ecosystem\npresents extraordinary opportunities for students and early-career\nprofessionals. We outline the emerging scientific frontiers powered by\nhigh-resolution simulations and artificial intelligence, suggest a practical\npath for navigating a more fluid career landscape, and propose how education\nand training must evolve to equip the next generation for success."}
{"id": "2510.20865", "categories": ["physics.hist-ph", "cond-mat.dis-nn", "cond-mat.str-el", "cond-mat.supr-con", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.20865", "abs": "https://arxiv.org/abs/2510.20865", "authors": ["Premala Chandra", "Piers Coleman", "Clare C. Yu"], "title": "Philip Warren Anderson", "comment": "A biographical memoir of P. W. Anderson to be published in\n  Biographical Memoirs of Fellows of the Royal Society. 27 pages, 7\n  figures/photos", "summary": "Philip Warren Anderson was a pioneering theoretical physicist whose work\nfundamentally shaped our understanding of complex systems. Anderson received\nthe Nobel Prize in Physics in 1977 for his groundbreaking research on\nlocalization and magnetism, yet he did so much more. His work on magnetism\nincluded antiferromagnetism, superexchange, the Kondo problem and local\nmagnetic moments in metals. Anderson pointed out the importance of disorder\nthrough his work on localization, non-crystalline solids and spin glasses. In\nsuperconductivity, he is known for the dirty superconductor theorem, showing\nthe gauge-invariance of the BCS theory, his study of flux creep, and for his\ncollaboration with experimentalists to realize the Josephson effect. Anderson's\nresonating valence bond theory may yet play an important role in high\ntemperature superconductivity. Anderson was also fascinated by broken symmetry,\nand he laid the theoretical groundwork for what is now known as the\nAnderson-Higgs mechanism, showing how gauge bosons can acquire mass - an\ninsight that played a foundational role in the Standard Model of particle\nphysics. In his seminal \"More is Different\" paper, Anderson argued that the\ncollective emergent phenomena that arise in complex interacting systems cannot\nbe deduced from their fundamental parts. Anderson's legacy endures not only\nthrough the lasting impact of his scientific work but also through his\ninfluence on generations of physicists who continue to explore the rich\nlandscape of collective behavior in nature."}
{"id": "2510.21241", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21241", "abs": "https://arxiv.org/abs/2510.21241", "authors": ["Michal Outrata"], "title": "On the recent advances of spectral analysis for systems arising from fully-implicit RK methods", "comment": null, "summary": "This work deals with two groups of spectral analysis results for matrices\narising in fully implicit Runge-Kutta methods used for linear time-dependent\npartial differential equations. These were applied for different formulations\nof the same problem and used different tools to arrive at results that do not\nimmediately coincide. We show the equivalence of the results as well as the\nequivalence of the approaches, unifying the two directions."}
{"id": "2510.21213", "categories": ["physics.comp-ph", "physics.chem-ph", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.21213", "abs": "https://arxiv.org/abs/2510.21213", "authors": ["Yulong Pan", "Michael Lindsey"], "title": "Fast adaptive discontinuous basis sets for electronic structure", "comment": null, "summary": "We develop a discontinuous Galerkin (DG) framework for automatically\nconstructing adaptive basis sets for electronic structure calculations. By\nallowing basis functions to be discontinuous across element interfaces, our\napproach supports flexible combinations of atom-centered and polynomial basis\nsets, maintains favorable numerical conditioning, and induces structured\nsparsity of the one- and two-electron integrals, which we compute using\nspecialised numerical integration strategies. We also introduce\nmultigrid-preconditioned Poisson solvers that enable fast algorithms for both\nHartree-Fock (HF) and density functional theory (DFT) calculations within our\nDG basis sets. Moreover, these basis sets naturally support adaptive multigrid\npreconditioning for the linear eigensolvers employed within the self-consistent\nfield iteration for HF and DFT. Numerical experiments for HF and DFT\ndemonstrate that our approach achieves chemical accuracy with modest basis\nsizes that compare favorably to the sizes of ordinary GTO basis sets achieving\nsimilar accuracy, while offering additional structured sparsity and improved\ncomputational scalability in the size-extensive limit. The framework thus\nprovides a flexible route toward the construction of systematically improvable\nand structured adaptive basis sets for electronic structure theory."}
{"id": "2510.21318", "categories": ["nlin.CD", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.21318", "abs": "https://arxiv.org/abs/2510.21318", "authors": ["Jian Zu", "Zhiguo Xu", "Jingyue Hao"], "title": "A Deep Learning Framework for Identifying Weakly Chaotic, Strongly Chaotic, Resonant and Non-resonant Orbits in the Generalized Kicked Rotator", "comment": null, "summary": "Identifying the types of orbits is an important topic in the study of chaotic\ndynamical systems. Beyond the well-known distinctly chaotic and regular\nmotions, we focus on dynamics occurring in regions where regular and chaotic\nmotions coexist and intertwine, which potentially indicating weakly chaotic\norbits. This intermediate regime lies between strongly chaotic dynamics,\ncharacterized by exponential sensitivity and completely non-chaotic, purely\nregular behavior. In this paper, we introduce a deep learning framework to\nidentify the types of orbits in the generalized kicked rotator system, which is\nchallenging to study due to its complex and mixed chaotic behaviors. Our deep\nlearning framework can be divided into two steps. First, we propose a novel\nalgorithm that integrates the weighted Birkhoff average, the Lyapunov exponent,\nand the correlation dimension to identify weakly chaotic orbits. The algorithm\ncategorizes orbits into four types: weakly chaotic, strongly chaotic, and\nregular orbits (which are further subdivided into resonant and non-resonant\norbits), thereby creating a valuable dataset required for deep learning models.\nSecond, we demonstrate that a well-trained 2D-CNN achieves high performance in\naccurately classifying orbits, largely because it effectively leverages the 2D\nstructural information of the phase space relation. To our knowledge, this is\nthe first paper to identify weakly chaotic orbits using deep learning methods.\nThe method can be easily extend to other models."}
{"id": "2510.21230", "categories": ["cs.CE", "physics.comp-ph", "65Y05"], "pdf": "https://arxiv.org/pdf/2510.21230", "abs": "https://arxiv.org/abs/2510.21230", "authors": ["Jose Alfonso Pinzon Escobar", "Markus Mühlhäußer", "Hans-Joachim Bungartz", "Philipp Neumann"], "title": "Linked Cell Traversal Algorithms for Three-Body Interactions in Molecular Dynamics", "comment": "26 pages", "summary": "In this work, algorithms for the parallel computation of three-body\ninteractions in molecular dynamics are developed. While traversals for the\ncomputation of pair interactions are readily available in the literature, here,\nsuch traversals are extended to allow for the computation between molecules\nstored across three cells. A general framework for the computation of\nthree-body interactions in linked cells is described, and then used to\nimplement the corresponding traversals. In addition, our analysis is combined\nwith the commonly used cutoff conditions, because they influence the total\nworkload of the computation of interactions. The combinations between\ntraversals and truncation conditions are validated using the well-known\nLennard-Jones fluid. Validation case studies are taken from the literature and\nconfigured into homogeneous and inhomogeneous scenarios. Finally, strong\nscalability and performance in terms of molecule updates are measured at\nnode-level."}
{"id": "2510.21201", "categories": ["physics.ao-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.21201", "abs": "https://arxiv.org/abs/2510.21201", "authors": ["Quan Mu"], "title": "Light scattering by random convex polyhedron in geometric optics approximation", "comment": null, "summary": "Based on the convex hull construction algorithm, a new geometrical model of\nice crystals is proposed to investigate the scattering properties of cirrus\nclouds particles. Light scattering matrices involving complete polarization\ninformation are calculated in geometric optics approximation for randomly\noriented large crystals with random and given convex polyhedron shape. The\nproposed model construction method and computational scheme of light scattering\nmatrix works for any convex polyhedron within the scope of geometrical optics.\nTo illustrate the broad applicability of the proposed ice crystal model,\nscattering matrices for three ice crystal examples with different geometrical\nshapes are calculated under a unified computational framework. Diffraction and\nabsorption are not considered in this work. The calculated results for the\nclassical hexagonal column model show overall agreement with those reported by\nother authors. The crystal model and scattering matrix computational framework\ndeveloped in this study are applicable to radiative transfer simulations and\nremote sensing data interpretation in terrestrial and planetary atmospheres."}
{"id": "2510.21006", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21006", "abs": "https://arxiv.org/abs/2510.21006", "authors": ["Akshay Naik", "Ramavarapu S. Sreenivas", "William R. Norris", "Albert E. Patterson", "Ahmet Soylemezoglu", "Dustin Nottage"], "title": "Safety Monitor for Off-Road Planning with Uncertainty Bounded Bekker Costs", "comment": null, "summary": "Reliable off-road autonomy requires operational constraints so that behavior\nstays predictable and safe when soil strength is uncertain. This paper presents\na runtime assurance safety monitor that collaborates with any planner and uses\na Bekker-based cost model with bounded uncertainty. The monitor builds an upper\nconfidence traversal cost from a lightweight pressure sinkage model identified\nin field tests and checks each planned motion against two limits: maximum\nsinkage and rollover margin. If the risk of crossing either limit is too high,\nthe monitor switches to a certified fallback that reduces vehicle speed,\nincreases standoff from soft ground, or stops on firmer soil. This separation\nlets the planner focus on efficiency while the monitor keeps the vehicle within\nclear safety limits on board. Wheel geometry, wheel load estimate, and a soil\nraster serve as inputs, which tie safety directly to vehicle design and let the\nmonitor set clear limits on speed, curvature, and stopping at run time. The\nmethod carries uncertainty analytically into the upper confidence cost and\napplies simple intervention rules. Tuning of the sinkage limit, rollover\nmargin, and risk window trades efficiency for caution while keeping the monitor\nlight enough for embedded processors. Results from a simulation environment\nspanning loam to sand include intervention rates, violation probability, and\npath efficiency relative to the nominal plan, and a benchtop static loading\ncheck provides initial empirical validation."}
{"id": "2510.21006", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21006", "abs": "https://arxiv.org/abs/2510.21006", "authors": ["Akshay Naik", "Ramavarapu S. Sreenivas", "William R. Norris", "Albert E. Patterson", "Ahmet Soylemezoglu", "Dustin Nottage"], "title": "Safety Monitor for Off-Road Planning with Uncertainty Bounded Bekker Costs", "comment": null, "summary": "Reliable off-road autonomy requires operational constraints so that behavior\nstays predictable and safe when soil strength is uncertain. This paper presents\na runtime assurance safety monitor that collaborates with any planner and uses\na Bekker-based cost model with bounded uncertainty. The monitor builds an upper\nconfidence traversal cost from a lightweight pressure sinkage model identified\nin field tests and checks each planned motion against two limits: maximum\nsinkage and rollover margin. If the risk of crossing either limit is too high,\nthe monitor switches to a certified fallback that reduces vehicle speed,\nincreases standoff from soft ground, or stops on firmer soil. This separation\nlets the planner focus on efficiency while the monitor keeps the vehicle within\nclear safety limits on board. Wheel geometry, wheel load estimate, and a soil\nraster serve as inputs, which tie safety directly to vehicle design and let the\nmonitor set clear limits on speed, curvature, and stopping at run time. The\nmethod carries uncertainty analytically into the upper confidence cost and\napplies simple intervention rules. Tuning of the sinkage limit, rollover\nmargin, and risk window trades efficiency for caution while keeping the monitor\nlight enough for embedded processors. Results from a simulation environment\nspanning loam to sand include intervention rates, violation probability, and\npath efficiency relative to the nominal plan, and a benchtop static loading\ncheck provides initial empirical validation."}
{"id": "2510.20827", "categories": ["physics.soc-ph", "cs.CY", "cs.DL"], "pdf": "https://arxiv.org/pdf/2510.20827", "abs": "https://arxiv.org/abs/2510.20827", "authors": ["Qing Ke", "Tianxing Pan", "Jin Mao"], "title": "The geography of novel and atypical research", "comment": "Accepted at Research Policy; data and code at\n  https://zenodo.org/records/15250119", "summary": "The production of knowledge has become increasingly a global endeavor. Yet,\nlocation related factors, such as local working environment and national policy\ndesigns, may continue to affect what kind of science is being pursued. Here we\nexamine the geography of the production of creative science by country, through\nthe lens of novelty and atypicality proposed in Uzzi et al. (2013). We quantify\na country's representativeness in novel and atypical science, finding\npersistent differences in propensity to generate creative works, even among\ndeveloped countries that are large producers in science. We further cluster\ncountries based on how their tendency to publish novel science changes over\ntime, identifying one group of emerging countries. Our analyses point out the\nrecent emergence of China not only as a large producer in science but also as a\nleader that disproportionately produces more novel and atypical research.\nDiscipline specific analysis indicates that China's over-production of atypical\nscience is limited to a few disciplines, especially its most prolific ones like\nmaterials science and chemistry."}
{"id": "2510.21279", "categories": ["math.NA", "cs.NA", "60H35, 37M25, 65C30"], "pdf": "https://arxiv.org/pdf/2510.21279", "abs": "https://arxiv.org/abs/2510.21279", "authors": ["Xin Liu", "Zhihui Liu"], "title": "Ergodic Estimates of One-Step Numerical Approximations for Superlinear SODEs", "comment": "15 pages", "summary": "This paper establishes the first-order convergence rate for the ergodic error\nof numerical approximations to a class of stochastic ODEs (SODEs) with\nsuperlinear coefficients and multiplicative noise. By leveraging the generator\napproach to the Stein method, we derive a general error representation formula\nfor one-step numerical schemes. Under suitable dissipativity and smoothness\nconditions, we prove that the error between the accurate invariant measure\n$\\pi$ and the numerical invariant measure $\\pi_\\tau$ is of order\n$\\mathscr{O}(\\tau)$, which is sharp. Our framework applies to several recently\nstudied schemes, including the tamed Euler, projected Euler, and backward Euler\nmethods."}
{"id": "2510.21683", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2510.21683", "abs": "https://arxiv.org/abs/2510.21683", "authors": ["Simon Butson", "Mathew Cleveland", "Alex Long", "Todd Palmer"], "title": "Reduced Floating-Point Precision Implicit Monte Carlo", "comment": "33 pages, 9 figures, 6 tables", "summary": "This work demonstrates algorithms to accurately compute solutions to thermal\nradiation transport problems using a reduced floating-point precision\nimplementation of the Implicit Monte Carlo method. Several techniques falling\ninto the categories of arithmetic manipulations and scaling methods are\nevaluated for their ability to improve the accuracy of reduced-precision\ncomputations. The results for half- and double-precision implementations of\nvarious thermal radiation benchmark problems are compared."}
{"id": "2510.21328", "categories": ["physics.ao-ph", "astro-ph.EP", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.21328", "abs": "https://arxiv.org/abs/2510.21328", "authors": ["Leonard Schulz", "Karl-Heinz Glassmeier", "Moritz Herberhold", "Adam Mitchell", "Daniel M. Murphy", "John M. C. Plane", "Ferdinand Plaschke"], "title": "Space waste: An update of the anthropogenic matter injection into Earth atmosphere", "comment": "Preprint submitted to Advances in Space Research", "summary": "Large satellite constellations are one of the main reasons for an increasing\namount of mass being brought into low Earth orbit in recent years. After end of\nlife, the satellites, as well as rocket stages, reenter Earth's atmosphere.\nThis space waste burns up and thus injects a substantial amount of its matter\ninto the mesosphere and lower thermosphere. A first comprehensive analysis of\nthe anthropogenic injection and a comparison to the natural injection by\nmeteoroids was presented by Schulz & Glassmeier (2021). They found significant\nand even the dominant injection of several metal elements regularly used in\nspacecraft compared to the natural injection. The first observations of space\nwaste remnants in stratospheric aerosol particles (Murphy et al., 2023)\nconfirmed several of these estimates, but also revealed differences and new\ninsights. The current study presents an update to the space waste injection\nestimates of Schulz & Glassmeier (2021), assessing the years from 2015 to 2025\nbut also considering future mass influx scenarios. 43 elements are considered\nand thus a much more detailed comparison to the meteoric injection is possible.\nComparison of estimated elemental fluxes to stratospheric aerosol data shows\nexcellent agreement. From 2020 onward, a strong rise in space waste mass influx\nto the atmosphere can be seen. Future scenarios discussed by Schulz &\nGlassmeier (2021) may already be reached by the end of 2025. In 2024, 24\nelements were dominating the meteoric injection compared to 18 in 2015. Several\nof them are transition metals, which are known for their catalytic activity.\nThis indicates a substantial risk of long-term adverse effects on the\natmosphere such as ozone depletion, radiative effects and changes in cloud\nformation, if no action is taken. Research is urgently needed into the\natmospheric accumulation, chemistry, and general atmospheric effects of\nspecific elements."}
{"id": "2510.21025", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21025", "abs": "https://arxiv.org/abs/2510.21025", "authors": ["Ahmed Saad Al-Karsani", "Maryam Khanbaghi", "Aleksandar Zečević"], "title": "A Connectively Stable and Robust DAPI Control Scheme for Islanded Networks of Microgrids", "comment": null, "summary": "The transition towards clean energy and the introduction of Distributed\nEnergy Resources (DERs) are giving rise to the emergence of Microgrids (MGs)\nand Networks of MGs (NMGs). MGs and NMGs can operate autonomously in islanded\nmode. However, they face challenges in terms of secondary level frequency and\nvoltage regulation, due to the variable nature of Renewable Energy Sources\n(RES) and loads. Distributed-Averaging Proportional-Integral (DAPI) control has\nbeen proposed in the literature for distributed frequency and voltage control\nof droop-controlled DERs, but it is not robust to operational or structural\nperturbations. To address this, we propose a robust DAPI frequency and voltage\ncontrol scheme that ensures robustness using the concept of connective\nstability, along with the invariant ellipsoid technique for disturbance\nrejection. Simulation of an NMG model in\nMATLAB\\textsuperscript{\\textregistered}/Simulink\\textsuperscript{\\textregistered}\nconsisting of 3 MGs and 5 DERs validates the effectiveness of the proposed\nmethod, and demonstrates that it can successfully mitigate the effects of major\ndisturbances such as cyberattacks."}
{"id": "2510.21025", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21025", "abs": "https://arxiv.org/abs/2510.21025", "authors": ["Ahmed Saad Al-Karsani", "Maryam Khanbaghi", "Aleksandar Zečević"], "title": "A Connectively Stable and Robust DAPI Control Scheme for Islanded Networks of Microgrids", "comment": null, "summary": "The transition towards clean energy and the introduction of Distributed\nEnergy Resources (DERs) are giving rise to the emergence of Microgrids (MGs)\nand Networks of MGs (NMGs). MGs and NMGs can operate autonomously in islanded\nmode. However, they face challenges in terms of secondary level frequency and\nvoltage regulation, due to the variable nature of Renewable Energy Sources\n(RES) and loads. Distributed-Averaging Proportional-Integral (DAPI) control has\nbeen proposed in the literature for distributed frequency and voltage control\nof droop-controlled DERs, but it is not robust to operational or structural\nperturbations. To address this, we propose a robust DAPI frequency and voltage\ncontrol scheme that ensures robustness using the concept of connective\nstability, along with the invariant ellipsoid technique for disturbance\nrejection. Simulation of an NMG model in\nMATLAB\\textsuperscript{\\textregistered}/Simulink\\textsuperscript{\\textregistered}\nconsisting of 3 MGs and 5 DERs validates the effectiveness of the proposed\nmethod, and demonstrates that it can successfully mitigate the effects of major\ndisturbances such as cyberattacks."}
{"id": "2510.20992", "categories": ["physics.soc-ph", "cs.CY", "econ.GN", "q-fin.EC", "91D10, 90B06", "I.6.3; I.6.4; J.4"], "pdf": "https://arxiv.org/pdf/2510.20992", "abs": "https://arxiv.org/abs/2510.20992", "authors": ["Flora Roumpani", "Joel Dearden", "Alan Wilson"], "title": "Urban Planning in 3D with a Two-tier LUTI model", "comment": "Preprint, 5000 words, 16 figures", "summary": "The two-tier Lowry model brings dynamic simulations of population and\nemployment directly into the planning process. By linking regional modelling\nwith neighbourhood design, the framework enables planners to explore how\nalternative planning scenarios may evolve over time. The upper tier captures\nregional flows of people, jobs, and services, while the lower tier allocates\nthese to fine-grain zones such as neighbourhoods or parcels. Implemented in\nCityEngine, the approach allows interactive visualisation and evaluation of\nmulti-scale scenarios. A case study in South Yorkshire (UK) illustrates how\nregional forecasts can be translated into local design responses, connecting\nquantitative modelling with 3D spatial planning."}
{"id": "2510.21289", "categories": ["math.NA", "cs.NA", "65N15, 65N30, 65N55"], "pdf": "https://arxiv.org/pdf/2510.21289", "abs": "https://arxiv.org/abs/2510.21289", "authors": ["Christian Alber", "Lukas Holbach"], "title": "Multiscale Spectral Generalized Finite Element Methods for Discontinuous Galerkin Schemes", "comment": null, "summary": "We propose a multiscale spectral generalized finite element method (MS-GFEM)\nfor discontinuous Galerkin (DG) discretizations. The method builds local\napproximations on overlapping subdomains as the sum of a local source solution\nand a correction from an optimal spectral coarse space, which is obtained from\na generalized eigenproblem. The global solution is then assembled via a\npartition of unity. We prove nearly exponential decay of the approximation\nerror for second-order elliptic problems discretized with a weighted symmetric\ninterior-penalty DG scheme."}
{"id": "2510.21230", "categories": ["cs.CE", "physics.comp-ph", "65Y05"], "pdf": "https://arxiv.org/pdf/2510.21230", "abs": "https://arxiv.org/abs/2510.21230", "authors": ["Jose Alfonso Pinzon Escobar", "Markus Mühlhäußer", "Hans-Joachim Bungartz", "Philipp Neumann"], "title": "Linked Cell Traversal Algorithms for Three-Body Interactions in Molecular Dynamics", "comment": "26 pages", "summary": "In this work, algorithms for the parallel computation of three-body\ninteractions in molecular dynamics are developed. While traversals for the\ncomputation of pair interactions are readily available in the literature, here,\nsuch traversals are extended to allow for the computation between molecules\nstored across three cells. A general framework for the computation of\nthree-body interactions in linked cells is described, and then used to\nimplement the corresponding traversals. In addition, our analysis is combined\nwith the commonly used cutoff conditions, because they influence the total\nworkload of the computation of interactions. The combinations between\ntraversals and truncation conditions are validated using the well-known\nLennard-Jones fluid. Validation case studies are taken from the literature and\nconfigured into homogeneous and inhomogeneous scenarios. Finally, strong\nscalability and performance in terms of molecule updates are measured at\nnode-level."}
{"id": "2510.21507", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2510.21507", "abs": "https://arxiv.org/abs/2510.21507", "authors": ["Lingke Jiang", "G. Brooke Anderson", "Yanran Li", "Xiao Wu", "Victoria D. Lynch", "Robbie M. Parks"], "title": "Characterizing global tropical cyclone events of 2024", "comment": null, "summary": "Full impact assessment of tropical cyclones each year requires a\ncomprehensive sociodemographic analysis. We evaluated sociodemographic\ncharacteristics of tropical cyclone-impacted regions during the 2024 calendar\nyear in recent historical context of 1980-2024. In 2024, tropical cyclone-force\nwind affected an estimated 429,902,820 people (5.5% of global population), and\nhurricane-force wind an estimated 59,672,600 people (0.8%). Our findings\nprovide a global context for tropical cyclones to better guide resilience and\nrecovery efforts."}
{"id": "2510.21044", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21044", "abs": "https://arxiv.org/abs/2510.21044", "authors": ["Kunal Shankar", "Ninad Gaikwad", "Anamika Dubey"], "title": "House Thermal Model Estimation: Robustness Across Seasons and Setpoints", "comment": "This manuscript is a version of our paper accepted at the 57th North\n  American Power Symposium (NAPS) 2025", "summary": "Achieving the flexibility from house heating, cooling, and ventilation\nsystems (HVAC) has the potential to enable large-scale demand response by\naggregating HVAC load adjustments across many homes. This demand response\nstrategy helps distribution grid to flexibly ramp-up or ramp-down local load\ndemand so that it can optimally match the bulk power system generation profile.\nHowever, achieving this capability requires house thermal models that are both\ncomputationally efficient and robust to operating conditions. In this work,\nparameters of the Resistance-Capacitance (RC) network thermal model for houses\nare estimated using three optimization algorithms: Nonlinear Least Squares\n(NLS), Batch Estimation (BE), and Maximum Likelihood Estimation (MLE). The\nresulting models are evaluated through a Forward-Simulation across four\ndifferent seasons and three setpoints. The results illustrate a principled way\nof selecting reduced order models and estimation methods with respect to the\nrobustness offered to seasonal and setpoint variations in training-testing\ndatasets"}
{"id": "2510.21044", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21044", "abs": "https://arxiv.org/abs/2510.21044", "authors": ["Kunal Shankar", "Ninad Gaikwad", "Anamika Dubey"], "title": "House Thermal Model Estimation: Robustness Across Seasons and Setpoints", "comment": "This manuscript is a version of our paper accepted at the 57th North\n  American Power Symposium (NAPS) 2025", "summary": "Achieving the flexibility from house heating, cooling, and ventilation\nsystems (HVAC) has the potential to enable large-scale demand response by\naggregating HVAC load adjustments across many homes. This demand response\nstrategy helps distribution grid to flexibly ramp-up or ramp-down local load\ndemand so that it can optimally match the bulk power system generation profile.\nHowever, achieving this capability requires house thermal models that are both\ncomputationally efficient and robust to operating conditions. In this work,\nparameters of the Resistance-Capacitance (RC) network thermal model for houses\nare estimated using three optimization algorithms: Nonlinear Least Squares\n(NLS), Batch Estimation (BE), and Maximum Likelihood Estimation (MLE). The\nresulting models are evaluated through a Forward-Simulation across four\ndifferent seasons and three setpoints. The results illustrate a principled way\nof selecting reduced order models and estimation methods with respect to the\nrobustness offered to seasonal and setpoint variations in training-testing\ndatasets"}
{"id": "2510.21226", "categories": ["physics.soc-ph", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2510.21226", "abs": "https://arxiv.org/abs/2510.21226", "authors": ["Hao-Xiang Jiang", "Chao-Ran Cai", "Ji-Qiang Zhang", "Ming Tang"], "title": "Role division drives impact of resource allocation on epidemic spreading", "comment": null, "summary": "Based on the real-world hierarchical structure of resource allocation, this\npaper presents a coupled dynamic model of resource allocation and epidemic\nspreading that incorporates a role-based division of network nodes into\nresource allocators and recipients. As the average number of links per\nrecipient from allocators increases, the prevalence exhibits one of four\ndistinct response patterns across conditions: monotonically increasing,\nmonotonically decreasing, U-shaped trend, or a sudden decrease with large\nfluctuations. Analysis of the underlying physical mechanisms reveals three key\nfeatures: (i) a trade-off between efficient resource allocation and infection\nrisk for allocators, (ii) the critical importance of avoiding resource\nredundancy under high therapeutic resource efficiency, and (iii)\ncascade-induced bistability."}
{"id": "2510.20978", "categories": ["math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.20978", "abs": "https://arxiv.org/abs/2510.20978", "authors": ["Ayoub El Hanchi", "Murat Erdogdu", "Chris Maddison"], "title": "A Geometric Analysis of PCA", "comment": null, "summary": "What property of the data distribution determines the excess risk of\nprincipal component analysis? In this paper, we provide a precise answer to\nthis question. We establish a central limit theorem for the error of the\nprincipal subspace estimated by PCA, and derive the asymptotic distribution of\nits excess risk under the reconstruction loss. We obtain a non-asymptotic upper\nbound on the excess risk of PCA that recovers, in the large sample limit, our\nasymptotic characterization. Underlying our contributions is the following\nresult: we prove that the negative block Rayleigh quotient, defined on the\nGrassmannian, is generalized self-concordant along geodesics emanating from its\nminimizer of maximum rotation less than $\\pi/4$."}
{"id": "2510.20928", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.20928", "abs": "https://arxiv.org/abs/2510.20928", "authors": ["Zhenghao Zeng", "David Arbour", "Avi Feller", "Ishita Dasgupta", "Atanu R Sinha", "Edward H. Kennedy"], "title": "Handling Missing Responses under Cluster Dependence with Applications to Language Model Evaluation", "comment": "27 pages, 3 figures", "summary": "Human annotations play a crucial role in evaluating the performance of GenAI\nmodels. Two common challenges in practice, however, are missing annotations\n(the response variable of interest) and cluster dependence among human-AI\ninteractions (e.g., questions asked by the same user may be highly correlated).\nReliable inference must address both these issues to achieve unbiased\nestimation and appropriately quantify uncertainty when estimating average\nscores from human annotations. In this paper, we analyze the doubly robust\nestimator, a widely used method in missing data analysis and causal inference,\napplied to this setting and establish novel theoretical properties under\ncluster dependence. We further illustrate our findings through simulations and\na real-world conversation quality dataset. Our theoretical and empirical\nresults underscore the importance of incorporating cluster dependence in\nmissing response problems to perform valid statistical inference."}
{"id": "2510.21290", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21290", "abs": "https://arxiv.org/abs/2510.21290", "authors": ["Juan Esteban Suarez Cardona", "Holger Boche", "Gitta Kutyniok"], "title": "A Variational Framework for the Algorithmic Complexity of PDE Solutions", "comment": null, "summary": "Partial Differential Equations (PDEs) are fundamental tools for modeling\nphysical phenomena, yet most PDEs of practical interest cannot be solved\nanalytically and require numerical approximations. The feasibility of such\nnumerical methods, however, is ultimately constrained by the limitations of\nexisting computation models. Since digital computers constitute the primary\nphysical realizations of numerical computation, and Turing machines define\ntheir theoretical limits, the question of Turing computability of PDE solutions\narises as a problem of fundamental theoretical significance. The Turing\ncomputability of PDE solutions provides a rigorous framework to distinguish\nequations that are, in principle, algorithmically solvable from those that\ninherently encode undecidable or non-computable behavior. Once computability is\nestablished, complexity theory extends the analysis by quantifying the\ncomputational resources required to approximate the corresponding PDE\nsolutions. In this work, we present a novel framework based on least-squares\nvariational formulations and their associated gradient flows to study the\ncomputability and complexity of PDE solutions from an optimization perspective.\nOur approach enables the approximation of PDE solution operators via discrete\ngradient flows, linking structural properties of the PDE, such as coercivity,\nellipticity, and convexity, to the inherent complexity of their solutions. This\nframework characterizes both regimes where PDEs admit effective numerical\nsolvers in polynomial-time and those exhibiting complexity blowup, where the\ninput data possess polynomial-time complexity, yet the solution itself scales\nsuper-polynomially."}
{"id": "2510.21539", "categories": ["physics.ao-ph", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.21539", "abs": "https://arxiv.org/abs/2510.21539", "authors": ["Johannes Lohmann"], "title": "Direct test for critical slowing down before Dansgaard-Oeschger events via the volcanic climate response", "comment": null, "summary": "It is tested whether past abrupt climate changes support the validity of\nstatistical early-warning signals (EWS) as predictor of future climate tipping\npoints. EWS are expected increases in amplitude and correlation of fluctuations\ndriven by noise. This is a symptom of critical slowing down (CSD), where a\nsystem's recovery from an external perturbation becomes slower as a tipping\npoint (represented by a bifurcation) is approached. EWS are a simple, indirect\nmeasure of CSD, but subject to assumptions on the noise process and measurement\nstationarity that are hard to verify. In this work the existence of CSD before\nthe Dansgaard-Oeschger (DO) events of the last glacial period is directly\ntested by inferring the climate's recovery from large volcanic eruptions. By\naveraging over hundreds of eruptions, a well-defined, stationary perturbation\nis constructed and the average climate response is measured by eight ice core\nproxies. As the abrupt DO warming transitions are approached, the climate\nresponse to eruptions remains the same, indicating no CSD. For the abrupt DO\ncooling transitions, however, some key proxies show evidence of larger climate\nresponse and slower recovery as the transitions are approached. By comparison,\nalmost all proxies show statistical EWS before cooling and warming transitions,\nbut with only weak confidence for the warming transitions. There is thus\nqualitative agreement of CSD and EWS, in that the evidence for bifurcation\nprecursors is larger for the cooling transitions. However, the discrepancy that\nmany proxies show EWS but no direct CSD (and vice versa) highlights that\nstatistical EWS in individual observables need to be interpreted with care."}
{"id": "2510.21051", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21051", "abs": "https://arxiv.org/abs/2510.21051", "authors": ["Rebecca G. Hart", "Wanjiku A. Makumi", "Rushikesh Kamalapurkar", "Warren E. Dixon"], "title": "Lyapunov-Based Physics-Informed Deep Neural Networks with Skew Symmetry Considerations", "comment": null, "summary": "Deep neural networks (DNNs) are powerful black-box function approximators\nwhich have been shown to yield improved performance compared to traditional\nneural network (NN) architectures. However, black-box algorithms do not\nincorporate known physics of the system and can yield results which are\nphysically implausible. Physics-informed neural networks (PINNs) have grown in\npopularity due to their ability to leverage known physical principles in the\nlearning process which has been empirically shown to improve performance\ncompared to traditional black-box methods. This paper introduces the first\nphysics-informed DNN controller for an Euler-Lagrange dynamic system where the\nadaptation laws are designed using a Lyapunov-based stability analysis to\naccount for the skew-symmetry property of the inertia matrix and\ncentripetal-Coriolis matrix. A Lyapunov-based stability analysis is provided to\nguarantee asymptotic convergence of the tracking error and the skew-symmetric\nprediction error. Simulations indicate that the developed update law\ndemonstrates improvement in individual and overall function approximation\ncapabilities when compared to a physics-informed adaptation law which does not\nincorporate knowledge of system symmetries."}
{"id": "2510.21051", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21051", "abs": "https://arxiv.org/abs/2510.21051", "authors": ["Rebecca G. Hart", "Wanjiku A. Makumi", "Rushikesh Kamalapurkar", "Warren E. Dixon"], "title": "Lyapunov-Based Physics-Informed Deep Neural Networks with Skew Symmetry Considerations", "comment": null, "summary": "Deep neural networks (DNNs) are powerful black-box function approximators\nwhich have been shown to yield improved performance compared to traditional\nneural network (NN) architectures. However, black-box algorithms do not\nincorporate known physics of the system and can yield results which are\nphysically implausible. Physics-informed neural networks (PINNs) have grown in\npopularity due to their ability to leverage known physical principles in the\nlearning process which has been empirically shown to improve performance\ncompared to traditional black-box methods. This paper introduces the first\nphysics-informed DNN controller for an Euler-Lagrange dynamic system where the\nadaptation laws are designed using a Lyapunov-based stability analysis to\naccount for the skew-symmetry property of the inertia matrix and\ncentripetal-Coriolis matrix. A Lyapunov-based stability analysis is provided to\nguarantee asymptotic convergence of the tracking error and the skew-symmetric\nprediction error. Simulations indicate that the developed update law\ndemonstrates improvement in individual and overall function approximation\ncapabilities when compared to a physics-informed adaptation law which does not\nincorporate knowledge of system symmetries."}
{"id": "2510.21481", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.21481", "abs": "https://arxiv.org/abs/2510.21481", "authors": ["Célestin Zimmerlin", "Thomas Louail", "Manuel Moussallam", "Marc Barthelemy"], "title": "The dynamics of discovery and the Heaps-Zipf relationship", "comment": "9 pages, 4 figures", "summary": "When following a sequence - such as reading a text or tracking a user's\nactivity - one can measure how the \"dictionary\" of distinct elements (types)\ngrows with the number of observations (tokens). When this growth follows a\npower law, it is referred to as Heaps' law, a regularity often associated with\nZipf's law and frequently used to characterize human innovation and discovery\nprocesses. While random sampling from a Zipf-like distribution can reproduce\nHeaps' law, this connection relies on the assumption of temporal independence -\nan assumption often violated in real-world systems although frequently found in\nthe literature. Here, we investigate how temporal correlations in token\nsequences affect the type-token curve. In systems like music listening and web\nbrowsing, domain-specific correlations in token ordering lead to systematic\ndeviations from the Zipf-Heaps framework, effectively decoupling the type-token\nplot from the rank-frequency distribution. Using a minimal one-parameter model,\nwe reproduce a wide variety of type-token trajectories, including the extremal\ncases that bound all possible behaviors compatible with a given frequency\ndistribution. Our results demonstrate that type-token growth reflects not only\nthe empirical distribution of type frequencies, but also the temporal structure\nof the sequence - a factor often overlooked in empirical applications of\nscaling laws to characterize human behavior."}
{"id": "2510.21077", "categories": ["math.ST", "math.PR", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.21077", "abs": "https://arxiv.org/abs/2510.21077", "authors": ["Ruoyu Wu"], "title": "Limiting Spectral Distribution of High-dimensional Multivariate Kendall-$τ$", "comment": null, "summary": "The multivariate Kendall-$\\tau$ statistic, denoted by $K_n$, plays a\nsignificant role in robust statistical analysis. This paper establishes the\nlimiting properties of the empirical spectral distribution (ESD) of $K_n$. We\ndemonstrate that the ESD of $\\frac{1}{2}pK_n$ converges almost surely to the\nMar\\v{c}enko--Pastur law with variance parameter $\\frac{1}{2}$, analogous to\nthe classical result for sample covariance matrices.\n  Using Stieltjes transform techniques, we extend these results to the\nindependent component model, deriving a fixed-point equation that characterizes\nthe limiting spectral distribution of $\\frac{1}{2}tr\\Sigma K_n$. The\ntheoretical findings are validated through comprehensive simulation studies."}
{"id": "2510.20942", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.20942", "abs": "https://arxiv.org/abs/2510.20942", "authors": ["Heeju Lim", "Victor E. Lachos", "Victor H. Lachos"], "title": "Bayesian analysis of flexible Heckman selection models using Hamiltonian Monte Carlo", "comment": null, "summary": "The Heckman selection model is widely used in econometric analysis and other\nsocial sciences to address sample selection bias in data modeling. A common\nassumption in Heckman selection models is that the error terms follow an\nindependent bivariate normal distribution. However, real-world data often\ndeviates from this assumption, exhibiting heavy-tailed behavior, which can lead\nto inconsistent estimates if not properly addressed. In this paper, we propose\na Bayesian analysis of Heckman selection models that replace the Gaussian\nassumption with well-known members of the class of scale mixture of normal\ndistributions, such as the Student's-t and contaminated normal distributions.\nFor these complex structures, Stan's default No-U-Turn sampler is utilized to\nobtain posterior simulations. Through extensive simulation studies, we compare\nthe performance of the Heckman selection models with normal, Student's-t and\ncontaminated normal distributions. We also demonstrate the broad applicability\nof this methodology by applying it to medical care and labor supply data. The\nproposed algorithms are implemented in the R package HeckmanStan."}
{"id": "2510.20939", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.20939", "abs": "https://arxiv.org/abs/2510.20939", "authors": ["Matej Mosko", "Andrej Gendiar"], "title": "Tensor-Network study of Ising model on infinite hyperbolic dodecahedral lattice", "comment": "14 pages, 15 figures, 2 tables", "summary": "We propose a tensor-network-based algorithm to study the classical Ising\nmodel on an infinitely large hyperbolic lattice with a regular 3D tesselation\nof identical dodecahedra. We reformulate the corner transfer matrix\nrenormalization group (CTMRG) algorithm from 2D to 3D to reproduce the known\nresults on the cubic lattice. Consequently, we generalize the CTMRG to the\nhyperbolic dodecahedral lattice, which is an infinite-dimensional lattice. We\nanalyze the spontaneous magnetization, von Neumann entropy, and correlation\nlength to find a continuous non-critical phase transition on the dodecahedral\nlattice. The phase transition temperature is estimated to be $T_{\\rm pt}\n\\approx 4.66$. We find the magnetic critical exponents $\\beta= 0.4999$ and\n$\\delta=3.007$ that confirm the mean-field universality class in accord with\npredictions of Monte Carlo and high-temperature series expansions. The\nalgorithm can be applied to arbitrary multi-state spin models."}
{"id": "2510.21355", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21355", "abs": "https://arxiv.org/abs/2510.21355", "authors": ["Mukul Dwivedi", "Andreas Rupp"], "title": "A numerical method for the fractional Zakharov-Kuznetsov equation", "comment": null, "summary": "This paper develops a fully discrete Fourier spectral Galerkin (FSG) method\nfor the fractional Zakharov-Kuznetsov (fZK) equation posed on a two-dimensional\nperiodic domain. The equation generalizes the classical ZK model to incorporate\nnonlocal dispersion through a fractional Laplacian of order $\\alpha \\in [1,2]$.\nWe first propose a semi-discrete FSG scheme in space that preserves the\ndiscrete analogs of mass, momentum, and energy. The existence and uniqueness of\nsemi-discrete solutions are established. Using compactness arguments, we prove\nthe uniform convergence of the semi-discrete approximations to the unique\nsolution of the fZK equation for the periodic initial data in\n$H^{1+\\alpha}_{\\mathrm{per}}(\\Omega)$. The method achieves spectral convergence\nof order $\\mathcal{O}(N^{-r})$ for initial data in $H^r_{\\mathrm{per}}$ with $r\n\\geq \\alpha+1$, and exponential convergence for analytic solutions utilizing a\nmodified projection. An efficient integrating-factor Runge-Kutta time\ndiscretization is designed to handle the stiff fractional term, and an error\nanalysis is presented. Numerical experiments validate the theoretical results\nand demonstrate the method's effectiveness across various fractional orders."}
{"id": "2510.21136", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21136", "abs": "https://arxiv.org/abs/2510.21136", "authors": ["Chengming Lyu", "Zhenfei Tan", "Xiaoyuan Xu", "Chen Fu", "Zheng Yan", "Mohammad Shahidehpour"], "title": "Environment-Dependent Components Identification of Behind-the-Meter Resources via Inverse Optimization", "comment": null, "summary": "With the increasing penetration of behind-the-meter (BTM) resources, it is\nvital to monitor the components of these resources and deduce their response\nbehavior to external environment. Owing to data privacy, however, the\nappliance-wise measurement is invisible to the power system operator, which\nhinders the accurate modeling of load identification. To this end, this paper\nproposes a hybrid physics-inspired and data-driven framework for decomposing\nBTM components based on external measurement of total load and environmental\nfactors. The total load is decomposed into different environment-dependent\ncomponents, namely storage-like component, PV generation component,\nthermostatically-controlled load component, and periodic component. The overall\nload identification adopts a double-layer iterative solution framework. A\ndata-driven inverse optimization algorithm is developed to identify parameters\nof the energy storage-like component. The physics-inspired model is proposed to\nidentify the capacity and response of the rest components. The modeling\naccuracy and robustness of the proposed method are validated by numerical\ntests. The application significance of the proposed BTM identification method\nis also validated in electricity market clearing for reducing system operation\ncosts."}
{"id": "2510.21136", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21136", "abs": "https://arxiv.org/abs/2510.21136", "authors": ["Chengming Lyu", "Zhenfei Tan", "Xiaoyuan Xu", "Chen Fu", "Zheng Yan", "Mohammad Shahidehpour"], "title": "Environment-Dependent Components Identification of Behind-the-Meter Resources via Inverse Optimization", "comment": null, "summary": "With the increasing penetration of behind-the-meter (BTM) resources, it is\nvital to monitor the components of these resources and deduce their response\nbehavior to external environment. Owing to data privacy, however, the\nappliance-wise measurement is invisible to the power system operator, which\nhinders the accurate modeling of load identification. To this end, this paper\nproposes a hybrid physics-inspired and data-driven framework for decomposing\nBTM components based on external measurement of total load and environmental\nfactors. The total load is decomposed into different environment-dependent\ncomponents, namely storage-like component, PV generation component,\nthermostatically-controlled load component, and periodic component. The overall\nload identification adopts a double-layer iterative solution framework. A\ndata-driven inverse optimization algorithm is developed to identify parameters\nof the energy storage-like component. The physics-inspired model is proposed to\nidentify the capacity and response of the rest components. The modeling\naccuracy and robustness of the proposed method are validated by numerical\ntests. The application significance of the proposed BTM identification method\nis also validated in electricity market clearing for reducing system operation\ncosts."}
{"id": "2510.21681", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.21681", "abs": "https://arxiv.org/abs/2510.21681", "authors": ["Mariano Devoto", "Pablo Ariel Cipriotti"], "title": "The Anatomy of Blame: A Network Analysis of Strategic Responsibility-Shifting After a Systemic Disaster", "comment": "Preprint. No journal submitted yet. 11,200 words, 6 figures, R code\n  and data available on request", "summary": "After disasters, blame becomes a key mechanism through which institutions\nnegotiate responsibility and legitimacy. Yet the structure of these exchanges\nremains poorly understood. Using evidence from the Grenfell Tower fire, we\nmodelled accusations among public, private and regulatory actors as a directed\nnetwork. The resulting pattern was highly interconnected, revealing that blame\ncirculated through reciprocated and clustered ties rather than simple\none-to-one accusations. These configurations indicate that institutions did not\nmerely assign responsibility but engaged in strategic counter-blame and\ncoalition-building to manage exposure. Comparisons with reference models\nconfirmed that such dynamics exceed what would be expected from structural\nconstraints alone. By mapping how blame spreads and concentrates across\norganisational systems, this study provides quantitative evidence for\nlong-standing theories of blame avoidance and highlights how accountability in\ncomplex governance settings becomes collectively negotiated and structurally\nembedded."}
{"id": "2510.21277", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.21277", "abs": "https://arxiv.org/abs/2510.21277", "authors": ["Florian Gossard", "François Bachoc", "Jean Baccou", "Thibaut Le Gouic", "Jacques Liandrat", "Tony Glantz"], "title": "Kriging measure-valued data with sparse observations: application to nuclear safety studies", "comment": null, "summary": "This work addresses the interpolation of probability measures within a\nspatial statistics framework. We develop a Kriging approach in the Wasserstein\nspace, leveraging the quantile function representation of the one-dimensional\nWasserstein distance. To mitigate the inaccuracies in semivariogram estimation\nthat arise from sparse datasets, we combine this formulation with\ncross-validation techniques. In particular, we introduce a variant of the\nvirtual cross-validation formulas tailored to quantile functions. The\neffectiveness of the proposed method is demonstrated on a controlled toy\nproblem as well as on a real-world application from nuclear safety."}
{"id": "2510.21047", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.21047", "abs": "https://arxiv.org/abs/2510.21047", "authors": ["Ziyang Liu", "Ning Hao", "Yue Selena Niu", "Han Xiao", "Hongxu Ding"], "title": "Autocorrelation Test under Frequent Mean Shifts", "comment": null, "summary": "Testing for the presence of autocorrelation is a fundamental problem in time\nseries analysis. Classical methods such as the Box-Pierce test rely on the\nassumption of stationarity, necessitating the removal of non-stationary\ncomponents such as trends or shifts in the mean prior to application. However,\nthis is not always practical, particularly when the mean structure is complex,\nsuch as being piecewise constant with frequent shifts. In this work, we propose\na new inferential framework for autocorrelation in time series data under\nfrequent mean shifts. In particular, we introduce a Shift-Immune Portmanteau\n(SIP) test that reliably tests for autocorrelation and is robust against mean\nshifts. We illustrate an application of our method to nanopore sequencing data."}
{"id": "2510.21269", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.21269", "abs": "https://arxiv.org/abs/2510.21269", "authors": ["Christophe Chatelain"], "title": "Tensor Renormalization-Group study of the surface critical behavior of a frustrated two-layer Ising model", "comment": null, "summary": "Two replicas of a 2D Ising model are coupled by frustrated spin-spin\ninteractions. It is known that this inter-layer coupling is marginal and that\nthe bulk critical behavior belongs to the Ashkin-Teller (AT) universality\nclass, as the $J_1$-$J_2$ Ising model. In this work, the surface critical\nbehavior is studied numerically by Tensor Renormalization-Group calculations.\nThe Bond-Weight Tensor Renormalization Group algorithm is extended to tackle\nsystems with boundaries. It is observed that the two-fold degeneracy of the\nsurface magnetic scaling dimension of the AT model is lifted in the frustrated\ntwo-layer Ising model (F2LIM). The splitting is explained by the breaking of\nthe ${\\mathbb Z}_2$-symmetry under spin reversal of a single Ising replica in\nthe F2LIM. The two distinct surface magnetic scaling dimensions $x_1^s$ and\n$x_2^s$ of the F2LIM satisfies a simple duality relation $x_1^s=1/4x_2^s$."}
{"id": "2510.20917", "categories": ["math.OC", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.20917", "abs": "https://arxiv.org/abs/2510.20917", "authors": ["Russell Gabrys", "Stefan Sremac"], "title": "A Convex Optimization Approach to the Discrete Hanging Chain Problem", "comment": null, "summary": "In this paper we investigate the discrete version of the classical hanging\nchain problem. We generalize the problem, by allowing for arbitrary mass and\nlength of each link. We show that the shape of the chain can be obtained by\nsolving a convex optimization problem. Then we use optimality conditions to\nshow that the problem can be further reduced to solving a single non-linear\nequation, when the links of the chain have symmetric mass and length."}
{"id": "2510.20862", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "math-ph", "math.MP", "math.OA"], "pdf": "https://arxiv.org/pdf/2510.20862", "abs": "https://arxiv.org/abs/2510.20862", "authors": ["Nigel Higson", "Emil Prodan"], "title": "A Universal Chern Model on Arbitrary Triangulations", "comment": null, "summary": "Given a triangulation of a closed orientable surface, we consider the lattice\nwith sites at the vertices, edges and facets of the triangulation. Borrowing\nfrom mathematics literature, we introduce on this lattice a pair of\ntight-binding Hamiltonians derived from the boundary and Poincar\\'e duality\nmaps of finite simplicial manifolds. These Hamiltonians have been proved to\nhave clean topological spectral gaps carrying non-trivial Chern numbers in the\nlimit of infinite refinement of the triangulation. We confirm this via\nnumerical simulations, and demonstrate how these models enable topological edge\nmodes at the surfaces of real-world objects. Furthermore, we describe a\nmetamaterial whose dynamics reproduces that of the proposed model, thus\nbringing the topological metamaterials closer to real-world applications."}
{"id": "2510.21381", "categories": ["math.NA", "cs.NA", "65M15, 65M12, 65L04"], "pdf": "https://arxiv.org/pdf/2510.21381", "abs": "https://arxiv.org/abs/2510.21381", "authors": ["Carlos Arranz-Simón", "Alexander Ostermann"], "title": "Exponential integrators for parabolic problems with non-homogeneous boundary conditions", "comment": "18 pages", "summary": "Exponential Runge-Kutta methods are a well-established tool for the numerical\nintegration of parabolic evolution equations. However, these schemes are\ntypically developed under the assumption of homogeneous boundary conditions. In\nthis paper, we extend classical convergence results to the case of\nnon-homogeneous boundary conditions. Since non-homogeneous boundary conditions\ntypically cause order reduction, we introduce a correction strategy based on\nsmooth extensions of the boundary data. This results in a reformulation as a\nhomogeneous problem with modified source term, to which standard exponential\nintegrators can be applied. For linear problems, we prove that the corrected\nschemes recover the expected convergence order, and hat higher orders can be\nattained with suitable quadrature rules, reaching order $2s$ for s-stage Gauss\ncollocation methods. For semilinear problems, our approach preserves the\nconvergence orders guaranteed by exponential Runge-Kutta methods satisfying the\ncorresponding stiff order conditions. Numerical experiments validate the\ntheoretical findings."}
{"id": "2510.21179", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21179", "abs": "https://arxiv.org/abs/2510.21179", "authors": ["Frederik Wagner Madsen", "Joy Dalmacio Billanes", "Bo Nørregaard Jørgensen", "Zheng Ma"], "title": "Green Hydrogen under Uncertainty: Evaluating Power-to-X Strategies Using Agent-Based Simulation and Multi-Criteria Decision Framework", "comment": null, "summary": "The transition toward net-zero energy systems requires scalable and\ncost-effective deployment of Power-to-X technologies, particularly green\nhydrogen production. Despite increasing investments, a critical research gap\nremains in dynamically assessing how different operational strategies affect\nthe feasibility of hydrogen production under real-world energy market\nconditions. Most existing studies rely on static, techno-economic models and\noverlook actor interactions, infrastructure limitations, and regulatory\ncomplexity. This paper presents a novel modeling framework that integrates\nagent-based simulation with multi-criteria decision-making to evaluate green\nhydrogen production strategies using co-located wind and solar generation.\nThree operational strategies - grid-only, on-site-only, and hybrid - are\napplied across three electrolyzer capacity levels (10 MW, 50 MW, and 100 MW)\nwithin a Danish case study. Real electricity tariffs, emissions factors, and\nmarket data are used to simulate technical, economic, and environmental\nperformance indicators. The results show that hybrid strategies consistently\noutperform grid-only configurations in terms of cost and emissions while\nmaintaining stable hydrogen output. Although on-site-only strategies minimize\nemissions and costs, they fail to meet fixed production demands. This framework\noffers novel scientific contributions by modeling dynamic actor interactions\nand integrating system performance evaluation into strategic planning.\nPractically, it provides actionable insights for energy planners and\npolicymakers designing resilient and efficient Power-to-X systems in\nrenewable-rich contexts."}
{"id": "2510.21179", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21179", "abs": "https://arxiv.org/abs/2510.21179", "authors": ["Frederik Wagner Madsen", "Joy Dalmacio Billanes", "Bo Nørregaard Jørgensen", "Zheng Ma"], "title": "Green Hydrogen under Uncertainty: Evaluating Power-to-X Strategies Using Agent-Based Simulation and Multi-Criteria Decision Framework", "comment": null, "summary": "The transition toward net-zero energy systems requires scalable and\ncost-effective deployment of Power-to-X technologies, particularly green\nhydrogen production. Despite increasing investments, a critical research gap\nremains in dynamically assessing how different operational strategies affect\nthe feasibility of hydrogen production under real-world energy market\nconditions. Most existing studies rely on static, techno-economic models and\noverlook actor interactions, infrastructure limitations, and regulatory\ncomplexity. This paper presents a novel modeling framework that integrates\nagent-based simulation with multi-criteria decision-making to evaluate green\nhydrogen production strategies using co-located wind and solar generation.\nThree operational strategies - grid-only, on-site-only, and hybrid - are\napplied across three electrolyzer capacity levels (10 MW, 50 MW, and 100 MW)\nwithin a Danish case study. Real electricity tariffs, emissions factors, and\nmarket data are used to simulate technical, economic, and environmental\nperformance indicators. The results show that hybrid strategies consistently\noutperform grid-only configurations in terms of cost and emissions while\nmaintaining stable hydrogen output. Although on-site-only strategies minimize\nemissions and costs, they fail to meet fixed production demands. This framework\noffers novel scientific contributions by modeling dynamic actor interactions\nand integrating system performance evaluation into strategic planning.\nPractically, it provides actionable insights for energy planners and\npolicymakers designing resilient and efficient Power-to-X systems in\nrenewable-rich contexts."}
{"id": "2510.21335", "categories": ["math.ST", "stat.ML", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.21335", "abs": "https://arxiv.org/abs/2510.21335", "authors": ["Philip Boeken", "Onno Zoeter", "Joris M. Mooij"], "title": "Conditional Forecasts and Proper Scoring Rules for Reliable and Accurate Performative Predictions", "comment": null, "summary": "Performative predictions are forecasts which influence the outcomes they aim\nto predict, undermining the existence of correct forecasts and standard methods\nof elicitation and estimation. We show that conditioning forecasts on\ncovariates that separate them from the outcome renders the target distribution\nforecast-invariant, guaranteeing well-posedness of the forecasting problem.\nHowever, even under this condition, classical proper scoring rules fail to\nelicit correct forecasts. We prove a general impossibility result and identify\ntwo solutions: (i) in decision-theoretic settings, elicitation of correct and\nincentive-compatible forecasts is possible if forecasts are separating; (ii)\nscoring with unbiased estimates of the divergence between the forecast and the\ninduced distribution of the target variable yields correct forecasts. Applying\nthese insights to parameter estimation, conditional forecasts and proper\nscoring rules enable performatively stable estimation of performatively correct\nparameters, resolving the issues raised by Perdomo et al. (2020). Our results\nexpose fundamental limits of classical forecast evaluation and offer new tools\nfor reliable and accurate forecasting in performative settings."}
{"id": "2510.21116", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.21116", "abs": "https://arxiv.org/abs/2510.21116", "authors": ["Bolun Liu", "Trang Quynh Nguyen", "Elizabeth A. Stuart", "Bryan Lau", "Amii M. Kress", "Michael R. Elliott", "Kyle R. Busse", "Ellen C. Caniglia", "Yajnaseni Chakraborti", "Amy J. Elliott", "James E. Gern", "Alison E. Hipwell", "Catherine J. Karr", "Kaja Z. LeWinn", "Li Luo", "Hans-Georg Müller", "Sunni L. Mumford", "Ruby H. N. Nguyen", "Emily Oken", "Janet L. Peacock", "Enrique F. Schisterman", "Arjun Sondhi", "Rosalind J. Wright", "Yidong Zhou", "Elizabeth L. Ogburn"], "title": "Sensitivity Analysis when Generalizing Causal Effects from Multiple Studies to a Target Population: Motivation from the ECHO Program", "comment": null, "summary": "Unobserved effect modifiers can induce bias when generalizing causal effect\nestimates to target populations. In this work, we extend a sensitivity analysis\nframework assessing the robustness of study results to unobserved effect\nmodification that adapts to various generalizability scenarios, including\nmultiple (conditionally) randomized trials, observational studies, or\ncombinations thereof. This framework is interpretable and does not rely on\ndistributional or functional assumptions about unknown parameters. We\ndemonstrate how to leverage the multi-study setting to detect violation of the\ngeneralizability assumption through hypothesis testing, showing with\nsimulations that the proposed test achieves high power under real-world sample\nsizes. Finally, we apply our sensitivity analysis framework to analyze the\ngeneralized effect estimate of secondhand smoke exposure on birth weight using\ncohort sites from the Environmental influences on Child Health Outcomes (ECHO)\nstudy."}
{"id": "2510.21336", "categories": ["cond-mat.stat-mech", "cond-mat.soft", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2510.21336", "abs": "https://arxiv.org/abs/2510.21336", "authors": ["Timur Aslyamov", "Massimiliano Esposito", "Mathijs Janssen"], "title": "Faradaic and capacitive charging of an electrolyte-filled pore in response to a small applied potential", "comment": "15 pages, 5 figures", "summary": "Electrochemical devices often charge both through Faradaic reactions and\nelectric double layer formation. Here, we study these coupled processes in a\nmodel system of a long electrolyte-filled pore subject to a small\nsuddenly-applied potential, close to the equilibrium potential $\\Psi^\\text{eq}$\nat which there is no net Faradaic charge transfer. Specifically, we solve the\ncoupled Poisson-Nernst-Planck and Frumkin-Butler-Volmer equations by asymptotic\napproximations, using the pore's small inverse aspect ratio as the small\nparameter. In the early-time limit, the reaction-diffusion equations yield an\nextended Faradaic transmission line model that includes a voltage source,\n$\\Psi_\\text{eq}$, biasing the Faradaic reactions, captured by the resistance\n$R_F$. In the long-time limit, the model exhibits a nontrivial potential of\nzero charge, $\\Psi_\\text{pzc} = \\Psi_\\text{eq}[1 - \\hat{Z}(0)/R_F]$, where\n$\\hat{Z}(0)$ is the experimentally accessible zero-frequency impedance of the\nsystem. This expression provides a new means to experimentally measure the\nFaradaic contribution to $\\Psi_\\text{pzc}$."}
{"id": "2510.21010", "categories": ["math.OC", "90C29, 90C25, 90C59, 90B50, 97N80"], "pdf": "https://arxiv.org/pdf/2510.21010", "abs": "https://arxiv.org/abs/2510.21010", "authors": ["Ludovic Salomon", "Daniel Dörfler", "Andreas Löhne"], "title": "MOCVXPY: a CVXPY extension for multiobjective optimization", "comment": null, "summary": "MOCVXPY is an open-source Python library for convex vector optimization. It\nis built on top of CVXPY, a domain-specific language for single-objective\nconvex optimization. MOCVXPY enables practitioners to describe their convex\nvector optimization problem in an intuitive algebraic language, that closely\nfollows the mathematical formulation. This work presents the main features of\nMOCVXPY, explains some background of the algorithms it employs to solve the\noptimization problems, and illustrates its functionality through examples and\ntwo real-world applications in finance and energy. MOCVXPY is available at\nhttps://github.com/salomonl/mocvxpy under the Apache 2.0 licence, with some\ndocumentation and examples."}
{"id": "2510.20893", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.20893", "abs": "https://arxiv.org/abs/2510.20893", "authors": ["Lei Su"], "title": "$\\mathbb{Z}_2$ lattice gauge theories: fermionic gauging, transmutation, and Kramers-Wannier dualities", "comment": "6+17 pages. This work is dedicated to C. N. Yang", "summary": "We generalize the gauging of $\\mathbb{Z}_2$ symmetries by inserting Majorana\nfermions, establishing parallel duality correspondences for bosonic and\nfermionic lattice systems. Using this fermionic gauging, we construct fermionic\nanalogs of $\\mathbb{Z}_2$ gauge theories dual to the transverse-field Ising\nmodel, interpretable as Majorana stabilizer codes. We demonstrate a unitary\nequivalence between the $\\mathbb{Z}_2$ gauge theory obtained by gauging the\nfermion parity of a free fermionic system and the conventional $\\mathbb{Z}_2$\ngauge theory with potentially nonlocal terms on the square lattice with\ntoroidal geometry. This equivalence is implemented by a linear-depth local\nunitary circuit, connecting the bosonic and fermionic toric codes through a\ndirection-dependent anyonic transmutation. The gauge theory obtained by gauging\nfermion parity is further shown to be equivalent to a folded Ising chain\nobtained via the Jordan--Wigner transformation. We clarify the distinction\nbetween the recently proposed Kramers--Wannier dualities and those obtained by\ngauging the $\\mathbb{Z}_2$ symmetry along a space-covering path. Our results\nextend naturally to higher-dimensional $\\mathbb{Z}_2$ lattice gauge theories,\nproviding a unified framework for bosonic and fermionic dualities and offering\nnew insights for quantum computation and simulation."}
{"id": "2510.21394", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21394", "abs": "https://arxiv.org/abs/2510.21394", "authors": ["Marco Caliari", "Fabio Cassini"], "title": "Matrix- and tensor-oriented numerical schemes for the evolutionary space-fractional complex Ginzburg--Landau equation", "comment": null, "summary": "In this manuscript, we propose matrix- and tensor-oriented methods for the\nnumerical solution of the multidimensional evolutionary space-fractional\ncomplex Ginzburg--Landau equation. After a suitable spatial semidiscretization,\nthe resulting system of ordinary differential equations is time integrated with\nstiff-resistant schemes. The needed actions of special matrix functions (e.g.,\ninverse, exponential, and the so-called $\\varphi$-functions) are efficiently\ncomputed in a direct way by exploiting the underlying tensor structure of the\ntask and taking advantage of high performance BLAS and parallelizable pointwise\noperations. Several numerical experiments in 2D and 3D, where we apply the\nproposed technique in the context of linearly-implicit and exponential-type\nschemes, show the reliability and superiority of the approach against the\nstate-of-the-art, allowing to obtain speedups which range from one to two\norders of magnitude. Finally, we demonstrate that in our context a single GPU\ncan be effectively exploited to boost the computations both on consumer- and\nprofessional-level hardware."}
{"id": "2510.21227", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.21227", "abs": "https://arxiv.org/abs/2510.21227", "authors": ["Ke Sun", "Jingyi Yan", "Zhenglin Li", "Shaorong Xie"], "title": "The Role of Information Incompleteness in Defending Against Stealth Attacks", "comment": null, "summary": "The effectiveness of Data Injections Attacks (DIAs) critically depends on the\ncompleteness of the system information accessible to adversaries. This\nrelationship positions information incompleteness enhancement as a vital\ndefense strategy for degrading DIA performance. In this paper, we focus on the\ninformation-theoretic stealth attacks, where the attacker encounters a\nfundamental tradeoff between the attack stealthiness and destructiveness.\nSpecifically, we systematically characterize how incomplete admittance\ninformation impacts the dual objectives. In particular, we establish sufficient\nconditions for two distinct operational regimes: (i) stealthiness intensifies\nwhile destructive potential diminishes and (ii) destructiveness increases while\nstealth capability weakens. For scenarios beyond these regimes, we propose a\nmaximal incompleteness strategy to optimally degrade stealth capability. To\nsolve the associated optimization problem, the feasible region is reduced\nwithout excluding the optimal solution, and a heuristic algorithm is then\nintroduced to effectively identify the near-optimal solutions within the\nreduced region. Numerical simulations are conducted on IEEE test systems to\nvalidate the findings."}
{"id": "2510.21227", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.21227", "abs": "https://arxiv.org/abs/2510.21227", "authors": ["Ke Sun", "Jingyi Yan", "Zhenglin Li", "Shaorong Xie"], "title": "The Role of Information Incompleteness in Defending Against Stealth Attacks", "comment": null, "summary": "The effectiveness of Data Injections Attacks (DIAs) critically depends on the\ncompleteness of the system information accessible to adversaries. This\nrelationship positions information incompleteness enhancement as a vital\ndefense strategy for degrading DIA performance. In this paper, we focus on the\ninformation-theoretic stealth attacks, where the attacker encounters a\nfundamental tradeoff between the attack stealthiness and destructiveness.\nSpecifically, we systematically characterize how incomplete admittance\ninformation impacts the dual objectives. In particular, we establish sufficient\nconditions for two distinct operational regimes: (i) stealthiness intensifies\nwhile destructive potential diminishes and (ii) destructiveness increases while\nstealth capability weakens. For scenarios beyond these regimes, we propose a\nmaximal incompleteness strategy to optimally degrade stealth capability. To\nsolve the associated optimization problem, the feasible region is reduced\nwithout excluding the optimal solution, and a heuristic algorithm is then\nintroduced to effectively identify the near-optimal solutions within the\nreduced region. Numerical simulations are conducted on IEEE test systems to\nvalidate the findings."}
{"id": "2510.21505", "categories": ["math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.21505", "abs": "https://arxiv.org/abs/2510.21505", "authors": ["Shogo Nakakita"], "title": "Sparse estimation for the drift of high-dimensional Ornstein--Uhlenbeck processes with i.i.d. paths", "comment": "23 pages, 2 figures", "summary": "We study sparsity-regularized maximum likelihood estimation for the drift\nparameter of high-dimensional non-stationary Ornstein--Uhlenbeck processes\ngiven repeated measurements of i.i.d. paths. In particular, we show that Lasso\nand Slope estimators can achieve the minimax optimal rate of convergence. We\nexhibit numerical experiments for sparse estimation methods and show their\nperformance."}
{"id": "2510.21119", "categories": ["stat.ME", "stat.ML", "62K86, 65F55"], "pdf": "https://arxiv.org/pdf/2510.21119", "abs": "https://arxiv.org/abs/2510.21119", "authors": ["Lei Shi", "David Arbour", "Raghavendra Addanki", "Ritwik Sinha", "Avi Feller"], "title": "Leveraging semantic similarity for experimentation with AI-generated treatments", "comment": "31 pages, 5 figures", "summary": "Large Language Models (LLMs) enable a new form of digital experimentation\nwhere treatments combine human and model-generated content in increasingly\nsophisticated ways. The main methodological challenge in this setting is\nrepresenting these high-dimensional treatments without losing their semantic\nmeaning or rendering analysis intractable. Here, we address this problem by\nfocusing on learning low-dimensional representations that capture the\nunderlying structure of such treatments. These representations enable\ndownstream applications such as guiding generative models to produce meaningful\ntreatment variants and facilitating adaptive assignment in online experiments.\nWe propose double kernel representation learning, which models the causal\neffect through the inner product of kernel-based representations of treatments\nand user covariates. We develop an alternating-minimization algorithm that\nlearns these representations efficiently from data and provides convergence\nguarantees under a low-rank factor model. As an application of this framework,\nwe introduce an adaptive design strategy for online experimentation and\ndemonstrate the method's effectiveness through numerical experiments."}
{"id": "2510.21340", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.21340", "abs": "https://arxiv.org/abs/2510.21340", "authors": ["Daiki Sekizawa", "Sosuke Ito", "Masafumi Oizumi"], "title": "Koopman Mode Decomposition of Thermodynamic Dissipation in Nonlinear Langevin Dynamics", "comment": null, "summary": "Nonlinear oscillations are commonly observed in complex systems far from\nequilibrium, such as living organisms. These oscillations are essential for\nsustaining vital processes, like neuronal firing, circadian rhythms, and\nheartbeats. In such systems, thermodynamic dissipation is necessary to maintain\noscillations against noise. However, due to their nonlinear dynamics, it has\nbeen challenging to determine how the characteristics of oscillations, such as\nfrequency, amplitude, and coherent patterns across elements, influence\ndissipation. To resolve this issue, we employ Koopman mode decomposition, which\nrecasts nonlinear dynamics as a linear evolution in a function space. This\nlinearization allows the dynamics to be decomposed into temporal oscillatory\nmodes coherent across elements, with the Koopman eigenvalues determining their\nfrequencies. Using this method, we decompose thermodynamic dissipation caused\nby nonconservative forces into contributions from oscillatory modes in\noverdamped nonlinear Langevin dynamics. We show that the dissipation from each\nmode is proportional to its frequency squared and its intensity, providing an\ninterpretable, mode-by-mode picture. In the noisy FitzHugh--Nagumo model, we\ndemonstrate the effectiveness of this framework in quantifying the impact of\noscillatory modes on dissipation during nonlinear phenomena like stochastic\nresonance and bifurcation. For instance, our analysis of stochastic resonance\nreveals that the greatest dissipation at the optimal noise intensity is\nsupported by a broad spectrum of frequencies, whereas at non-optimal noise\nlevels, dissipation is dominated by specific frequency modes. Our work offers a\ngeneral approach to connecting oscillations to dissipation in noisy\nenvironments and improves our understanding of diverse oscillation phenomena\nfrom a nonequilibrium thermodynamic perspective."}
{"id": "2510.21033", "categories": ["math.OC", "cs.LG", "math.DG", "90C26, 68T07, 53Z50"], "pdf": "https://arxiv.org/pdf/2510.21033", "abs": "https://arxiv.org/abs/2510.21033", "authors": ["Willem Diepeveen", "Melanie Weber"], "title": "Iso-Riemannian Optimization on Learned Data Manifolds", "comment": null, "summary": "High-dimensional data that exhibit an intrinsic low-dimensional structure are\nubiquitous in machine learning and data science. While various approaches allow\nfor learning the corresponding data manifold from finite samples, performing\ndownstream tasks such as optimization directly on these learned manifolds\npresents a significant challenge. This work introduces a principled framework\nfor optimization on learned data manifolds using iso-Riemannian geometry. Our\napproach addresses key limitations of classical Riemannian optimization in this\nsetting, specifically, that the Levi-Civita connection fails to yield\nconstant-speed geodesics, and that geodesic convexity assumptions break down\nunder the learned pullback constructions commonly used in practice. To overcome\nthese challenges, we propose new notions of monotonicity and Lipschitz\ncontinuity tailored to the iso-Riemannian setting and propose iso-Riemannian\ndescent algorithms for which we provide a detailed convergence analysis. We\ndemonstrate the practical effectiveness of those algorithms on both synthetic\nand real datasets, including MNIST under a learned pullback structure. Our\napproach yields interpretable barycentres, improved clustering, and provably\nefficient solutions to inverse problems, even in high-dimensional settings.\nThese results establish that optimization under iso-Riemannian geometry can\novercome distortions inherent to learned manifold mappings."}
{"id": "2510.20901", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.20901", "abs": "https://arxiv.org/abs/2510.20901", "authors": ["Oscar Bouverot-Dupuis", "Laura Foini", "Alberto Rosso"], "title": "The generic Mott transition in the sine-Gordon model through an embedded worm algorithm", "comment": "35 pages, 20 figures", "summary": "The generic Mott transition in one-dimensional quantum systems can be\ndescribed by the sine-Gordon model with a tilt via bosonization. Because the\nconfiguration space of the sine-Gordon model separates into distinct\ntopological sectors, standard local Monte Carlo schemes are limited to very\nsmall system sizes. To overcome this limitation, we introduce the smooth worm\n(SmoWo) Monte Carlo algorithm which enlarges the configuration space to allow\nsmooth transitions between topological sectors. The method combines worm\nupdates with event-chain Monte Carlo moves. We explicitly prove its validity\nand quantify its performance. Thanks to the substantial acceleration achieved\nby the SmoWo algorithm, we are able to simulate large system sizes, providing a\nprecise picture of the different phases and critical behaviour of the\nsine-Gordon model."}
{"id": "2510.21429", "categories": ["math.NA", "cs.NA", "65M50"], "pdf": "https://arxiv.org/pdf/2510.21429", "abs": "https://arxiv.org/abs/2510.21429", "authors": ["Kevin Dijkstra", "Carlotta Giannelli", "Deepesh Toshniwal"], "title": "Macro-element Refinement schemes for THB-Splines: Applications to Bézier Projection and Structure-Preserving Discretizations", "comment": null, "summary": "This paper introduces a novel adaptive refinement strategy for Isogeometric\nAnalysis (IGA) using Truncated Hierarchical B-splines (THB-splines). The\nproposed strategy enhances locally-refined meshes for specific applications,\nsimplifying implementation. We focus on two key applications: an $L^2$-stable\nlocal projector for THB-splines via B\\'ezier projection [Dijkstra and Toshniwal\n(2023)], and structure-preserving discretizations using THB-splines [Evans et\nal. (2020), Shepherd and Toshniwal (2024)]. Previous methods required mesh\nmodifications to retain crucial properties like local linear independence and\nthe exactness of discrete de Rham complexes. Our approach introduces a\nmacro-element-based refinement technique, refining $\\vec{q} =\nq_1\\times\\cdots\\times q_n$ blocks of elements, termed $\\vec{q}$-boxes, where\nthe block size $\\vec{q}$ is determined by the spline degree and application.\nFor the B\\'ezier projection, we refine $\\vec{p}$-boxes (i.e., $\\vec{q} =\n\\vec{p}$), ensuring THB-splines are locally linearly independent in these\nboxes, which enables a straightforward extension of the B\\'ezier projection\nalgorithm, greatly improving upon Dijkstra and Toshniwal (2023). For\nstructure-preserving discretizations, we refine $(\\vec{p+1})$-boxes (i.e.,\n$\\vec{q} = \\vec{p}+\\vec{1}$), demonstrating that this choice meets the\nsufficient conditions for ensuring the exactness of the THB-spline de Rham\ncomplex, as outlined by Shepherd and Toshniwal (2024), in any dimension. This\ncritical aspect allows for adaptive simulations without additional mesh\nmodifications. The effectiveness of our framework is supported by theoretical\nproofs and numerical experiments, including optimal convergence for adaptive\napproximation and simulations of the incompressible Navier-Stokes equations."}
{"id": "2510.21238", "categories": ["eess.SY", "cs.AI", "cs.IT", "cs.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.21238", "abs": "https://arxiv.org/abs/2510.21238", "authors": ["Wangqian Chen", "Junting Chen", "Shuguang Cui"], "title": "Physics-Informed Neural Networks for MIMO Beam Map and Environment Reconstruction", "comment": null, "summary": "As communication networks evolve towards greater complexity (e.g., 6G and\nbeyond), a deep understanding of the wireless environment becomes increasingly\ncrucial. When explicit knowledge of the environment is unavailable,\ngeometry-aware feature extraction from channel state information (CSI) emerges\nas a pivotal methodology to bridge physical-layer measurements with network\nintelligence. This paper proposes to explore the received signal strength (RSS)\ndata, without explicit 3D environment knowledge, to jointly construct the radio\nbeam map and environmental geometry for a multiple-input multiple-output (MIMO)\nsystem. Unlike existing methods that only learn blockage structures, we propose\nan oriented virtual obstacle model that captures the geometric features of both\nblockage and reflection. Reflective zones are formulated to identify relevant\nreflected paths according to the geometry relation of the environment. We\nderive an analytical expression for the reflective zone and further analyze its\ngeometric characteristics to develop a reformulation that is more compatible\nwith deep learning representations. A physics-informed deep learning framework\nthat incorporates the reflective-zone-based geometry model is proposed to learn\nthe blockage, reflection, and scattering components, along with the beam\npattern, which leverages physics prior knowledge to enhance network\ntransferability. Numerical experiments demonstrate that, in addition to\nreconstructing the blockage and reflection geometry, the proposed model can\nconstruct a more accurate MIMO beam map with a 32%-48% accuracy improvement."}
{"id": "2510.21238", "categories": ["eess.SY", "cs.AI", "cs.IT", "cs.SY", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.21238", "abs": "https://arxiv.org/abs/2510.21238", "authors": ["Wangqian Chen", "Junting Chen", "Shuguang Cui"], "title": "Physics-Informed Neural Networks for MIMO Beam Map and Environment Reconstruction", "comment": null, "summary": "As communication networks evolve towards greater complexity (e.g., 6G and\nbeyond), a deep understanding of the wireless environment becomes increasingly\ncrucial. When explicit knowledge of the environment is unavailable,\ngeometry-aware feature extraction from channel state information (CSI) emerges\nas a pivotal methodology to bridge physical-layer measurements with network\nintelligence. This paper proposes to explore the received signal strength (RSS)\ndata, without explicit 3D environment knowledge, to jointly construct the radio\nbeam map and environmental geometry for a multiple-input multiple-output (MIMO)\nsystem. Unlike existing methods that only learn blockage structures, we propose\nan oriented virtual obstacle model that captures the geometric features of both\nblockage and reflection. Reflective zones are formulated to identify relevant\nreflected paths according to the geometry relation of the environment. We\nderive an analytical expression for the reflective zone and further analyze its\ngeometric characteristics to develop a reformulation that is more compatible\nwith deep learning representations. A physics-informed deep learning framework\nthat incorporates the reflective-zone-based geometry model is proposed to learn\nthe blockage, reflection, and scattering components, along with the beam\npattern, which leverages physics prior knowledge to enhance network\ntransferability. Numerical experiments demonstrate that, in addition to\nreconstructing the blockage and reflection geometry, the proposed model can\nconstruct a more accurate MIMO beam map with a 32%-48% accuracy improvement."}
{"id": "2510.21047", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.21047", "abs": "https://arxiv.org/abs/2510.21047", "authors": ["Ziyang Liu", "Ning Hao", "Yue Selena Niu", "Han Xiao", "Hongxu Ding"], "title": "Autocorrelation Test under Frequent Mean Shifts", "comment": null, "summary": "Testing for the presence of autocorrelation is a fundamental problem in time\nseries analysis. Classical methods such as the Box-Pierce test rely on the\nassumption of stationarity, necessitating the removal of non-stationary\ncomponents such as trends or shifts in the mean prior to application. However,\nthis is not always practical, particularly when the mean structure is complex,\nsuch as being piecewise constant with frequent shifts. In this work, we propose\na new inferential framework for autocorrelation in time series data under\nfrequent mean shifts. In particular, we introduce a Shift-Immune Portmanteau\n(SIP) test that reliably tests for autocorrelation and is robust against mean\nshifts. We illustrate an application of our method to nanopore sequencing data."}
{"id": "2510.21174", "categories": ["stat.ME", "stat.CO", "62F99"], "pdf": "https://arxiv.org/pdf/2510.21174", "abs": "https://arxiv.org/abs/2510.21174", "authors": ["Kenyon Ng", "Weichang Yu", "Howard D. Bondell"], "title": "Expectation-propagation for Bayesian empirical likelihood inference", "comment": "15 pages (+31 appendix). 4 figures", "summary": "Bayesian inference typically relies on specifying a parametric model that\napproximates the data-generating process. However, misspecified models can\nyield poor convergence rates and unreliable posterior calibration. Bayesian\nempirical likelihood offers a semi-parametric alternative by replacing the\nparametric likelihood with a profile empirical likelihood defined through\nmoment constraints, thereby avoiding explicit distributional assumptions.\nDespite these advantages, Bayesian empirical likelihood faces substantial\ncomputational challenges, including the need to solve a constrained\noptimization problem for each likelihood evaluation and difficulties with\nnon-convex posterior support, particularly in small-sample settings. This paper\nintroduces a variational approach based on expectation-propagation to\napproximate the Bayesian empirical-likelihood posterior, balancing\ncomputational cost and accuracy without altering the target posterior via\nadjustments such as pseudo-observations. Empirically, we show that our approach\ncan achieve a superior cost-accuracy trade-off relative to existing methods,\nincluding Hamiltonian Monte Carlo and variational Bayes. Theoretically, we show\nthat the approximation and the Bayesian empirical-likelihood posterior are\nasymptotically equivalent."}
{"id": "2510.21670", "categories": ["cond-mat.stat-mech", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.21670", "abs": "https://arxiv.org/abs/2510.21670", "authors": ["Julien Brémont"], "title": "Beyond Poisson: First-Passage Asymptotics of Renewal Shot Noise", "comment": null, "summary": "The first-passage time (FPT) of a stochastic signal to a threshold is a\nfundamental observable across physics, biology, and finance. While renewal shot\nnoise is a canonical model for such signals, analytical results for its FPT\nhave remained confined to the Poisson (Markovian) case, despite the prevalence\nof non-Poisson arrival statistics in applications from neuronal spiking to gene\nexpression. We break this long-standing barrier by deriving the first universal\nasymptotic formula for the mean FPT $\\langle T_b \\rangle$ to reach level $b$\nfor renewal shot noise with general arrival statistics and exponential marks.\nOur central result is a closed-form expression that reveals precisely how\ngeneral inter-arrival statistics impact the naive Arrhenius law. We show that\nthe short-time behavior of the interarrival distribution dictates universal\nscaling corrections, ranging from stretched-exponential to algebraic, that can\ndramatically accelerate threshold crossing. Furthermore, we argue and confirm\nnumerically that the full FPT distribution becomes exponential at large\nthresholds, implying that $\\langle T_b \\rangle$ provides a complete asymptotic\ncharacterization. Our work, enabled by a novel exact solution for the moments\nof the noise, establishes a general framework for analyzing extreme events in\nnon-Markovian systems with relaxation."}
{"id": "2510.21062", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.21062", "abs": "https://arxiv.org/abs/2510.21062", "authors": ["Gejia Zhang", "Robert Mieth"], "title": "Reliability-Aware Control of Distributed Energy Resources using Multi-Source Data Models", "comment": null, "summary": "Distributed energy resources offer a control-based option to improve\ndistribution system reliability by ensuring system states that positively\nimpact component failure rates. This option is an attractive complement to\notherwise costly and lengthy physical infrastructure upgrades. However,\nrequired models that adequately map operational decisions and environmental\nconditions to system failure risk are lacking because of data unavailability\nand the fact that distribution system failures remain rare events. This paper\naddresses this gap and proposes a multi-source data model that consistently\nmaps comprehensive weather and system state information to component failure\nrates. To manage collinearity in the available features, we propose two\nensemble tree-based models that systematically identify the most influential\nfeatures and reduce the dataset's dimensionality based on each feature's impact\non failure rate estimates. These estimates are embedded within a sequential,\nnon-convex optimization procedure, that dynamically updates operational control\ndecisions. We perform a numerical experiment to demonstrate the cost and\nreliability benefits that can be achieved through this reliability-aware\ncontrol approach and to analyze the properties of each proposed estimation\nmodel."}
{"id": "2510.21005", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.21005", "abs": "https://arxiv.org/abs/2510.21005", "authors": ["Yiliu Li", "Esteban Rojas-Gatjens", "Yinjie Guo", "Birui Yang", "Dihao Sun", "Luke Holtzman", "Juseung Oh", "Katayun Barmak", "Cory R. Dean", "James C. Hone", "Nathaniel Gabor", "Eric A. Arsenault", "Xiaoyang Zhu"], "title": "Photoinduced Metal-to-Insulator Transitions in 2D Moiré Devices", "comment": "13 pages, 4 figures, SI", "summary": "Photoexcitation has been utilized to control quantum matter and to uncover\nmetastable phases far from equilibrium. Among demonstrations to date, the most\ncommon is the photo-induced transition from correlated insulators to metallic\nstates; however, the reverse process without initial orders has not been\nobserved. Here, we show ultrafast metal-to-insulator transition in gate-doped\nWS2/WSe2 and WSe2/WSe2 moir\\'e devices using photo-thermionic hole injection\nfrom graphite gates. The resulting correlated insulators are metastable, with\nlifetimes exceeding microseconds. These findings establish an effective\nmechanism for the ultrafast control of correlated electronic phases in van der\nWaals heterostructures."}
{"id": "2510.21471", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21471", "abs": "https://arxiv.org/abs/2510.21471", "authors": ["Marvin Knöller", "Jörg Nick"], "title": "The temporal domain derivative in inverse acoustic obstacle scattering", "comment": null, "summary": "This work describes and analyzes the domain derivative for a time-dependent\nacoustic scattering problem. We study the nonlinear operator that maps a\nsound-soft scattering object to the solution of the time-dependent wave\nequation evaluated at a finite number of points away from the obstacle. The\nFr\\'echet derivative of this operator with respect to variations of the\nscatterer coincides with point evaluations of the temporal domain derivative.\nThe latter is the solution to another time-dependent scattering problem, for\nwhich a well-posedness result is shown under sufficient temporal regularity of\nthe incoming wave. Applying convolution quadrature to this scattering problem\ngives a stable and provably convergent semi-discretization in time, provided\nthat the incoming wave is sufficient regular. Using the discrete domain\nderivative in a Gauss--Newton method, we describe an efficient algorithm to\nreconstruct the boundary of an unknown scattering object from time domain\nmeasurements in a few points away from the boundary. Numerical examples for the\nacoustic wave equation in two dimensions demonstrate the performance of the\nmethod."}
{"id": "2510.21294", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21294", "abs": "https://arxiv.org/abs/2510.21294", "authors": ["Maxime Grosso", "Pierre Riedinger", "Jamal Daafouz"], "title": "The PhasorArray Toolbox for Harmonic Analysis and Control Design", "comment": null, "summary": "We present a MATLAB package called the Pha-sorArray Toolbox that has been\ndeveloped to make harmonic analysis and control methods both practical and\nuser-friendly. The toolbox adopts an object-oriented architecture that enables\nintuitive manipulation of periodic matrices through overloaded operators for\naddition, multiplication, convolution, and automatic Toeplitz construction. Its\nadvanced features include harmonic Sylvester, Lyapunov and Riccati equations\nsolvers, and seamless integration with YALMIP, thereby facilitating advanced\ncontrol and analysis techniques based on Linear Matrix Inequalities (LMIs) in\nthe harmonic framework."}
{"id": "2510.21294", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21294", "abs": "https://arxiv.org/abs/2510.21294", "authors": ["Maxime Grosso", "Pierre Riedinger", "Jamal Daafouz"], "title": "The PhasorArray Toolbox for Harmonic Analysis and Control Design", "comment": null, "summary": "We present a MATLAB package called the Pha-sorArray Toolbox that has been\ndeveloped to make harmonic analysis and control methods both practical and\nuser-friendly. The toolbox adopts an object-oriented architecture that enables\nintuitive manipulation of periodic matrices through overloaded operators for\naddition, multiplication, convolution, and automatic Toeplitz construction. Its\nadvanced features include harmonic Sylvester, Lyapunov and Riccati equations\nsolvers, and seamless integration with YALMIP, thereby facilitating advanced\ncontrol and analysis techniques based on Linear Matrix Inequalities (LMIs) in\nthe harmonic framework."}
{"id": "2510.21249", "categories": ["stat.ME", "stat.AP", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.21249", "abs": "https://arxiv.org/abs/2510.21249", "authors": ["Daniele Girolimetto", "Anastasios Panagiotelis", "Tommaso Di Fonzo", "Han Li"], "title": "Forecast reconciliation with non-linear constraints", "comment": null, "summary": "Methods for forecasting time series adhering to linear constraints have seen\nnotable development in recent years, especially with the advent of forecast\nreconciliation. This paper extends forecast reconciliation to the open question\nof non-linearly constrained time series. Non-linear constraints can emerge with\nvariables that are formed as ratios such as mortality rates and unemployment\nrates. On the methodological side, Non-linearly Constrained Reconciliation\n(NLCR) is proposed. This algorithm adjusts forecasts that fail to meet\nnon-linear constraints, in a way that ensures the new forecasts meet the\nconstraints. The NLCR method is a projection onto a non-linear surface,\nformulated as a constrained optimisation problem. On the theoretical side,\noptimisation methods are again used, this time to derive sufficient conditions\nfor when the NLCR methodology is guaranteed to improve forecast accuracy.\nFinally on the empirical side, NLCR is applied to two datasets from demography\nand economics and shown to significantly improve forecast accuracy relative to\nrelevant benchmarks."}
{"id": "2510.20824", "categories": ["nlin.CD", "cond-mat.mtrl-sci", "cond-mat.stat-mech", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.20824", "abs": "https://arxiv.org/abs/2510.20824", "authors": ["Liteng Yang", "Yuliang Liu", "Jing Liu", "Hongxuan Li", "Wei Chen"], "title": "A Probability Space at Inception of Stochastic Process", "comment": "14 pages, 1 figure", "summary": "Recently, progress has been made in the theory of turbulence, which provides\na framework on how a deterministic process changes to a stochastic one owing to\nthe change in thermodynamic states. It is well known that, in the framework of\nNewtonian mechanics, motions are dissipative; however, when subjected to\nperiodic motion, a system can produce nondissipative motions intermittently and\nsubject to resonance. It is in resonance that turbulence occurs in fluid flow,\nsolid vibration, thermal transport, etc. In this, the findings from these\nphysical systems are analyzed in the framework of statistics with their own\nprobability space to establish their compliance to the stochastic process. In\nparticular, a systematic alignment of the inception of the stochastic process\nwith the signed measure theory, signed probability space, and stochastic\nprocess was investigated. It was found that the oscillatory load from the\ndissipative state excited the system and resulted in a quasi-periodic\nprobability density function with the negative probability regimes. In\naddition, the vectorial nature of the random velocity splits the probability\ndensity function along both the positive and negative axes with slight\nasymmetricity. By assuming that a deterministic process has a probability of 1,\nwe can express the inception of a stochastic process, and the subsequent\nbenefit is that a dynamic fractal falls on the probability density function.\nMoreover, we leave some questions of inconsistency between the physical system\nand the measurement theory for future investigation. We believe that the\nestablishment of the probability density function of resonance nondissipative\ndynamics in contemporary statistics should make many mathematical tools\navailable and the analytical formulas for the random velocity and probability\ndensity function can provide a convenient platform for the development of\nstatistics."}
{"id": "2510.21126", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.21126", "abs": "https://arxiv.org/abs/2510.21126", "authors": ["Nagisa Sugishita", "Margarida Carvalho"], "title": "Complexity of Bilevel Linear Programming with a Single Upper-Level Variable", "comment": "27 pages, 1 figure", "summary": "Bilevel linear programming (LP) is one of the simplest classes of bilevel\noptimization problems, yet it is known to be NP-hard in general. Specifically,\ndetermining whether the optimal objective value of a bilevel LP is at least as\ngood as a given threshold, a standard decision version of the problem, is\nNP-complete. However, this decision problem becomes tractable when either the\nnumber of lower-level variables or the number of lower-level constraints is\nfixed, which prompts the question: What if restrictions are placed on the\nupper-level problem? In this paper, we address this gap by showing that the\ndecision version of bilevel LP remains NP-complete even when there is only a\nsingle upper-level variable, no upper-level constraints (apart from the\nconstraint enforcing optimality of the lower-level decision) and all variables\nare bounded between 0 and 1. This result implies that fixing the number of\nvariables or constraints in the upper-level problem alone does not lead to\ntractability in general. On the positive side, we show that there is a\npolynomial-time algorithm that finds a local optimal solution of such a\nrational bilevel LP instance. We also demonstrate that many combinatorial\noptimization problems, such as the knapsack problem and the traveling salesman\nproblem, can be written as such a bilevel LP instance."}
{"id": "2510.21008", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.21008", "abs": "https://arxiv.org/abs/2510.21008", "authors": ["Yiliu Li", "Esteban Rojas-Gatjens", "Yinjie Guo", "Birui Yang", "Dihao Sun", "Luke Holtzman", "Juseung Oh", "Katayun Barmak", "Cory R. Dean", "James C. Hone", "Nathaniel Gabor", "Eric A. Arsenault", "Xiaoyang Zhu"], "title": "Ultrafast Charge-Doping via Photo-Thermionic Injection in van der Waals Devices", "comment": "16 pages, 4 figures, SI", "summary": "Van der Waals (vdW) heterostructures of two-dimensional (2D) materials have\nbecome a rich playground for the exploration of correlated quantum phases, and\nrecent studies have begun to probe their non-equilibrium dynamics under\nfemtosecond laser excitation. In a time-resolved experiment, optical excitation\nof the multilayer structure can lead not only to rich dynamic responses from\nthe target layers, such as moir\\'e interfaces, but also to additional device\nfunctionality from the layer degree of freedom. Here, we investigate optical\nexcitation in a prototypical moir\\'e device of dual-gated twisted WSe2\nbilayers, with few-layer graphite gates and hexagonal boron nitride (hBN)\nspacers. We establish an ultrafast photodoping mechanism in the moir\\'e bilayer\nfrom photo-thermionic emission of the graphite gates. Using transient\nreflectance experiments, we reveal photo-induced hole injection evidenced by:\n(i) a shift of gate voltages at which optical signatures of correlated\ninsulators are observed, (ii) a persistent optical signature indicative of\ncharge diffusion at microsecond timescales and local charge buildup from\npulse-to-pulse accumulation, and (iii) photoinduced absorption due likely to\ntransient formation of correlated insulators. We further demonstrate that the\ninjected holes can be selectively controlled by tuning the excitation energy,\nfluence, and gate bias."}
{"id": "2510.21517", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.21517", "abs": "https://arxiv.org/abs/2510.21517", "authors": ["Clément Guillet"], "title": "Error Estimates for Sparse Tensor Products of B-spline Approximation Spaces", "comment": null, "summary": "This work introduces and analyzes B-spline approximation spaces defined on\ngeneral geometric domains obtained through a mapping from a parameter domain.\nThese spaces are constructed as sparse-grid tensor products of univariate\nspaces in the parameter domain and are mapped to the physical domain via a\ngeometric parametrization. Both the univariate approximation spaces and the\ngeometric mapping are built using maximally smooth B-splines. We construct two\nsuch spaces, employing either the sparse-grid combination technique or the\nhierarchical subspace decomposition of sparse-grid tensor products, and we\nprove their mathematical equivalence. Furthermore, we derive approximation\nerror estimates and inverse inequalities that highlight the advantages of\nsparse-grid tensor products. Specifically, under suitable regularity\nassumptions on the solution, these spaces achieve the same approximation order\nas standard tensor product spaces while using significantly fewer degrees of\nfreedom. Additionally, our estimates indicate that, in the case of\nnon-tensor-product domains, stronger regularity assumptions on the solution --\nparticularly concerning isotropic (non-mixed) derivatives -- are required to\nachieve optimal convergence rates compared to sparse-grid methods defined on\ntensor-product domains."}
{"id": "2510.21308", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21308", "abs": "https://arxiv.org/abs/2510.21308", "authors": ["Zhengang Zhong", "Ehecatl Antonio del Rio-Chanona", "Panagiotis Petsagkourakis"], "title": "Data-driven Koopman MPC using Mixed Stochastic-Deterministic Tubes", "comment": "This is the accepted version. It will appear in Journal of Process\n  Control, 2025", "summary": "This paper presents a novel data-driven stochastic MPC design for\ndiscrete-time nonlinear systems with additive disturbances by leveraging the\nKoopman operator and a distributionally robust optimization (DRO) framework. By\nlifting the dynamical system into a linear space, we achieve a\nfinite-dimensional approximation of the Koopman operator. We explicitly account\nfor the modeling approximation and additive disturbance error by a mixed\nstochastic-deterministic tube for the lifted linear model. This ensures the\nregulation of the original nonlinear system while complying with the\nprespecified constraints. Stochastic and deterministic tubes are constructed\nusing a DRO and a hyper-cube hull, respectively. We provide finite sample error\nbounds for both types of tubes. The effectiveness of the proposed approach is\ndemonstrated through numerical simulations."}
{"id": "2510.21308", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21308", "abs": "https://arxiv.org/abs/2510.21308", "authors": ["Zhengang Zhong", "Ehecatl Antonio del Rio-Chanona", "Panagiotis Petsagkourakis"], "title": "Data-driven Koopman MPC using Mixed Stochastic-Deterministic Tubes", "comment": "This is the accepted version. It will appear in Journal of Process\n  Control, 2025", "summary": "This paper presents a novel data-driven stochastic MPC design for\ndiscrete-time nonlinear systems with additive disturbances by leveraging the\nKoopman operator and a distributionally robust optimization (DRO) framework. By\nlifting the dynamical system into a linear space, we achieve a\nfinite-dimensional approximation of the Koopman operator. We explicitly account\nfor the modeling approximation and additive disturbance error by a mixed\nstochastic-deterministic tube for the lifted linear model. This ensures the\nregulation of the original nonlinear system while complying with the\nprespecified constraints. Stochastic and deterministic tubes are constructed\nusing a DRO and a hyper-cube hull, respectively. We provide finite sample error\nbounds for both types of tubes. The effectiveness of the proposed approach is\ndemonstrated through numerical simulations."}
{"id": "2510.21579", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.21579", "abs": "https://arxiv.org/abs/2510.21579", "authors": ["Ken Newman", "Shaini Naha", "Leah Jackson-Blake", "Cairistiona Topp", "Miriam Glendell", "Adam Butler"], "title": "A Comparison for Non-Specialists of Workflow Steps and Similarity of Factor Rankings for Several Global Sensitivity Analysis Methods", "comment": null, "summary": "Global sensitivity analysis (GSA) is a recommended step in the use of\ncomputer simulation models. GSA quantifies the relative importance of model\ninputs on outputs (Factor Ranking), identifies inputs that could be fixed, thus\nsimplifying model calibration (Factor Fixing), and pinpointing areas for future\ndata collection (Factor Prioritization). Given the wide variety of GSA methods,\nchoosing between methods can be challenging for non-GSA experts. Issues include\nworkflow steps and complexity, interpretation of GSA outputs, and the degree of\nsimilarity between methods in Factor Ranking. We conducted a study of both\nwidely and less commonly used GSA methods applied to three simulators of\ndiffering complexity. All methods share common issues around implementation\nwith specification of parameter ranges particularly critical. Similarities in\nFactor Rankings were generally high based on Kendall's W. Sobol' first order\nand total sensitivity indices were easy to interpret and informative with\nregression trees providing additional insight into interactions."}
{"id": "2510.20893", "categories": ["cond-mat.str-el", "cond-mat.stat-mech", "hep-lat", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.20893", "abs": "https://arxiv.org/abs/2510.20893", "authors": ["Lei Su"], "title": "$\\mathbb{Z}_2$ lattice gauge theories: fermionic gauging, transmutation, and Kramers-Wannier dualities", "comment": "6+17 pages. This work is dedicated to C. N. Yang", "summary": "We generalize the gauging of $\\mathbb{Z}_2$ symmetries by inserting Majorana\nfermions, establishing parallel duality correspondences for bosonic and\nfermionic lattice systems. Using this fermionic gauging, we construct fermionic\nanalogs of $\\mathbb{Z}_2$ gauge theories dual to the transverse-field Ising\nmodel, interpretable as Majorana stabilizer codes. We demonstrate a unitary\nequivalence between the $\\mathbb{Z}_2$ gauge theory obtained by gauging the\nfermion parity of a free fermionic system and the conventional $\\mathbb{Z}_2$\ngauge theory with potentially nonlocal terms on the square lattice with\ntoroidal geometry. This equivalence is implemented by a linear-depth local\nunitary circuit, connecting the bosonic and fermionic toric codes through a\ndirection-dependent anyonic transmutation. The gauge theory obtained by gauging\nfermion parity is further shown to be equivalent to a folded Ising chain\nobtained via the Jordan--Wigner transformation. We clarify the distinction\nbetween the recently proposed Kramers--Wannier dualities and those obtained by\ngauging the $\\mathbb{Z}_2$ symmetry along a space-covering path. Our results\nextend naturally to higher-dimensional $\\mathbb{Z}_2$ lattice gauge theories,\nproviding a unified framework for bosonic and fermionic dualities and offering\nnew insights for quantum computation and simulation."}
{"id": "2510.21152", "categories": ["math.OC", "91A23, 93E20, 60H10, 49N10"], "pdf": "https://arxiv.org/pdf/2510.21152", "abs": "https://arxiv.org/abs/2510.21152", "authors": ["Yuxin Ye", "Jingtao Shi"], "title": "Linear-Quadratic Non-zero Sum Differential Game with Asymmetric Delayed Information", "comment": "23 pages", "summary": "This paper is concerned with a linear-quadratic non-zero sum differential\ngame with asymmetric delayed information. To be specific, two players exist\ntime delays simultaneously which are different, leading the dynamical system\nbeing an asymmetric information structure. By virtue of stochastic maximum\nprinciple, the stochastic Hamiltonian system is given which is a delayed\nforward-backward stochastic differential equation. Utilizing discretisation\napproach and backward iteration technique, we establish the relationship\nbetween forward and backward processes under asymmetric delayed information\nstructure and obtain the state-estimate feedback Nash equilibrium of our\nproblem."}
{"id": "2510.21158", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.21158", "abs": "https://arxiv.org/abs/2510.21158", "authors": ["Takafumi Kitazawa", "Yasuyuki Shimura", "Takahiro Onimaru", "Shun Tsuchida", "Katsunori Kubo", "Yoshinori Haga", "Hironori Sakai", "Yoshifumi Tokiwa", "Shinsaku Kambe", "Yo Tokunaga"], "title": "Paramagnetic electron-nuclear spin entanglement in HoCo2Zn20", "comment": "15 pages, 11 figures", "summary": "We investigated electron-nuclear spin entanglement in the paramagnetic ground\nstate of the Ho-based cubic compound HoCo2Zn20. From analyses of magnetization\nand specific heat data, we determined the cubic crystalline electric field\n(CEF) parameters, the magnetic exchange constant, and the hyperfine coupling\nconstant between the 4f magnetic moment and the 165Ho nuclear spin. Our results\nshow that the Gamma5 CEF ground state is split by the hyperfine coupling, with\nan energy width of 1.3 K at 0 T, and that the true paramagnetic ground state is\na quasi-sextet arising primarily from entanglement between the f-electron\neffective spin S = 1 and the 165Ho nuclear spin I = 7/2. We further demonstrate\nthat, depending on the CEF parameters, the paramagnetic ground state can switch\nto an electron-nuclear coupled dectet. These findings underscore the importance\nof accurately identifying the electron-nuclear level scheme for understanding\nthe low-temperature properties of rare-earth compounds containing spin-active\nnuclei."}
{"id": "2510.21662", "categories": ["math.NA", "cs.NA", "65M60, 65M15, 35K30"], "pdf": "https://arxiv.org/pdf/2510.21662", "abs": "https://arxiv.org/abs/2510.21662", "authors": ["Deepika Garg", "Maxim Olshanskii"], "title": "A Stabilized Trace FEM for Surface Cahn--Hilliard Equations: Analysis and Simulations", "comment": "18 pages, 26 figures", "summary": "This paper addresses the analysis and numerical assessment of a computational\nmethod for solving the Cahn--Hilliard equation defined on a surface. The\nproposed approach combines the stabilized trace finite element method for\nspatial discretization with an implicit--explicit scheme for temporal\ndiscretization. The method belongs to a class of unfitted finite element\nmethods that use a fixed background mesh and a level-set function for implicit\nsurface representation. We establish the numerical stability of the discrete\nproblem by showing a suitable energy dissipation law for it. We further derive\noptimal-order error estimates assuming simplicial background meshes and finite\nelement spaces of order $m \\geq 1$. The effectiveness of the method is\ndemonstrated through numerical experiments on several two-dimensional closed\nsurfaces, confirming the theoretical results and illustrating the robustness\nand convergence properties of the scheme."}
{"id": "2510.21321", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21321", "abs": "https://arxiv.org/abs/2510.21321", "authors": ["Kanghui He", "Anil Alan", "Shengling Shi", "Ton van den Boom", "Bart De Schutter"], "title": "Predictive control barrier functions for piecewise affine systems with non-smooth constraints", "comment": null, "summary": "Obtaining control barrier functions (CBFs) with large safe sets for complex\nnonlinear systems and constraints is a challenging task. Predictive CBFs\naddress this issue by using an online finite-horizon optimal control problem\nthat implicitly defines a large safe set. The optimal control problem, also\nknown as the predictive safety filter (PSF), involves predicting the system's\nflow under a given backup control policy. However, for non-smooth systems and\nconstraints, some key elements, such as CBF gradients and the sensitivity of\nthe flow, are not well-defined, making the current methods inadequate for\nensuring safety. Additionally, for control-non-affine systems, the PSF is\ngenerally nonlinear and non-convex, posing challenges for real-time\ncomputation. This paper considers piecewise affine systems, which are usually\ncontrol-non-affine, under nonlinear state and polyhedral input constraints. We\nsolve the safety issue by incorporating set-valued generalized Clarke\nderivatives in the PSF design. We show that enforcing CBF constraints across\nall elements of the generalized Clarke derivatives suffices to guarantee\nsafety. Moreover, to lighten the computational overhead, we propose an explicit\napproximation of the PSF. The resulting control methods are demonstrated\nthrough numerical examples."}
{"id": "2510.21321", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21321", "abs": "https://arxiv.org/abs/2510.21321", "authors": ["Kanghui He", "Anil Alan", "Shengling Shi", "Ton van den Boom", "Bart De Schutter"], "title": "Predictive control barrier functions for piecewise affine systems with non-smooth constraints", "comment": null, "summary": "Obtaining control barrier functions (CBFs) with large safe sets for complex\nnonlinear systems and constraints is a challenging task. Predictive CBFs\naddress this issue by using an online finite-horizon optimal control problem\nthat implicitly defines a large safe set. The optimal control problem, also\nknown as the predictive safety filter (PSF), involves predicting the system's\nflow under a given backup control policy. However, for non-smooth systems and\nconstraints, some key elements, such as CBF gradients and the sensitivity of\nthe flow, are not well-defined, making the current methods inadequate for\nensuring safety. Additionally, for control-non-affine systems, the PSF is\ngenerally nonlinear and non-convex, posing challenges for real-time\ncomputation. This paper considers piecewise affine systems, which are usually\ncontrol-non-affine, under nonlinear state and polyhedral input constraints. We\nsolve the safety issue by incorporating set-valued generalized Clarke\nderivatives in the PSF design. We show that enforcing CBF constraints across\nall elements of the generalized Clarke derivatives suffices to guarantee\nsafety. Moreover, to lighten the computational overhead, we propose an explicit\napproximation of the PSF. The resulting control methods are demonstrated\nthrough numerical examples."}
{"id": "2510.21661", "categories": ["stat.ME", "stat.CO"], "pdf": "https://arxiv.org/pdf/2510.21661", "abs": "https://arxiv.org/abs/2510.21661", "authors": ["Heyang Ji", "Carmen Tekwe"], "title": "MECfda: An R Package for Bias Correction Due to Measurement Error in Functional and Scalar Covariates in Scalar-on-Function Regression Models", "comment": null, "summary": "Functional data analysis (FDA) deals with high-resolution data recorded over\na continuum, such as time, space or frequency. Device-based assessments of\nphysical activity or sleep are objective yet still prone to measurement error.\nWe present MECfda, an R package that (i) fits scalar-on-function, generalized\nscalar-on-function, and functional quantile regression models, and (ii)\nprovides bias-corrected estimation when functional covariates are measured with\nerror. By unifying these tools under a consistent syntax, MECfda enables robust\ninference for FDA applications that involve noisy functional data."}
{"id": "2510.21109", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "physics.optics"], "pdf": "https://arxiv.org/pdf/2510.21109", "abs": "https://arxiv.org/abs/2510.21109", "authors": ["Federico Ghimenti", "Adithya Sriram", "Atsushi Yamamura", "Hideo Mabuchi", "Surya Ganguli"], "title": "The geometry and dynamics of annealed optimization in the coherent Ising machine with hidden and planted solutions", "comment": null, "summary": "The coherent Ising machine (CIM) is a nonconventional hardware architecture\nfor finding approximate solutions to large-scale combinatorial optimization\nproblems.It operates by annealing a laser gain parameter to adiabatically\ndeform a high-dimensional energy landscape over a set of soft spins, going from\na simple convex landscape to the more complex optimization landscape of\ninterest. We address how the evolving energy landscapes guides the optimization\ndynamics against problems with hidden planted solutions. We study the\nSherrington-Kirkpatrick spin-glass with ferromagnetic couplings that favor a\nhidden configuration by combining the replica method, random matrix theory, the\nKac-Rice method and dynamical mean field theory. We characterize energy,\nnumber, location, and Hessian eigenspectra of global minima, local minima, and\ncritical points as the landscape evolves. We find that low energy global minima\ndevelop soft-modes which the optimization dynamics can exploit to descend the\nenergy landscape. Even when these global minima are aligned to the hidden\nconfiguration, there can be exponentially many higher energy local minima that\nare all unaligned with the hidden solution. Nevertheless, the annealed\noptimization dynamics can evade this cloud of unaligned high energy local\nminima and descend near to aligned lower energy global minima. Eventually, as\nthe landscape is further annealed, these global minima become rigid,\nterminating any further optimization gains from annealing. We further consider\na second optimization problem, the Wishart planted ensemble, which contains a\nhidden planted solution in a landscape with tunable ruggedness. We describe CIM\nphase transitions between recoverability and non-recoverability of the hidden\nsolution. Overall, we find intriguing relations between high-dimensional\ngeometry and dynamics in analog machines for combinatorial optimization."}
{"id": "2510.21208", "categories": ["math.OC", "93E20, 49K45, 60K35, 60H30"], "pdf": "https://arxiv.org/pdf/2510.21208", "abs": "https://arxiv.org/abs/2510.21208", "authors": ["Somnath Pradhan", "Serdar Yuksel"], "title": "Near Optimality of Discrete-Time Approximations for Controlled McKean-Vlasov Diffusions and Interacting Particle Systems", "comment": "23 pages", "summary": "We study stochastic optimal control problems for (possibly degenerate)\nMcKean-Vlasov controlled diffusions and obtain discrete-time as well as finite\ninteracting particle approximations. (i) Under mild assumptions, we first prove\nthe existence of optimal relaxed controls by endowing the space of relaxed\npolicies with a compact weak topology. (ii) Establishing continuity of the cost\nin control policy, we establish near-optimality of piecewise-constant strict\npolicies, show that the discrete-time value functions (finite-horizon and\ndiscounted infinite-horizon) converge to their continuous-time counterparts as\nthe timestep converges to zero, and that optimal discrete-time policies are\nnear-optimal for the original continuous-time problem, where rates of\nconvergence are also obtained. (iii) We then extend these approximation and\nnear-optimality results to $N$-particle interacting systems under centralized\nor decentralized mean-field sharing information structure, proving that the\ndiscrete-time McKean-Vlasov policy is asymptotically optimal as $N\\to \\infty$\nand the time step goes to zero. We thus develop an approximation of\nMcKean-Vlasov optimal control problems via discrete-time McKean-Vlasov control\nproblems (and associated numerical methods such as finite model approximation),\nand also show the near optimality of such approximate policy solutions for the\n$N$-agent interacting models under centralized and decentralized control."}
{"id": "2510.21291", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.21291", "abs": "https://arxiv.org/abs/2510.21291", "authors": ["Alejandro Blanco Peces", "Jaime Merino"], "title": "Altermagnetism in an interacting model of Kagome materials", "comment": "7 pages, 4 figures, + Supplementary Material (7 pages, 5 figures)", "summary": "The Hubbard model on the Kagome lattice is a widely used interacting model\nfor describing the electronic properties of various transition metal-based\nKagome materials. We find altermagnetism driven by Coulomb interaction in the\nKagome Hubbard model at Dirac filling with no spin-orbit coupling nor explicit\nspatial symmetry breaking present. We show how this insulating altermagnet is\nrelevant to other lattices with larger unit cells such as the Lieb-Kagome\nlattice. The ALM found displays a characteristic magnon splitting which can be\ndetected in inelastic neutron scattering experiments on interacting Kagome\nmaterials."}
{"id": "2510.20826", "categories": ["physics.comp-ph", "cs.NA", "math.NA", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.20826", "abs": "https://arxiv.org/abs/2510.20826", "authors": ["Hai Zhu", "Chia-Nan Yeh", "Miguel A. Morales", "Leslie Greengard", "Shidong Jiang", "Jason Kaye"], "title": "Interpolative separable density fitting on adaptive real space grids", "comment": "12 pages, 8 figures", "summary": "We generalize the interpolative separable density fitting (ISDF) method, used\nfor compressing the four-index electron repulsion integral (ERI) tensor, to\nincorporate adaptive real space grids for potentially highly localized\nsingle-particle basis functions. To do so, we employ a fast adaptive algorithm,\nthe recently-introduced dual-space multilevel kernel-splitting method, to solve\nthe Poisson equation for the ISDF auxiliary basis functions. The adaptive grids\nare generated using a high-order accurate, black-box procedure that satisfies a\nuser-specified error tolerance. Our algorithm relies on the observation, which\nwe prove, that an adaptive grid resolving the pair densities appearing in the\nERI tensor can be straightforwardly constructed from one that resolves the\nsingle-particle basis functions, with the number of required grid points\ndiffering only by a constant factor. We find that the ISDF compression\nefficiency for the ERI tensor with highly localized basis sets is comparable to\nthat for smoother basis sets compatible with uniform grids. To demonstrate the\nperformance of our procedure, we consider several molecular systems with\nall-electron basis sets which are intractable using uniform grid-based methods.\nOur work establishes a pathway for scalable many-body electronic structure\nsimulations with arbitrary smooth basis functions, making simulations of\nphenomena like core-level excitations feasible on a large scale."}
{"id": "2510.21546", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21546", "abs": "https://arxiv.org/abs/2510.21546", "authors": ["Johannes Autenrieb", "Mark Spiller"], "title": "Auction-Based Responsibility Allocation for Scalable Decentralized Safety Filters in Cooperative Multi-Agent Collision Avoidance", "comment": "6 pages, 3 figures, Submitted to Control Engineering Practice and\n  IFAC World Congress 2026", "summary": "This paper proposes a scalable decentralized safety filter for multi-agent\nsystems based on high-order control barrier functions (HOCBFs) and\nauction-based responsibility allocation. While decentralized HOCBF formulations\nensure pairwise safety under input bounds, they face feasibility and\nscalability challenges as the number of agents grows. Each agent must evaluate\nan increasing number of pairwise constraints, raising the risk of infeasibility\nand making it difficult to meet real-time requirements. To address this, we\nintroduce an auction-based allocation scheme that distributes constraint\nenforcement asymmetrically among neighbors based on local control effort\nestimates. The resulting directed responsibility graph guarantees full safety\ncoverage while reducing redundant constraints and per-agent computational load.\nSimulation results confirm safe and efficient coordination across a range of\nnetwork sizes and interaction densities."}
{"id": "2510.21546", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21546", "abs": "https://arxiv.org/abs/2510.21546", "authors": ["Johannes Autenrieb", "Mark Spiller"], "title": "Auction-Based Responsibility Allocation for Scalable Decentralized Safety Filters in Cooperative Multi-Agent Collision Avoidance", "comment": "6 pages, 3 figures, Submitted to Control Engineering Practice and\n  IFAC World Congress 2026", "summary": "This paper proposes a scalable decentralized safety filter for multi-agent\nsystems based on high-order control barrier functions (HOCBFs) and\nauction-based responsibility allocation. While decentralized HOCBF formulations\nensure pairwise safety under input bounds, they face feasibility and\nscalability challenges as the number of agents grows. Each agent must evaluate\nan increasing number of pairwise constraints, raising the risk of infeasibility\nand making it difficult to meet real-time requirements. To address this, we\nintroduce an auction-based allocation scheme that distributes constraint\nenforcement asymmetrically among neighbors based on local control effort\nestimates. The resulting directed responsibility graph guarantees full safety\ncoverage while reducing redundant constraints and per-agent computational load.\nSimulation results confirm safe and efficient coordination across a range of\nnetwork sizes and interaction densities."}
{"id": "2510.21708", "categories": ["stat.ME", "62J15"], "pdf": "https://arxiv.org/pdf/2510.21708", "abs": "https://arxiv.org/abs/2510.21708", "authors": ["David S. Robertson", "Thomas Jaki"], "title": "Optimal weighted tests for replication studies and the two-trials rule", "comment": "28 pages", "summary": "Replication studies for scientific research are an important part of ensuring\nthe reliability and integrity of experimental findings. In the context of\nclinical trials, the concept of replication has been formalised by the\n'two-trials' rule, where two pivotal studies are required to show positive\nresults before a drug can be approved. In experiments testing multiple\nhypotheses simultaneously, control of the overall familywise error rate (FWER)\nis additionally required in many contexts. The well-known Bonferroni procedure\ncontrols the FWER, and a natural extension is to introduce weights into this\nprocedure to reflect the a-priori importance of hypotheses or to maximise some\nmeasure of the overall power of the experiment. In this paper, we consider\nanalysing a replication study using an optimal weighted Bonferroni procedure,\nwith the weights based on the results of the original study that is being\nreplicated and the optimality criterion being to maximise the disjunctive power\nof the trial (the power to reject at least one non-null hypothesis). We show\nthat using the proposed procedure can lead to a substantial increase in the\ndisjunctive power of the replication study, and is robust to changes in the\neffect sizes between the two studies."}
{"id": "2510.21274", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.21274", "abs": "https://arxiv.org/abs/2510.21274", "authors": ["Eliabelle Mauduit", "Eloïse Berthier", "Andrea Simonetto"], "title": "Time-varying Gaussian Process Bandit Optimization with Experts: no-regret in logarithmically-many side queries", "comment": null, "summary": "We study a time-varying Bayesian optimization problem with bandit feedback,\nwhere the reward function belongs to a Reproducing Kernel Hilbert Space (RKHS).\nWe approach the problem via an upper-confidence bound Gaussian Process\nalgorithm, which has been proven to yield no-regret in the stationary case.\n  The time-varying case is more challenging and no-regret results are out of\nreach in general in the standard setting. As such, we instead tackle the\nquestion of how many additional observations asked to an expert are required to\nregain a no-regret property. To do so, we formulate the presence of past\nobservation via an uncertainty injection procedure, and we reframe the problem\nas a heteroscedastic Gaussian Process regression. In addition, to achieve a\nno-regret result, we discard long outdated observations and replace them with\nupdated (possibly very noisy) ones obtained by asking queries to an external\nexpert. By leveraging and extending sparse inference to the heteroscedastic\ncase, we are able to secure a no-regret result in a challenging time-varying\nsetting with only logarithmically-many side queries per time step. Our method\ndemonstrates that minimal additional information suffices to counteract\ntemporal drift, ensuring efficient optimization despite time variation."}
{"id": "2510.21616", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.21616", "abs": "https://arxiv.org/abs/2510.21616", "authors": ["Hope Whitelock", "Allen O. Scheie", "Marissa McMaster", "Ian A. Leahy", "Li Xing", "Mykhaylo Ozerov", "Dmitry Smirnov", "Eun Sang Choi", "C. dela Cruz", "M. O. Ajeesh", "Eliana S. Krakovsky", "Daniel Rehn", "Jie Xing", "Athena S. Sefat", "Minhyea Lee"], "title": "Direct observation of the crystal electric-field splitting under magnetic field and uncovering field-induced magnetic phase transition in triangular rare-earth magnet CsErSe$_2$", "comment": "13 pages, 9 figures", "summary": "An indispensable step toward understanding magnetic interaction in rare-earth\nmagnets is the determination of spatially anisotropic single-ion properties\nresulting from the crystal electric field (CEF) physics. The CEF Hamiltonian\nexhibits a discrete energy spectrum governed by a set of independent parameters\nthat reflect the site symmetry of the magnetic ion. However, experimentally\ndetermining these parameters for magnetic ions at low-symmetry sites has been\nproven highly challenging. In this study, we directly measured the CEF level\nsplitting under magnetic fields (B) using optical spectroscopy and extracted\nboth CEF parameters and the exchange energies of a triangular insulating magnet\nCsErSe$_2$ as a model system. With increasing field, we find many CEF levels\nundergo level-crossing, which accompanies switching of the eigenstate.\nParticularly, such a crossing occurring at the ground state results in a\nstep-like increase in magnetization that we captured with the low-temperature\nAC magnetic susceptibility measurements. Our work demonstrates that the\naccurately determined CEF Hamiltonian parameters enable uncovering the rich\nphysics of field-induced collective magnetic phenomena, and potentially lead to\na new route to magnetic frustration."}
{"id": "2510.21607", "categories": ["math.OC", "cs.NA", "math.AP", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.21607", "abs": "https://arxiv.org/abs/2510.21607", "authors": ["Yuan Zhong"], "title": "Multilevel Picard scheme for solving high-dimensional drift control problems with state constraints", "comment": "108 pages, 3 figures", "summary": "Motivated by applications to the dynamic control of queueing networks, we\ndevelop a simulation-based scheme, the so-called multilevel Picard (MLP)\napproximation, for solving high-dimensional drift control problems whose states\nare constrained to stay within the nonnegative orthant, over a finite time\nhorizon. We prove that under suitable conditions, the MLP approximation\novercomes the curse of dimensionality in the following sense: To approximate\nthe value function and its gradient evaluated at a given time and state to\nwithin a prescribed accuracy $\\varepsilon$, the computational complexity grows\nat most polynomially in the problem dimension $d$ and $1/\\varepsilon$. To\nillustrate the effectiveness of the scheme, we carry out numerical experiments\nfor a class of test problems that are related to the dynamic scheduling problem\nof parallel server systems in heavy traffic, and demonstrate that the scheme is\ncomputationally feasible up to dimension at least $20$."}
{"id": "2510.21556", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21556", "abs": "https://arxiv.org/abs/2510.21556", "authors": ["Sophie Hall", "Florian Dörfler", "Timm Faulwasser"], "title": "System-Theoretic Analysis of Dynamic Generalized Nash Equilibrium Problems -- Turnpikes and Dissipativity", "comment": null, "summary": "Generalized Nash equilibria are used in multi-agent control applications to\nmodel strategic interactions between agents that are coupled in the cost,\ndynamics, and constraints. We study the properties of open-loop GNE\ntrajectories from a system-theoretic perspective. We show how strict\ndissipativity generates the turnpike phenomenon in GNE solutions. Moreover, we\nestablish a converse turnpike result, i.e., the implication from turnpike to\nstrict dissipativity. We derive conditions under which the steady-state GNE is\nthe optimal operating point and, using a game value function, we give a local\ncharacterization of the geometry of storage functions. Finally, we design\nlinear terminal penalties that ensure GNE open-loop trajectories converge to\nand remain at the steady-state GNE. These connections provide the foundation\nfor future system-theoretic analysis of GNEs similar to those existing in\noptimal control."}
{"id": "2510.21556", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.21556", "abs": "https://arxiv.org/abs/2510.21556", "authors": ["Sophie Hall", "Florian Dörfler", "Timm Faulwasser"], "title": "System-Theoretic Analysis of Dynamic Generalized Nash Equilibrium Problems -- Turnpikes and Dissipativity", "comment": null, "summary": "Generalized Nash equilibria are used in multi-agent control applications to\nmodel strategic interactions between agents that are coupled in the cost,\ndynamics, and constraints. We study the properties of open-loop GNE\ntrajectories from a system-theoretic perspective. We show how strict\ndissipativity generates the turnpike phenomenon in GNE solutions. Moreover, we\nestablish a converse turnpike result, i.e., the implication from turnpike to\nstrict dissipativity. We derive conditions under which the steady-state GNE is\nthe optimal operating point and, using a game value function, we give a local\ncharacterization of the geometry of storage functions. Finally, we design\nlinear terminal penalties that ensure GNE open-loop trajectories converge to\nand remain at the steady-state GNE. These connections provide the foundation\nfor future system-theoretic analysis of GNEs similar to those existing in\noptimal control."}
{"id": "2510.21390", "categories": ["math.OC", "65K10, 90C26, 90C30"], "pdf": "https://arxiv.org/pdf/2510.21390", "abs": "https://arxiv.org/abs/2510.21390", "authors": ["Laura Selicato", "Flavia Esposito", "Andersen Ang"], "title": "Binno: A 1st-order method for Bi-level Nonconvex Nonsmooth Optimization for Matrix Factorizations", "comment": "29 pages, 5 figures", "summary": "In this work, we develop a method for nonconvex, nonsmooth bi-level\noptimization and we introduce Binno, a first order method that leverages\nproximal constructions together with carefully designed descent conditions and\nvariational analysis. Within this framework, Binno provably enforces a descent\nproperty for the overall objective surrogate associated with the bi-level\nproblem. Each iteration performs blockwise proximal-gradient updates for the\nupper and the lower problems separately and then forms a calibrated,\nblock-diagonal convex combination of the two tentative iterates. A linesearch\nselects the combination weights to enforce simultaneous descent of both\nlevel-wise objectives, and we establish conditions guaranteeing the existence\nof such weights together with descent directions induced by the associated\nproximal-gradient maps. We also apply Binno in the context of sparse low-rank\nfactorization, where the upper level uses elementwise $\\ell_1$ penalties and\nthe lower level uses nuclear norms, coupled via a Frobenius data term. We test\nBinno on synthetic matrix and a real traffic-video dataset, attaining lower\nrelative reconstruction error and higher peak signal-to-noise ratio than some\nstandard methods."}
{"id": "2510.20865", "categories": ["physics.hist-ph", "cond-mat.dis-nn", "cond-mat.str-el", "cond-mat.supr-con", "hep-th"], "pdf": "https://arxiv.org/pdf/2510.20865", "abs": "https://arxiv.org/abs/2510.20865", "authors": ["Premala Chandra", "Piers Coleman", "Clare C. Yu"], "title": "Philip Warren Anderson", "comment": "A biographical memoir of P. W. Anderson to be published in\n  Biographical Memoirs of Fellows of the Royal Society. 27 pages, 7\n  figures/photos", "summary": "Philip Warren Anderson was a pioneering theoretical physicist whose work\nfundamentally shaped our understanding of complex systems. Anderson received\nthe Nobel Prize in Physics in 1977 for his groundbreaking research on\nlocalization and magnetism, yet he did so much more. His work on magnetism\nincluded antiferromagnetism, superexchange, the Kondo problem and local\nmagnetic moments in metals. Anderson pointed out the importance of disorder\nthrough his work on localization, non-crystalline solids and spin glasses. In\nsuperconductivity, he is known for the dirty superconductor theorem, showing\nthe gauge-invariance of the BCS theory, his study of flux creep, and for his\ncollaboration with experimentalists to realize the Josephson effect. Anderson's\nresonating valence bond theory may yet play an important role in high\ntemperature superconductivity. Anderson was also fascinated by broken symmetry,\nand he laid the theoretical groundwork for what is now known as the\nAnderson-Higgs mechanism, showing how gauge bosons can acquire mass - an\ninsight that played a foundational role in the Standard Model of particle\nphysics. In his seminal \"More is Different\" paper, Anderson argued that the\ncollective emergent phenomena that arise in complex interacting systems cannot\nbe deduced from their fundamental parts. Anderson's legacy endures not only\nthrough the lasting impact of his scientific work but also through his\ninfluence on generations of physicists who continue to explore the rich\nlandscape of collective behavior in nature."}
{"id": "2510.21612", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.21612", "abs": "https://arxiv.org/abs/2510.21612", "authors": ["Yorie Nakahira", "Fangzhou Xiao", "Victoria Kostina", "John C. Doyle"], "title": "Rate-cost tradeoffs in continuous-time control with a biomolecular application", "comment": null, "summary": "This paper focuses on rate-limited control of the generalized\nOrnstein-Uhlenbeck process where the control action can be either\nmultiplicative or additive, and the noise variance can depend on the control\naction. We derive a lower bound on the data rate necessary to achieve the\ndesired control cost. The lower bound is attained with equality if the control\nis performed via an additive white Gaussian channel. The system model\napproximates the dynamics of a discrete-state molecular birth-death process,\nand the result has direct implications on the control of a biomolecular system\nvia chemical reactions, where the multiplicative control corresponds to the\ndegradation rate, the additive control corresponds to the production rate, and\nthe control objective is to decrease the fluctuations of the controlled\nmolecular species around their desired concentration levels."}
{"id": "2510.21612", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.21612", "abs": "https://arxiv.org/abs/2510.21612", "authors": ["Yorie Nakahira", "Fangzhou Xiao", "Victoria Kostina", "John C. Doyle"], "title": "Rate-cost tradeoffs in continuous-time control with a biomolecular application", "comment": null, "summary": "This paper focuses on rate-limited control of the generalized\nOrnstein-Uhlenbeck process where the control action can be either\nmultiplicative or additive, and the noise variance can depend on the control\naction. We derive a lower bound on the data rate necessary to achieve the\ndesired control cost. The lower bound is attained with equality if the control\nis performed via an additive white Gaussian channel. The system model\napproximates the dynamics of a discrete-state molecular birth-death process,\nand the result has direct implications on the control of a biomolecular system\nvia chemical reactions, where the multiplicative control corresponds to the\ndegradation rate, the additive control corresponds to the production rate, and\nthe control objective is to decrease the fluctuations of the controlled\nmolecular species around their desired concentration levels."}
{"id": "2510.21397", "categories": ["math.OC", "econ.TH", "49L12, 49L20, 91BXX, 91AXX"], "pdf": "https://arxiv.org/pdf/2510.21397", "abs": "https://arxiv.org/abs/2510.21397", "authors": ["Emmanuelle Augeraud-Véron", "Daria Ghilli", "Fausto Gozzi", "Marta Leocata"], "title": "Optimal policies for environmental assets under spatial heterogeneity and global awareness", "comment": null, "summary": "The aim of this paper is to formulate and study a stochastic model for the\nmanagement of environmental assets in a geographical context where in each\nplace the local authorities take their policy decisions maximizing their own\nwelfare, hence not cooperating each other. A key feature of our model is that\nthe welfare depends not only on the local environmental asset, but also on the\nglobal one, making the problem much more interesting but technically much more\ncomplex to study, since strategic interaction among players arise.\n  We study the problem first from the $N$-players game perspective and find\nopen and closed loop Nash equilibria in explicit form. We also study the\nconvergence of the $N$-players game (when $n\\to +\\infty$) to a suitable Mean\nField Game whose unique equilibrium is exactly the limit of both the open and\nclosed loop Nash equilibria found above, hence supporting their meaning for the\ngame. Then we solve explicitly the problem from the cooperative perspective of\nthe social planner and compare its solution to the equilibria of the\n$N$-players game. Moreover we find the Pigouvian tax which aligns the\ndecentralized closed loop equilibrium to the social optimum."}
{"id": "2510.21415", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21415", "abs": "https://arxiv.org/abs/2510.21415", "authors": ["Jietian Liu", "Peter Seiler"], "title": "Robust Regret Control with Uncertainty-Dependent Baseline", "comment": null, "summary": "This paper proposes a robust regret control framework in which the\nperformance baseline adapts to the realization of system uncertainty. The plant\nis modeled as a discrete-time, uncertain linear time-invariant system with\nreal-parametric uncertainty. The performance baseline is the optimal non-causal\ncontroller constructed with full knowledge of the disturbance and the specific\nrealization of the uncertain plant. We show that a controller achieves robust\nadditive regret relative to this baseline if and only if it satisfies a\nrelated, robust $H_\\infty$ performance condition on a modified plant. One\ntechnical issue is that the modified plant can, in general, have a complicated\nnonlinear dependence on the uncertainty. We use a linear approximation step so\nthat the robust additive regret condition can be recast as a standard\n$\\mu$-synthesis problem. A numerical example is used to demonstrate the\nproposed approach."}
{"id": "2510.21415", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21415", "abs": "https://arxiv.org/abs/2510.21415", "authors": ["Jietian Liu", "Peter Seiler"], "title": "Robust Regret Control with Uncertainty-Dependent Baseline", "comment": null, "summary": "This paper proposes a robust regret control framework in which the\nperformance baseline adapts to the realization of system uncertainty. The plant\nis modeled as a discrete-time, uncertain linear time-invariant system with\nreal-parametric uncertainty. The performance baseline is the optimal non-causal\ncontroller constructed with full knowledge of the disturbance and the specific\nrealization of the uncertain plant. We show that a controller achieves robust\nadditive regret relative to this baseline if and only if it satisfies a\nrelated, robust $H_\\infty$ performance condition on a modified plant. One\ntechnical issue is that the modified plant can, in general, have a complicated\nnonlinear dependence on the uncertainty. We use a linear approximation step so\nthat the robust additive regret condition can be recast as a standard\n$\\mu$-synthesis problem. A numerical example is used to demonstrate the\nproposed approach."}
{"id": "2510.21415", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21415", "abs": "https://arxiv.org/abs/2510.21415", "authors": ["Jietian Liu", "Peter Seiler"], "title": "Robust Regret Control with Uncertainty-Dependent Baseline", "comment": null, "summary": "This paper proposes a robust regret control framework in which the\nperformance baseline adapts to the realization of system uncertainty. The plant\nis modeled as a discrete-time, uncertain linear time-invariant system with\nreal-parametric uncertainty. The performance baseline is the optimal non-causal\ncontroller constructed with full knowledge of the disturbance and the specific\nrealization of the uncertain plant. We show that a controller achieves robust\nadditive regret relative to this baseline if and only if it satisfies a\nrelated, robust $H_\\infty$ performance condition on a modified plant. One\ntechnical issue is that the modified plant can, in general, have a complicated\nnonlinear dependence on the uncertainty. We use a linear approximation step so\nthat the robust additive regret condition can be recast as a standard\n$\\mu$-synthesis problem. A numerical example is used to demonstrate the\nproposed approach."}
{"id": "2510.21490", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21490", "abs": "https://arxiv.org/abs/2510.21490", "authors": ["Jared Miller", "Fabian Jakob", "Carsten Scherer", "Andrea Iannelli"], "title": "Analysis and Synthesis of Switched Optimization Algorithms", "comment": null, "summary": "Deployment of optimization algorithms on networked systems face challenges\nassociated with time delays and corruptions. One particular instance is the\npresence of time-varying delays arising from factors such as packet drops and\nirregular sampling. Fixed time delays can destabilize gradient descent\nalgorithms, and this degradation is exacerbated by time-varying delays. This\nwork concentrates on the analysis and creation of discrete-time optimization\nalgorithms with certified exponential convergence rates that are robust against\nswitched uncertainties between the optimizer and the gradient oracle. These\noptimization algorithms are implemented by a switch-scheduled output feedback\ncontrollers. Rate variation and sawtooth behavior (packet drops) in\ntime-varying delays can be imposed through constraining switching sequences.\nAnalysis is accomplished by bisection in the convergence rate to find\nZames-Falb filter coefficents. Synthesis is performed by alternating between a\nfilter coefficient search for a fixed controller, and a controller search for\nfixed multipliers."}
{"id": "2510.21490", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21490", "abs": "https://arxiv.org/abs/2510.21490", "authors": ["Jared Miller", "Fabian Jakob", "Carsten Scherer", "Andrea Iannelli"], "title": "Analysis and Synthesis of Switched Optimization Algorithms", "comment": null, "summary": "Deployment of optimization algorithms on networked systems face challenges\nassociated with time delays and corruptions. One particular instance is the\npresence of time-varying delays arising from factors such as packet drops and\nirregular sampling. Fixed time delays can destabilize gradient descent\nalgorithms, and this degradation is exacerbated by time-varying delays. This\nwork concentrates on the analysis and creation of discrete-time optimization\nalgorithms with certified exponential convergence rates that are robust against\nswitched uncertainties between the optimizer and the gradient oracle. These\noptimization algorithms are implemented by a switch-scheduled output feedback\ncontrollers. Rate variation and sawtooth behavior (packet drops) in\ntime-varying delays can be imposed through constraining switching sequences.\nAnalysis is accomplished by bisection in the convergence rate to find\nZames-Falb filter coefficents. Synthesis is performed by alternating between a\nfilter coefficient search for a fixed controller, and a controller search for\nfixed multipliers."}
{"id": "2510.21421", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.21421", "abs": "https://arxiv.org/abs/2510.21421", "authors": ["Haruya Shimizu", "Masahiro Yukawa"], "title": "Plugging Weight-tying Nonnegative Neural Network into Proximal Splitting Method: Architecture for Guaranteeing Convergence to Optimal Point", "comment": "13 pages, 9 figures", "summary": "We propose a novel multi-layer neural network architecture that gives a\npromising neural network empowered optimization approach to the image\nrestoration problem. The proposed architecture is motivated by the recent study\nof monotone Lipschitz-gradient (MoL-Grad) denoiser (Yukawa and Yamada, 2025)\nwhich establishes an ``explainable'' plug-and-play (PnP) framework in the sense\nof disclosing the objective minimized. The architecture is derived from the\ngradient of a superposition of functions associated with each layer, having the\nweights in the encoder and decoder tied with each other. Convexity of the\npotential, and thus monotonicity of its gradient (denoiser), is ensured by\nrestricting ourselves to nonnegative weights. Unlike the previous PnP\napproaches with theoretical guarantees, the denoiser is free from constraints\non the Lipschitz constant of the denoiser. Our PnP algorithm employing the\nweight-tying nonnegative neural network converges to a minimizer of the\nobjective involving an ``implicit'' weakly convex regularizer induced by the\ndenoiser. The convergence analysis relies on an efficient technique to preserve\nthe overall convexity even in the ill-conditioned case where the loss function\nis not strongly convex. The simulation study shows the advantages of the\nLipschitz-constraint-free nature of the proposed denoiser in training time as\nwell as deblurring performance."}
{"id": "2510.21468", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.21468", "abs": "https://arxiv.org/abs/2510.21468", "authors": ["Emre Sahinoglu", "Youbang Sun", "Shahin Shahrampour"], "title": "Finite-Time Analysis of Stochastic Nonconvex Nonsmooth Optimization on the Riemannian Manifolds", "comment": "To Appear in NeurIPS 2025", "summary": "This work addresses the finite-time analysis of nonsmooth nonconvex\nstochastic optimization under Riemannian manifold constraints. We adapt the\nnotion of Goldstein stationarity to the Riemannian setting as a performance\nmetric for nonsmooth optimization on manifolds. We then propose a Riemannian\nOnline to NonConvex (RO2NC) algorithm, for which we establish the sample\ncomplexity of $O(\\epsilon^{-3}\\delta^{-1})$ in finding\n$(\\delta,\\epsilon)$-stationary points. This result is the first-ever\nfinite-time guarantee for fully nonsmooth, nonconvex optimization on manifolds\nand matches the optimal complexity in the Euclidean setting. When gradient\ninformation is unavailable, we develop a zeroth order version of RO2NC\nalgorithm (ZO-RO2NC), for which we establish the same sample complexity. The\nnumerical results support the theory and demonstrate the practical\neffectiveness of the algorithms."}
{"id": "2510.21490", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.21490", "abs": "https://arxiv.org/abs/2510.21490", "authors": ["Jared Miller", "Fabian Jakob", "Carsten Scherer", "Andrea Iannelli"], "title": "Analysis and Synthesis of Switched Optimization Algorithms", "comment": null, "summary": "Deployment of optimization algorithms on networked systems face challenges\nassociated with time delays and corruptions. One particular instance is the\npresence of time-varying delays arising from factors such as packet drops and\nirregular sampling. Fixed time delays can destabilize gradient descent\nalgorithms, and this degradation is exacerbated by time-varying delays. This\nwork concentrates on the analysis and creation of discrete-time optimization\nalgorithms with certified exponential convergence rates that are robust against\nswitched uncertainties between the optimizer and the gradient oracle. These\noptimization algorithms are implemented by a switch-scheduled output feedback\ncontrollers. Rate variation and sawtooth behavior (packet drops) in\ntime-varying delays can be imposed through constraining switching sequences.\nAnalysis is accomplished by bisection in the convergence rate to find\nZames-Falb filter coefficents. Synthesis is performed by alternating between a\nfilter coefficient search for a fixed controller, and a controller search for\nfixed multipliers."}
{"id": "2510.21607", "categories": ["math.OC", "cs.NA", "math.AP", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.21607", "abs": "https://arxiv.org/abs/2510.21607", "authors": ["Yuan Zhong"], "title": "Multilevel Picard scheme for solving high-dimensional drift control problems with state constraints", "comment": "108 pages, 3 figures", "summary": "Motivated by applications to the dynamic control of queueing networks, we\ndevelop a simulation-based scheme, the so-called multilevel Picard (MLP)\napproximation, for solving high-dimensional drift control problems whose states\nare constrained to stay within the nonnegative orthant, over a finite time\nhorizon. We prove that under suitable conditions, the MLP approximation\novercomes the curse of dimensionality in the following sense: To approximate\nthe value function and its gradient evaluated at a given time and state to\nwithin a prescribed accuracy $\\varepsilon$, the computational complexity grows\nat most polynomially in the problem dimension $d$ and $1/\\varepsilon$. To\nillustrate the effectiveness of the scheme, we carry out numerical experiments\nfor a class of test problems that are related to the dynamic scheduling problem\nof parallel server systems in heavy traffic, and demonstrate that the scheme is\ncomputationally feasible up to dimension at least $20$."}
{"id": "2510.21617", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.21617", "abs": "https://arxiv.org/abs/2510.21617", "authors": ["Alan Luner", "Benjamin Grimmer"], "title": "A Practical Adaptive Subgame Perfect Gradient Method", "comment": "26 pages, 9 figures", "summary": "We present a performant gradient method for smooth convex optimization,\ndrawing inspiration from several recent advances in the field. Our algorithm,\nthe Adaptive Subgame Perfect Gradient Method (ASPGM) is based on the notion of\nsubgame perfection, attaining a dynamic strengthening of minimax optimality. At\neach iteration, ASPGM makes a momentum-type update, optimized dynamically based\non a (limited) memory/bundle of past first-order information. ASPGM is\nlinesearch-free, parameter-free, and adaptive due to its use of recently\ndeveloped auto-conditioning, restarting, and preconditioning ideas. We show\nthat ASPGM is competitive with state-of-the-art L-BFGS methods on a wide range\nof smooth convex problems. Unlike quasi-Newton methods, however, our core\nalgorithm underlying ASPGM has strong, subgame perfect, non-asymptotic\nguarantees, providing certificates of solution quality, resulting in simple\nstopping criteria and restarting conditions."}
{"id": "2510.21650", "categories": ["math.OC", "q-fin.MF", "q-fin.PM", "49L20, 91G10, 49L25, 60H30"], "pdf": "https://arxiv.org/pdf/2510.21650", "abs": "https://arxiv.org/abs/2510.21650", "authors": ["Erhan Bayraktar", "Bingyan Han", "Jingjie Zhang"], "title": "Goal-based portfolio selection with fixed transaction costs", "comment": null, "summary": "We study a goal-based portfolio selection problem in which an investor aims\nto meet multiple financial goals, each with a specific deadline and target\namount. Trading the stock incurs a strictly positive transaction cost. Using\nthe stochastic Perron's method, we show that the value function is the unique\nviscosity solution to a system of quasi-variational inequalities. The existence\nof an optimal trading strategy and goal funding scheme is established.\nNumerical results reveal complex optimal trading regions and show that the\noptimal investment strategy differs substantially from the V-shaped strategy\nobserved in the frictionless case."}
{"id": "2510.21698", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.21698", "abs": "https://arxiv.org/abs/2510.21698", "authors": ["Daniel Bienstock", "Matias Villagra"], "title": "Advanced Cutting-Plane Algorithms for ACOPF", "comment": null, "summary": "We propose a disciplined, numerically stable, and scalable approach to SDP\nrelaxations of the ACOPF problem based on linear cutting-planes. Our method can\nbe warm-started and, owing to its linear nature, enables the computation of\ntight and accurate bounds for large-scale multi-period relaxations -- well\nbeyond what nonlinear convex solvers can achieve. Preliminary experiments show\npromising results when benchmarked against state-of-the-art bounds on PGLIB\ninstances."}
{"id": "2510.21612", "categories": ["eess.SY", "cs.IT", "cs.SY", "math.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2510.21612", "abs": "https://arxiv.org/abs/2510.21612", "authors": ["Yorie Nakahira", "Fangzhou Xiao", "Victoria Kostina", "John C. Doyle"], "title": "Rate-cost tradeoffs in continuous-time control with a biomolecular application", "comment": null, "summary": "This paper focuses on rate-limited control of the generalized\nOrnstein-Uhlenbeck process where the control action can be either\nmultiplicative or additive, and the noise variance can depend on the control\naction. We derive a lower bound on the data rate necessary to achieve the\ndesired control cost. The lower bound is attained with equality if the control\nis performed via an additive white Gaussian channel. The system model\napproximates the dynamics of a discrete-state molecular birth-death process,\nand the result has direct implications on the control of a biomolecular system\nvia chemical reactions, where the multiplicative control corresponds to the\ndegradation rate, the additive control corresponds to the production rate, and\nthe control objective is to decrease the fluctuations of the controlled\nmolecular species around their desired concentration levels."}
