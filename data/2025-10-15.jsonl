{"id": "2510.12136", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2510.12136", "abs": "https://arxiv.org/abs/2510.12136", "authors": ["Sarah Fields", "Norman Christ"], "title": "Nevanlinna-Pick interpolation from uncertain data", "comment": null, "summary": "The calculation of inclusive processes that involve the production of many\nparticles is a challenge for lattice QCD, a Euclidean-space method that is far\nremoved from real-time, multiparticle production. A new approach to this\nproblem based on Nevanlinna-Pick interpolation has been proposed by Bergamaschi\net al. Here we extend their method by exploring the propagation of the\nstatistical and systematic errors that accompany a lattice QCD calculation\nthrough this interpolation process. A simplified example of a multiparticle\nspectral function is studied with a focus on the possible applications of these\nmethods to the calculation of inclusive heavy-particle decays."}
{"id": "2510.12168", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2510.12168", "abs": "https://arxiv.org/abs/2510.12168", "authors": ["Yoshiaki Koma", "Miho Koma"], "title": "Finite-length flux tube in the dual Ginzburg-Landau theory on the dual lattice", "comment": "33 pages, 43 figures", "summary": "The dual Ginzburg-Landau (DGL) theory is one of the nonperturbative effective\nfield theories of QCD. The DGL theory describes the QCD vacuum as a dual\nsuperconductor and possesses electric flux-tube solutions via the dual Meissner\neffect, which applies to the quark confinement mechanism. We demonstrate a\npowerful numerical method for solving the field equations in the DGL theory\nwith U(1) dual gauge symmetry. An essential aspect of our method is to\nformulate the DGL theory on the dual lattice, which enables us to investigate\nany system composed of finite-length flux tubes in a systematic manner. Taking\nfull advantage of the dual lattice formulation, we investigate the\nfinite-length flux-tube solution corresponding to the quark-antiquark system in\ndetail, which exposes the significant terminal effects absent in the infinitely\nlong flux-tube solution. We also study the flux-tube interaction in the two-\nand multi-flux-tube systems, providing new insights into the nonperturbative\nproperties of QCD."}
{"id": "2510.12148", "categories": ["physics.ao-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12148", "abs": "https://arxiv.org/abs/2510.12148", "authors": ["Yuki Yasuda", "Ryo Onishi"], "title": "Probabilistic Super-Resolution for Urban Micrometeorology via a Schr√∂dinger Bridge", "comment": null, "summary": "This study employs a neural network that represents the solution to a\nSchr\\\"odinger bridge problem to perform super-resolution of 2-m temperature in\nan urban area. Schr\\\"odinger bridges generally describe transformations between\ntwo data distributions based on diffusion processes. We use a specific\nSchr\\\"odinger-bridge model (SM) that directly transforms low-resolution data\ninto high-resolution data, unlike denoising diffusion probabilistic models\n(simply, diffusion models; DMs) that generate high-resolution data from\nGaussian noise. Low-resolution and high-resolution data were obtained from\nseparate numerical simulations with a physics-based model under common initial\nand boundary conditions. Compared with a DM, the SM attains comparable accuracy\nat one-fifth the computational cost, requiring 50 neural-network evaluations\nper datum for the DM and only 10 for the SM. Furthermore, high-resolution\nsamples generated by the SM exhibit larger variance, implying superior\nuncertainty quantification relative to the DM. Owing to the reduced\ncomputational cost of the SM, our results suggest the feasibility of real-time\nensemble micrometeorological prediction using SM-based super-resolution."}
{"id": "2510.12139", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.12139", "abs": "https://arxiv.org/abs/2510.12139", "authors": ["Yanzhao Jia", "Zhaobo Wu", "Zheyi Cao", "Shihao Ji", "Xu Tianhao", "Zihui Song"], "title": "RAID-0e: A Resilient Striping Array Architecture for Balanced Performance and Availability", "comment": null, "summary": "This paper introduces a novel disk array architecture, designated RAID-0e\n(Resilient Striping Array), designed to superimpose a low-overhead fault\ntolerance layer upon traditional RAID 0 (striping). By employing a logically\nand physically separate parity domain to protect a primary data domain, RAID-0e\nmitigates the risk of array-wide data loss from common, non-catastrophic media\nfailures, such as isolated bad blocks, transient read errors, or sector-level\ncorruption. The architecture is engineered to preserve the intrinsic read\nperformance advantages of RAID 0 while significantly enhancing data\navailability and operational resilience. This document provides a comprehensive\nexposition of the architectural principles, operational workflows, performance\ncharacteristics, failure mode analysis, and security considerations of RAID-0e.\nIt is presented as an experimental yet pragmatic solution for environments\nseeking a new equilibrium between I/O performance, storage cost, and data\nresilience, particularly where full drive failure is a secondary concern to\nmedia degradation."}
{"id": "2510.11740", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.11740", "abs": "https://arxiv.org/abs/2510.11740", "authors": ["Yulin An", "Xueqi Zhao", "Enrique del Castillo"], "title": "Monitoring 3D Lattice Structures in Additive Manufacturing Using Topological Data Analysis", "comment": "22 pages, 13 figures, 12 tables", "summary": "We present a new method for the statistical process control of lattice\nstructures using tools from Topological Data Analysis. Motivated by\napplications in additive manufacturing, such as aerospace components and\nbiomedical implants, where hollow lattice geometries are critical, the proposed\nframework is based on monitoring the persistent homology properties of parts.\nSpecifically, we focus on homological features of dimensions zero and one,\ncorresponding to connected components and one-dimensional loops, to\ncharacterize and detect changes in the topology of lattice structures. A\nnonparametric hypothesis testing procedure and a control charting scheme are\nintroduced to monitor these features during production. Furthermore, we conduct\nextensive run-length analysis via various simulated but real-life\nlattice-structured parts. Our results demonstrate that persistent homology is\nwell-suited for detecting topological anomalies in complex geometries and\noffers a robust, intrinsically geometrical alternative to other SPC methods for\nmesh and point data."}
{"id": "2510.11728", "categories": ["cs.SI", "cs.AI", "68R10, 68T07", "G.2.2; H.2.8; I.2.6"], "pdf": "https://arxiv.org/pdf/2510.11728", "abs": "https://arxiv.org/abs/2510.11728", "authors": ["Bingqiao Gu", "Jiale Zeng", "Xingqin Qi", "Dong Li"], "title": "Modeling Hypergraph Using Large Language Models", "comment": "10 pages, 5 figures", "summary": "Due to the advantages of hypergraphs in modeling high-order relationships in\ncomplex systems, they have been applied to higher-order clustering, hypergraph\nneural networks and computer vision. These applications rely heavily on access\nto high-quality, large-scale real-world hypergraph data. Yet, compared to\ntraditional pairwise graphs, real hypergraph datasets remain scarce in both\nscale and diversity. This shortage significantly limits the development and\nevaluation of advanced hypergraph learning algorithms. Therefore, how to\nquickly generate large-scale hypergraphs that conform to the characteristics of\nreal networks is a crucial task that has not received sufficient attention.\nMotivated by recent advances in large language models (LLMs), particularly\ntheir capabilities in semantic reasoning, structured generation, and simulating\nhuman behavior, we investigate whether LLMs can facilitate hypergraph\ngeneration from a fundamentally new perspective. We introduce HyperLLM, a novel\nLLM-driven hypergraph generator that simulates the formation and evolution of\nhypergraphs through a multi-agent collaboration. The framework integrates\nprompts and structural feedback mechanisms to ensure that the generated\nhypergraphs reflect key real-world patterns. Extensive experiments across\ndiverse datasets demonstrate that HyperLLM achieves superior fidelity to\nstructural and temporal hypergraph patterns, while requiring minimal\nstatistical priors. Our findings suggest that LLM-based frameworks offer a\npromising new direction for hypergraph modeling."}
{"id": "2510.11831", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "math-ph", "math.MP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.11831", "abs": "https://arxiv.org/abs/2510.11831", "authors": ["Ben T. McDonough", "Marius Lemm", "Andrew Lucas"], "title": "Non-perturbatively slow spread of quantum correlations in non-resonant systems", "comment": null, "summary": "Strong disorder often has drastic consequences for quantum dynamics. This is\nbest illustrated by the phenomenon of Anderson localization in non-interacting\nsystems, where destructive quantum wave interference leads to the complete\nabsence of particle and information transport over macroscopic distances. In\nthis work, we investigate the extent to which strong disorder leads to provably\nslow dynamics in many-body quantum lattice models. We show that in any spatial\ndimension, strong disorder leads to a non-perturbatively small velocity for\nballistic information transport under unitary quantum dynamics, almost surely\nin the thermodynamic limit, in every many-body state. In these models, we also\nprove the existence of a \"prethermal many-body localized regime\", where\nentanglement spreads logarithmically slowly, up to non-perturbatively long time\nscales. More generally, these conclusions hold for all models corresponding to\nquantum perturbations to a classical Hamiltonian obeying a simple non-resonant\ncondition. Deterministic non-resonant models are found, including spin systems\nin strong incommensurate lattice potentials. Consequently, quantum dynamics in\nnon-resonant potentials is asymptotically easier to simulate on both classical\nor quantum computers, compared to a generic many-body system."}
{"id": "2510.12006", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12006", "abs": "https://arxiv.org/abs/2510.12006", "authors": ["Riku Yamamoto", "Sejun Park", "Zachary W. Riedel", "Phurba Sherpa", "Joe D. Thompson", "Filip Ronning", "Eric D. Bauer", "Adam P. Dioguardi", "Michihiro Hirata"], "title": "Evidence for easy-plane XY ferromagnetism in heavy-fermion quantum-critical CeRh6Ge4", "comment": null, "summary": "We report $^{73}$Ge nuclear quadrupole resonance (NQR) and magnetic resonance\n(NMR) spectroscopy in the heavy-fermion quantum-critical ferromagnet\nCeRh$_6$Ge$_4$. NQR and NMR spectral measurements at the two non-equivalent Ge\nsites reveal electric field gradient tensors and the directions of their\nprincipal axes relative to the hexagonal basal plane. The spin-lattice\nrelaxation rate $1/T_1$ experiments reveal a clear critical slowing down\napproaching the ferromagnetic transition. $1/T_1$ in the paramagnetic state is\nfound to be predominantly caused by fluctuating 4$f$-local moments. The Knight\nshift shows Curie-Weiss behavior at high temperature and a deviation from this\nbelow $T^\\ast$ $\\approx$ 25 K possibly due to a mixture of crystalline electric\nfield effects and Kondo screening. Order-parameter-like behavior of hyperfine\nfields at the Ge sites and ferromagnetic signal enhancement are observed in\nZeeman-perturbed NQR, with uniform ferromagnetic order and a small ordered\nmoment of $\\approx$ 0.26 $\\mu_B$/Ce confined within the $ab$-plane. The ordered\nmoment shows a notable in-plane magnetic stiffness against out-of-plane\nradiofrequency fields and has an (XY-type) in-plane isotropic nature. Our\nresults reveal a strong easy-plane anisotropy of 4$f$-electron moment and\nsuggest an involved interplay of hybridization and local moment physics in this\nquantum critical heavy-fermion ferromagnet."}
{"id": "2510.11848", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11848", "abs": "https://arxiv.org/abs/2510.11848", "authors": ["Efstratios Reppas", "Ali Wadi", "Brendan Gould", "Kyriakos G. Vamvoudakis"], "title": "Quantum Deception: Honey-X Deception using Quantum Games", "comment": "Submitted to 2026 American Control Conference (ACC), New Orleans, LA", "summary": "In this paper, we develop a framework for deception in quantum games,\nextending the Honey-X paradigm from classical zero-sum settings into the\nquantum domain. Building on a view of deception in classical games as\nmanipulation of a player's perception of the payoff matrix, we formalize\nquantum deception as controlled perturbations of the payoff Hamiltonian subject\nto a deception budget. We show that when victims are aware of possible\ndeception, their equilibrium strategies surprisingly coincide with those of\nnaive victims who fully trust the deceptive Hamiltonian. This equivalence\nallows us to cast quantum deception as a bilevel optimization problem, which\ncan be reformulated into a bilinear semidefinite program. To illustrate the\nframework, we present simulations on quantum versions of the Penny Flip game,\ndemonstrating how quantum strategy spaces and non-classical payoffs can amplify\nthe impact of deception relative to classical formulations."}
{"id": "2510.11727", "categories": ["cs.ET", "cond-mat.mtrl-sci", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.11727", "abs": "https://arxiv.org/abs/2510.11727", "authors": ["Benius Dunn", "Javier Meza-Arroyo", "Armi Tiihonen", "Mark Lee", "Julia W. P. Hsu"], "title": "Multi-objective Bayesian Optimization with Human-in-the-Loop for Flexible Neuromorphic Electronics Fabrication", "comment": null, "summary": "Neuromorphic computing hardware enables edge computing and can be implemented\nin flexible electronics for novel applications. Metal oxide materials are\npromising candidates for fabricating flexible neuromorphic electronics, but\nsuffer from processing constraints due to the incompatibilities between oxides\nand polymer substrates. In this work, we use photonic curing to fabricate\nflexible metal-insulator-metal capacitors with solution-processible aluminum\noxide dielectric tailored for neuromorphic applications. Because photonic\ncuring outcomes depend on many input parameters, identifying an optimal\nprocessing condition through a traditional grid-search approach is unfeasible.\nHere, we apply multi-objective Bayesian optimization (MOBO) to determine\nphotonic curing conditions that optimize the trade-off between desired\nelectrical properties of large capacitance-frequency dispersion and low leakage\ncurrent. Furthermore, we develop a human-in-the-loop (HITL) framework for\nincorporating failed experiments into the MOBO machine learning workflow,\ndemonstrating that this framework accelerates optimization by reducing the\nnumber of experimental rounds required. Once optimization is concluded, we\nanalyze different Pareto-optimal conditions to tune the dielectrics properties\nand provide insight into the importance of different inputs through Shapley\nAdditive exPlanations analysis. The demonstrated framework of combining MOBO\nwith HITL feedback can be adapted to a wide range of multi-objective\nexperimental problems that have interconnected inputs and high experimental\nfailure rates to generate usable results for machine learning models."}
{"id": "2510.12685", "categories": ["q-fin.CP"], "pdf": "https://arxiv.org/pdf/2510.12685", "abs": "https://arxiv.org/abs/2510.12685", "authors": ["Runyao Yu", "Ruochen Wu", "Yongsheng Han", "Jochen L. Cremer"], "title": "Orderbook Feature Learning and Asymmetric Generalization in Intraday Electricity Markets", "comment": "8 pages, 3 figures, 5 tables", "summary": "Accurate probabilistic forecasting of intraday electricity prices is critical\nfor market participants to inform trading decisions. Existing studies rely on\nspecific domain features, such as Volume-Weighted Average Price (VWAP) and the\nlast price. However, the rich information in the orderbook remains\nunderexplored. Furthermore, these approaches are often developed within a\nsingle country and product type, making it unclear whether the approaches are\ngeneralizable. In this paper, we extract 384 features from the orderbook and\nidentify a set of powerful features via feature selection. Based on selected\nfeatures, we present a comprehensive benchmark using classical statistical\nmodels, tree-based ensembles, and deep learning models across two countries\n(Germany and Austria) and two product types (60-min and 15-min). We further\nperform a systematic generalization study across countries and product types,\nfrom which we reveal an asymmetric generalization phenomenon."}
{"id": "2510.11737", "categories": ["cond-mat.stat-mech", "cs.IT", "math.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.11737", "abs": "https://arxiv.org/abs/2510.11737", "authors": ["Kentaro Imafuku"], "title": "Algorithmic Temperature Induced by Adopted Regular Universal Turing Machine", "comment": "12 pages, 2 figures", "summary": "We prove that an effective temperature naturally emerges from the algorithmic\nstructure of a regular universal Turing machine (UTM), without introducing any\nexternal physical parameter. In particular, the redundancy growth of the\nmachine's wrapper language induces a Boltzmann--like exponential weighting over\nprogram lengths, yielding a canonical ensemble interpretation of algorithmic\nprobability. This establishes a formal bridge between algorithmic information\ntheory and statistical mechanics, in which the adopted UTM determines the\nintrinsic ``algorithmic temperature.'' We further show that this temperature\napproaches its maximal limit under the universal mixture (Solomonoff\ndistribution), and discuss its epistemic meaning as the resolution level of an\nobserver."}
{"id": "2510.11808", "categories": ["math.NA", "cs.NA", "65M22, 35L65, 35Q31"], "pdf": "https://arxiv.org/pdf/2510.11808", "abs": "https://arxiv.org/abs/2510.11808", "authors": ["Jordan Hoffart", "Matthias Maier", "John N. Shadid", "Ignacio Tomas"], "title": "Structure-preserving finite-element approximations of the magnetic Euler-Poisson equations", "comment": "28 pages, 4 figures", "summary": "We develop a structure-preserving numerical discretization for the\nelectrostatic Euler-Poisson equations with a constant magnetic field. The\nscheme preserves positivity of the density, positivity of the internal energy\nand a minimum principle of the specific entropy, as well as global properties,\nsuch as total energy balance. The scheme uses an operator splitting approach\ncomposed of two subsystems: the compressible Euler equations of gas dynamics\nand a source system. The source system couples the electrostatic potential,\nmomentum, and Lorentz force, thus incorporating electrostatic plasma and\ncyclotron motions. Because of the high-frequency phenomena it describes, the\nsource system is discretized with an implicit time-stepping scheme. We use a\nPDE Schur complement approach for the numerical approximation of the solution\nof the source system. Therefore, it reduces to a single non-symmetric\nPoisson-like problem that is solved for each time step.\n  Our focus with the present work is on the efficient solution of problems\nclose to the magnetic-drift limit. Such asymptotic limit is characterized by\nthe co-existence of slowly moving, smooth flows with very high-frequency\noscillations, spanning timescales that differ by over 10 orders of magnitude,\nmaking their numerical solution quite challenging.\n  We illustrate the capability of the scheme by computing a diocotron\ninstability and present growth rates that compare favorably with existing\nanalytical results. The model, though a simplified version of the\nEuler-Maxwell's system, represents a stepping stone toward electromagnetic\nsolvers that are capable of working in the electrostatic and magnetic-drift\nlimits, as well as the hydrodynamic regime."}
{"id": "2510.11843", "categories": ["math.OC", "cs.MA", "math.PR"], "pdf": "https://arxiv.org/pdf/2510.11843", "abs": "https://arxiv.org/abs/2510.11843", "authors": ["Anran Hu", "Zijiu Lyu"], "title": "Mean-Field Games with Constraints", "comment": null, "summary": "This paper introduces a framework of Constrained Mean-Field Games (CMFGs),\nwhere each agent solves a constrained Markov decision process (CMDP). This\nformulation captures scenarios in which agents' strategies are subject to\nfeasibility, safety, or regulatory restrictions, thereby extending the scope of\nclassical mean field game (MFG) models. We first establish the existence of\nCMFG equilibria under a strict feasibility assumption, and we further show\nuniqueness under a classical monotonicity condition. To compute equilibria, we\ndevelop Constrained Mean-Field Occupation Measure Optimization (CMFOMO), an\noptimization-based scheme that parameterizes occupation measures and shows that\nfinding CMFG equilibria is equivalent to solving a single optimization problem\nwith convex constraints and bounded variables. CMFOMO does not rely on\nuniqueness of the equilibria and can approximate all equilibria with arbitrary\naccuracy. We further prove that CMFG equilibria induce $O(1 / \\sqrt{N})$-Nash\nequilibria in the associated constrained $N$-player games, thereby extending\nthe classical justification of MFGs as approximations for large but finite\nsystems. Numerical experiments on a modified Susceptible-Infected-Susceptible\n(SIS) epidemic model with various constraints illustrate the effectiveness and\nflexibility of the framework."}
{"id": "2510.11848", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.11848", "abs": "https://arxiv.org/abs/2510.11848", "authors": ["Efstratios Reppas", "Ali Wadi", "Brendan Gould", "Kyriakos G. Vamvoudakis"], "title": "Quantum Deception: Honey-X Deception using Quantum Games", "comment": "Submitted to 2026 American Control Conference (ACC), New Orleans, LA", "summary": "In this paper, we develop a framework for deception in quantum games,\nextending the Honey-X paradigm from classical zero-sum settings into the\nquantum domain. Building on a view of deception in classical games as\nmanipulation of a player's perception of the payoff matrix, we formalize\nquantum deception as controlled perturbations of the payoff Hamiltonian subject\nto a deception budget. We show that when victims are aware of possible\ndeception, their equilibrium strategies surprisingly coincide with those of\nnaive victims who fully trust the deceptive Hamiltonian. This equivalence\nallows us to cast quantum deception as a bilevel optimization problem, which\ncan be reformulated into a bilinear semidefinite program. To illustrate the\nframework, we present simulations on quantum versions of the Penny Flip game,\ndemonstrating how quantum strategy spaces and non-classical payoffs can amplify\nthe impact of deception relative to classical formulations."}
{"id": "2510.11930", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2510.11930", "abs": "https://arxiv.org/abs/2510.11930", "authors": ["Kazi Tahsin Mahmood", "M. Arif Hasan"], "title": "Topological Vibration Analysis of Elastic Lattices via Bloch Sphere Mapping", "comment": null, "summary": "Mechanical lattices support topological wave phenomena governed by geometric\nphases. We develop a compact Hilbert space description for one-dimensional\nelastic chains, expressing intra-cell motion as a normalized superposition of\northogonal eigenstates and tracking complex amplitudes as trajectories on a\nBloch sphere. For diatomic lattices, this framework makes inversion symmetry\nprotection explicit: the relative phase between in-phase and out-of-phase modes\nis piecewise locked, and the Zak phase is quantized with band-dependent jumps\nat symmetry points. Extending the analysis to triatomic lattices shows that\nrestoring inversion retains quantization, whereas breaking it dequantizes the\ngeometric phase while leaving the spectral origin invariant. Viewing\nnorm-preserving transformations of the modal coefficient pair as Bloch sphere\nrotations, we demonstrate classical analogues of single-qubit logic gates. A\npi-phase rotation about a transverse axis swaps the modal poles, and a\nlongitudinal-axis phase flip maps balanced superpositions to their conjugates.\nThese gate-like operations are realized by controlled evolution across\nwavenumber space and can be driven or reprogrammed through spatiotemporal\nstiffness modulation. Introducing space-time modulation hybridizes carrier and\nsideband harmonics, producing continuous phase winding and open-path geometric\nphases accumulated along the Floquet trajectory. Across static and modulated\nregimes, the framework unifies algebraic and geometric viewpoints, remains\nrobust to gauge and basis choices, and operates directly on amplitude-phase\ndata. The results clarify how symmetry, modulation, and topology jointly govern\ndispersion, modal mixing, and phase accumulation, providing tools to analyze\nand design vibration and acoustic functionalities in engineered structures."}
{"id": "2510.12412", "categories": ["math.ST", "stat.TH", "62E10"], "pdf": "https://arxiv.org/pdf/2510.12412", "abs": "https://arxiv.org/abs/2510.12412", "authors": ["Sarah Lumpp", "Mathias Drton"], "title": "On weak convergence of Gaussian conditional distributions", "comment": "7 pages, 6 pages of appendix", "summary": "Weak convergence of joint distributions generally does not imply convergence\nof conditional distributions. In particular, conditional distributions need not\nconverge when joint Gaussian distributions converge to a singular Gaussian\nlimit. Algebraically, this is due to the fact that at singular covariance\nmatrices, Schur complements are not continuous functions of the matrix entries.\nOur results lay out special conditions under which convergence of Gaussian\nconditional distributions nevertheless occurs, and we exemplify how this allows\none to reason about conditional independence in a new class of graphical\nmodels."}
{"id": "2510.12189", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2510.12189", "abs": "https://arxiv.org/abs/2510.12189", "authors": ["Ryuji Hashimoto", "Takehiro Takayanagi", "Masahiro Suzuki", "Kiyoshi Izumi"], "title": "Agent-Based Simulation of a Financial Market with Large Language Models", "comment": null, "summary": "In real-world stock markets, certain chart patterns -- such as price declines\nnear historical highs -- cannot be fully explained by fundamentals alone. These\nphenomena suggest the presence of path dependence in price formation, where\ninvestor decisions are influenced not only by current market conditions but\nalso by the trajectory of prices leading up to the present. Path dependence has\ndrawn attention in behavioral finance as a key mechanism behind such anomalies.\nOne plausible driver of path dependence is human loss aversion, anchored to\nindividual reference points like purchase prices or past peaks, which vary with\npersonal context. However, capturing such subtle behavioral tendencies in\ntraditional agent-based market simulations has remained a challenge. We propose\nthe Fundamental-Chartist-LLM-Agent (FCLAgent), which uses large language models\n(LLMs) to emulate human-like trading decisions. In this framework, (1) buy/sell\ndecisions are made by LLMs based on individual situations, while (2) order\nprice and volume follow standard rule-based methods. Simulations show that\nFCLAgents reproduce path-dependent patterns that conventional agents fail to\ncapture. Furthermore, an analysis of FCLAgents' behavior reveals that the\nreference points guiding loss aversion vary with market trajectories,\nhighlighting the potential of LLM-based agents to model nuanced investor\nbehavior."}
{"id": "2510.11844", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.11844", "abs": "https://arxiv.org/abs/2510.11844", "authors": ["Mingao Yuan", "Feng Yu"], "title": "Hypothesis testing for the dimension of random geometric graph", "comment": null, "summary": "Random geometric graphs (RGGs) offer a powerful tool for analyzing the\ngeometric and dependence structures in real-world networks. For example, it has\nbeen observed that RGGs are a good model for protein-protein interaction\nnetworks. In RGGs, nodes are randomly distributed over an $m$-dimensional\nmetric space, and edges connect the nodes if and only if their distance is less\nthan some threshold. When fitting RGGs to real-world networks, the first step\nis probably to input or estimate the dimension $m$. However, it is not clear\nwhether the prespecified dimension is equal to the true dimension. In this\npaper, we investigate this problem using hypothesis testing. Under the null\nhypothesis, the dimension is equal to a specific value, while the alternative\nhypothesis asserts the dimension is not equal to that value. We propose the\nfirst statistical test. Under the null hypothesis, the proposed test statistic\nconverges in law to the standard normal distribution, and under the alternative\nhypothesis, the test statistic is unbounded in probability. We derive the\nasymptotic distribution by leveraging the asymptotic theory of degenerate\nU-statistics with kernel function dependent on the number of nodes. This\napproach differs significantly from prevailing methods used in network\nhypothesis testing problems. Moreover, we also propose an efficient approach to\ncompute the test statistic based on the adjacency matrix. Simulation studies\nshow that the proposed test performs well. We also apply the proposed test to\nmultiple real-world networks to test their dimensions."}
{"id": "2510.11739", "categories": ["cs.SI", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.11739", "abs": "https://arxiv.org/abs/2510.11739", "authors": ["Muhammad Hamza", "Rizwan Jafar"], "title": "Celebrity Profiling on Short Urdu Text using Twitter Followers' Feed", "comment": null, "summary": "Social media has become an essential part of the digital age, serving as a\nplatform for communication, interaction, and information sharing. Celebrities\nare among the most active users and often reveal aspects of their personal and\nprofessional lives through online posts. Platforms such as Twitter provide an\nopportunity to analyze language and behavior for understanding demographic and\nsocial patterns. Since followers frequently share linguistic traits and\ninterests with the celebrities they follow, textual data from followers can be\nused to predict celebrity demographics. However, most existing research in this\nfield has focused on English and other high-resource languages, leaving Urdu\nlargely unexplored.\n  This study applies modern machine learning and deep learning techniques to\nthe problem of celebrity profiling in Urdu. A dataset of short Urdu tweets from\nfollowers of subcontinent celebrities was collected and preprocessed. Multiple\nalgorithms were trained and compared, including Logistic Regression, Support\nVector Machines, Random Forests, Convolutional Neural Networks, and Long\nShort-Term Memory networks. The models were evaluated using accuracy,\nprecision, recall, F1-score, and cumulative rank (cRank). The best performance\nwas achieved for gender prediction with a cRank of 0.65 and an accuracy of\n0.65, followed by moderate results for age, profession, and fame prediction.\nThese results demonstrate that follower-based linguistic features can be\neffectively leveraged using machine learning and neural approaches for\ndemographic prediction in Urdu, a low-resource language."}
{"id": "2510.12286", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.12286", "abs": "https://arxiv.org/abs/2510.12286", "authors": ["Stefano Gagliani", "Feliciano Giuseppe Pacifico", "Lorenzo Chicchi", "Duccio Fanelli", "Diego Febbe", "Lorenzo Buffoni", "Raffaele Marino"], "title": "Train Stochastic Non Linear Coupled ODEs to Classify and Generate", "comment": null, "summary": "A general class of dynamical systems which can be trained to operate in\nclassification and generation modes are introduced. A procedure is proposed to\nplant asymptotic stationary attractors of the deterministic model. Optimizing\nthe dynamical system amounts to shaping the architecture of inter-nodes\nconnection to steer the evolution towards the assigned equilibrium, as a\nfunction of the class to which the item - supplied as an initial condition -\nbelongs to. Under the stochastic perspective, point attractors are turned into\nprobability distributions, made analytically accessible via the linear noise\napproximation. The addition of noise proves beneficial to oppose adversarial\nattacks, a property that gets engraved into the trained adjacency matrix and\ntherefore also inherited by the deterministic counterpart of the optimized\nstochastic model. By providing samples from the target distribution as an input\nto a feedforward neural network (or even to a dynamical model of the same\ntypology of the adopted for classification purposes), yields a fully generative\nscheme. Conditional generation is also possible by merging classification and\ngeneration modalities. Automatic disentanglement of isolated key features is\nfinally proven."}
{"id": "2510.12009", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2510.12009", "abs": "https://arxiv.org/abs/2510.12009", "authors": ["Zhehao Ge", "Conor Smith", "Zehao He", "Yubo Yang", "Qize Li", "Ziyu Xiang", "Jianghan Xiao", "Wenjie Zhou", "Salman Kahn", "Melike Erdi", "Rounak Banerjee", "Takashi Taniguchi", "Kenji Watanabe", "Seth Ariel Tongay", "Miguel A. Morales", "Shiwei Zhang", "Feng Wang", "Michael F. Crommie"], "title": "Visualizing the Impact of Quenched Disorder on 2D Electron Wigner Solids", "comment": null, "summary": "Electron Wigner solids (WSs)1-12 provide an ideal system for understanding\nthe competing effects of electron-electron and electron-disorder interactions,\na central unsolved problem in condensed matter physics. Progress in this topic\nhas been limited by a lack of single-defect-resolved experimental measurements\nas well as accurate theoretical tools to enable realistic experiment-theory\ncomparison. Here we overcome these limitations by combining atomically-resolved\nscanning tunneling microscopy (STM) with quantum Monte Carlo (QMC) simulation\nof disordered 2D electron WSs. STM was used to image the electron density\n($n_e$) dependent evolution of electron WSs in gate-tunable bilayer MoSe$_2$\ndevices with varying long-range ($n_\\mathrm{LR}$) and short-range\n($n_\\mathrm{SR}$) disorder densities. These images were compared to QMC\nsimulations using realistic disorder maps extracted from experiment, thus\nallowing the roles of different disorder types to be disentangled. We identify\ntwo distinct physical regimes for disordered electron WSs that depend on the\nmagnitude of $n_\\mathrm{SR}$. For $n_\\mathrm{SR} \\lesssim n_e$ the WS behavior\nis dominated by long-range disorder and features extensive mixed solid-liquid\nphases, a new type of re-entrant melting-crystallization, and prominent Friedel\noscillations. In contrast, when $n_\\mathrm{SR} \\gg n_e$ these features are\nsuppressed and a more robust amorphous WS phase emerges that persists to higher\n$n_e$, highlighting the importance of short-range disorder in this regime. Our\nwork establishes a new framework for studying disordered quantum solids via a\ncombined experimental-theoretical approach."}
{"id": "2510.12205", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12205", "abs": "https://arxiv.org/abs/2510.12205", "authors": ["Himel Ghosh", "Sayak Chatterjee", "Antik Ganguly", "Shreetama Karmakar", "Koushik Sarkar"], "title": "Sleepy Chauffeur Detection and Alert Techniques for Road Safety", "comment": "8 pages, 5 figures, International Journal on Recent Innovation in\n  Microelectronics and Microcontrollers Applications Vol. 1, Issue 1 - 2018", "summary": "The most startling of the contemporary problems is the sleepiness of\nchauffeur which causes lots of car accidents. Prevention of those impending\naccidents by detecting and alerting the sleepy chauffeur is vital, otherwise\nthat would lead to loss of lives and various traumas along with severe\ninjuries. The slumber or sleep may be caused by huge stress, pressure,\nrelentless work load or alcoholism, for which sleep deprivation occurs and the\nchauffeur while driving gets drowsy. So far, considerable amount of systems has\nbeen developed to detect drowsiness of drivers, most of which mainly depend on\nimage processing algorithms using cameras. Some of them also incorporate\nartificial intelligence and machine learning based algorithms. This paper\npresents a review of the existing systems and also proposes an easy and cheap\nsystem using sensors and Arduino, capable of detecting sleepiness and generates\nsiren alarm and send alert message to take precautionary measures."}
{"id": "2510.11730", "categories": ["cs.ET", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2510.11730", "abs": "https://arxiv.org/abs/2510.11730", "authors": ["Connor G. McMahan", "Gavin Chang", "Raymond Nguyen", "Souren Soukiazian", "David A. Smith", "Tobias Schaedler", "David Shahan"], "title": "Wireless Sensing of Temperature, Strain and Crack Growth in 3D-Printed Metal Structures via Magnetoelastic and Thermomagnetic Inclusions", "comment": "16 pages, 9 figures", "summary": "In this study, we demonstrate the first realization of wireless strain and\ntemperature sensing within 3D-printed metallic structures using standard\nelectromagnetic inspection hardware. This establishes a path toward need-based\nparts maintenance driven by accurate damage assessments instead of relying on\nregularly scheduled maintenance teardowns, extending the service intervals of\nstructures operating in harsh environments. To this end, we encapsulate\nmagnetoelastic and thermomagnetic materials inside microtubes and embed the\nsensing elements during additive manufacturing. Mechanical and thermal stimuli\naffect the magnetic permeability of the embedded materials, which modulates the\nimpedance of a coil placed on or near the surface of the printed part. We\ndemonstrate strain sensing accurate to +/-27x10-6 over at least a 6x10-4 strain\nrange, and temperature sensing accurate to +/-0.75oC over a 70oC range, both to\na 95% confidence interval. We highlight these sensors' capabilities by\ndetecting the onset of plasticity and fatigue-driven crack growth thousands of\ncycles before critical failure. This extends non-destructive eddy-current\ndamage detection to accurate, real-time strain and temperature monitoring\nwithin metallic structures."}
{"id": "2510.11747", "categories": ["cond-mat.stat-mech", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.11747", "abs": "https://arxiv.org/abs/2510.11747", "authors": ["Marco Bianucci", "Mauro Bologna", "Daniele Lagomarsino-Oneto", "Riccardo Mannella"], "title": "Universal behaviors of the multi-time correlation functions of random processes with renewal: the step noise case (the random velocity of a L√©vy walk)", "comment": "67 pages, 22 Figures", "summary": "Stochastic processes with renewal properties are powerful tools for modeling\nsystems where memory effects and long-time correlations play a significant\nrole. In this work, we study a broad class of renewal processes where a\nvariable's value changes according to a prescribed Probability Density Function\n(PDF), $p(\\xi)$, after random waiting times $\\theta$. This model is relevant\nacross many fields, including classical chaos, nonlinear hydrodynamics, quantum\ndots, cold atom dynamics, biological motion, foraging, and finance. We derive a\ngeneral analytical expression for the $n$-time correlation function by\naveraging over process realizations. Our analysis identifies the conditions for\nstationarity, aging, and long-range correlations based on the waiting time and\njump distributions. Among the many consequences of our analysis, two new key\nresults emerge. First, for Poissonian waiting times, the correlation function\nquickly approaches that of telegraphic noise. Second, for power-law waiting\ntimes with $\\mu>2$, , \\emph{any $n$-time correlation function asymptotically\nreduces to the two-time correlation evaluated at the earliest and latest time\npoints}. This second result reveals a universal long-time behavior where the\nsystem's full statistical structure becomes effectively two-time reducible.\nFurthermore, if the jump PDF $p(\\xi)$ has fat tails, this convergence becomes\nindependent of the waiting time PDF and is significantly accelerated, requiring\nonly modest increases in either the number of realizations or the trajectory\nlengths. Building upon earlier work that established the universality of the\ntwo-point correlation function (i.e., a unique formal expression depending\nsolely on the variance of $\\xi$ and on the waiting-time PDF), the present study\nextends that universality to the full statistical description of a broad class\nof renewal-type stochastic processes."}
{"id": "2510.11949", "categories": ["math.NA", "cs.NA", "65T50, 68U10, 90C10"], "pdf": "https://arxiv.org/pdf/2510.11949", "abs": "https://arxiv.org/abs/2510.11949", "authors": ["Howard W Levinson", "Isaac Viviano"], "title": "Recovery of Integer Images from Limited DFT Measurements with Lattice Methods", "comment": "50 pages, 13 figures, 4 tables", "summary": "Exact reconstruction of an image from measurements of its Discrete Fourier\nTransform (DFT) typically requires all DFT coefficients to be available.\nHowever, incorporating the prior assumption that the image contains only\ninteger values enables unique recovery from a limited subset of DFT\ncoefficients. This paper develops both theoretical and algorithmic foundations\nfor this problem. We use algebraic properties of the DFT to define a reduction\nfrom two-dimensional recovery to several well-chosen one-dimensional\nrecoveries. Our reduction framework characterizes the minimum number and\nlocation of DFT coefficients that must be sampled to guarantee unique\nreconstruction of an integer-valued image. Algorithmically, we develop\nreconstruction procedures which use dynamic programming to efficiently recover\nan integer signal or image from its minimal set of DFT measurements. While the\nnew inversion algorithms still involve NP-hard subproblems, we demonstrate how\nthe divide-and-conquer approach drastically reduces the associated search\nspace. To solve the NP-hard subproblems, we employ a lattice-based framework\nwhich leverages the LLL approximation algorithm to make the algorithms fast and\npractical. We provide an analysis of the lattice method, suggesting approximate\nparameter choices to ensure correct inversion. Numerical results for the\nalgorithms support the parameter analysis and demonstrate successful recovery\nof large integer images."}
{"id": "2510.11990", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.11990", "abs": "https://arxiv.org/abs/2510.11990", "authors": ["Cody Melcher", "Afrooz Jalilzadeh", "Erfan Yazdandoost Hamedani"], "title": "Linear Convergence of a Unified Primal--Dual Algorithm for Convex--Concave Saddle Point Problems with Quadratic Growth", "comment": null, "summary": "In this paper, we study saddle point (SP) problems, focusing on\nconvex-concave optimization involving functions that satisfy either two-sided\nquadratic functional growth (QFG) or two-sided quadratic gradient growth\n(QGG)--novel conditions tailored specifically for SP problems as extensions of\nquadratic growth conditions in minimization. These conditions relax the\ntraditional requirement of strong convexity-strong concavity, thereby\nencompassing a broader class of problems. We propose a generalized accelerated\nprimal-dual (GAPD) algorithm to solve SP problems with non-bilinear objective\nfunctions, unifying and extending existing methods. We prove that our method\nachieves a linear convergence rate under these relaxed conditions.\nAdditionally, we provide examples of structured SP problems that satisfy either\ntwo-sided QFG or QGG, demonstrating the practical applicability and relevance\nof our approach."}
{"id": "2510.12205", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12205", "abs": "https://arxiv.org/abs/2510.12205", "authors": ["Himel Ghosh", "Sayak Chatterjee", "Antik Ganguly", "Shreetama Karmakar", "Koushik Sarkar"], "title": "Sleepy Chauffeur Detection and Alert Techniques for Road Safety", "comment": "8 pages, 5 figures, International Journal on Recent Innovation in\n  Microelectronics and Microcontrollers Applications Vol. 1, Issue 1 - 2018", "summary": "The most startling of the contemporary problems is the sleepiness of\nchauffeur which causes lots of car accidents. Prevention of those impending\naccidents by detecting and alerting the sleepy chauffeur is vital, otherwise\nthat would lead to loss of lives and various traumas along with severe\ninjuries. The slumber or sleep may be caused by huge stress, pressure,\nrelentless work load or alcoholism, for which sleep deprivation occurs and the\nchauffeur while driving gets drowsy. So far, considerable amount of systems has\nbeen developed to detect drowsiness of drivers, most of which mainly depend on\nimage processing algorithms using cameras. Some of them also incorporate\nartificial intelligence and machine learning based algorithms. This paper\npresents a review of the existing systems and also proposes an easy and cheap\nsystem using sensors and Arduino, capable of detecting sleepiness and generates\nsiren alarm and send alert message to take precautionary measures."}
{"id": "2510.12227", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2510.12227", "abs": "https://arxiv.org/abs/2510.12227", "authors": ["Roberto Flores", "Jerome Daquin", "Mauro Pontani", "Hadi Susanto", "Elena Fantino"], "title": "Uncontrolled geostationary satellites: mapping periodic transitions to chaos with Lagrangian Descriptors", "comment": null, "summary": "Uncontrolled geostationary satellites abandoned near an unstable equilibrium\npoint of the equator experience irregular transitions between dynamical states\n(continuous circulation, long and short libration). They are caused by the\ninteraction between the longitudinal dynamics, governed by the tesseral\nharmonics of the geopotential, and the orbital precession forced by Earth's\noblateness and lunisolar perturbations. The transitions are extremely sensitive\nto small perturbations, making the long-term evolution unpredictable. Recently,\na Monte Carlo analysis of trajectories starting in the immediate vicinity of\nthe 165 degrees E unstable equilibrium point, revealed that the evolution to\nchaos is not gradual. It occurs via sudden episodes of disorder at specific\npoints of the precession cycle, when the orbital inclination is minimal. Due to\nthe high cost of the statistical analysis, the results were limited to a single\ninitial longitude. This paper applies modified versions of the diameter\nLagrangian descriptor to reduce the computational burden. This enables mapping\nthe dynamical behavior over the complete range of longitudes where transitions\nbetween modes of motion are possible, considering both unstable equilibrium\npoints (165 degrees E and 15 degrees W). It is found that the episodes of chaos\nremain linked to the orbital inclination cycle, but their timing depends on the\ninitial spacecraft longitude. As the initial position moves farther away from\nthe unstable point, the transitions take place at higher values of the orbital\ninclination. The longitudes where the transitions occur at maximum inclination\ncorrespond to the boundaries of the chaotic region."}
{"id": "2510.12442", "categories": ["math.ST", "stat.TH", "62B10, 62G05, 94A17"], "pdf": "https://arxiv.org/pdf/2510.12442", "abs": "https://arxiv.org/abs/2510.12442", "authors": ["Siddhartha Chakraborty", "Asok K. Nanda"], "title": "On estimation of weighted cumulative residual Tsallis entropy", "comment": "23 pages", "summary": "Recently, weighted cumulative residual Tsallis entropy has been introduced in\nthe literature as a generalization of weighted cumulative residual entropy. We\nstudy some new properties of weighted cumulative residual Tsallis entropy\nmeasure. Next, we propose some non-parametric estimators of this measure.\nAsymptotic properties of these estimators are discussed. Performance of these\nestimators are compared by mean squared error. Non-parametric estimators for\nweighted cumulative residual entropy measure are also discussed. Two uniformity\ntests are proposed based on an estimator of these two measures and power of the\ntests are compared with some popular tests. The tests perform reasonably well."}
{"id": "2510.12342", "categories": ["nlin.AO", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.12342", "abs": "https://arxiv.org/abs/2510.12342", "authors": ["Henry Irvine", "Georg A. Gottwald"], "title": "Finte-size induced random switching of chimeras in a deterministic two-population Kuramoto-Sakaguchi model", "comment": null, "summary": "The two-population Kuramoto-Sakaguchi model for interacting populations of\nphase oscillators exhibits chimera states whereby one population is\nsynchronised and the other is desynchronised. Which of the two populations is\nsynchronised depends on the initial conditions. We show that this deterministic\nmodel exhibits random switches of their chimera states, alternating between\nwhich of the two populations is synchronised and which is not. We show that\nthese random switches are induced by the finite size of the network. We provide\nnumerical evidence that the switches are governed by a Poisson process and that\nthe time between switches grows exponentially with the system size, rendering\nswitches unobservable for all practical purposes in sufficiently large\nnetworks. We develop a reduced stochastic model for the synchronised\npopulation, based on a central limit theorem controlling the collective effect\nof the desynchronised population on the synchronised one, and show that this\nstochastic model well reproduces the statistical behaviour of the full\ndeterministic model. We further determine critical fluctuation sizes capable of\ninducing switches and provide estimates for the mean switching times from an\nassociated Kramers problem."}
{"id": "2510.11876", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.11876", "abs": "https://arxiv.org/abs/2510.11876", "authors": ["J. M. Nield", "M. C. Baddock", "G. F. S. Wiggs", "J. Best", "K. T. Christensen", "P. Delorme", "A. Valdez", "N. R. Bristow", "M. H. T. Hipondoka", "D. P. Goss", "N. S. Wallum", "P. Claudin"], "title": "Quantifying the form-flow-saltation dynamics of aeolian sand ripples", "comment": null, "summary": "Ripples are the most fundamental and ubiquitous aeolian bedforms formed on\nsandy surfaces, but their small size and fast response times make them\ninherently difficult to measure. However, these attributes also make ripples\nexcellent flow indicators, and they have been used extensively in planetary\nlocations for this purpose. Here, we use terrestrial laser scanning to measure\nripple morphometry and celerity coincidently, as well as saltation height above\nrippled surfaces. We find that although ripple height and wavelength respond\nlinearly to increased shear velocity, under strong winds ripple celerity\nexhibits a non-linear increase. This relationship at high wind speeds is also\nreflected in the response of aerodynamic roughness and saltation dynamics, with\na greater maximum saltation height present over ripple lee slopes. Importantly,\nwhen using ripple patterns as indicators of flow conditions, celerity or height\nshould be used in preference to wavelength as their dynamics respond faster to\nchanging wind speed. In planetary and stratigraphic settings where measuring\ncelerity is not possible, wavelength should be considered as indicative of\nconsistent wind conditions rather than the full range of sand transporting wind\nspeeds."}
{"id": "2510.11983", "categories": ["physics.soc-ph", "math.DS"], "pdf": "https://arxiv.org/pdf/2510.11983", "abs": "https://arxiv.org/abs/2510.11983", "authors": ["David Sabin-Miller", "Christopher Harding"], "title": "Data-Driven Modeling of U.S. Ideological Dynamics", "comment": "14 pages, 12 figures", "summary": "The dynamics of political opinion are a critical component of modern society\nwith large-scale implications for the evolution of intra- and international\npolitical discourse and policy. Here we utilize recent high-resolution survey\ndata to quantitatively capture leading-order psychological and\ninformation-environmental patterns. We then inform simulations of a theoretical\ndynamical framework with several different models for how populations' ideology\nevolves over time, including a model which reproduces current macro-scale\nideological distributions given the empirical micro-scale data gathered. This\neffort represents an attempt to discover true underlying trends of political\nreasoning in general audiences, and to extrapolate the long-term implications\nof those trends as they interact with the political exposure landscape.\nAccurate modeling of this ecosystem has the potential to predict catastrophic\noutcomes such as hyperpolarization, and to inform effective intervention\nstrategies aimed at preserving and rebuilding constructive political\ncommunication."}
{"id": "2510.12368", "categories": ["cs.CE", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12368", "abs": "https://arxiv.org/abs/2510.12368", "authors": ["Stefano Riva", "Carolina Introini", "Jos√® Nathan Kutz", "Antonio Cammi"], "title": "Constrained Sensing and Reliable State Estimation with Shallow Recurrent Decoders on a TRIGA Mark II Reactor", "comment": null, "summary": "Shallow Recurrent Decoder networks are a novel data-driven methodology able\nto provide accurate state estimation in engineering systems, such as nuclear\nreactors. This deep learning architecture is a robust technique designed to map\nthe temporal trajectories of a few sparse measures to the full state space,\nincluding unobservable fields, which is agnostic to sensor positions and able\nto handle noisy data through an ensemble strategy, leveraging the short\ntraining times and without the need for hyperparameter tuning. Following its\napplication to a novel reactor concept, this work investigates the performance\nof Shallow Recurrent Decoders when applied to a real system. The underlying\nmodel is represented by a fluid dynamics model of the TRIGA Mark II research\nreactor; the architecture will use both synthetic temperature data coming from\nthe numerical model and leveraging experimental temperature data recorded\nduring a previous campaign. The objective of this work is, therefore, two-fold:\n1) assessing if the architecture can reconstruct the full state of the system\n(temperature, velocity, pressure, turbulence quantities) given sparse data\nlocated in specific, low-dynamics channels and 2) assessing the correction\ncapabilities of the architecture (that is, given a discrepancy between model\nand data, assessing if sparse measurements can provide some correction to the\narchitecture output). As will be shown, the accurate reconstruction of every\ncharacteristic field, using both synthetic and experimental data, in real-time\nmakes this approach suitable for interpretable monitoring and control purposes\nin the framework of a reactor digital twin."}
{"id": "2510.11847", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML", "stat.TH", "G.3; I.5.1"], "pdf": "https://arxiv.org/pdf/2510.11847", "abs": "https://arxiv.org/abs/2510.11847", "authors": ["Sam Hawke", "Eric Zhang", "Jiawen Chen", "Didong Li"], "title": "Contrastive Dimension Reduction: A Systematic Review", "comment": null, "summary": "Contrastive dimension reduction (CDR) methods aim to extract signal unique to\nor enriched in a treatment (foreground) group relative to a control\n(background) group. This setting arises in many scientific domains, such as\ngenomics, imaging, and time series analysis, where traditional dimension\nreduction techniques such as Principal Component Analysis (PCA) may fail to\nisolate the signal of interest. In this review, we provide a systematic\noverview of existing CDR methods. We propose a pipeline for analyzing\ncase-control studies together with a taxonomy of CDR methods based on their\nassumptions, objectives, and mathematical formulations, unifying disparate\napproaches under a shared conceptual framework. We highlight key applications\nand challenges in existing CDR methods, and identify open questions and future\ndirections. By providing a clear framework for CDR and its applications, we aim\nto facilitate broader adoption and motivate further developments in this\nemerging field."}
{"id": "2510.11746", "categories": ["cs.SI", "cs.CL", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.11746", "abs": "https://arxiv.org/abs/2510.11746", "authors": ["Mykola Makhortykh", "Aytalina Kulichkina", "Kateryna Maikovska"], "title": "Evolution of wartime discourse on Telegram: A comparative study of Ukrainian and Russian policymakers' communication before and after Russia's full-scale invasion of Ukraine", "comment": "46 pages", "summary": "This study examines elite-driven political communication on Telegram during\nthe ongoing Russo-Ukrainian war, the first large-scale European war in the\nsocial media era. Using a unique dataset of Telegram public posts from\nUkrainian and Russian policymakers (2019-2024), we analyze changes in\ncommunication volume, thematic content, and actor engagement following Russia's\n2022 full-scale invasion. Our findings show a sharp increase in Telegram\nactivity after the invasion, particularly among ruling-party policymakers.\nUkrainian policymakers initially focused on war-related topics, but this\nemphasis declined over time In contrast, Russian policymakers largely avoided\nwar-related discussions, instead emphasizing unrelated topics, such as Western\ncrises, to distract public attention. We also identify differences in\ncommunication strategies between large and small parties, as well as individual\npolicymakers. Our findings shed light on how policymakers adapt to wartime\ncommunication challenges and offer critical insights into the dynamics of\nonline political discourse during times of war."}
{"id": "2510.12349", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.12349", "abs": "https://arxiv.org/abs/2510.12349", "authors": ["Igor N. Karnaukhov"], "title": "$Œ∑$-pairing in the model with two-particle hybridization of conduction and localized electrons", "comment": "8 pages, 2 figures", "summary": "Within the framework of a model, that takes into account two-particle\nhybridization of conduction and localized electrons, the effective interaction\nbetween conduction electrons is calculated. It is shown that this interaction\nis attractive when the energy of the localized electron corresponding to the\ntwo-particle state lies in the conduction band above the Fermi energy. The\nmagnitude of the attractive interaction is minimal for $\\eta$-paired states of\nconduction electrons. We generalize the original $\\eta$-pairing construction\nfor the proposed model and show that the superconducting state can indeed be\nrealized."}
{"id": "2510.12318", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12318", "abs": "https://arxiv.org/abs/2510.12318", "authors": ["P√•l Forr Austnes", "Matthieu Jacobs", "Lu Wang", "Mario Paolone"], "title": "Empowering Prosumers: Incentive Design for Local Electricity Markets Under Generalized Uncertainty and Grid Constraints", "comment": null, "summary": "Since the 1990s, widespread introduction of central (wholesale) electricity\nmarkets has been seen across multiple continents, driven by the search for\nefficient operation of the power grid through competition. The increase of\nrenewables has made significant impacts both on central electricity markets and\ndistribution-level grids as renewable power generation is often connected to\nthe latter. These stochastic renewable technologies have both advantages and\ndisadvantages. On one hand they offer very low marginal cost and carbon\nemissions, while on the other hand, their output is uncertain, requiring\nflexible backup power with high marginal cost. Flexibility from end-prosumers\nor smaller market participants is therefore seen as a key enabler of\nlarge-scale integration of renewables. However, current central electricity\nmarkets do not directly include uncertainty into the market clearing and do not\naccount for physical constraints of distribution grids. In this paper we\npropose a local electricity market framework based on probabilistic locational\nmarginal pricing, effectively accounting for uncertainties in production,\nconsumption and grid variables. The model includes a representation of the grid\nusing the lindistflow equations and accounts for the propagation of uncertainty\nusing general Polynomial Chaos (gPC). A two-stage convex model is proposed; in\nthe day-ahead stage, probability distributions of prices are calculated for\nevery timestep, where the expected values represent the day-ahead (spot)\nprices. In the real-time stage, uncertainties are realized (measured) and a\ntrivial calculation reveals the real-time price. Through four instructive\ncase-studies we highlight the effectiveness of the method to incentivize\nend-prosumers' participation in the market, while ensuring that their behavior\ndoes not have an adverse impact on the operation of the grid."}
{"id": "2510.12278", "categories": ["cs.ET", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.12278", "abs": "https://arxiv.org/abs/2510.12278", "authors": ["Alessia Ciacco", "Francesca Guerriero", "Eneko Osaba"], "title": "Quantum Annealing for Staff Scheduling in Educational Environments", "comment": "8 pages, 3 tables, and 1 figure. Paper submitted to the International\n  Conference on Quantum Communications, Networking, and Computing (QCNC 2026)", "summary": "We address a novel staff allocation problem that arises in the organization\nof collaborators among multiple school sites and educational levels. The\nproblem emerges from a real case study in a public school in Calabria, Italy,\nwhere staff members must be distributed across kindergartens, primary, and\nsecondary schools under constraints of availability, competencies, and\nfairness. To tackle this problem, we develop an optimization model and\ninvestigate a solution approach based on quantum annealing. Our computational\nexperiments on real-world data show that quantum annealing is capable of\nproducing balanced assignments in short runtimes. These results provide\nevidence of the practical applicability of quantum optimization methods in\neducational scheduling and, more broadly, in complex resource allocation tasks."}
{"id": "2510.11763", "categories": ["cond-mat.stat-mech", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2510.11763", "abs": "https://arxiv.org/abs/2510.11763", "authors": ["Virgile Troude", "Didier Sornette"], "title": "Non-Normal Eigenvector Amplification in Multi-Dimensional Kesten Processes", "comment": "30 pages (double column) and 4 figures", "summary": "Heavy-tailed fluctuations and power law statistics pervade physics, finance,\nand economics, yet their origin is often ascribed to systems poised near\ncriticality. Here we show that such behavior can emerge far from instability\nthrough a universal mechanism of non-normal eigenvector amplification in\nmultidimensional Kesten processes $x_{t+1}=A_t x_t+\\eta_t$, where $A_t$ are\nrandom interaction matrices and $\\eta_t$ represents external inputs, capturing\nthe evolving interdependence among $N$ coupled components. Even when each\nrandom multiplicative matrix is spectrally stable, non-orthogonal eigenvectors\ngenerate transient growth that renormalizes the Lyapunov exponent and lowers\nthe tail exponent, producing stationary power laws without eigenvalues crossing\nthe stability boundary. We derive explicit relations linking the Lyapunov\nexponent and the tail index to the statistics of the condition number,\n$\\gamma\\!\\sim\\!\\gamma_0+\\ln\\kappa$ and\n$\\alpha\\!\\sim\\!-2\\gamma/\\sigma_\\kappa^2$, confirmed by numerical simulations.\nThis framework offers a unifying geometric perspective that help interpret\ndiverse phenomena, including polymer stretching in turbulence, magnetic field\namplification in dynamos, volatility clustering and wealth inequality in\nfinancial systems. Non-normal interactions provide a collective route to\nscale-free behavior in globally stable systems, defining a new universality\nclass where multiplicative feedback and transient amplification generate\ncritical-like statistics without spectral criticality."}
{"id": "2510.12018", "categories": ["math.NA", "cs.NA", "65N30", "G.1.8"], "pdf": "https://arxiv.org/pdf/2510.12018", "abs": "https://arxiv.org/abs/2510.12018", "authors": ["Slimane Adjerid", "Tao Lin", "Haroun Meghaichi"], "title": "Construction of Basis Functions for the Geometry Conforming Immersed Finite Element Method", "comment": null, "summary": "The Frenet apparatus is a new framework for constructing high order\ngeometry-conforming immersed finite element functions for interface problems.\nIn this report, we present a procedure for constructing the local IFE bases in\nsome detail as well as a new approach for constructing orthonormal bases using\nthe singular value decomposition of the local generalized Vandermonde matrix. A\nsample implementation in MATLAB is provided to showcase the simplicity and\nextensionability of the framework."}
{"id": "2510.11998", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.11998", "abs": "https://arxiv.org/abs/2510.11998", "authors": ["Luca Santosuosso", "Sonja Wogrin"], "title": "Distributed Stochastic Model Predictive Control with Temporal Aggregation for the Joint Dispatch of Cascaded Hydropower and Renewables", "comment": null, "summary": "This paper addresses the real-time energy dispatch of a hybrid system\ncomprising cascaded hydropower plants, wind, and solar units, jointly\nparticipating in the day-ahead energy market under inflow, renewable\ngeneration, and price uncertainties. Traditional scenario-based stochastic\nmodel predictive control (MPC) faces severe computational bottlenecks due to\nthe complexity arising from the temporal, asset, and scenario dimensions of\nthis control problem. To address this, we propose a novel control scheme that\ncombines time series aggregation (TSA) with distributed stochastic MPC. TSA is\napplied exclusively to the tail of the MPC prediction horizon to preserve\nreal-time accuracy, while distributed optimization enables decomposition across\nassets and scenarios. Notably, the controller offers a formal performance\nguarantee through theoretically validated bounds on its approximation error.\nSimulations on a real-world case study confirm the controller's effectiveness,\nachieving a 42% reduction in execution time compared to centralized full-scale\nMPC."}
{"id": "2510.12318", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12318", "abs": "https://arxiv.org/abs/2510.12318", "authors": ["P√•l Forr Austnes", "Matthieu Jacobs", "Lu Wang", "Mario Paolone"], "title": "Empowering Prosumers: Incentive Design for Local Electricity Markets Under Generalized Uncertainty and Grid Constraints", "comment": null, "summary": "Since the 1990s, widespread introduction of central (wholesale) electricity\nmarkets has been seen across multiple continents, driven by the search for\nefficient operation of the power grid through competition. The increase of\nrenewables has made significant impacts both on central electricity markets and\ndistribution-level grids as renewable power generation is often connected to\nthe latter. These stochastic renewable technologies have both advantages and\ndisadvantages. On one hand they offer very low marginal cost and carbon\nemissions, while on the other hand, their output is uncertain, requiring\nflexible backup power with high marginal cost. Flexibility from end-prosumers\nor smaller market participants is therefore seen as a key enabler of\nlarge-scale integration of renewables. However, current central electricity\nmarkets do not directly include uncertainty into the market clearing and do not\naccount for physical constraints of distribution grids. In this paper we\npropose a local electricity market framework based on probabilistic locational\nmarginal pricing, effectively accounting for uncertainties in production,\nconsumption and grid variables. The model includes a representation of the grid\nusing the lindistflow equations and accounts for the propagation of uncertainty\nusing general Polynomial Chaos (gPC). A two-stage convex model is proposed; in\nthe day-ahead stage, probability distributions of prices are calculated for\nevery timestep, where the expected values represent the day-ahead (spot)\nprices. In the real-time stage, uncertainties are realized (measured) and a\ntrivial calculation reveals the real-time price. Through four instructive\ncase-studies we highlight the effectiveness of the method to incentivize\nend-prosumers' participation in the market, while ensuring that their behavior\ndoes not have an adverse impact on the operation of the grid."}
{"id": "2510.12525", "categories": ["nlin.CD", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.12525", "abs": "https://arxiv.org/abs/2510.12525", "authors": ["Kolja Kypke", "Peter Ashwin", "Peter Ditlevsen"], "title": "Chaotic variability in a model of coupled ice streams", "comment": "23 pages, 9 figures", "summary": "Regions of fast-flowing ice in ice sheets, known as ice streams, have been\ntheorized to be able to exhibit build-up/surge oscillatory variability due to\nthermomechanical coupling at the base of the ice. A simple model of three\ncoupled ice streams is constructed to replicate the spatial configuration of a\nsingle ice stream being bisected into two termini. The model is constructed to\nmimic existing branching ice streams in northern Greenland. This model is shown\nto exhibit both steady-flow and build-up/surge oscillations. Further, the\nvariability can be chaotic due to the nonlinear coupling of three\nincommensurate frequencies. This provides a mode of chaotic internal\nvariability for ice sheets that contain these types of ice streams."}
{"id": "2510.11747", "categories": ["cond-mat.stat-mech", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.11747", "abs": "https://arxiv.org/abs/2510.11747", "authors": ["Marco Bianucci", "Mauro Bologna", "Daniele Lagomarsino-Oneto", "Riccardo Mannella"], "title": "Universal behaviors of the multi-time correlation functions of random processes with renewal: the step noise case (the random velocity of a L√©vy walk)", "comment": "67 pages, 22 Figures", "summary": "Stochastic processes with renewal properties are powerful tools for modeling\nsystems where memory effects and long-time correlations play a significant\nrole. In this work, we study a broad class of renewal processes where a\nvariable's value changes according to a prescribed Probability Density Function\n(PDF), $p(\\xi)$, after random waiting times $\\theta$. This model is relevant\nacross many fields, including classical chaos, nonlinear hydrodynamics, quantum\ndots, cold atom dynamics, biological motion, foraging, and finance. We derive a\ngeneral analytical expression for the $n$-time correlation function by\naveraging over process realizations. Our analysis identifies the conditions for\nstationarity, aging, and long-range correlations based on the waiting time and\njump distributions. Among the many consequences of our analysis, two new key\nresults emerge. First, for Poissonian waiting times, the correlation function\nquickly approaches that of telegraphic noise. Second, for power-law waiting\ntimes with $\\mu>2$, , \\emph{any $n$-time correlation function asymptotically\nreduces to the two-time correlation evaluated at the earliest and latest time\npoints}. This second result reveals a universal long-time behavior where the\nsystem's full statistical structure becomes effectively two-time reducible.\nFurthermore, if the jump PDF $p(\\xi)$ has fat tails, this convergence becomes\nindependent of the waiting time PDF and is significantly accelerated, requiring\nonly modest increases in either the number of realizations or the trajectory\nlengths. Building upon earlier work that established the universality of the\ntwo-point correlation function (i.e., a unique formal expression depending\nsolely on the variance of $\\xi$ and on the waiting-time PDF), the present study\nextends that universality to the full statistical description of a broad class\nof renewal-type stochastic processes."}
{"id": "2510.12614", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "nlin.AO", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2510.12614", "abs": "https://arxiv.org/abs/2510.12614", "authors": ["Eric Alejandro Rozan", "Mario Ignacio Simoy", "Sebastian Bouzat", "Marcelo Nestor Kuperman"], "title": "Modeling Epidemics on Multiplex Networks: Epidemic Threshold and Basic Reproduction Number", "comment": "22 pages, 7 figures", "summary": "Accurate epidemic forecasting requires models that account for the layered\nand heterogeneous nature of real social interactions. The basic reproduction\nnumber $\\mathcal R_0$ calculated from models that assume homogeneous mixing or\nsingle-layer contact structures have limited applicability to complex social\nsystems. Here, we propose an expression of $\\mathcal R_0$ in the context of\nmultiplex networks, enabling the analysis of disease transmission across\nmultiple social layers.\n  We adapt the Degree-Based Mean-Field (DBMF) SIR model for single-layered\ncomplex networks to the multiplex setting, where each layer has its own degree\ndistribution and infection rate. Using the Next Generation Matrix method, we\nderive an analytical expression for the basic reproduction number $\\mathcal\nR_0$. Numerical integration of the multiplex DBMF equations shows that\n$\\mathcal R_0 = 1$ marks the epidemic threshold and governs the functional\ndependence of key outbreak indicators. In addition to the exact result for the\n$\\mathcal R_0$, we provide an approximation denoted as $\\tau$, which is easier\nto compute and more straightforward to interpret in terms of the parameters of\nthe system, and shares most of the expected properties of the basic\nreproduction number.\n  Stochastic agent-based simulations confirm these results, demonstrating a\ndirect correspondence between $\\tau$ and the average number of secondary\ninfections in the early epidemic phase, in line with the interpretation of\n$\\mathcal R_0$.\n  This research provides a robust generalization of $\\mathcal R_0$ for layered\ncontact structures, offering a more realistic basis for epidemic forecasting\nand the design of intervention strategies."}
{"id": "2510.12525", "categories": ["nlin.CD", "physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2510.12525", "abs": "https://arxiv.org/abs/2510.12525", "authors": ["Kolja Kypke", "Peter Ashwin", "Peter Ditlevsen"], "title": "Chaotic variability in a model of coupled ice streams", "comment": "23 pages, 9 figures", "summary": "Regions of fast-flowing ice in ice sheets, known as ice streams, have been\ntheorized to be able to exhibit build-up/surge oscillatory variability due to\nthermomechanical coupling at the base of the ice. A simple model of three\ncoupled ice streams is constructed to replicate the spatial configuration of a\nsingle ice stream being bisected into two termini. The model is constructed to\nmimic existing branching ice streams in northern Greenland. This model is shown\nto exhibit both steady-flow and build-up/surge oscillations. Further, the\nvariability can be chaotic due to the nonlinear coupling of three\nincommensurate frequencies. This provides a mode of chaotic internal\nvariability for ice sheets that contain these types of ice streams."}
{"id": "2510.12012", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.12012", "abs": "https://arxiv.org/abs/2510.12012", "authors": ["Rulla Al-Haideri", "Changhe Liu", "Karim Ismail", "Bilal Farooq", "Chi Zhang"], "title": "Latent Class Logit Kernel Framework for Surrogate Safety: Identifying Behavioural Thresholds through Conflict Indicator Profiles", "comment": null, "summary": "Crash data objectively characterize road safety but are rare and often\nunsuitable for proactive safety management. Traffic conflict indicators such as\ntime-to-collision (TTC) provide continuous measures of collision proximity but\nrequire thresholds to distinguish routine from safety-critical interactions.\nExtreme Value Theory (EVT) offers statistically defined thresholds, yet these\ndo not necessarily represent how drivers perceive and respond to conflict. This\nstudy introduces a behavioural modelling framework that identifies candidate\nbehavioural thresholds (CBTs) by explicitly modelling how drivers adjust their\nmovements under conflict conditions. The framework is based on a Latent Class\nLogit Kernel (LC-LK) model that captures inter-class heterogeneity (routine vs.\ndefensive driving) and intra-class correlation between overlapping spatial\nalternatives. This yields probability curves showing how the likelihood of\ndefensive manoeuvres varies with conflict indicators, from which CBTs such as\ninflection points and crossovers can be extracted. The framework tests four\nhypotheses: (1) drivers exhibit varying degrees of membership in both low- and\nhigh-risk classes; (2) membership shifts systematically with conflict values,\nrevealing behavioural thresholds; (3) this relationship follows a logistic\nshape, with stable behaviour at safe levels and rapid transitions near critical\npoints; and (4) even in free flow, drivers maintain a baseline caution level.\nApplication to naturalistic roundabout trajectories revealed stable TTC\nthresholds (0.8-1.1 s) but unstable MTTC2 estimates (e.g., 34 s), suggesting\ncognitive limits in processing complex indicators. Overall, the framework\ncomplements EVT by offering a structured, behaviourally grounded method for\nidentifying and validating thresholds in surrogate safety analysis."}
{"id": "2510.11853", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.11853", "abs": "https://arxiv.org/abs/2510.11853", "authors": ["Anirban Chatterjee", "Aaditya Ramdas"], "title": "A Martingale Kernel Two-Sample Test", "comment": null, "summary": "The Maximum Mean Discrepancy (MMD) is a widely used multivariate distance\nmetric for two-sample testing. The standard MMD test statistic has an\nintractable null distribution typically requiring costly resampling or\npermutation approaches for calibration. In this work we leverage a martingale\ninterpretation of the estimated squared MMD to propose martingale MMD (mMMD), a\nquadratic-time statistic which has a limiting standard Gaussian distribution\nunder the null. Moreover we show that the test is consistent against any fixed\nalternative and for large sample sizes, mMMD offers substantial computational\nsavings over the standard MMD test, with only a minor loss in power."}
{"id": "2510.12125", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2510.12125", "abs": "https://arxiv.org/abs/2510.12125", "authors": ["Mengyang Chen", "Lingwei Wei", "Wei Zhou", "Songlin Hu"], "title": "Structure-aware Propagation Generation with Large Language Models for Fake News Detection", "comment": null, "summary": "The spread of fake news on social media poses a serious threat to public\ntrust and societal stability. While propagation-based methods improve fake news\ndetection by modeling how information spreads, they often suffer from\nincomplete propagation data. Recent work leverages large language models (LLMs)\nto generate synthetic propagation, but typically overlooks the structural\npatterns of real-world discussions. In this paper, we propose a novel\nstructure-aware synthetic propagation enhanced detection (StruSP) framework to\nfully capture structural dynamics from real propagation. It enables LLMs to\ngenerate realistic and structurally consistent propagation for better\ndetection. StruSP explicitly aligns synthetic propagation with real-world\npropagation in both semantic and structural dimensions. Besides, we also design\na new bidirectional evolutionary propagation (BEP) learning strategy to better\nalign LLMs with structural patterns of propagation in the real world via\nstructure-aware hybrid sampling and masked propagation modeling objective.\nExperiments on three public datasets demonstrate that StruSP significantly\nimproves fake news detection performance in various practical detection\nscenarios. Further analysis indicates that BEP enables the LLM to generate more\nrealistic and diverse propagation semantically and structurally."}
{"id": "2510.12602", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12602", "abs": "https://arxiv.org/abs/2510.12602", "authors": ["Minghuan Zeng", "Ling Qin", "Shiping Feng", "Dong-Hui Xu", "Rui Wang"], "title": "The spin Hall conductivity in the hole-doped bilayer Haldane-Hubbard model with odd-parity ALM", "comment": "7 pages, 3 figures", "summary": "Spin current generated electrically is among the core phenomena of\nspintronics for driving high-performance spin device applications. Here, on the\nbasis of systematic investigations for the hole doped single-layer\nHaldane-Hubbard(HH) model, we propose a new bilayer HH model to realize the\ncompensated odd-parity spin splitting and the $T$-even spin Hall conductivity\nwhere the two layers are connected by the time reversal transformation. Our\nresults show that the vanishing layer-dependent electric potential $V_{L}$\ngives rise to odd-parity ALM protected by the combined symmetry $TM_{xy}$ with\n$T$ and $M_{xy}$ being the time reversal and mirror reflection perpendicular to\n$z$ axis, and the $T$-even spin Hall conductivity simultaneously. In addition,\nthough the staggered magnetization within each layer is substantially impacted\nby the layer-dependent electric potential, small $V_{L}$'s only bring\nnegligible changes to the net magnetization and the spin Hall conductivity,\nindicating that the alternating spin splitting in momentum space and the spin\nHall conductivity are insusceptible to external elements. Most importantly, our\nwork provides a general framework for the simultaneous realization of the\ncompensated odd-parity spin splitting in momentum space and the spin Hall\nconductivity in collinear magnets, in terms of stacked multi-layer systems."}
{"id": "2510.12335", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12335", "abs": "https://arxiv.org/abs/2510.12335", "authors": ["Stavros Orfanoudakis", "Frans Oliehoek", "Peter Palesnky", "Pedro P. Vergara"], "title": "Physics-Informed Reinforcement Learning for Large-Scale EV Smart Charging Considering Distribution Network Voltage Constraints", "comment": null, "summary": "Electric Vehicles (EVs) offer substantial flexibility for grid services, yet\nlarge-scale, uncoordinated charging can threaten voltage stability in\ndistribution networks. Existing Reinforcement Learning (RL) approaches for\nsmart charging often disregard physical grid constraints or have limited\nperformance for complex large-scale tasks, limiting their scalability and\nreal-world applicability. This paper introduces a physics-informed (PI) RL\nalgorithm that integrates a differentiable power flow model and voltage-based\nreward design into the Twin Delayed Deep Deterministic Policy Gradient (TD3)\nalgorithm, enabling EVs to deliver real-time voltage support while meeting user\ndemands. The resulting PI-TD3 algorithm achieves faster convergence, improved\nsample efficiency, and reliable voltage magnitude regulation under uncertain\nand overloaded conditions. Benchmarks on the IEEE 34-bus and 123-bus networks\nshow that the proposed PI-TD3 outperforms both model-free RL and\noptimization-based baselines in grid constraint management, user satisfaction,\nand economic metrics, even as the system scales to hundreds of EVs. These\nadvances enable robust, scalable, and practical EV charging strategies that\nenhance grid resilience and support distribution networks operation."}
{"id": "2510.12407", "categories": ["eess.SY", "cs.ET", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12407", "abs": "https://arxiv.org/abs/2510.12407", "authors": ["Fabrizio Orlando", "Deborah Volpe", "Giacomo Orlandi", "Mariagrazia Graziano", "Fabrizio Riente", "Marco Vacca"], "title": "High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization", "comment": null, "summary": "Combinatorial Optimization (CO) problems exhibit exponential complexity,\nmaking their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a\nquantum-inspired algorithm to obtain approximate solutions to largescale CO\nproblems written in the Ising form. It explores the solution space by emulating\nthe adiabatic evolution of a network of Kerr-nonlinear parametric oscillators\n(KPOs), where each oscillator represents a variable in the problem. The optimal\nsolution corresponds to the ground state of this system. A key advantage of\nthis approach is the possibility of updating multiple variables simultaneously,\nmaking it particularly suited for hardware implementation. To enhance solution\nquality and convergence speed, variations of the algorithm have been proposed\nin the literature, including ballistic (bSB), discrete (dSB), and thermal\n(HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and\nHbSB using dedicated software models, evaluating the feasibility of using a\nfixed-point representation for hardware implementation. We then present an\nopensource hardware architecture implementing the dSB algorithm for\nField-Programmable Gate Arrays (FPGAs). The design allows users to adjust the\ndegree of algorithmic parallelization based on their specific requirements. A\nproof-of-concept implementation that solves 256-variable problems was achieved\non an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut\nand knapsack problems."}
{"id": "2510.11776", "categories": ["cond-mat.stat-mech", "hep-th", "math-ph", "math.MP", "nlin.SI", "82B20 (primary) 82B26, 20C35 (secondary)"], "pdf": "https://arxiv.org/pdf/2510.11776", "abs": "https://arxiv.org/abs/2510.11776", "authors": ["Joaqu√≠n L√≥pez-Su√°rez", "Alexios P. Polychronakos", "Konstantinos Sfetsos"], "title": "Adjoint ferromagnets", "comment": "31 pages, 8 figures", "summary": "We derive the phase structure and thermodynamics of ferromagnets consisting\nof elementary magnets carrying the adjoint representation of $SU(N)$ and\ncoupled through two-body quadratic interactions. Such systems have a continuous\n$SU(N)$ symmetry as well as a discrete conjugation symmetry. We uncover a rich\nspectrum of phases and transitions, involving a paramagnetic and two distinct\nferromagnetic phases that can coexist as stable and metastable states in\ndifferent combinations over a range of temperatures. The ferromagnetic phases\nbreak $SU(N)$ invariance in various channels, leading to spontaneous\nmagnetization. Interestingly, the conjugation symmetry also breaks over a range\nof temperatures and group ranks $N$, providing a realization of a spontaneously\nbroken discrete symmetry."}
{"id": "2510.12027", "categories": ["math.NA", "cs.NA", "43A90, 41A25, 41A55, 65D12, 65D32"], "pdf": "https://arxiv.org/pdf/2510.12027", "abs": "https://arxiv.org/abs/2510.12027", "authors": ["Zhengjie Sun", "Mengyuan Lv", "Xingping Sun"], "title": "Monte Carlo quasi-interpolation of spherical data", "comment": null, "summary": "We establish a deterministic and stochastic spherical quasi-interpolation\nframework featuring scaled zonal kernels derived from radial basis functions on\nthe ambient Euclidean space. The method incorporates both quasi-Monte Carlo and\nMonte Carlo quadrature rules to construct easily computable quasi-interpolants,\nwhich provide efficient approximation to Sobolev-space functions for both clean\nand noisy data. To enhance the approximation power and robustness of our\nquasi-interpolants, we develop a multilevel method in which quasi-interpolants\nconstructed with graded resolutions join force to reduce the error of\napproximation. In addition, we derive probabilistic concentration inequalities\nfor our quasi-interpolants in pertinent stochastic settings. The construction\nof our quasi-interpolants does not require solving any linear system of\nequations. Numerical experiments show that our quasi-interpolation algorithm is\nmore stable and robust against noise than comparable ones in the literature."}
{"id": "2510.12007", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.12007", "abs": "https://arxiv.org/abs/2510.12007", "authors": ["Cody Melcher", "Zeinab Alizadeh", "Lindsey Hiett", "Afrooz Jalilzadeh", "Erfan Yazdandoost Hamedani"], "title": "Semi-infinite Nonconvex Constrained Min-Max Optimization", "comment": "Accepted at NeurIPS 2025", "summary": "Semi-Infinite Programming (SIP) has emerged as a powerful framework for\nmodeling problems with infinite constraints, however, its theoretical\ndevelopment in the context of nonconvex and large-scale optimization remains\nlimited. In this paper, we investigate a class of nonconvex min-max\noptimization problems with nonconvex infinite constraints, motivated by\napplications such as adversarial robustness and safety-constrained learning. We\npropose a novel inexact dynamic barrier primal-dual algorithm and establish its\nconvergence properties. Specifically, under the assumption that the squared\ninfeasibility residual function satisfies the Lojasiewicz inequality with\nexponent $\\theta \\in (0,1)$, we prove that the proposed method achieves\n$\\mathcal{O}(\\epsilon^{-3})$, $\\mathcal{O}(\\epsilon^{-6\\theta})$, and\n$\\mathcal{O}(\\epsilon^{-3\\theta/(1-\\theta)})$ iteration complexities to achieve\nan $\\epsilon$-approximate stationarity, infeasibility, and complementarity\nslackness, respectively. Numerical experiments on robust multitask learning\nwith task priority further illustrate the practical effectiveness of the\nalgorithm."}
{"id": "2510.12335", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12335", "abs": "https://arxiv.org/abs/2510.12335", "authors": ["Stavros Orfanoudakis", "Frans Oliehoek", "Peter Palesnky", "Pedro P. Vergara"], "title": "Physics-Informed Reinforcement Learning for Large-Scale EV Smart Charging Considering Distribution Network Voltage Constraints", "comment": null, "summary": "Electric Vehicles (EVs) offer substantial flexibility for grid services, yet\nlarge-scale, uncoordinated charging can threaten voltage stability in\ndistribution networks. Existing Reinforcement Learning (RL) approaches for\nsmart charging often disregard physical grid constraints or have limited\nperformance for complex large-scale tasks, limiting their scalability and\nreal-world applicability. This paper introduces a physics-informed (PI) RL\nalgorithm that integrates a differentiable power flow model and voltage-based\nreward design into the Twin Delayed Deep Deterministic Policy Gradient (TD3)\nalgorithm, enabling EVs to deliver real-time voltage support while meeting user\ndemands. The resulting PI-TD3 algorithm achieves faster convergence, improved\nsample efficiency, and reliable voltage magnitude regulation under uncertain\nand overloaded conditions. Benchmarks on the IEEE 34-bus and 123-bus networks\nshow that the proposed PI-TD3 outperforms both model-free RL and\noptimization-based baselines in grid constraint management, user satisfaction,\nand economic metrics, even as the system scales to hundreds of EVs. These\nadvances enable robust, scalable, and practical EV charging strategies that\nenhance grid resilience and support distribution networks operation."}
{"id": "2510.12532", "categories": ["nlin.CD", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.12532", "abs": "https://arxiv.org/abs/2510.12532", "authors": ["Domenico Lippolis"], "title": "Spatiotemporal stability of synchronized coupled map lattice states", "comment": "15 pages, 5 figures", "summary": "In the realm of spatiotemporal chaos, unstable periodic orbits play a major\nrole in understanding the dynamics. Their stability changes and bifurcations in\ngeneral are thus of central interest. Here, coupled map lattice discretizations\nof nonlinear partial differential equations, exhibiting a variety of behaviors\ndepending on the coupling strength, are considered. In particular, the linear\nstability analysis of synchronized states is performed by evaluating the\nBravais lattice orbit Jacobian in its reciprocal space first Brillouin zone,\nwith space and time treated on equal grounds. The eigenvalues of the orbit\nJacobian operator, computed as functions of the coupling strength, tell us\nabout the stability of the periodic orbit under a perturbation of a certain\ntime- and space frequency. Moreover, the stability under aperiodic, that is,\nincoherent perturbations, is revealed by integrating the sum of the stability\nexponents over all space-time frequencies."}
{"id": "2510.11847", "categories": ["stat.ME", "math.ST", "stat.CO", "stat.ML", "stat.TH", "G.3; I.5.1"], "pdf": "https://arxiv.org/pdf/2510.11847", "abs": "https://arxiv.org/abs/2510.11847", "authors": ["Sam Hawke", "Eric Zhang", "Jiawen Chen", "Didong Li"], "title": "Contrastive Dimension Reduction: A Systematic Review", "comment": null, "summary": "Contrastive dimension reduction (CDR) methods aim to extract signal unique to\nor enriched in a treatment (foreground) group relative to a control\n(background) group. This setting arises in many scientific domains, such as\ngenomics, imaging, and time series analysis, where traditional dimension\nreduction techniques such as Principal Component Analysis (PCA) may fail to\nisolate the signal of interest. In this review, we provide a systematic\noverview of existing CDR methods. We propose a pipeline for analyzing\ncase-control studies together with a taxonomy of CDR methods based on their\nassumptions, objectives, and mathematical formulations, unifying disparate\napproaches under a shared conceptual framework. We highlight key applications\nand challenges in existing CDR methods, and identify open questions and future\ndirections. By providing a clear framework for CDR and its applications, we aim\nto facilitate broader adoption and motivate further developments in this\nemerging field."}
{"id": "2510.12381", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.12381", "abs": "https://arxiv.org/abs/2510.12381", "authors": ["Yixuan Y Zheng", "Hideki Takayasu", "Misako Takayasu"], "title": "Do Railway Commuters Exhibit Consistent Route Choice Rationality Across Different Contexts and Time? Evidence from Tokyo metropolitan Commutes", "comment": null, "summary": "Recent advances in data collection and technology enable a deeper\nunderstanding of complex urban commuting, yet few studies have rigorously\nanalyzed the temporal stability and Origin-Destination (OD) heterogeneity of\nroute choice. To address this, we analyze one year of smartphone position data\nfrom over one million users in the Tokyo metropolitan area to extract\nhigh-resolution commuting trajectories. Our methodology is twofold: First, we\ndevelop algorithms to process raw position data, accurately extracting the\ncommuting trajectory, transportation mode, and transfer stations. Second, by\nreinterpreting the Multinomial Logit (MNL) model through the canonical ensemble\nframework of statistical physics, we model route choice rationality as a\ntemperature-dependent system. Our approach uniquely measures behavioral\nconsistency in terms of rationality and preference stability over time, and\ndistinguishes systematic from random heterogeneity. Our results reveal temporal\nstability in aggregate route choice behavior across the entire urban region\nthroughout 2023. Also, we found heterogeneity dependent on the origin and\ndestination (OD) pair. This variation is reflected as a bimodal split in the\nestimated route parameters, indicating that for certain attributes, commuters\nfall into two distinct groups with contrasting preference signs. We believe\nthat our findings serve a basis for future urban route choice modeling by\nsuggesting the importance of elabolating the model of transfer in railway."}
{"id": "2510.11863", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.11863", "abs": "https://arxiv.org/abs/2510.11863", "authors": ["Jiaqi Tong", "Fan Li"], "title": "On the permutation invariance principle for causal estimands", "comment": null, "summary": "In many causal inference problems, multiple action variables share the same\ncausal role, such as mediators, factors, network units, or genotypes, yet lack\na natural ordering. To avoid ambiguity in interpretation, causal estimands\nshould remain unchanged under relabeling, an implicit principle we refer to as\npermutation invariance. We formally characterize this principle, analyze its\nalgebraic and combinatorial structure for verification, and present a class of\nweighted estimands that are permutation-invariant while capturing interactions\nof all orders. We further provide guidance on selecting weights that yield\nresidual-free estimands, whose inclusion-exclusion sums capture the maximal\neffect, and extend our results to ratio effect measures."}
{"id": "2510.12243", "categories": ["cs.SI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2510.12243", "abs": "https://arxiv.org/abs/2510.12243", "authors": ["Jeanne Choi", "DongJae Kang", "Yubin Choi", "Juhoon Lee", "Joseph Seering"], "title": "CrisisNews: A Dataset Mapping Two Decades of News Articles on Online Problematic Behavior at Scale", "comment": "The first two authors hold equal contribution", "summary": "As social media adoption grows globally, online problematic behaviors\nincreasingly escalate into large-scale crises, requiring an evolving set of\nmitigation strategies. While HCI research often analyzes problematic behaviors\nwith pieces of user-generated content as the unit of analysis, less attention\nhas been given to event-focused perspectives that track how discrete events\nevolve. In this paper, we examine 'social media crises': discrete patterns of\nproblematic behaviors originating and evolving within social media that cause\nlarger-scale harms. Using global news coverage, we present a dataset of 93,250\nnews articles covering social media-endemic crises from the past 20 years. We\nanalyze a representative subset to classify stakeholder roles, behavior types,\nand outcomes, uncovering patterns that inform more nuanced classification of\nsocial media crises beyond content-based descriptions. By adopting a wider\nperspective, this research seeks to inform the design of safer platforms,\nenabling proactive measures to mitigate crises and foster more trustworthy\nonline environments."}
{"id": "2510.12613", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2510.12613", "abs": "https://arxiv.org/abs/2510.12613", "authors": ["Jordan Teeter", "Topojit Debnath", "Harshil Goyal", "Md Sabbir Hossen Bijoy", "Maedeh Taheri", "Nicholas Sesing", "Fariborz Kargar", "Kirill Shtengel", "Tina Salguero", "Roger K. Lake", "Alexander A. Balandin"], "title": "Quantum Spin Singlet and Classical N√©el-Ordered Ground States in MoX3 (X = I, Br) Spin-3/2 Dimerized Antiferromagnetic Chain Crystals", "comment": "36 pages, 8 figures", "summary": "We report that MoX3 (X = I, Br) are rare van der Waals materials that exhibit\nsignatures of both quantum spin chains with a spin singlet ground state and\nclassical Neel order. Bulk single crystals grown by chemical vapor transport\nexhibit classical antiferromagnetic ground states with a transition temperature\nof ~40 K as revealed by susceptibility and specific heat measurements. Above 40\nK, the susceptibilities show the large, broad peaks associated with a quantum\nspin-singlet ground state and large singlet-triplet gaps of 21 meV and 25 meV.\nMonte Carlo simulations, density matrix renormalization-group calculations for\nfinite spin-3/2 chains, and density functional theory reproduce the\nexperimental behavior, confirming the interplay between strong one-dimensional\nintrachain and weak three-dimensional interchain couplings. MoX3 offers a\nunique platform for exploring quantum magnetism and magnetic excitations at the\natomic chain limit, as these materials combine a 1D van der Waals motif, spin\nchain behavior, and classical interchain order."}
{"id": "2510.12338", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12338", "abs": "https://arxiv.org/abs/2510.12338", "authors": ["Mohamed Abdalmoaty", "Verena H√§berle", "Xiuqiang He", "Florian D√∂rfler"], "title": "Ultrafast Grid Impedance Identification in $dq$-Asymmetric Three-Phase Power Systems", "comment": null, "summary": "We propose a non-parametric frequency-domain method to identify small-signal\n$dq$-asymmetric grid impedances, over a wide frequency band, using\ngrid-connected converters. Existing identification methods are faced with\nsignificant trade-offs: e.g., passive approaches rely on ambient harmonics and\nrare grid events and thus can only provide estimates at a few frequencies,\nwhile many active approaches that intentionally perturb grid operation require\nlong time series measurement and specialized equipment. Although active\ntime-domain methods reduce the measurement time, they either make crude\nsimplifying assumptions or require laborious model order tuning. Our approach\neffectively addresses these challenges: it does not require specialized\nexcitation signals or hardware and achieves ultrafast ($<1$ s) identification,\ndrastically reducing measurement time. Being non-parametric, our approach also\nmakes no assumptions on the grid structure. A detailed electromagnetic\ntransient simulation is used to validate the method and demonstrate its clear\nsuperiority over existing alternatives."}
{"id": "2510.12599", "categories": ["cond-mat.stat-mech", "cond-mat.quant-gas", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.12599", "abs": "https://arxiv.org/abs/2510.12599", "authors": ["Sebastian Deffner"], "title": "Quantum thermodynamics of Gross-Pitaevskii qubits", "comment": "9 pages, 6 figures", "summary": "What are the resources that can be leveraged for a thermodynamic device to\nexhibit genuine quantum advantage? Typically, the answer to this question is\nsought in quantum correlations. In the present work, we show that quantum Otto\nengines that operate with nonlinear qubits significantly outperform linear\nengines. To this end, we develop a comprehensive thermodynamic description of\nnonlinear qubits starting with identifying the proper thermodynamic equilibrium\nstate. We then show that for ideal cycles as well as at maximum power the\nefficiency of the nonlinear engine is significantly higher. Interestingly,\nnonlinear dynamics can be thought of as an effective description of a\ncorrelated, complex quantum many body system. Hence, our findings corroborate\ncommon wisdom, while at the same time propose a new design of more efficient\nquantum engines."}
{"id": "2510.12109", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.12109", "abs": "https://arxiv.org/abs/2510.12109", "authors": ["Zhao Zhang", "Na Ou"], "title": "Stochastic Finite Volume Approximation with Clustering in the Parameter Space for Forward Uncertainty Quantification of PDEs with Random Parameters", "comment": null, "summary": "The uncertainty quantification (UQ) for partial differential equations (PDEs)\nwith random parameters is important for science and engineering. Forward UQ\nquantifies the impact of random parameters on the solution or the\nquantity-of-interest (QoI). In the current study, we propose a new extension of\nthe stochastic finite volume (SFV) method by clustering samples in the\nparameter space. Compared to classic SFV based on structured grid in the\nparameter space, the new scheme based on clustering extends SFV to parameter\nspaces of higher dimensions. This paper presents the construction of SFV\nschemes for typical parametric elliptic, parabolic and hyperbolic equations for\nDarcy flows in porous media, as well as the error analysis, demonstration and\nvalidation of the new extension using typical reservoir simulation test cases."}
{"id": "2510.12105", "categories": ["math.OC", "90C33, 65K15, 90C26"], "pdf": "https://arxiv.org/pdf/2510.12105", "abs": "https://arxiv.org/abs/2510.12105", "authors": ["Lei Zhao", "Daoli Zhu", "Shuzhong Zhang"], "title": "New Classes of Non-monotone Variational Inequality Problems Solvable via Proximal Gradient on Smooth Gap Functions", "comment": null, "summary": "In this paper, we study the local linear convergence behavior of\nproximal-gradient (PG) descent algorithm on a parameterized gap-function\nreformulation of a smooth but non-monotone variational inequality problem\n(VIP). The aim is to solve the non-monotone VI problem without assuming the\nexistence of a Minty-type solution. We first introduce and study various error\nbound conditions for the gap functions in relation to the VI model. In\nparticular, we show that uniform type error bounds imply level-set type error\nbounds for composite optimization, revealing a key hierarchical structure\nthere. As a result, local linear convergence is established under some\neasy-verifiable conditions induced by level-set error bounds, the gradient\nLipschitz condition and a suitable initialization condition. Furthermore, for\nnon-monotone affine VIs we present a homotopy continuation scheme that achieves\nglobal convergence by dynamically tracing a solution path. Our numerical\nexperiments show the efficacy of the proposed approach, leading to the\nsolutions of a broad class of non-monotone VI problems resulting from the need\nto compute Nash equilibria, traffic controls, and the GAN models."}
{"id": "2510.12338", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12338", "abs": "https://arxiv.org/abs/2510.12338", "authors": ["Mohamed Abdalmoaty", "Verena H√§berle", "Xiuqiang He", "Florian D√∂rfler"], "title": "Ultrafast Grid Impedance Identification in $dq$-Asymmetric Three-Phase Power Systems", "comment": null, "summary": "We propose a non-parametric frequency-domain method to identify small-signal\n$dq$-asymmetric grid impedances, over a wide frequency band, using\ngrid-connected converters. Existing identification methods are faced with\nsignificant trade-offs: e.g., passive approaches rely on ambient harmonics and\nrare grid events and thus can only provide estimates at a few frequencies,\nwhile many active approaches that intentionally perturb grid operation require\nlong time series measurement and specialized equipment. Although active\ntime-domain methods reduce the measurement time, they either make crude\nsimplifying assumptions or require laborious model order tuning. Our approach\neffectively addresses these challenges: it does not require specialized\nexcitation signals or hardware and achieves ultrafast ($<1$ s) identification,\ndrastically reducing measurement time. Being non-parametric, our approach also\nmakes no assumptions on the grid structure. A detailed electromagnetic\ntransient simulation is used to validate the method and demonstrate its clear\nsuperiority over existing alternatives."}
{"id": "2510.11853", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.11853", "abs": "https://arxiv.org/abs/2510.11853", "authors": ["Anirban Chatterjee", "Aaditya Ramdas"], "title": "A Martingale Kernel Two-Sample Test", "comment": null, "summary": "The Maximum Mean Discrepancy (MMD) is a widely used multivariate distance\nmetric for two-sample testing. The standard MMD test statistic has an\nintractable null distribution typically requiring costly resampling or\npermutation approaches for calibration. In this work we leverage a martingale\ninterpretation of the estimated squared MMD to propose martingale MMD (mMMD), a\nquadratic-time statistic which has a limiting standard Gaussian distribution\nunder the null. Moreover we show that the test is consistent against any fixed\nalternative and for large sample sizes, mMMD offers substantial computational\nsavings over the standard MMD test, with only a minor loss in power."}
{"id": "2510.12417", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2510.12417", "abs": "https://arxiv.org/abs/2510.12417", "authors": ["Andrea Musso", "Diego Rybski", "Dirk Helbing", "Frank Neffke"], "title": "Large cities lose their growth edge as urban systems mature", "comment": "15 pages, 4 figures, 2 tables", "summary": "From 1975 to 2025, urban populations have become increasingly concentrated in\nlarge cities. On average across countries, the share of urban residents living\nin cities with over one million people rose from 18\\% in 1975 to 39\\% in 2025.\nWill this trend towards greater concentration in large cities continue or level\noff? We introduce two new city population datasets that use consistent city\ndefinitions across countries and over time. The first covers the world between\n1975 and 2025, using satellite imagery. The second covers the U.S. between 1850\nand 2020, using census microdata. We find that urban growth follows a\nconsistent life cycle. Early in urbanization, large cities grow faster than\nsmaller ones. As urban systems mature, this growth advantage fades, and cities\nof all sizes grow at similar rates. We use this life cycle to project future\nconcentration in large cities. Our projections suggest that over the next 50\nyears, concentration will increase at less than half the rate observed in the\npast 50 years."}
{"id": "2510.11982", "categories": ["stat.ME", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2510.11982", "abs": "https://arxiv.org/abs/2510.11982", "authors": ["Pratyusa Datta", "Philippe Lemey", "Marc A. Suchard"], "title": "Inhomogeneous continuous-time Markov chains to infer flexible time-varying evolutionary rates", "comment": "24 pages, 11 figures", "summary": "Reconstructing evolutionary histories and estimating the rate of evolution\nfrom molecular sequence data is of central importance in evolutionary biology\nand infectious disease research. We introduce a flexible Bayesian phylogenetic\ninference framework that accommodates changing evolutionary rates over time by\nmodeling sequence character substitution processes as inhomogeneous\ncontinuous-time Markov chains (ICTMCs) acting along the unknown phylogeny,\nwhere the rate remains as an unknown, positive and integrable function of time.\nThe integral of the rate function appears in the finite-time transition\nprobabilities of the ICTMCs that must be efficiently computed for all branches\nof the phylogeny to evaluate the observed data likelihood. Circumventing\ncomputational challenges that arise from a fully nonparametric function, we\nsuccessfully parameterize the rate function as piecewise constant with a large\nnumber of epochs that we call the polyepoch clock model. This makes the\ntransition probability computation relatively inexpensive and continues to\nflexibly capture rate change over time. We employ a Gaussian Markov random\nfield prior to achieve temporal smoothing of the estimated rate function.\nHamiltonian Monte Carlo sampling enabled by scalable gradient evaluation under\nthis model makes our framework computationally efficient. We assess the\nperformance of the polyepoch clock model in recovering the true timescales and\nrates through simulations under two different evolutionary scenarios. We then\napply the polyepoch clock model to examine the rates of West Nile virus, Dengue\nvirus and influenza A/H3N2 evolution, and estimate the time-varying rate of\nSARS-CoV-2 spread in Europe in 2020."}
{"id": "2510.12348", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.12348", "abs": "https://arxiv.org/abs/2510.12348", "authors": ["Georgios Panayiotou", "Anand Mathew Muthukulam Simon", "Matteo Magnani", "Ece Calikus"], "title": "MOUFLON: Multi-group Modularity-based Fairness-aware Community Detection", "comment": null, "summary": "In this paper, we propose MOUFLON, a fairness-aware, modularity-based\ncommunity detection method that allows adjusting the importance of partition\nquality over fairness outcomes. MOUFLON uses a novel proportional balance\nfairness metric, providing consistent and comparable fairness scores across\nmulti-group and imbalanced network settings. We evaluate our method under both\nsynthetic and real network datasets, focusing on performance and the trade-off\nbetween modularity and fairness in the resulting communities, along with the\nimpact of network characteristics such as size, density, and group\ndistribution. As structural biases can lead to strong alignment between\ndemographic groups and network structure, we also examine scenarios with highly\nclustered homogeneous groups, to understand how such structures influence\nfairness outcomes. Our findings showcase the effects of incorporating fairness\nconstraints into modularity-based community detection, and highlight key\nconsiderations for designing and benchmarking fairness-aware social network\nanalysis methods."}
{"id": "2510.12667", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12667", "abs": "https://arxiv.org/abs/2510.12667", "authors": ["Martin Ulaga", "Jure Kokalj", "Takami Tohyama", "Peter Prelov≈°ek"], "title": "The anisotropic Heisenberg model close to the Ising limit: triangular lattice vs. effective models", "comment": null, "summary": "Stimulated by recent experiments on materials representing the realization of\nthe anisotropic Heisenberg spin-$1/2$ model on the triangular lattice, we\nexplore further properties of such a model in the easy-axis regime $\\alpha =\nJ_\\perp/J_z < 1$, as well as effective models that also capture such physics.\nWe show that anisotropic Heisenberg models on the honeycomb lattice and even on\nthe square lattice reveal similarities to the full triangular lattice in the\nmagnetization curve as well as in the transverse magnetization (superfluid)\norder parameter $m_\\perp$ at finite fields. Still, at $\\alpha \\ll 1$, results\nreveal gapless excitations and small but finite $m_\\perp >0 $ at effective\nfields corresponding to the triangular case without the field. In contrast,\nseveral additional numerical studies of the full model on the triangular\nlattice confirm the existence of the gap at $\\alpha \\ll 1$. In particular, the\nmagnetization curve $m(h)$ as well as the spin stiffness $\\rho_s$ indicate (at\nzero field) a transition/crossover from gapped to gapless regime at $\\alpha\n\\sim \\alpha^*$ with $\\alpha^* \\lesssim 0.5$. We also show that deviations from\nthe linear spin-wave theory and the emergence of the gap can be traced back to\nthe strong effective repulsion between magnon excitations, having similarity to\nstrongly correlated systems."}
{"id": "2510.12360", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12360", "abs": "https://arxiv.org/abs/2510.12360", "authors": ["Weijie Ren", "Haowen Liu", "Guang-Ren Duan"], "title": "A Unidirectionally Connected FAS Approach for 6-DOF Quadrotor Control", "comment": "This paper has been submitted to 2026 IFAC World Congress.\n  Corresponding author: Guang-Ren Duan", "summary": "This paper proposes a unidirectionally connected fully actuated system\n(UC-FAS) approach for the sub-stabilization and tracking control of 6-DOF\nquadrotors, tackling limitations both in state-space and FAS framework to some\nextent. The framework systematically converts underactuated quadrotor dynamics\ninto a UC-FAS model, unifying the existing different FAS transformation ways.\nBy eliminating estimation of the high-order derivatives of control inputs, a\ndrawback of current methods, the UC-FAS model simplifies controller design and\nenables direct eigenstructure assignment for closed-loop dynamics. Simulations\ndemonstrate precise 6-DOF tracking performance. This work bridges theoretical\nFAS approach advancements with practical implementation needs, offering a\nstandardized paradigm for nonlinear quadrotor control."}
{"id": "2510.12678", "categories": ["cond-mat.stat-mech", "math-ph", "math.MP"], "pdf": "https://arxiv.org/pdf/2510.12678", "abs": "https://arxiv.org/abs/2510.12678", "authors": ["Herbert Spohn"], "title": "The Popkov-Sch√ºtz two-lane lattice gas: Universality for general jump rates", "comment": null, "summary": "We consider the asymmetric version of the Popkov-Sch\\\"{u}tz two-lane lattice\ngas with general jump rates, subject to the stationary measure being of product\nform. This still leaves five free parameters. At density $\\tfrac{1}{2}$ the\neigenvalues of the flux Jacobian are degenerate. We compute the second order\nexpansion of the average fluxes at density $\\tfrac{1}{2}$ and thereby identify\nthe universality classes."}
{"id": "2510.12147", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.12147", "abs": "https://arxiv.org/abs/2510.12147", "authors": ["Xindan Zhang", "Jianping Zhao", "Yanren Hou"], "title": "A priori error estimates for stable generalized finite element discretization of parabolic interface optimal control problems", "comment": null, "summary": "In this paper, we investigate optimal control problems governed by the\nparabolic interface equation, in which the control acts on the interface. The\nsolution to this problem exhibits low global regularity due to the jump of the\ncoefficient across the interface and the control acting on the interface.\nConsequently, the traditional finite element method fails to achieve optimal\nconvergence rates when using a uniform mesh. To discretize the problem, we use\nfully discrete approximations based on the stable generalized finite element\nmethod for spatial discretization and the backward Euler scheme for temporal\ndiscretization, as well as variational discretization for the control variable.\nWe prove a priori error estimates for the control, state, and adjoint state.\nNumerical examples are provided to support the theoretical findings."}
{"id": "2510.12180", "categories": ["math.OC", "cs.LG", "35Q89, 49N80"], "pdf": "https://arxiv.org/pdf/2510.12180", "abs": "https://arxiv.org/abs/2510.12180", "authors": ["Mo Zhou", "Haosheng Zhou", "Ruimeng Hu"], "title": "Learning Mean-Field Games through Mean-Field Actor-Critic Flow", "comment": null, "summary": "We propose the Mean-Field Actor-Critic (MFAC) flow, a continuous-time\nlearning dynamics for solving mean-field games (MFGs), combining techniques\nfrom reinforcement learning and optimal transport. The MFAC framework jointly\nevolves the control (actor), value function (critic), and distribution\ncomponents through coupled gradient-based updates governed by partial\ndifferential equations (PDEs). A central innovation is the Optimal Transport\nGeodesic Picard (OTGP) flow, which drives the distribution toward equilibrium\nalong Wasserstein-2 geodesics. We conduct a rigorous convergence analysis using\nLyapunov functionals and establish global exponential convergence of the MFAC\nflow under a suitable timescale. Our results highlight the algorithmic\ninterplay among actor, critic, and distribution components. Numerical\nexperiments illustrate the theoretical findings and demonstrate the\neffectiveness of the MFAC framework in computing MFG equilibria."}
{"id": "2510.12360", "categories": ["eess.SY", "cs.RO", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12360", "abs": "https://arxiv.org/abs/2510.12360", "authors": ["Weijie Ren", "Haowen Liu", "Guang-Ren Duan"], "title": "A Unidirectionally Connected FAS Approach for 6-DOF Quadrotor Control", "comment": "This paper has been submitted to 2026 IFAC World Congress.\n  Corresponding author: Guang-Ren Duan", "summary": "This paper proposes a unidirectionally connected fully actuated system\n(UC-FAS) approach for the sub-stabilization and tracking control of 6-DOF\nquadrotors, tackling limitations both in state-space and FAS framework to some\nextent. The framework systematically converts underactuated quadrotor dynamics\ninto a UC-FAS model, unifying the existing different FAS transformation ways.\nBy eliminating estimation of the high-order derivatives of control inputs, a\ndrawback of current methods, the UC-FAS model simplifies controller design and\nenables direct eigenstructure assignment for closed-loop dynamics. Simulations\ndemonstrate precise 6-DOF tracking performance. This work bridges theoretical\nFAS approach advancements with practical implementation needs, offering a\nstandardized paradigm for nonlinear quadrotor control."}
{"id": "2510.12321", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.12321", "abs": "https://arxiv.org/abs/2510.12321", "authors": ["Yue Zhang", "Shanshan Luo", "Zhi Geng", "Yangbo He"], "title": "Optimal Treatment Rules under Missing Predictive Covariates: A Covariate-Balancing Doubly Robust Approach", "comment": null, "summary": "In precision medicine, one of the most important problems is estimating the\noptimal individualized treatment rules (ITR), which typically involves\nrecommending treatment decisions based on fully observed individual\ncharacteristics of patients to maximize overall clinical benefit. In practice,\nhowever, there may be missing covariates that are not necessarily confounders,\nand it remains uncertain whether these missing covariates should be included\nfor learning optimal ITRs. In this paper, we propose a covariate-balancing\ndoubly robust estimator for constructing optimal ITRs, which is particularly\nsuitable for situations with additional predictive covariates. The proposed\nmethod is based on two main steps: First, the propensity scores are estimated\nby solving the covariate-balancing equation. Second, an objective function is\nminimized to estimate the outcome model, with the function defined by the\nasymptotic variance under the correctly specified propensity score. The method\nhas three significant advantages: (i) It is doubly robust, ensuring consistency\nwhen either the propensity score or outcome model is correctly specified. (ii)\nIt minimizes variance within the class of augmented inverse probability\nweighted estimators. (iii) When applied to partially observed covariates\nrelated to the outcome, the method may further improve estimation efficiency.\nWe demonstrate the proposed method through extensive numerical simulations and\ntwo real-world datasets."}
{"id": "2510.12614", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "nlin.AO", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2510.12614", "abs": "https://arxiv.org/abs/2510.12614", "authors": ["Eric Alejandro Rozan", "Mario Ignacio Simoy", "Sebastian Bouzat", "Marcelo Nestor Kuperman"], "title": "Modeling Epidemics on Multiplex Networks: Epidemic Threshold and Basic Reproduction Number", "comment": "22 pages, 7 figures", "summary": "Accurate epidemic forecasting requires models that account for the layered\nand heterogeneous nature of real social interactions. The basic reproduction\nnumber $\\mathcal R_0$ calculated from models that assume homogeneous mixing or\nsingle-layer contact structures have limited applicability to complex social\nsystems. Here, we propose an expression of $\\mathcal R_0$ in the context of\nmultiplex networks, enabling the analysis of disease transmission across\nmultiple social layers.\n  We adapt the Degree-Based Mean-Field (DBMF) SIR model for single-layered\ncomplex networks to the multiplex setting, where each layer has its own degree\ndistribution and infection rate. Using the Next Generation Matrix method, we\nderive an analytical expression for the basic reproduction number $\\mathcal\nR_0$. Numerical integration of the multiplex DBMF equations shows that\n$\\mathcal R_0 = 1$ marks the epidemic threshold and governs the functional\ndependence of key outbreak indicators. In addition to the exact result for the\n$\\mathcal R_0$, we provide an approximation denoted as $\\tau$, which is easier\nto compute and more straightforward to interpret in terms of the parameters of\nthe system, and shares most of the expected properties of the basic\nreproduction number.\n  Stochastic agent-based simulations confirm these results, demonstrating a\ndirect correspondence between $\\tau$ and the average number of secondary\ninfections in the early epidemic phase, in line with the interpretation of\n$\\mathcal R_0$.\n  This research provides a robust generalization of $\\mathcal R_0$ for layered\ncontact structures, offering a more realistic basis for epidemic forecasting\nand the design of intervention strategies."}
{"id": "2510.12048", "categories": ["stat.ME", "stat.AP", "62R10"], "pdf": "https://arxiv.org/pdf/2510.12048", "abs": "https://arxiv.org/abs/2510.12048", "authors": ["Berkay Akturk", "Ufuk Beyaztas", "Han Lin Shang"], "title": "Robust Functional Logistic Regression", "comment": "31 pages, 5 figures, 2 tables", "summary": "Functional logistic regression is a popular model to capture a linear\nrelationship between binary response and functional predictor variables.\nHowever, many methods used for parameter estimation in functional logistic\nregression are sensitive to outliers, which may lead to inaccurate parameter\nestimates and inferior classification accuracy. We propose a robust estimation\nprocedure for functional logistic regression, in which the observations of the\nfunctional predictor are projected onto a set of finite-dimensional subspaces\nvia robust functional principal component analysis. This dimension-reduction\nstep reduces the outlying effects in the functional predictor. The logistic\nregression coefficient is estimated using an M-type estimator based on binary\nresponse and robust principal component scores. In doing so, we provide robust\nestimates by minimizing the effects of outliers in the binary response and\nfunctional predictor variables. Via a series of Monte-Carlo simulations and\nusing hand radiograph data, we examine the parameter estimation and\nclassification accuracy for the response variable. We find that the robust\nprocedure outperforms some existing robust and non-robust methods when outliers\nare present, while producing competitive results when outliers are absent. In\naddition, the proposed method is computationally more efficient than some\nexisting robust alternatives."}
{"id": "2510.12559", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2510.12559", "abs": "https://arxiv.org/abs/2510.12559", "authors": ["Olesya Razuvayevskaya", "Adel Tayebi", "Ulrikke Dybdal S√∏rensen", "Kalina Bontcheva", "Richard Rogers"], "title": "Timeliness, Consensus, and Composition of the Crowd: Community Notes on X", "comment": null, "summary": "This study presents the first large-scale quantitative analysis of the\nefficiency of X's Community Notes, a crowdsourced moderation system for\nidentifying and contextualising potentially misleading content. Drawing on over\n1.8 million notes, we examine three key dimensions of crowdsourced moderation:\nparticipation inequality, consensus formation, and timeliness. Despite the\nsystem's goal of collective moderation, we find substantial concentration\neffect, with the top 10% of contributors producing 58% of all notes (Gini\nCoefficient = 0.68). The observed consensus is rare-only 11.5% of notes reach\nagreement on publication, while 69% of posts receive conflicting\nclassifications. A majority of noted posts (approximately 68%) are annotated as\n\"Note Not Needed\", reflecting the repurposing of the platform for debate rather\nthan moderation. We found that such posts are paradoxically more likely to\nyield published notes (OR = 3.12). Temporal analyses show that the notes, on\naverage, are published 65.7 hours after the original post, with longer delays\nsignificantly reducing the likelihood of consensus. These results portray\nCommunity Notes as a stratified, deliberative system dominated by a small\ncontributor elite, marked by persistent dissensus, and constrained by\ntimeliness. We conclude this study by outlining design strategies to promote\nequity, faster consensus, and epistemic reliability in community-based\nmoderation."}
{"id": "2510.12682", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2510.12682", "abs": "https://arxiv.org/abs/2510.12682", "authors": ["J. Khatua", "S. M. Kumawat", "G. Senthil Murugan", "C. -L. Huang", "Heung-Sik Kim", "K. Sritharan", "R. Sankar", "Kwang-Yong Choi"], "title": "Possible Bose-Einstein condensation of magnons in a S = 5/2 honeycomb lattice", "comment": null, "summary": "Quantum magnets offer a unique platform for exploring exotic quantum phases\nand quantum phase transitions through external magnetic fields. A prominent\nexample is the field-induced Bose--Einstein condensation (BEC) of magnons near\nthe saturation field. While this behavior has been observed in low-spin\nsystems, its realization in high-spin, quasi-two-dimensional magnets -- where\nmultiple on-site excitations are possible -- remains exceptionally rare. Here,\nwe report thermodynamic and density functional theory results on single\ncrystals of the honeycomb-lattice antiferromagnet K$_{4}$MnMo$_{4}$O$_{15}$\nwith $S = 5/2$. The system undergoes a field-induced transition to a fully\npolarized state at the critical field $\\mu_{0}H_{\\rm s} = 6.4$~T. Our results\nreveal possible thermodynamic signatures of magnon BEC, $T_{\\mathrm{N}} \\sim\n(H_{\\rm s} - H)^{2/d}$ ($d = 3$), expanding the purview of BEC-driven quantum\ncriticality to a high-spin, quasi-two-dimensional antiferromagnets with\nnegligibly small anisotropy."}
{"id": "2510.12382", "categories": ["eess.SY", "cs.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.12382", "abs": "https://arxiv.org/abs/2510.12382", "authors": ["Honglin Wen", "Pierre Pinson"], "title": "Pooling Probabilistic Forecasts for Cooperative Wind Power Offering", "comment": "submission to PSCC 2026, 7 pages", "summary": "Wind power producers can benefit from forming coalitions to participate\ncooperatively in electricity markets. To support such collaboration, various\nprofit allocation rules rooted in cooperative game theory have been proposed.\nHowever, existing approaches overlook the lack of coherence among producers\nregarding forecast information, which may lead to ambiguity in offering and\nallocations. In this paper, we introduce a ``reconcile-then-optimize''\nframework for cooperative market offerings. This framework first aligns the\nindividual forecasts into a coherent joint forecast before determining market\noffers. With such forecasts, we formulate and solve a two-stage stochastic\nprogramming problem to derive both the aggregate offer and the corresponding\nscenario-based dual values for each trading hour. Based on these dual values,\nwe construct a profit allocation rule that is budget-balanced and stable.\nFinally, we validate the proposed method through empirical case studies,\ndemonstrating its practical effectiveness and theoretical soundness."}
{"id": "2510.12696", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.12696", "abs": "https://arxiv.org/abs/2510.12696", "authors": ["Lennart Dabelow"], "title": "Temperature and conditions for thermalization after canonical quenches", "comment": "13 pages, 5 figures", "summary": "We consider quenches of a quantum system that is prepared in a canonical\nequilibrium state of one Hamiltonian and then evolves unitarily in time under a\ndifferent Hamiltonian. Technically, our main result is a systematic expansion\nof the pre- and post-quench canonical ensembles in the quench strength. We\nfirst demonstrate how this can be used to predict the system's temperature\nafter the quench from equilibrium properties at the pre-quench temperature. For\na thermalizing post-quench system, it furthermore allows us to calculate\nequilibrium observable expectation values. Finally, in the presence of\nadditional conserved quantities besides the Hamiltonian, we obtain a hierarchy\nof necessary conditions for thermalization towards the (post-quench) canonical\nensemble. At first order, these thermalization conditions have a nice geometric\ninterpretation in operator space with the canonical covariance as a semi-inner\nproduct: The quench operator (difference between post- and pre-quench\nHamiltonians) and the conserved quantity must be orthogonal in the orthogonal\ncomplement of the post-quench Hamiltonian. We illustrate the results\nnumerically for a variety of setups involving integrable and nonintegrable\nmodels."}
{"id": "2510.12151", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.12151", "abs": "https://arxiv.org/abs/2510.12151", "authors": ["Gang Chen", "Chaoran Liu", "Yangwen Zhang"], "title": "Optimal $L^2$ error estimation for the unfitted interface finite element method based on the non-symmetric Nitsche's methods", "comment": null, "summary": "This paper establishes optimal error estimates in the $L^2$ for the\nnon-symmetric Nitsche method in an unfitted interface finite element setting.\nExtending our earlier work, we give a complete analysis for the Poisson\ninterface model and, by formulating a tailored dual problem that restores\nadjoint consistency, derive the desired bounds."}
{"id": "2510.12238", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.12238", "abs": "https://arxiv.org/abs/2510.12238", "authors": ["Boyang Zhang", "Zhiguo Wang", "Ya-Feng Liu"], "title": "A Gradient Guided Diffusion Framework for Chance Constrained Programming", "comment": null, "summary": "Chance constrained programming (CCP) is a powerful framework for addressing\noptimization problems under uncertainty. In this paper, we introduce a novel\nGradient-Guided Diffusion-based Optimization framework, termed GGDOpt, which\ntackles CCP through three key innovations. First, GGDOpt accommodates a broad\nclass of CCP problems without requiring the knowledge of the exact distribution\nof uncertainty-relying solely on a set of samples. Second, to address the\nnonconvexity of the chance constraints, it reformulates the CCP as a sampling\nproblem over the product of two distributions: an unknown data distribution\nsupported on a nonconvex set and a Boltzmann distribution defined by the\nobjective function, which fully leverages both first- and second-order gradient\ninformation. Third, GGDOpt has theoretical convergence guarantees and provides\npractical error bounds under mild assumptions. By progressively injecting noise\nduring the forward diffusion process to convexify the nonconvex feasible\nregion, GGDOpt enables guided reverse sampling to generate asymptotically\noptimal solutions. Experimental results on synthetic datasets and a waveform\ndesign task in wireless communications demonstrate that GGDOpt outperforms\nexisting methods in both solution quality and stability with nearly 80%\noverhead reduction."}
{"id": "2510.12382", "categories": ["eess.SY", "cs.SY", "stat.AP"], "pdf": "https://arxiv.org/pdf/2510.12382", "abs": "https://arxiv.org/abs/2510.12382", "authors": ["Honglin Wen", "Pierre Pinson"], "title": "Pooling Probabilistic Forecasts for Cooperative Wind Power Offering", "comment": "submission to PSCC 2026, 7 pages", "summary": "Wind power producers can benefit from forming coalitions to participate\ncooperatively in electricity markets. To support such collaboration, various\nprofit allocation rules rooted in cooperative game theory have been proposed.\nHowever, existing approaches overlook the lack of coherence among producers\nregarding forecast information, which may lead to ambiguity in offering and\nallocations. In this paper, we introduce a ``reconcile-then-optimize''\nframework for cooperative market offerings. This framework first aligns the\nindividual forecasts into a coherent joint forecast before determining market\noffers. With such forecasts, we formulate and solve a two-stage stochastic\nprogramming problem to derive both the aggregate offer and the corresponding\nscenario-based dual values for each trading hour. Based on these dual values,\nwe construct a profit allocation rule that is budget-balanced and stable.\nFinally, we validate the proposed method through empirical case studies,\ndemonstrating its practical effectiveness and theoretical soundness."}
{"id": "2510.12301", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.12301", "abs": "https://arxiv.org/abs/2510.12301", "authors": ["David Kronthaler", "Leonhard Held"], "title": "Edgington's Method for Random-Effects Meta-Analysis Part I: Estimation", "comment": null, "summary": "Meta-analysis can be formulated as combining $p$-values across studies into a\njoint $p$-value function, from which point estimates and confidence intervals\ncan be derived. We extend the meta-analytic estimation framework based on\ncombined $p$-value functions to incorporate uncertainty in heterogeneity\nestimation by employing a confidence distribution approach. Specifically, the\nconfidence distribution of Edgington's method is adjusted according to the\nconfidence distribution of the heterogeneity parameter constructed from the\ngeneralized heterogeneity statistic. Simulation results suggest that 95%\nconfidence intervals approach nominal coverage under most scenarios involving\nmore than three studies and heterogeneity. Under no heterogeneity or for only\nthree studies, the confidence interval typically overcovers, but is often\nnarrower than the Hartung-Knapp-Sidik-Jonkman interval. The point estimator\nexhibits small bias under model misspecification and moderate to large\nheterogeneity. Edgington's method provides a practical alternative to classical\napproaches, with adjustment for heterogeneity estimation uncertainty often\nimproving confidence interval coverage."}
{"id": "2510.12786", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2510.12786", "abs": "https://arxiv.org/abs/2510.12786", "authors": ["C. Iorio-Duval", "E. Beauchesne-Blanchet", "F. Perreault", "J. L. Santana Gonz√°lez", "W. Sun", "Y. F. Nie", "A. Gourgout", "G. Grissonnanche"], "title": "Quantum criticality at the end of a pseudogap phase in superconducting infinite-layer nickelates", "comment": "8 pages, 3 figures", "summary": "In many unconventional superconductors, the strange-metal regime is thought\nto emerge from quantum criticality, yet in cuprates this link is obscured by\nthe enigmatic pseudogap. Superconducting infinite-layer nickelates provide a\nnew arena to test this paradigm but are constrained to thin films, precluding\ncalorimetry. We use the Seebeck coefficient as a low-temperature proxy for\nentropy per carrier and uncover a clear quantum-critical thermodynamic\nsignature: in La$_{1-x}$Sr$_x$NiO$_2$ at the onset of $T$-linear resistivity\n($x=0.20$), $S/T$ diverges logarithmically upon cooling, $S/T \\propto \\log T$.\nBoltzmann transport based on ARPES-derived band structure reproduces the\nhigh-temperature magnitude and sign of $S/T$ and reveals a threefold mass\nrenormalization at the Fermi level. To identify the terminating phase, we\nanalyze Hall data across Nd$_{1-x}$Sr$_x$NiO$_2$ and show that its temperature\nevolution is quantitatively captured by a minimal two-band model in which a\nstrongly correlated Ni-$d_{x^2-y^2}$ Fermi surface exhibits Planckian\n$T$-linear scattering while the rare-earth Nd-$s$ pocket remains\nFermi-liquid-like. Inverting the zero-temperature Hall response reveals a\ncollapse of the Ni-$d_{x^2-y^2}$ band carrier density from $1+p$ to $p$ holes\nacross the critical doping, without long-range magnetic order -- mirroring the\ncuprate pseudogap transition in cuprates. These results establish a quantum\ncritical point at the end of a pseudogap-like phase in infinite-layer\nnickelates and unify the broader paradigm among correlated superconductors that\nstrange metal behaviour is intimately linked to quantum criticality."}
{"id": "2510.12407", "categories": ["eess.SY", "cs.ET", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12407", "abs": "https://arxiv.org/abs/2510.12407", "authors": ["Fabrizio Orlando", "Deborah Volpe", "Giacomo Orlandi", "Mariagrazia Graziano", "Fabrizio Riente", "Marco Vacca"], "title": "High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization", "comment": null, "summary": "Combinatorial Optimization (CO) problems exhibit exponential complexity,\nmaking their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a\nquantum-inspired algorithm to obtain approximate solutions to largescale CO\nproblems written in the Ising form. It explores the solution space by emulating\nthe adiabatic evolution of a network of Kerr-nonlinear parametric oscillators\n(KPOs), where each oscillator represents a variable in the problem. The optimal\nsolution corresponds to the ground state of this system. A key advantage of\nthis approach is the possibility of updating multiple variables simultaneously,\nmaking it particularly suited for hardware implementation. To enhance solution\nquality and convergence speed, variations of the algorithm have been proposed\nin the literature, including ballistic (bSB), discrete (dSB), and thermal\n(HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and\nHbSB using dedicated software models, evaluating the feasibility of using a\nfixed-point representation for hardware implementation. We then present an\nopensource hardware architecture implementing the dSB algorithm for\nField-Programmable Gate Arrays (FPGAs). The design allows users to adjust the\ndegree of algorithmic parallelization based on their specific requirements. A\nproof-of-concept implementation that solves 256-variable problems was achieved\non an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut\nand knapsack problems."}
{"id": "2510.11831", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech", "math-ph", "math.MP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2510.11831", "abs": "https://arxiv.org/abs/2510.11831", "authors": ["Ben T. McDonough", "Marius Lemm", "Andrew Lucas"], "title": "Non-perturbatively slow spread of quantum correlations in non-resonant systems", "comment": null, "summary": "Strong disorder often has drastic consequences for quantum dynamics. This is\nbest illustrated by the phenomenon of Anderson localization in non-interacting\nsystems, where destructive quantum wave interference leads to the complete\nabsence of particle and information transport over macroscopic distances. In\nthis work, we investigate the extent to which strong disorder leads to provably\nslow dynamics in many-body quantum lattice models. We show that in any spatial\ndimension, strong disorder leads to a non-perturbatively small velocity for\nballistic information transport under unitary quantum dynamics, almost surely\nin the thermodynamic limit, in every many-body state. In these models, we also\nprove the existence of a \"prethermal many-body localized regime\", where\nentanglement spreads logarithmically slowly, up to non-perturbatively long time\nscales. More generally, these conclusions hold for all models corresponding to\nquantum perturbations to a classical Hamiltonian obeying a simple non-resonant\ncondition. Deterministic non-resonant models are found, including spin systems\nin strong incommensurate lattice potentials. Consequently, quantum dynamics in\nnon-resonant potentials is asymptotically easier to simulate on both classical\nor quantum computers, compared to a generic many-body system."}
{"id": "2510.12188", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.12188", "abs": "https://arxiv.org/abs/2510.12188", "authors": ["Hao Zhang", "Kexin Li", "Wenlin Qiu"], "title": "Spatial two-grid compact difference scheme for two-dimensional nonlinear diffusion-wave equations with variable exponent", "comment": null, "summary": "This paper presents a spatial two-grid (STG) compact difference scheme for a\ntwo-dimensional (2D) nonlinear diffusion-wave equation with variable exponent,\nwhich describes, e.g., the propagation of mechanical diffusive waves in\nviscoelastic media with varying material properties. Following the idea of the\nconvolution approach, the diffusion-wave model is first transformed into an\nequivalent formulation. A fully discrete scheme is then developed by applying a\ncompact difference approximation in space and combining the averaged product\nintegration rule with linear interpolation quadrature in time. An efficient\nhigh-order two-grid algorithm is constructed by solving a small-scale nonlinear\nsystem on the coarse grid and a large-scale linearized system on the fine grid,\nwhere the bicubic spline interpolation operator is used to project coarse-grid\nsolutions to the fine grid. Under mild assumptions on the variable exponent\n$\\alpha(t)$, the stability and convergence of the STG compact difference scheme\nare rigorously established. Numerical experiments are finally presented to\nverify the accuracy and efficiency of the proposed method."}
{"id": "2510.12244", "categories": ["math.OC", "math.FA", "49J52, 52A41, 90C25", "G.1.6"], "pdf": "https://arxiv.org/pdf/2510.12244", "abs": "https://arxiv.org/abs/2510.12244", "authors": ["Matthew S. Scott"], "title": "Bilateral facial reduction: qualification-free subdifferential calculus and exact duality in convex analysis", "comment": "22 pages", "summary": "This paper introduces a geometric framework to extend convex analysis results\nbeyond standard qualification conditions such as intersecting relative\ninteriors of domains. We define the joint facial subspace $T$ as the span of\nthe face of $C - D$ generated by $0$, with its affine translation $T_a$\ncontaining $C \\cap D$. The intersections $C \\cap T_a$ and $D \\cap T_a$ are\nfaces of the original sets, establishing $T_a$ as a bilateral facial reduction\nwith parallels to Borwein-Wolkowicz facial reduction in conic programming. When\nreducing the domains of two convex functions to their joint facial subspace\n$T_a$, their relative interiors then always intersect, enabling unqualified\napplication of classical theorems via localization. Key generalizations include\nsubdifferential additivity, normal cones of intersections, a subdifferential\nchain rule, attained infimal convolution for $(f+g)^*,$ and an exact\nFenchel-Rockafellar dual. We characterize $T$ via generated faces and\ncomputationally through an iterative process converging in at most $n$ steps in\n$\\mathbb{R}^n$. Proofs are self-contained and introduce novel concepts like\nfacial subspaces and nested normals to describe convex boundaries and the\nlattice of faces."}
{"id": "2510.12407", "categories": ["eess.SY", "cs.ET", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12407", "abs": "https://arxiv.org/abs/2510.12407", "authors": ["Fabrizio Orlando", "Deborah Volpe", "Giacomo Orlandi", "Mariagrazia Graziano", "Fabrizio Riente", "Marco Vacca"], "title": "High-Parallel FPGA-Based Discrete Simulated Bifurcation for Large-Scale Optimization", "comment": null, "summary": "Combinatorial Optimization (CO) problems exhibit exponential complexity,\nmaking their resolution challenging. Simulated Adiabatic Bifurcation (aSB) is a\nquantum-inspired algorithm to obtain approximate solutions to largescale CO\nproblems written in the Ising form. It explores the solution space by emulating\nthe adiabatic evolution of a network of Kerr-nonlinear parametric oscillators\n(KPOs), where each oscillator represents a variable in the problem. The optimal\nsolution corresponds to the ground state of this system. A key advantage of\nthis approach is the possibility of updating multiple variables simultaneously,\nmaking it particularly suited for hardware implementation. To enhance solution\nquality and convergence speed, variations of the algorithm have been proposed\nin the literature, including ballistic (bSB), discrete (dSB), and thermal\n(HbSB) versions. In this work, we have comprehensively analyzed dSB, bSB, and\nHbSB using dedicated software models, evaluating the feasibility of using a\nfixed-point representation for hardware implementation. We then present an\nopensource hardware architecture implementing the dSB algorithm for\nField-Programmable Gate Arrays (FPGAs). The design allows users to adjust the\ndegree of algorithmic parallelization based on their specific requirements. A\nproof-of-concept implementation that solves 256-variable problems was achieved\non an AMD Kria KV260 SoM, a low-tier FPGA, validated using well-known max-cut\nand knapsack problems."}
{"id": "2510.12321", "categories": ["stat.ME", "math.ST", "stat.TH"], "pdf": "https://arxiv.org/pdf/2510.12321", "abs": "https://arxiv.org/abs/2510.12321", "authors": ["Yue Zhang", "Shanshan Luo", "Zhi Geng", "Yangbo He"], "title": "Optimal Treatment Rules under Missing Predictive Covariates: A Covariate-Balancing Doubly Robust Approach", "comment": null, "summary": "In precision medicine, one of the most important problems is estimating the\noptimal individualized treatment rules (ITR), which typically involves\nrecommending treatment decisions based on fully observed individual\ncharacteristics of patients to maximize overall clinical benefit. In practice,\nhowever, there may be missing covariates that are not necessarily confounders,\nand it remains uncertain whether these missing covariates should be included\nfor learning optimal ITRs. In this paper, we propose a covariate-balancing\ndoubly robust estimator for constructing optimal ITRs, which is particularly\nsuitable for situations with additional predictive covariates. The proposed\nmethod is based on two main steps: First, the propensity scores are estimated\nby solving the covariate-balancing equation. Second, an objective function is\nminimized to estimate the outcome model, with the function defined by the\nasymptotic variance under the correctly specified propensity score. The method\nhas three significant advantages: (i) It is doubly robust, ensuring consistency\nwhen either the propensity score or outcome model is correctly specified. (ii)\nIt minimizes variance within the class of augmented inverse probability\nweighted estimators. (iii) When applied to partially observed covariates\nrelated to the outcome, the method may further improve estimation efficiency.\nWe demonstrate the proposed method through extensive numerical simulations and\ntwo real-world datasets."}
{"id": "2510.12539", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12539", "abs": "https://arxiv.org/abs/2510.12539", "authors": ["Zhanle Zhao", "Son Dinh-Van", "Yuen Kwan Mo", "Siddartha Khastgir", "Matthew D. Higgins"], "title": "Optimising Communication Control Factors for Energy Consumption in Rural LOS V2X", "comment": null, "summary": "Connected braking can reduce fatal collisions in connected and autonomous\nvehicles (CAVs) by using reliable, low-latency 5G New Radio (NR) links,\nespecially NR Sidelink Vehicle-to-Everything (V2X). In rural areas, road side\nunits are sparse and power-constrained or off-grid, so energy efficiency must\nbe considered alongside safety. This paper studies how three communication\ncontrol factors including subcarrier spacing ($\\mathrm{SCS}$), modulation and\ncoding scheme ($\\mathrm{MCS}$), and transmit power ($P_{\\mathrm{t}}$) should be\nconfigured to balance safety and energy consumption in rural line-of-sight\n(LOS) scenarios in light and heavy traffic scenarios. Safety is quantified by\nthe packet receive ratio ($\\mathrm{PRR}$) against the minimum communication\ndistance $D_{\\mathrm{comm}}$, defined as the distance that the vehicle travels\nduring the transmission of the safety message. Results show that, under heavy\ntraffic, increasing $P_{\\mathrm{t}}$ and selecting a low-rate $\\mathrm{MCS}$ at\n$\\mathrm{SCS} = 30$ kHz sustains high $\\mathrm{PRR}$ at $D_{\\mathrm{comm}}$,\nalbeit with higher energy cost. In light traffic, maintaining lower\n$P_\\mathrm{t}$ with low $\\mathrm{MCS}$ levels achieves a favorable\nreliability-energy trade-off while preserving acceptable $\\mathrm{PRR}$ at\n$D_{\\mathrm{comm}}$. These findings demonstrate the necessity of adaptive,\nenergy-aware strategy to guarantee both safety and energy efficiency in rural\nV2X systems."}
{"id": "2510.12286", "categories": ["cond-mat.dis-nn", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.12286", "abs": "https://arxiv.org/abs/2510.12286", "authors": ["Stefano Gagliani", "Feliciano Giuseppe Pacifico", "Lorenzo Chicchi", "Duccio Fanelli", "Diego Febbe", "Lorenzo Buffoni", "Raffaele Marino"], "title": "Train Stochastic Non Linear Coupled ODEs to Classify and Generate", "comment": null, "summary": "A general class of dynamical systems which can be trained to operate in\nclassification and generation modes are introduced. A procedure is proposed to\nplant asymptotic stationary attractors of the deterministic model. Optimizing\nthe dynamical system amounts to shaping the architecture of inter-nodes\nconnection to steer the evolution towards the assigned equilibrium, as a\nfunction of the class to which the item - supplied as an initial condition -\nbelongs to. Under the stochastic perspective, point attractors are turned into\nprobability distributions, made analytically accessible via the linear noise\napproximation. The addition of noise proves beneficial to oppose adversarial\nattacks, a property that gets engraved into the trained adjacency matrix and\ntherefore also inherited by the deterministic counterpart of the optimized\nstochastic model. By providing samples from the target distribution as an input\nto a feedforward neural network (or even to a dynamical model of the same\ntypology of the adopted for classification purposes), yields a fully generative\nscheme. Conditional generation is also possible by merging classification and\ngeneration modalities. Automatic disentanglement of isolated key features is\nfinally proven."}
{"id": "2510.12307", "categories": ["math.NA", "cs.NA", "65N30, 65N15, 74D05"], "pdf": "https://arxiv.org/pdf/2510.12307", "abs": "https://arxiv.org/abs/2510.12307", "authors": ["Isaac Bermudez", "Bryan Gomez-Vargas", "Andres E. Rubiano", "Ricardo Ruiz-Baier"], "title": "Fully mixed virtual element schemes for steady-state poroelastic stress-assisted diffusion", "comment": null, "summary": "We propose a fully mixed virtual element method for the numerical\napproximation of the coupling between stress-altered diffusion and linear\nelasticity equations with strong symmetry of total poroelastic stress (using\nthe Hellinger--Reissner principle). A novelty of this work is that we introduce\na less restrictive assumption on the stress-assisted diffusion coefficient,\nrequiring an analysis of the perturbed diffusion equation using Banach spaces.\nThe solvability of the continuous and discrete problems is established using a\nsuitable modification of the abstract theory for perturbed saddle-point\nproblems in Banach spaces (which is in itself a new result of independent\ninterest). In addition, we establish optimal a priori error estimates. The\nmethod and its analysis are robust with respect to the poromechanical\nparameters. We also include a number of numerical examples that illustrate the\nproperties of the proposed scheme."}
{"id": "2510.12333", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.12333", "abs": "https://arxiv.org/abs/2510.12333", "authors": ["Yingjie Ma", "Jing Guo", "Alexis B. Dubs", "Krystian K. Ganko", "Richard D. Braatz"], "title": "Adaptive Nonlinear Model Predictive Control of Monoclonal Antibody Glycosylation in CHO Cell Culture", "comment": null, "summary": "N-glycosylation is a critical quality attribute of monoclonal antibodies\n(mAbs), the dominant class of biopharmaceuticals. Controlling glycosylation\nremains difficult due to intrinsic pathway complexity, limited online\nmeasurements, and a lack of tailored control strategies. This work applies an\nadaptive nonlinear model predictive control (ANMPC) framework to a fed-batch\nmAb production process, using a multiscale model that links extracellular\nconditions to intracellular Golgi reactions to predict glycan profiles. Model\nparameters are updated online as new measurements arrive, after which a\nshrinking-horizon optimization computes the control inputs; only the first\ncontrol move is implemented each cycle. Case studies show that, with a minimal\nday-1 galactose excitation, ANMPC mitigates model-plant mismatch and achieves\nup to 130% and 96% higher performance than open-loop optimization and state\nNMPC, respectively. Under more realistic conditions (partial measurement\navailability and longer preparation time), ANMPC maintains comparable\nperformance, indicating robustness to practical limitations. Overall, the\nresults demonstrate that ANMPC can actively shape glycan distributions in\nsilico and offers a viable path toward closed-loop control of mAb\nglycosylation."}
{"id": "2510.12539", "categories": ["eess.SY", "cs.SY", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.12539", "abs": "https://arxiv.org/abs/2510.12539", "authors": ["Zhanle Zhao", "Son Dinh-Van", "Yuen Kwan Mo", "Siddartha Khastgir", "Matthew D. Higgins"], "title": "Optimising Communication Control Factors for Energy Consumption in Rural LOS V2X", "comment": null, "summary": "Connected braking can reduce fatal collisions in connected and autonomous\nvehicles (CAVs) by using reliable, low-latency 5G New Radio (NR) links,\nespecially NR Sidelink Vehicle-to-Everything (V2X). In rural areas, road side\nunits are sparse and power-constrained or off-grid, so energy efficiency must\nbe considered alongside safety. This paper studies how three communication\ncontrol factors including subcarrier spacing ($\\mathrm{SCS}$), modulation and\ncoding scheme ($\\mathrm{MCS}$), and transmit power ($P_{\\mathrm{t}}$) should be\nconfigured to balance safety and energy consumption in rural line-of-sight\n(LOS) scenarios in light and heavy traffic scenarios. Safety is quantified by\nthe packet receive ratio ($\\mathrm{PRR}$) against the minimum communication\ndistance $D_{\\mathrm{comm}}$, defined as the distance that the vehicle travels\nduring the transmission of the safety message. Results show that, under heavy\ntraffic, increasing $P_{\\mathrm{t}}$ and selecting a low-rate $\\mathrm{MCS}$ at\n$\\mathrm{SCS} = 30$ kHz sustains high $\\mathrm{PRR}$ at $D_{\\mathrm{comm}}$,\nalbeit with higher energy cost. In light traffic, maintaining lower\n$P_\\mathrm{t}$ with low $\\mathrm{MCS}$ levels achieves a favorable\nreliability-energy trade-off while preserving acceptable $\\mathrm{PRR}$ at\n$D_{\\mathrm{comm}}$. These findings demonstrate the necessity of adaptive,\nenergy-aware strategy to guarantee both safety and energy efficiency in rural\nV2X systems."}
{"id": "2510.12337", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.12337", "abs": "https://arxiv.org/abs/2510.12337", "authors": ["Nina Drobac", "Margaux Br√©g√®re", "Joseph de Vilmarest", "Olivier Wintenberger"], "title": "Sliding-Window Signatures for Time Series: Application to Electricity Demand Forecasting", "comment": null, "summary": "Nonlinear and delayed effects of covariates often render time series\nforecasting challenging. To this end, we propose a novel forecasting framework\nbased on ridge regression with signature features calculated on sliding\nwindows. These features capture complex temporal dynamics without relying on\nlearned or hand-crafted representations. Focusing on the discrete-time setting,\nwe establish theoretical guarantees, namely universality of approximation and\nstationarity of signatures. We introduce an efficient sequential algorithm for\ncomputing signatures on sliding windows. The method is evaluated on both\nsynthetic and real electricity demand data. Results show that signature\nfeatures effectively encode temporal and nonlinear dependencies, yielding\naccurate forecasts competitive with those based on expert knowledge."}
{"id": "2510.12549", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12549", "abs": "https://arxiv.org/abs/2510.12549", "authors": ["Jieming Ke", "Jimin Wang", "Ji-Feng Zhang"], "title": "Privacy-Preserving Distributed Estimation with Limited Data Rate", "comment": null, "summary": "This paper focuses on the privacy-preserving distributed estimation problem\nwith a limited data rate, where the observations are the sensitive information.\nSpecifically, a binary-valued quantizer-based privacy-preserving distributed\nestimation algorithm is developed, which improves the algorithm's\nprivacy-preserving capability and simultaneously reduces the communication\ncosts. The algorithm's privacy-preserving capability, measured by the Fisher\ninformation matrix, is dynamically enhanced over time. Notably, the Fisher\ninformation matrix of the output signals with respect to the sensitive\ninformation converges to zero at a polynomial rate, and the improvement in\nprivacy brought by the quantizers is quantitatively characterized as a\nmultiplicative effect. Regarding the communication costs, each sensor transmits\nonly 1 bit of information to its neighbours at each time step. Additionally,\nthe assumption on the negligible quantization error for real-valued messages is\nnot required. While achieving the requirements of privacy preservation and\nreducing communication costs, the algorithm ensures that its estimates converge\nalmost surely to the true value of the unknown parameter by establishing a\nco-design guideline for the time-varying privacy noises and step-sizes. A\npolynomial almost sure convergence rate is obtained, and then the trade-off\nbetween privacy and convergence rate is established. Numerical examples\ndemonstrate the main results."}
{"id": "2510.12532", "categories": ["nlin.CD", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2510.12532", "abs": "https://arxiv.org/abs/2510.12532", "authors": ["Domenico Lippolis"], "title": "Spatiotemporal stability of synchronized coupled map lattice states", "comment": "15 pages, 5 figures", "summary": "In the realm of spatiotemporal chaos, unstable periodic orbits play a major\nrole in understanding the dynamics. Their stability changes and bifurcations in\ngeneral are thus of central interest. Here, coupled map lattice discretizations\nof nonlinear partial differential equations, exhibiting a variety of behaviors\ndepending on the coupling strength, are considered. In particular, the linear\nstability analysis of synchronized states is performed by evaluating the\nBravais lattice orbit Jacobian in its reciprocal space first Brillouin zone,\nwith space and time treated on equal grounds. The eigenvalues of the orbit\nJacobian operator, computed as functions of the coupling strength, tell us\nabout the stability of the periodic orbit under a perturbation of a certain\ntime- and space frequency. Moreover, the stability under aperiodic, that is,\nincoherent perturbations, is revealed by integrating the sum of the stability\nexponents over all space-time frequencies."}
{"id": "2510.12499", "categories": ["math.NA", "cs.NA", "65M06, 65M12, 76A15", "G.1.8; I.6.8"], "pdf": "https://arxiv.org/pdf/2510.12499", "abs": "https://arxiv.org/abs/2510.12499", "authors": ["Wenshuai Hu", "Guanghua Ji"], "title": "On the maximum bound principle and energy dissipation of exponential time differencing methods for the chiral liquid crystal blue phases", "comment": "35 pages, 5 figures", "summary": "The blue phases are fascinating and complex states of chiral liquid crystals\nwhich can be modeled by a comprehensive framework of the Landau-de theory,\nsatisfying energy dissipation and maximum bound principle.\n  In this paper, we develop and analyze first and second order exponential time\ndifferencing numerical schemes for the gradient flow of the chiral liquid\ncrystal blue phases, which preserve the maximum bound principle and energy\ndissipation unconditionally at the semi-discrete level.\n  The fully discrete schemes are obtained coupled with the Fourier spectral\nmethod in space.\n  And we propose a novel matrix-form Helmholtz basis transformation method to\ndiagonalize the combined operator of the Laplacian and the curl operator, which\nis a key step in the implementation of the proposed schemes.\n  Then by constructing auxiliary functions, we drive the $L^\\infty$ boundedness\nof the numerical solutions and obtain the energy dissipation and the error\nestimates in $L^2$ and $L^\\infty$ norm.\n  Various numerical experiments are presented to validate the theoretical\nresults and demonstrate the effectiveness of the proposed methods in simulating\nthe dynamics of blue phases in chiral liquid crystals."}
{"id": "2510.12345", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.12345", "abs": "https://arxiv.org/abs/2510.12345", "authors": ["Said Boulite", "Abdellatif Elgrou", "Lahcen Maniar", "Abdelaziz Rhandi"], "title": "Carleman Estimates and Controllability of Forward Stochastic Parabolic Equations with General Dynamic Boundary Conditions", "comment": null, "summary": "We derive a new Carleman estimate for a general backward stochastic parabolic\nequation with dynamic boundary conditions, incorporating weak divergence source\nterms in both the bulk and surface equations. This estimate is obtained through\ntwo main steps: first, by refining a known Carleman estimate for backward\nstochastic parabolic equations to explicitly account for the dependence of the\nparameters on the final control time \\(T\\); second, by applying a duality\ntechnique to address weak divergence source terms. As an application, we prove\nthe null and approximate controllability of forward stochastic parabolic\nequations with dynamic boundary conditions, which involve both reaction and\nconvection terms with bounded adapted coefficients, as well as general\nsecond-order parabolic operators. Additionally, we provide an explicit estimate\nfor the null-controllability cost in terms of the final control time \\(T\\) and\nthe coefficients of the equation."}
{"id": "2510.12549", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12549", "abs": "https://arxiv.org/abs/2510.12549", "authors": ["Jieming Ke", "Jimin Wang", "Ji-Feng Zhang"], "title": "Privacy-Preserving Distributed Estimation with Limited Data Rate", "comment": null, "summary": "This paper focuses on the privacy-preserving distributed estimation problem\nwith a limited data rate, where the observations are the sensitive information.\nSpecifically, a binary-valued quantizer-based privacy-preserving distributed\nestimation algorithm is developed, which improves the algorithm's\nprivacy-preserving capability and simultaneously reduces the communication\ncosts. The algorithm's privacy-preserving capability, measured by the Fisher\ninformation matrix, is dynamically enhanced over time. Notably, the Fisher\ninformation matrix of the output signals with respect to the sensitive\ninformation converges to zero at a polynomial rate, and the improvement in\nprivacy brought by the quantizers is quantitatively characterized as a\nmultiplicative effect. Regarding the communication costs, each sensor transmits\nonly 1 bit of information to its neighbours at each time step. Additionally,\nthe assumption on the negligible quantization error for real-valued messages is\nnot required. While achieving the requirements of privacy preservation and\nreducing communication costs, the algorithm ensures that its estimates converge\nalmost surely to the true value of the unknown parameter by establishing a\nco-design guideline for the time-varying privacy noises and step-sizes. A\npolynomial almost sure convergence rate is obtained, and then the trade-off\nbetween privacy and convergence rate is established. Numerical examples\ndemonstrate the main results."}
{"id": "2510.12356", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.12356", "abs": "https://arxiv.org/abs/2510.12356", "authors": ["Virginia Murru", "Matt P. Wand"], "title": "Variational Inference for Count Response Semiparametric Regression: A Convex Solution", "comment": null, "summary": "We develop a version of variational inference for Bayesian count response\nregression-type models that possesses attractive attributes such as convexity\nand closed form updates. The convex solution aspect entails numerically stable\nfitting algorithms, whilst the closed form aspect makes the methodology fast\nand easy to implement. The essence of the approach is the use of P\\'olya-Gamma\naugmentation of a Negative Binomial likelihood, a finite-valued prior on the\nshape parameter and the structured mean field variational Bayes paradigm. The\napproach applies to general count response situations. For concreteness, we\nfocus on generalized linear mixed models within the semiparametric regression\nclass of models. Real-time fitting is also described."}
{"id": "2510.12589", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12589", "abs": "https://arxiv.org/abs/2510.12589", "authors": ["Hadi Nemati", "√Ålvaro Ortega", "Pedro S√°nchez-Mart√≠n", "Lukas Sigrist", "Luis Rouco", "Ignacio Egido"], "title": "Enhancing Robust Multi-Market Participation of Renewable-Based VPPs through Flexible Resources", "comment": null, "summary": "In the transition toward a sustainable power system, renewable-based Virtual\nPower Plants (RVPPs) have emerged as a promising solution to the challenges of\nintegrating renewable energy sources into electricity markets. Their viability,\nhowever, depends on effective market participation strategies and the ability\nto manage uncertainties while leveraging flexible resources. This paper\nanalyzes the impact of different flexible resources - such as concentrated\nsolar power plants, hydro plants, biomass plants, and flexible demand - on the\nparticipation of RVPPs in energy and reserve markets. Multiple sources of\nuncertainty in generation, consumption, and electricity prices are addressed\nusing a two-stage robust optimization approach. The contribution of different\ntechnologies to RVPP profitability is evaluated through a marginal contribution\nmethod, ensuring fair allocation of profits among them according to their\nactual role in energy and reserve provision across markets. Simulations for an\nRVPP in southern Spain demonstrate how strategic decisions and the availability\nof flexible resources influence viability, market participation, and unit\nscheduling."}
{"id": "2510.12614", "categories": ["physics.soc-ph", "cond-mat.stat-mech", "nlin.AO", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2510.12614", "abs": "https://arxiv.org/abs/2510.12614", "authors": ["Eric Alejandro Rozan", "Mario Ignacio Simoy", "Sebastian Bouzat", "Marcelo Nestor Kuperman"], "title": "Modeling Epidemics on Multiplex Networks: Epidemic Threshold and Basic Reproduction Number", "comment": "22 pages, 7 figures", "summary": "Accurate epidemic forecasting requires models that account for the layered\nand heterogeneous nature of real social interactions. The basic reproduction\nnumber $\\mathcal R_0$ calculated from models that assume homogeneous mixing or\nsingle-layer contact structures have limited applicability to complex social\nsystems. Here, we propose an expression of $\\mathcal R_0$ in the context of\nmultiplex networks, enabling the analysis of disease transmission across\nmultiple social layers.\n  We adapt the Degree-Based Mean-Field (DBMF) SIR model for single-layered\ncomplex networks to the multiplex setting, where each layer has its own degree\ndistribution and infection rate. Using the Next Generation Matrix method, we\nderive an analytical expression for the basic reproduction number $\\mathcal\nR_0$. Numerical integration of the multiplex DBMF equations shows that\n$\\mathcal R_0 = 1$ marks the epidemic threshold and governs the functional\ndependence of key outbreak indicators. In addition to the exact result for the\n$\\mathcal R_0$, we provide an approximation denoted as $\\tau$, which is easier\nto compute and more straightforward to interpret in terms of the parameters of\nthe system, and shares most of the expected properties of the basic\nreproduction number.\n  Stochastic agent-based simulations confirm these results, demonstrating a\ndirect correspondence between $\\tau$ and the average number of secondary\ninfections in the early epidemic phase, in line with the interpretation of\n$\\mathcal R_0$.\n  This research provides a robust generalization of $\\mathcal R_0$ for layered\ncontact structures, offering a more realistic basis for epidemic forecasting\nand the design of intervention strategies."}
{"id": "2510.12521", "categories": ["math.NA", "cs.LG", "cs.NA", "65J20, 68T05"], "pdf": "https://arxiv.org/pdf/2510.12521", "abs": "https://arxiv.org/abs/2510.12521", "authors": ["Sebastian Banert", "Christoph Brauer", "Dirk Lorenz", "Lionel Tondji"], "title": "Why the noise model matters: A performance gap in learned regularization", "comment": null, "summary": "This article addresses the challenge of learning effective regularizers for\nlinear inverse problems. We analyze and compare several types of learned\nvariational regularization against the theoretical benchmark of the optimal\naffine reconstruction, i.e. the best possible affine linear map for minimizing\nthe mean squared error. It is known that this optimal reconstruction can be\nachieved using Tikhonov regularization, but this requires precise knowledge of\nthe noise covariance to properly weight the data fidelity term. However, in\nmany practical applications, noise statistics are unknown. We therefore\ninvestigate the performance of regularization methods learned without access to\nthis noise information, focusing on Tikhonov, Lavrentiev, and quadratic\nregularization. Our theoretical analysis and numerical experiments demonstrate\nthat for non-white noise, a performance gap emerges between these methods and\nthe optimal affine reconstruction. Furthermore, we show that these different\ntypes of regularization yield distinct results, highlighting that the choice of\nregularizer structure is critical when the noise model is not explicitly\nlearned. Our findings underscore the significant value of accurately modeling\nor co-learning noise statistics in data-driven regularization."}
{"id": "2510.12374", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.12374", "abs": "https://arxiv.org/abs/2510.12374", "authors": ["Zilong Cui", "Ran Gu"], "title": "Heuristic Bundle Upper Bound Based Polyhedral Bundle Method for Semidefinite Programming", "comment": null, "summary": "Semidefinite programming (SDP) is a fundamental class of convex optimization\nproblems with diverse applications in mathematics, engineering, machine\nlearning, and related disciplines. This paper investigates the application of\nthe polyhedral bundle method to standard SDPs. The basic idea of this method is\nto approximate semidefinite constraints using linear constraints, and thereby\ntransform the SDP problem into a series of quadratic programming subproblems.\nHowever, the number of linear constraints often increases continuously during\nthe iteration process, leading to a significant reduction in the solution\nefficiency. Therefore, based on the idea of limiting the upper bound on the\nnumber of bundles, we heuristically select the upper bound through numerical\nexperiments according to the rank of the primal optimal solution and propose a\nmodified subproblem. In this way, under the premise of ensuring the\napproximation ability of the lower approximation model, we minimize the number\nof bundles as much as possible to improve the solution efficiency of the\nsubproblems. The algorithm performs well in both Max-Cut problems and random\nSDP problems. In particular, for random sparse SDP problems with low condition\nnumbers, under the condition of a relative accuracy of \\(10^{-4}\\), it shows a\nsignificant improvement compared with algorithms such as interior-point\nmethods."}
{"id": "2510.12589", "categories": ["eess.SY", "cs.SY"], "pdf": "https://arxiv.org/pdf/2510.12589", "abs": "https://arxiv.org/abs/2510.12589", "authors": ["Hadi Nemati", "√Ålvaro Ortega", "Pedro S√°nchez-Mart√≠n", "Lukas Sigrist", "Luis Rouco", "Ignacio Egido"], "title": "Enhancing Robust Multi-Market Participation of Renewable-Based VPPs through Flexible Resources", "comment": null, "summary": "In the transition toward a sustainable power system, renewable-based Virtual\nPower Plants (RVPPs) have emerged as a promising solution to the challenges of\nintegrating renewable energy sources into electricity markets. Their viability,\nhowever, depends on effective market participation strategies and the ability\nto manage uncertainties while leveraging flexible resources. This paper\nanalyzes the impact of different flexible resources - such as concentrated\nsolar power plants, hydro plants, biomass plants, and flexible demand - on the\nparticipation of RVPPs in energy and reserve markets. Multiple sources of\nuncertainty in generation, consumption, and electricity prices are addressed\nusing a two-stage robust optimization approach. The contribution of different\ntechnologies to RVPP profitability is evaluated through a marginal contribution\nmethod, ensuring fair allocation of profits among them according to their\nactual role in energy and reserve provision across markets. Simulations for an\nRVPP in southern Spain demonstrate how strategic decisions and the availability\nof flexible resources influence viability, market participation, and unit\nscheduling."}
{"id": "2510.12504", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.12504", "abs": "https://arxiv.org/abs/2510.12504", "authors": ["Rub√©n Martos", "Christophe Ambroise", "Guillem Rigaill"], "title": "Causal inference of post-transcriptional regulation timelines from long-read sequencing in Arabidopsis thaliana", "comment": "25 pages. GitHub repository at\n  https://github.com/rmartosprieto/chloroDAG.git", "summary": "We propose a novel framework for reconstructing the chronology of genetic\nregulation using causal inference based on Pearl's theory. The approach\nproceeds in three main stages: causal discovery, causal inference, and\nchronology construction. We apply it to the ndhB and ndhD genes of the\nchloroplast in Arabidopsis thaliana, generating four alternative maturation\ntimeline models per gene, each derived from a different causal discovery\nalgorithm (HC, PC, LiNGAM, or NOTEARS). Two methodological challenges are\naddressed: the presence of missing data, handled via an EM algorithm that\njointly imputes missing values and estimates the Bayesian network, and the\nselection of the $\\ell_1$-regularization parameter in NOTEARS, for which we\nintroduce a stability selection strategy. The resulting causal models\nconsistently outperform reference chronologies in terms of both reliability and\nmodel fit. Moreover, by combining causal reasoning with domain expertise, the\nframework enables the formulation of testable hypotheses and the design of\ntargeted experimental interventions grounded in theoretical predictions."}
{"id": "2510.12435", "categories": ["math.OC", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.12435", "abs": "https://arxiv.org/abs/2510.12435", "authors": ["Dirk Lauinger", "Deepjyoti Deka", "Sungho Shin"], "title": "The value of storage in electricity distribution: The role of storage", "comment": null, "summary": "Electricity distribution companies deploy battery storage to defer grid\nupgrades by reducing peak demand. In deregulated jurisdictions, such storage\noften sits idle because regulatory constraints bar participation in electricity\nmarkets. Here, we develop an optimization framework that, to our knowledge,\nprovides the first formal model of market participation constraints within\nstorage investment and operation planning. Applying the framework to a\nMassachusetts case study, we find that market participation could deliver\nsimilar savings as peak demand reduction. Under current conditions, market\nparticipation does not increase storage investment, but at very low storage\ncosts, could incentivize deployment beyond local distribution needs. This might\nrun contrary to the separation of distribution from generation in deregulated\nmarkets. Our framework can identify investment levels appropriate for local\ndistribution needs."}
{"id": "2510.12583", "categories": ["math.NA", "cs.NA"], "pdf": "https://arxiv.org/pdf/2510.12583", "abs": "https://arxiv.org/abs/2510.12583", "authors": ["J. Woodfield", "A. Lobbe"], "title": "Easy-to-Implement One-Step Schemes for Stochastic Integration", "comment": null, "summary": "Convenient, easy to implement stochastic integration methods are developed on\nthe basis of abstract one-step deterministic order $p$ integration techniques.\nThe abstraction as an arbitrary one step map allows the inspection of easy to\nimplement stochastic exponential time differencing Runge-Kutta (SETDRK),\nstochastic integrating factor Runge-Kutta (SIFRK) and stochastic RK (SRK)\nschemes. Such schemes require minimal modifications to existing deterministic\nschemes and converging to the Stratonovich SDE, whilst inheriting many of their\ndesirable properties.\n  These schemes capture all symmetric terms in the Stratonovich-Taylor\nexpansion, are order $p$ in the limit of vanishing noise, can attain at least\nstrong order $p/2$ or $p/2-1/2$ (parity dependent) for drift commutative noise,\nstrong order $1$ for commutative noise, and strong order $1/2$ for\nmultidimensional non-commutative noise. Numerical convergence is demonstrated\nusing different bases of noise for 2nd, 3rd and 4th order SETDRK, SIFRK and SRK\nschemes for a stochastic KdV equation."}
{"id": "2510.12425", "categories": ["math.OC", "cs.CV", "65K10, 68T07, 94A08"], "pdf": "https://arxiv.org/pdf/2510.12425", "abs": "https://arxiv.org/abs/2510.12425", "authors": ["Peng Chen", "Deliang Wei", "Jiale Yao", "Fang Li"], "title": "Tensor Completion via Monotone Inclusion: Generalized Low-Rank Priors Meet Deep Denoisers", "comment": "22 pages, 5 figures", "summary": "Missing entries in multi dimensional data pose significant challenges for\ndownstream analysis across diverse real world applications. These data are\nnaturally modeled as tensors, and recent completion methods integrating global\nlow rank priors with plug and play denoisers have demonstrated strong empirical\nperformance. However, these approaches often rely on empirical convergence\nalone or unrealistic assumptions, such as deep denoisers acting as proximal\noperators of implicit regularizers, which generally does not hold. To address\nthese limitations, we propose a novel tensor completion framework grounded in\nthe monotone inclusion paradigm, which unifies generalized low rank priors with\ndeep pseudo contractive denoisers and extends beyond traditional convex\noptimization. Building on the Davis Yin splitting scheme, we develop the GTCTV\nDPC algorithm and rigorously establish its global convergence. Extensive\nexperiments demonstrate that GTCTV DPC consistently outperforms existing\nmethods in both quantitative metrics and visual quality, particularly at low\nsampling rates."}
{"id": "2510.12435", "categories": ["math.OC", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.12435", "abs": "https://arxiv.org/abs/2510.12435", "authors": ["Dirk Lauinger", "Deepjyoti Deka", "Sungho Shin"], "title": "The value of storage in electricity distribution: The role of storage", "comment": null, "summary": "Electricity distribution companies deploy battery storage to defer grid\nupgrades by reducing peak demand. In deregulated jurisdictions, such storage\noften sits idle because regulatory constraints bar participation in electricity\nmarkets. Here, we develop an optimization framework that, to our knowledge,\nprovides the first formal model of market participation constraints within\nstorage investment and operation planning. Applying the framework to a\nMassachusetts case study, we find that market participation could deliver\nsimilar savings as peak demand reduction. Under current conditions, market\nparticipation does not increase storage investment, but at very low storage\ncosts, could incentivize deployment beyond local distribution needs. This might\nrun contrary to the separation of distribution from generation in deregulated\nmarkets. Our framework can identify investment levels appropriate for local\ndistribution needs."}
{"id": "2510.12607", "categories": ["stat.ME", "62E20, 62G10, 60F15, 60H10"], "pdf": "https://arxiv.org/pdf/2510.12607", "abs": "https://arxiv.org/abs/2510.12607", "authors": ["Akram Heidari", "Mark Podolskij"], "title": "On goodness-of-fit testing for volatility in McKean-Vlasov models", "comment": "13 pages", "summary": "This paper develops a statistical framework for goodness-of-fit testing of\nvolatility functions in McKean-Vlasov stochastic differential equations, which\ndescribe large systems of interacting particles with distribution-dependent\ndynamics. While integrated volatility estimation in classical SDEs is now well\nestablished, formal model validation and goodness-of-fit testing for\nMcKean-Vlasov systems remain largely unexplored, particularly in regimes with\nboth large particle limits and high-frequency sampling. We propose a test\nstatistic based on discrete observations of particle systems, analysed in a\njoint regime where both the number of particles and the sampling frequency\nincrease. The estimators involved are proven to be consistent, and the test\nstatistic is shown to satisfy a central limit theorem, converging in\ndistribution to a centred Gaussian law."}
{"id": "2510.12456", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12456", "abs": "https://arxiv.org/abs/2510.12456", "authors": ["Jukka-Pekka Humaloja", "Nikolaos Bekiaris-Liberis"], "title": "Micro-Macro Backstepping Control of Large-Scale Hyperbolic Systems (Extended Version)", "comment": "22 pages, 5 figures", "summary": "We introduce a control design and analysis framework for micro-macro,\nboundary control of large-scale, $n+m$ hyperbolic PDE systems. Specifically, we\ndevelop feedback laws for stabilization of hyperbolic systems at the micro\nlevel (i.e., of the large-scale system) that employ a) measurements obtained\nfrom the $n+m$ system (i.e., at micro level) and kernels constructed based on\nan $\\infty+\\infty$ continuum system counterpart (i.e., at macro level), or b)\nkernels and measurements both stemming from a continuum counterpart, or c)\naveraged-continuum kernels/measurements. We also address (d)) stabilization of\nthe continuum (macro) system, employing continuum kernels and measurements.\nTowards addressing d) we derive in a constructive manner an $\\infty+\\infty$\ncontinuum approximation of $n+m$ hyperbolic systems and establish that its\nsolutions approximate, for large $n$ and $m$, the solutions of the $n+m$\nsystem. We then construct a feedback law for stabilization of the\n$\\infty+\\infty$ system via introduction of a continuum-PDE backstepping\ntransformation. We establish well-posedness of the resulting 4-D kernel\nequations and prove closed-loop stability via construction of a novel Lyapunov\nfunctional. Furthermore, under control configuration a) we establish that the\nclosed-loop system is exponentially stable provided that $n$ and $m$ are large,\nby proving that the exact, stabilizing $n+m$ control kernels can be accurately\napproximated by the continuum kernels. While under control configurations b)\nand c), we establish closed-loop stability capitalizing on the established\nsolutions' and kernels' approximation properties via employment of\ninfinite-dimensional ISS arguments. We provide two numerical simulation\nexamples to illustrate the effectiveness and potential limitations of our\ndesign approach."}
{"id": "2510.12632", "categories": ["math.NA", "cs.NA", "math.SP"], "pdf": "https://arxiv.org/pdf/2510.12632", "abs": "https://arxiv.org/abs/2510.12632", "authors": ["Lamsahel Noureddine", "Abdeladim El Akri", "Ahmed Ratnani"], "title": "IGA Laplace Eigenfrequencies Distributions and Estimations: Impact of Reparametrization on Eigenfrequency Behavior", "comment": null, "summary": "This work addresses the Galerkin isogeometric discretization of the\none-dimensional Laplace eigenvalue problem subject to homogeneous Dirichlet\nboundary conditions on a bounded interval. We employ GLT theory to analyze the\nbehavior of the eigenfrequencies when a reparametrization is applied to the\ncomputational domain. Under suitable assumptions on the reparametrization\ntransformation, we prove that a structured pattern emerges in the distribution\nof eigenfrequencies when the problem is reframed through GLT-symbol analysis.\nAdditionally, we establish results that refine and extend those of [3],\nincluding a uniform discrete Weyl's law. Furthermore, we derive several\neigenfrequency estimates by establishing that the symbol exhibits\nasymptotically linear behavior near zero."}
{"id": "2510.12435", "categories": ["math.OC", "cs.SY", "econ.GN", "eess.SY", "q-fin.EC"], "pdf": "https://arxiv.org/pdf/2510.12435", "abs": "https://arxiv.org/abs/2510.12435", "authors": ["Dirk Lauinger", "Deepjyoti Deka", "Sungho Shin"], "title": "The value of storage in electricity distribution: The role of storage", "comment": null, "summary": "Electricity distribution companies deploy battery storage to defer grid\nupgrades by reducing peak demand. In deregulated jurisdictions, such storage\noften sits idle because regulatory constraints bar participation in electricity\nmarkets. Here, we develop an optimization framework that, to our knowledge,\nprovides the first formal model of market participation constraints within\nstorage investment and operation planning. Applying the framework to a\nMassachusetts case study, we find that market participation could deliver\nsimilar savings as peak demand reduction. Under current conditions, market\nparticipation does not increase storage investment, but at very low storage\ncosts, could incentivize deployment beyond local distribution needs. This might\nrun contrary to the separation of distribution from generation in deregulated\nmarkets. Our framework can identify investment levels appropriate for local\ndistribution needs."}
{"id": "2510.12456", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12456", "abs": "https://arxiv.org/abs/2510.12456", "authors": ["Jukka-Pekka Humaloja", "Nikolaos Bekiaris-Liberis"], "title": "Micro-Macro Backstepping Control of Large-Scale Hyperbolic Systems (Extended Version)", "comment": "22 pages, 5 figures", "summary": "We introduce a control design and analysis framework for micro-macro,\nboundary control of large-scale, $n+m$ hyperbolic PDE systems. Specifically, we\ndevelop feedback laws for stabilization of hyperbolic systems at the micro\nlevel (i.e., of the large-scale system) that employ a) measurements obtained\nfrom the $n+m$ system (i.e., at micro level) and kernels constructed based on\nan $\\infty+\\infty$ continuum system counterpart (i.e., at macro level), or b)\nkernels and measurements both stemming from a continuum counterpart, or c)\naveraged-continuum kernels/measurements. We also address (d)) stabilization of\nthe continuum (macro) system, employing continuum kernels and measurements.\nTowards addressing d) we derive in a constructive manner an $\\infty+\\infty$\ncontinuum approximation of $n+m$ hyperbolic systems and establish that its\nsolutions approximate, for large $n$ and $m$, the solutions of the $n+m$\nsystem. We then construct a feedback law for stabilization of the\n$\\infty+\\infty$ system via introduction of a continuum-PDE backstepping\ntransformation. We establish well-posedness of the resulting 4-D kernel\nequations and prove closed-loop stability via construction of a novel Lyapunov\nfunctional. Furthermore, under control configuration a) we establish that the\nclosed-loop system is exponentially stable provided that $n$ and $m$ are large,\nby proving that the exact, stabilizing $n+m$ control kernels can be accurately\napproximated by the continuum kernels. While under control configurations b)\nand c), we establish closed-loop stability capitalizing on the established\nsolutions' and kernels' approximation properties via employment of\ninfinite-dimensional ISS arguments. We provide two numerical simulation\nexamples to illustrate the effectiveness and potential limitations of our\ndesign approach."}
{"id": "2510.12663", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2510.12663", "abs": "https://arxiv.org/abs/2510.12663", "authors": ["Michail Tsagris"], "title": "The $Œ±$--regression for compositional data: a unified framework for standard, spatially-lagged, and geographically-weighted regression models", "comment": null, "summary": "Compositional data-vectors of non--negative components summing to\nunity--frequently arise in scientific applications where covariates influence\nthe relative proportions of components, yet traditional regression approaches\nstruggle with the unit-sum constraint and zero values. This paper revisits the\n$\\alpha$--regression framework, which uses a flexible power transformation\nparameterized by $\\alpha$ to interpolate between raw data analysis and\nlog-ratio methods, naturally handling zeros without imputation while allowing\ndata-driven transformation selection. We formulate $\\alpha$--regression as a\nnon-linear least squares problem, provide efficient estimation via the\nLevenberg-Marquardt algorithm with explicit gradient and Hessian derivations,\nestablish asymptotic normality of the estimators, and derive marginal effects\nfor interpretation. The framework is extended to spatial settings through two\nmodels: the $\\alpha$--spatially lagged X regression model, which incorporates\nspatial spillover effects via spatially lagged covariates with decomposition\ninto direct and indirect effects, and the geographically weighted\n$\\alpha$--regression, which allows coefficients to vary spatially for capturing\nlocal relationships. Application to Greek agricultural land-use data\ndemonstrates that spatial extensions substantially improve predictive\nperformance."}
{"id": "2510.12512", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12512", "abs": "https://arxiv.org/abs/2510.12512", "authors": ["Bryan Van Scoy", "Gianluca Bianchin"], "title": "Temporal Variabilities Limit Convergence Rates in Gradient-Based Online Optimization", "comment": null, "summary": "This paper investigates the fundamental performance limits of gradient-based\nalgorithms for time-varying optimization. Leveraging the internal model\nprinciple and root locus techniques, we show that temporal variabilities impose\nintrinsic limits on the achievable rate of convergence. For a problem with\ncondition ratio $\\kappa$ and time variation whose model has degree $n$, we show\nthat the worst-case convergence rate of any minimal-order gradient-based\nalgorithm is $\\rho_\\text{TV} = (\\frac{\\kappa-1}{\\kappa+1})^{1/n}$. This bound\nreveals a fundamental tradeoff between problem conditioning, temporal\ncomplexity, and rate of convergence. We further construct explicit controllers\nthat attain the bound for low-degree models of time variation."}
{"id": "2510.12456", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12456", "abs": "https://arxiv.org/abs/2510.12456", "authors": ["Jukka-Pekka Humaloja", "Nikolaos Bekiaris-Liberis"], "title": "Micro-Macro Backstepping Control of Large-Scale Hyperbolic Systems (Extended Version)", "comment": "22 pages, 5 figures", "summary": "We introduce a control design and analysis framework for micro-macro,\nboundary control of large-scale, $n+m$ hyperbolic PDE systems. Specifically, we\ndevelop feedback laws for stabilization of hyperbolic systems at the micro\nlevel (i.e., of the large-scale system) that employ a) measurements obtained\nfrom the $n+m$ system (i.e., at micro level) and kernels constructed based on\nan $\\infty+\\infty$ continuum system counterpart (i.e., at macro level), or b)\nkernels and measurements both stemming from a continuum counterpart, or c)\naveraged-continuum kernels/measurements. We also address (d)) stabilization of\nthe continuum (macro) system, employing continuum kernels and measurements.\nTowards addressing d) we derive in a constructive manner an $\\infty+\\infty$\ncontinuum approximation of $n+m$ hyperbolic systems and establish that its\nsolutions approximate, for large $n$ and $m$, the solutions of the $n+m$\nsystem. We then construct a feedback law for stabilization of the\n$\\infty+\\infty$ system via introduction of a continuum-PDE backstepping\ntransformation. We establish well-posedness of the resulting 4-D kernel\nequations and prove closed-loop stability via construction of a novel Lyapunov\nfunctional. Furthermore, under control configuration a) we establish that the\nclosed-loop system is exponentially stable provided that $n$ and $m$ are large,\nby proving that the exact, stabilizing $n+m$ control kernels can be accurately\napproximated by the continuum kernels. While under control configurations b)\nand c), we establish closed-loop stability capitalizing on the established\nsolutions' and kernels' approximation properties via employment of\ninfinite-dimensional ISS arguments. We provide two numerical simulation\nexamples to illustrate the effectiveness and potential limitations of our\ndesign approach."}
{"id": "2510.12512", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12512", "abs": "https://arxiv.org/abs/2510.12512", "authors": ["Bryan Van Scoy", "Gianluca Bianchin"], "title": "Temporal Variabilities Limit Convergence Rates in Gradient-Based Online Optimization", "comment": null, "summary": "This paper investigates the fundamental performance limits of gradient-based\nalgorithms for time-varying optimization. Leveraging the internal model\nprinciple and root locus techniques, we show that temporal variabilities impose\nintrinsic limits on the achievable rate of convergence. For a problem with\ncondition ratio $\\kappa$ and time variation whose model has degree $n$, we show\nthat the worst-case convergence rate of any minimal-order gradient-based\nalgorithm is $\\rho_\\text{TV} = (\\frac{\\kappa-1}{\\kappa+1})^{1/n}$. This bound\nreveals a fundamental tradeoff between problem conditioning, temporal\ncomplexity, and rate of convergence. We further construct explicit controllers\nthat attain the bound for low-degree models of time variation."}
{"id": "2510.12466", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2510.12466", "abs": "https://arxiv.org/abs/2510.12466", "authors": ["Stephanie Riedm√ºller", "Niels Lindner"], "title": "Column Generation for Periodic Timetabling", "comment": null, "summary": "Periodic timetabling for public transportation networks is typically modelled\nas a Periodic Event Scheduling Problem (PESP). Solving instances of the\nbenchmark library PESPlib to optimality continues to pose a challenge. As a\nfurther approach towards this goal, we remodel the problem by a time\ndiscretization of the underlying graph and consider arc-based as well as\npath-based integer programming formulations. For the path-based case, we use\ncycles on the graph expansion of the operational lines as variables and,\ntherefore, include more of the problem inherent structure into the model. A\nconsequence is the validity of several known inequalities and a lower bound on\nthe LP-relaxation, that is the best known to date. As an extension we integrate\npassenger routing into the new model. The proposed models have an advantage in\nthe linear programming relaxation, on the one hand, but have an increased\nproblem size, on the other hand. We define the corresponding pricing problems\nfor the use of column generation to handle the size. Both models are\npractically tested on different problem instances."}
{"id": "2510.12512", "categories": ["math.OC", "cs.SY", "eess.SY"], "pdf": "https://arxiv.org/pdf/2510.12512", "abs": "https://arxiv.org/abs/2510.12512", "authors": ["Bryan Van Scoy", "Gianluca Bianchin"], "title": "Temporal Variabilities Limit Convergence Rates in Gradient-Based Online Optimization", "comment": null, "summary": "This paper investigates the fundamental performance limits of gradient-based\nalgorithms for time-varying optimization. Leveraging the internal model\nprinciple and root locus techniques, we show that temporal variabilities impose\nintrinsic limits on the achievable rate of convergence. For a problem with\ncondition ratio $\\kappa$ and time variation whose model has degree $n$, we show\nthat the worst-case convergence rate of any minimal-order gradient-based\nalgorithm is $\\rho_\\text{TV} = (\\frac{\\kappa-1}{\\kappa+1})^{1/n}$. This bound\nreveals a fundamental tradeoff between problem conditioning, temporal\ncomplexity, and rate of convergence. We further construct explicit controllers\nthat attain the bound for low-degree models of time variation."}
