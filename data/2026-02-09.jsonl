{"id": "2602.06401", "categories": ["q-fin.RM", "q-fin.MF"], "pdf": "https://arxiv.org/pdf/2602.06401", "abs": "https://arxiv.org/abs/2602.06401", "authors": ["Jose Da Fonseca", "Patrick Wong"], "title": "Wishart conditional tail risk measures: An analytic approach", "comment": null, "summary": "This study introduces a new analytical framework for quantifying multivariate risk measures. Using the Wishart process, which is a stochastic process with values in the space of positive definite matrices, we derive several conditional tail risk measures which, thanks to the remarkable analytical properties of the Wishart process, can be explicitly computed up to a one- or two-dimensional integration. These quantities can also be used to solve analytically a capital allocation problem based on conditional moments. Exploiting the stochastic differential equation property of the Wishart process, we show how an intertemporal (i.e., time-lagged) view of these risk measures can be embedded in the proposed framework. Several numerical examples show that the framework is versatile and operational, thus providing a useful tool for risk management."}
{"id": "2602.06535", "categories": ["quant-ph", "cs.DS", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.06535", "abs": "https://arxiv.org/abs/2602.06535", "authors": ["Giacomo Belli", "Michele Amoretti"], "title": "Algebraic Reduction to Improve an Optimally Bounded Quantum State Preparation Algorithm", "comment": "15 pages, 13 figures, 5 tables", "summary": "The preparation of $n$-qubit quantum states is a cross-cutting subroutine for many quantum algorithms, and the effort to reduce its circuit complexity is a significant challenge. In the literature, the quantum state preparation algorithm by Sun et al. is known to be optimally bounded, defining the asymptotically optimal width-depth trade-off bounds with and without ancillary qubits. In this work, a simpler algebraic decomposition is proposed to separate the preparation of the real part of the desired state from the complex one, resulting in a reduction in terms of circuit depth, total gates, and CNOT count when $m$ ancillary qubits are available. The reduction in complexity is due to the use of a single operator $Λ$ for each uniformly controlled gate, instead of the three in the original decomposition. Using the PennyLane library, this new algorithm for state preparation has been implemented and tested in a simulated environment for both dense and sparse quantum states, including those that are random and of physical interest. Furthermore, its performance has been compared with that of Möttönen et al.'s algorithm, which is a de facto standard for preparing quantum states in cases where no ancillary qubits are used, highlighting interesting lines of development."}
{"id": "2602.06123", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.06123", "abs": "https://arxiv.org/abs/2602.06123", "authors": ["Lisa Bombieri", "Torsten V. Zache", "Hannes Pichler", "Daniel González-Cuadra"], "title": "U(1) lattice gauge theory and string roughening on a triangular Rydberg array", "comment": null, "summary": "Lattice gauge theories (LGTs) describe fundamental interactions in particle physics. A central phenomenon in these theories is confinement, which binds quarks and antiquarks into hadrons through the formation of string-like flux tubes of gauge fields. Simulating confinement dynamics is a challenging task, but recent advances in quantum simulation are enabling the exploration of LGTs in regimes beyond the reach of classical computation. For analog devices, a major difficulty is the realization of strong plaquette interactions, which generate string fluctuations that can drive a roughening transition. Understanding string roughening -- where strong transversal functions lead to an effective restoration of translational symmetry at long distances -- is of central importance in the study of confinement. In this work, we show that string roughening emerges naturally in an analog Rydberg quantum simulator. We first map a triangular Rydberg array onto a (2+1)D U(1) LGT where plaquette terms appear as first-order processes. We study flux strings connecting static charges and demonstrate that, near a deconfined quantum critical point, the string exhibits logarithmic growth of its transverse width as the separation between charges increases, along with the universal Lüscher correction to the confining potential -- both signatures of string roughening. Finally, we investigate the real-time dynamics of an initially rigid string, observing large fluctuations after quenching into the roughening regime, as well as string breaking via particle-pair creation. Our results indicate that rough strings can be realized in experimentally accessible quantum simulators, opening the door to detailed studies of how strong fluctuations influence string-breaking dynamics."}
{"id": "2602.06175", "categories": ["math.ST", "cs.AI", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.06175", "abs": "https://arxiv.org/abs/2602.06175", "authors": ["Kaushik Sinha", "Christopher Tosh"], "title": "Optimal rates for density and mode estimation with expand-and-sparsify representations", "comment": "Accepted at AISTATS 2026", "summary": "Expand-and-sparsify representations are a class of theoretical models that capture sparse representation phenomena observed in the sensory systems of many animals. At a high level, these representations map an input $x \\in \\mathbb{R}^d$ to a much higher dimension $m \\gg d$ via random linear projections before zeroing out all but the $k \\ll m$ largest entries. The result is a $k$-sparse vector in $\\{0,1\\}^m$. We study the suitability of this representation for two fundamental statistical problems: density estimation and mode estimation. For density estimation, we show that a simple linear function of the expand-and-sparsify representation produces an estimator with minimax-optimal $\\ell_{\\infty}$ convergence rates. In mode estimation, we provide simple algorithms on top of our density estimator that recover single or multiple modes at optimal rates up to logarithmic factors under mild conditions."}
{"id": "2602.06298", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.06298", "abs": "https://arxiv.org/abs/2602.06298", "authors": ["Y. M. Vilk", "A. -M. S. Tremblay"], "title": "Pseudogap, Fermi liquid, Van Hove singularity and maxima of the compressibility and of the Knight shift as a function of doping in the two-dimensional Hubbard model", "comment": null, "summary": "Qualitative changes in thermodynamic and single-particle properties characterize the transition between the pseudogapped electronic liquid and the Fermi liquid. Recent cold-atom experiments on a simulator of the Hubbard model with nearest-neighbor hoppings \\cite{kendrick2025pseudogap} showed that the isothermal compressibility $κ(δ)$ has a maximum as a function of doping $δ$. Here we use the two-particle self-consistent plus (TPSC+) approach to explain these experiments and connect the maximum in $κ(δ)$ to the transformation of the single-particle spectrum from the pseudogapped to the metallic regime. This elucidates the nature of the pseudogap (PG). Specifically, the maximum in $κ(δ)$ practically coincides with the doping at which the precursor of the lower $(π,π)$ spin density wave (SDW) band at the antinodal point crosses the zero-frequency $ω=0$. The Knight shift, $χ_{sp}(0,0)(δ)$, as a function of doping, should also have a maximum. The maxima in both quantities should exist, at sufficiently low temperatures ($T$), in both the intermediate $U \\approx U_{Mott}$ and weak $U < U_{Mott}$ interaction limits. In both limits, the mechanism is critical thermal SDW fluctuations. At the antinodal pseudogap, the correlation length at $δ_{max}(T)$ can be small, controlled not by static but by dynamic critical thermal fluctuations. We also find that the SDW fluctuations are incommensurate at $δ=δ_{max}$. We predict that, at low $T$, the multiple peaks in the spin susceptibility in the incommensurate case lead to more than two SDW precursor peaks in the spectral function and density of states. By allowing access to parameter regimes relevant to cuprates-including further-neighbor hopping ($t', t''$) and low temperatures, our work provides a high-impact tool for further studies by the broader community."}
{"id": "2309.03085", "categories": ["quant-ph", "math-ph", "physics.hist-ph"], "pdf": "https://arxiv.org/pdf/2309.03085", "abs": "https://arxiv.org/abs/2309.03085", "authors": ["Jacob A. Barandes"], "title": "The Stochastic-Quantum Theorem", "comment": "32 pages, no figures", "summary": "This paper introduces several new classes of mathematical structures that have close connections with physics and with the theory of dynamical systems. The most general of these structures, called indivisible stochastic processes, collectively encompass many important kinds of stochastic processes, including Markov chains and random dynamical systems. This paper then states and proves a new theorem that establishes a precise correspondence between any indivisible stochastic process and a unitarily evolving quantum system. This theorem therefore leads to a new formulation of quantum theory, alongside the Hilbert-space, path-integral, and quasi-probability formulations. The theorem also provides a first-principles explanation for why quantum systems are based on the complex numbers, Hilbert spaces, linear-unitary time evolution, and the Born rule. In addition, the theorem suggests that by selecting a suitable Hilbert space, together with an appropriate choice of unitary evolution, one can simulate any indivisible stochastic process on a quantum computer, thereby potentially opening up an extensive set of novel applications for quantum computing."}
{"id": "2602.06153", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06153", "abs": "https://arxiv.org/abs/2602.06153", "authors": ["Anthony Almudevar", "Jacob Almudevar"], "title": "A Compound Logistic Regression Model for Binary Responses", "comment": "33 pages; 6 figures", "summary": "Logistic regression is the most commonly used method for constructing predictive models for binary responses. One significant drawback to this approach, however, is that the asymptotes of the logistic response function are fixed at 0 and 1, and there are many applications for which this constraint is inappropriate. More flexible models have been proposed for this application, most proceeding by supplementing the logistic response function with additional parameters. In this article we extend these models to allow correlated responses and the inclusion of covariates. This is achieved through the \\emph{compound logistic regression model}, for which the mean response is a function of several logistic regression functions. This permits a greater variety of models, while retaining the advantages of logistic regression."}
{"id": "2602.06279", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.06279", "abs": "https://arxiv.org/abs/2602.06279", "authors": ["Tomasz Szawełło", "Jeffrey D. Hyman", "Peter K. Kang", "Piotr Szymczak"], "title": "Structural barriers to complete homogenization and wormholing in dissolving porous and fractured rocks", "comment": "36 pages, 9 figures", "summary": "Dissolution in porous media and fractured rocks alters both the chemical composition of the fluid and the physical properties of the solid. Depending on system conditions, reactive flow may enlarge pores uniformly, widen pre-existing channels, or trigger instabilities that form wormholes. The resulting pattern reflects feedbacks among advection, diffusion, surface reaction, and the initial heterogeneity of the medium. Porous and fractured media can exhibit distinct characteristics -- for example, the presence of large fractures can significantly alter the network topology and overall connectivity of the system. We quantify these differences with three network models -- a regular pore network, a disordered pore network, and a discrete fracture network -- evaluated with a unified metric: the flow focusing profile. This metric effectively captures evolution of flow paths across all systems: it reveals a focusing front that propagates from the inlet in the wormholing regime, a system-wide decrease in focusing during uniform dissolution, and the progressive enlargement of pre-existing flow paths in the channeling regime. The metric shows that uniform dissolution cannot eliminate heterogeneity resulting from the network topology. This structural heterogeneity -- rather than just pore-diameter or fracture-aperture variance -- sets a fundamental limit on flow homogenization and must be accounted for when upscaling dissolution kinetics from pore or fracture scale to the reservoir level."}
{"id": "2602.06881", "categories": ["nlin.CD"], "pdf": "https://arxiv.org/pdf/2602.06881", "abs": "https://arxiv.org/abs/2602.06881", "authors": ["H. Párraga", "F. J. Arranz", "R. M. Benito", "F. Borondo"], "title": "Using correlation diagrams to study the vibrational spectrum of highly nonlinear floppy molecules: The K-CN case", "comment": null, "summary": "The correlation diagrams of vibrational energy levels considering the Planck constant as a variable parameter have proven as a very useful tool to study vibrational molecular states, and more specifically in relation to the quantum manifestations of chaos in such dynamical systems. In this paper, we consider the highly nonlinear K-CN molecule, showing how the regular classical structures, i.e., Kolmogorov-Arnold-Moser tori, existing in the mixed classical phase space appear in the quantum levels correlation diagram as emerging diabatic states, something that remains hidden when only the actual value of the Planck constant is considered. Additionally, a quantum transition from order to chaos is unveiled with the aid of these correlation diagrams, where it appears as a frontier of scarred functions."}
{"id": "2602.06424", "categories": ["q-fin.CP", "math.NA", "q-fin.MF", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.06424", "abs": "https://arxiv.org/abs/2602.06424", "authors": ["Chiheb Ben Hammouda", "Truong Ngoc Nguyen"], "title": "Single- and Multi-Level Fourier-RQMC Methods for Multivariate Shortfall Risk", "comment": null, "summary": "Multivariate shortfall risk measures provide a principled framework for quantifying systemic risk and determining capital allocations prior to aggregation in interconnected financial systems. Despite their well established theoretical properties, the numerical estimation of multivariate shortfall risk and the corresponding optimal allocations remains computationally challenging, as existing Monte Carlo based approaches can be numerically expensive due to slow convergence.\n  In this work, we develop a new class of single and multilevel numerical algorithms for estimating multivariate shortfall risk and the associated optimal allocations, based on a combination of Fourier inversion techniques and randomized quasi Monte Carlo (RQMC) sampling. Rather than operating in physical space, our approach evaluates the relevant expectations appearing in the risk constraint and its optimization in the frequency domain, where the integrands exhibit enhanced smoothness properties that are well suited for RQMC integration. We establish a rigorous mathematical framework for the resulting Fourier RQMC estimators, including convergence analysis and computational complexity bounds. Beyond the single level method, we introduce a multilevel RQMC scheme that exploits the geometric convergence of the underlying deterministic optimization algorithm to reduce computational cost while preserving accuracy.\n  Numerical experiments demonstrate that the proposed Fourier RQMC methods outperform sample average approximation and stochastic optimization benchmarks in terms of accuracy and computational cost across a range of models for the risk factors and loss structures. Consistent with the theoretical analysis, these results demonstrate improved asymptotic convergence and complexity rates relative to the benchmark methods, with additional savings achieved through the proposed multilevel RQMC construction."}
{"id": "2602.06215", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06215", "abs": "https://arxiv.org/abs/2602.06215", "authors": ["Milad Hasanzadeh", "Amin Kargarian"], "title": "Dynamic Quantum Optimal Communication Topology Design for Consensus Control in Linear Multi-Agent Systems", "comment": null, "summary": "This paper proposes a quantum framework for the design of communication topologies in consensus-based multi-agent systems. The communication graph is selected online by solving a mixed-integer quadratic program (MIQP) that minimizes a cost combining communication and distance penalties with degree-regularization terms, while enforcing exact connectivity through a flow-based formulation. To cope with the combinatorial complexity of this NP-hard problem, we develop a three-block ADMM scheme that decomposes the MIQP into a convex quadratic program in relaxed edge and flow variables, a pure binary unconstrained subproblem, and a closed-form auxiliary update. The binary subproblem is mapped to a quadratic unconstrained binary optimization (QUBO) Hamiltonian and approximately solved via quantum imaginary time evolution (QITE). The resulting time-varying, optimizer-generated Laplacians are applied to linear first- and second-order consensus dynamics. Numerical simulations on networks demonstrate that the proposed method produces connected topologies that satisfy degree constraints, achieve consensus, and incur costs comparable to those of classical mixed-integer solvers, thereby illustrating how quantum algorithms can be embedded as topology optimizers within closed-loop distributed control architectures."}
{"id": "2602.06431", "categories": ["cs.SI", "cs.AI", "cs.IR"], "pdf": "https://arxiv.org/pdf/2602.06431", "abs": "https://arxiv.org/abs/2602.06431", "authors": ["Abhishek Jangra", "Sachin Thukral", "Arnab Chatterjee", "Jayasree Raveendran"], "title": "A methodology for analyzing financial needs hierarchy from social discussions using LLM", "comment": "15 pages, 5 figures, 4 tables", "summary": "This study examines the hierarchical structure of financial needs as articulated in social media discourse, employing generative AI techniques to analyze large-scale textual data. While human needs encompass a broad spectrum from fundamental survival to psychological fulfillment financial needs are particularly critical, influencing both individual well-being and day-to-day decision-making. Our research advances the understanding of financial behavior by utilizing large language models (LLMs) to extract and analyze expressions of financial needs from social media posts. We hypothesize that financial needs are organized hierarchically, progressing from short-term essentials to long-term aspirations, consistent with theoretical frameworks established in the behavioral sciences. Through computational analysis, we demonstrate the feasibility of identifying these needs and validate the presence of a hierarchical structure within them. In addition to confirming this structure, our findings provide novel insights into the content and themes of financial discussions online. By inferring underlying needs from naturally occurring language, this approach offers a scalable and data-driven alternative to conventional survey methodologies, enabling a more dynamic and nuanced understanding of financial behavior in real-world contexts."}
{"id": "2602.06106", "categories": ["physics.soc-ph", "q-bio.PE"], "pdf": "https://arxiv.org/pdf/2602.06106", "abs": "https://arxiv.org/abs/2602.06106", "authors": ["Alexander Feigel", "Alexandre V. Morozov"], "title": "To clean or not to clean: The free-rider problem in sequentially shared resources", "comment": "12 pages, 4 figures in the main text, 1 figure in the Supplement", "summary": "Shared resources enhance productivity yet at the same time provide channels for biological and digital contamination, turning physical or digital hygiene into a cooperation dilemma prone to free-riding. Here we introduce a game of sequential sharing of common resources, an empirically parameterized evolutionary model of population dynamics in sequential-use settings such as gyms and shared workspaces. The success of the strategies implemented in the model, such as cleaning equipment before or after use, are based on the trade-offs between cleaning costs, contamination risk, and social incentives to mitigate disease transmission. We find that cooperative hygiene can be achieved by lowering the effective costs of cleaning, strengthening pro-social incentives, and monitoring population-level noncompliance. Remarkably, stability of fully altruistic populations is primarily affected by the cleaning costs. In contrast, increasing effective infection costs, for example through punishment, appears less important in this case. The model's evolutionary dynamics exhibit multi-stability, hysteresis, and abrupt shifts in strategy composition, broadly consistent with empirical observations from shared-use facilities. Our framework offers testable predictions and is amenable to quantitative calibration with behavioral and environmental data. Our predictions can be used to inform the design of cost-effective public health and digital security policies."}
{"id": "2602.06215", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06215", "abs": "https://arxiv.org/abs/2602.06215", "authors": ["Milad Hasanzadeh", "Amin Kargarian"], "title": "Dynamic Quantum Optimal Communication Topology Design for Consensus Control in Linear Multi-Agent Systems", "comment": null, "summary": "This paper proposes a quantum framework for the design of communication topologies in consensus-based multi-agent systems. The communication graph is selected online by solving a mixed-integer quadratic program (MIQP) that minimizes a cost combining communication and distance penalties with degree-regularization terms, while enforcing exact connectivity through a flow-based formulation. To cope with the combinatorial complexity of this NP-hard problem, we develop a three-block ADMM scheme that decomposes the MIQP into a convex quadratic program in relaxed edge and flow variables, a pure binary unconstrained subproblem, and a closed-form auxiliary update. The binary subproblem is mapped to a quadratic unconstrained binary optimization (QUBO) Hamiltonian and approximately solved via quantum imaginary time evolution (QITE). The resulting time-varying, optimizer-generated Laplacians are applied to linear first- and second-order consensus dynamics. Numerical simulations on networks demonstrate that the proposed method produces connected topologies that satisfy degree constraints, achieve consensus, and incur costs comparable to those of classical mixed-integer solvers, thereby illustrating how quantum algorithms can be embedded as topology optimizers within closed-loop distributed control architectures."}
{"id": "2602.06046", "categories": ["cond-mat.stat-mech", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.06046", "abs": "https://arxiv.org/abs/2602.06046", "authors": ["Amadeus Brandes"], "title": "The Preservation Tradeoff: A Thermodynamic Bound in the Diminishing-Returns Regime", "comment": "15 pages, 3 figures, 1 table", "summary": "Thermodynamic systems that preserve information against thermal fluctuations face a tradeoff distinct from transmission (Shannon) or erasure (Landauer). We establish a feasibility condition for this preservation problem within a broad class of systems exhibiting diminishing returns in error suppression. By defining the preservation stiffness S_kappa, a response function analogous to magnetic susceptibility, we derive an optimality condition linking S_kappa to the resource odds. This identity provides a substrate-agnostic diagnostic: deviations reveal thermodynamic inefficiency or operation outside the smooth reliability regime. For systems in the diminishing-returns regime -- a class we argue is typical of physically realistic error-correction -- the optimal maintenance allocation is bounded above by 50%; for the physically significant subclass exhibiting smooth saturation, it is further constrained to a 30-50% band. We derive this regime from two independent physical principles -- Shannon's channel capacity and Landauer's erasure bound -- whose convergence on the same functional form constitutes our central theoretical contribution. We validate this framework against kinetic proofreading data in E. coli and protocol overhead in TCP/IP networks, and specify conditions under which the prediction is falsifiable."}
{"id": "2602.06483", "categories": ["nlin.AO", "physics.acc-ph"], "pdf": "https://arxiv.org/pdf/2602.06483", "abs": "https://arxiv.org/abs/2602.06483", "authors": ["C. Evain", "A. -A. Diallo", "E. Roussel", "C. Szwaj", "M. Herda", "M. -A. Tordeux", "F. Ribeiro", "M. Labat", "N. Hubert", "J. -B. Brubach", "P. Roy", "S. Bielawski"], "title": "Synchronization of Synchrotron Radiation Bursts during a spatio-temporal Instability in accelerator-Based source", "comment": null, "summary": "Synchronization is a fundamental phenomenon in dynamical systems, occurring in a wide range of contexts such as mechanical, chemical, biological, and social systems. In this work, we explore a novel manifestation of synchronization in accelerator-based light sources, specifically in storage rings where relativistic electron bunches circulate and emit synchrotron radiation, used for user experiments. In such systems, a systematic spatio-temporal instability arises when the bunch contains a large number of electrons. This instability is characterized by the spontaneous formation of microstructures within the bunch, which appear with a bursting behavior. We demonstrate that these bursting events can be synchronized with an external sinusoidal signal by modulating the electric field in a radiofrequency (RF) cavity. This external modulation induces typical synchronization features such as Arnold tongues at fundamental, harmonic, and subharmonic frequencies of the natural bursting rate, as well as phase-slip phenomena near the synchronization threshold. The synchronization mechanism is analyzed using numerical simulations based on the Vlasov-Fokker-Planck equation, and a proof-of-principle experiment is conducted at the SOLEIL synchrotron facility."}
{"id": "2602.06198", "categories": ["q-fin.ST", "q-fin.TR"], "pdf": "https://arxiv.org/pdf/2602.06198", "abs": "https://arxiv.org/abs/2602.06198", "authors": ["Hangyi Zhao"], "title": "Insider Purchase Signals in Microcap Equities: Gradient Boosting Detection of Abnormal Returns", "comment": "9 pages, 4 figures, 4 tables", "summary": "This paper examines whether SEC Form 4 insider purchase filings predict abnormal returns in U.S. microcap stocks. The analysis covers 17,237 open-market purchases across 1,343 issuers from 2018 through 2024, restricted to market capitalizations between \\$30M and \\$500M. A gradient boosting classifier trained on insider identity, transaction history, and market conditions at disclosure achieves AUC of 0.70 on out-of-sample 2024 data. At an optimized threshold of 0.20, precision is 0.38 and recall is 0.69. The distance from the 52-week high dominates feature importance, accounting for 36% of predictive signal. A momentum pattern emerges in the data: transactions disclosed after price appreciation exceeding 10% yield the highest mean cumulative abnormal return (6.3%) and the highest probability of outperformance (36.7%). This contrasts with the simple mean-reversion intuition often applied to post-run-up entries. The result is robust to winsorization and holds across subsamples. These patterns are consistent with slower information incorporation in illiquid markets, where trend confirmation may filter for higher-conviction insider signals."}
{"id": "2602.06152", "categories": ["math.NA", "math.AP"], "pdf": "https://arxiv.org/pdf/2602.06152", "abs": "https://arxiv.org/abs/2602.06152", "authors": ["Jörg Nick"], "title": "The modulated Fourier expansion for waves propagating through time-modulated media", "comment": "28 pages, 7 figures", "summary": "Controlling waves by actively changing the material parameters of a medium enables the development of new acoustic and electrical devices. Modulating the material breaks classical properties like reciprocity and the conservation of energy, which complicates the mathematical analysis. Without a limiting amplitude principle, time-harmonic formulations are generally inapplicable. The present manuscript develops an alternative tool for the time-modulated acoustic wave equation, that is based on a modulated Fourier expansion (MFE). The solution is characterized by multiple smoothly varying coefficient functions, which solve a coupled system of evolutionary partial differential equations with temporally constant coefficients. For small-amplitude fast-time modulations, this system of evolutionary partial differential equations is shown to possess a smoothly varying solution, which characterizes the exact solution up to a small defect.\n  Discretization of the derived coupled system yields integrators that are stable and accurate when larger time steps are used, compared to those schemes that are applied to the time-modulated acoustic wave equation directly. Numerical experiments illustrate the theoretical results and the use of the approach."}
{"id": "2602.06178", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06178", "abs": "https://arxiv.org/abs/2602.06178", "authors": ["Rocio Balderrama", "Ignacio Ceresa Dussel", "Constanza Sanchez de la Vega"], "title": "Optimal Control Strategies for Epidemic Dynamics: Integrating SIR-SI and Lotka--Volterra Models", "comment": "3 figures, 15 pages", "summary": "In this work we present a mathematical model that integrates the epidemiological dynamics of a vector-borne disease (SIR-SI) with Lotka Volterra predator prey ecological interactions. The study analyzes how the presence of natural predators acts as a biological control mechanism to regulate the vector population and, consequently, disease transmission in host. \nWe introduce the concept of the ecological reproduction number, a threshold that links the amplitude of predator prey cycles to disease persistence, showing that natural control depends critically on the ratio between the maximum vector density and the minimum predator density. In scenarios where natural control is insufficient, we formulate an optimal control problem based on the release of predators. Using the Pontryagin Maximum Principle, we characterize the optimal strategy that minimizes the cumulative number of infected individuals and intervention costs, while simultaneously maximizing the susceptible host population at the end of the time horizon. Numerical simulations validate the effectiveness of the model, showing that external intervention mitigates the epidemic peak and stabilizes the system against the natural oscillations of biological populations."}
{"id": "2602.06091", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06091", "abs": "https://arxiv.org/abs/2602.06091", "authors": ["Hollis Williams"], "title": "Entanglement Before Spacetime in Quantum-Gravity-Induced Interactions", "comment": null, "summary": "Quantum-gravity-induced entanglement of massive systems (QGEM) is commonly approximated in the nonrelativistic static limit by a Newtonian interaction between spatially separated masses. In this work, we reformulate the gravitationally mediated interaction phase in a conformally invariant twistor framework in which no notion of spacetime distance is assumed. We show that the bilocal phase responsible for entanglement generation remains well-defined and non-factorizable even in the absence of spacetime geometry. The familiar Newtonian $1/r$ phase, relevant for QGEM protocols, arises only after the conformal invariance is broken by introducing the infinity twistor, which selects a particular spacetime representation of the underlying bilocal quantum interaction. Our results isolate the genuinely quantum content of QGEM protocols and clarify the contingent role played by spacetime geometry in mediating entanglement."}
{"id": "2602.06360", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.06360", "abs": "https://arxiv.org/abs/2602.06360", "authors": ["Jeongho Lee", "Junmo Song"], "title": "Robust Bayesian estimation in conditionally heteroscedastic time series models", "comment": "31 pages, 5 figures", "summary": "Outliers can seriously distort statistical inference by inducing excessive sensitivity in the likelihood function, thereby compromising the reliability of Bayesian estimation. To address this issue, we develop a robust Bayesian estimation method for conditionally heteroscedastic time series models by extending the density power divergence (DPD) framework to the Bayesian setting. The resulting DPD-based posterior distribution, controlled by a tuning parameter, achieves a smooth balance between efficiency and robustness. We establish the asymptotic properties of the proposed estimator; specifically, the DPD-based posterior is shown to satisfy a Bernstein-von Mises type theorem, converging to a normal distribution centered at the minimum DPD estimator (MDPDE). Furthermore, the corresponding Bayes estimator, defined as the posterior mean under the DPD-based posterior (EDPE), is asymptotically equivalent to the MDPDE. Monte Carlo simulations based on GARCH(1,1) models confirm that the proposed EDPE performs well under both uncontaminated and contaminated data, maintaining robustness where the ordinary Bayes estimator becomes severely biased. An empirical application to BTC-USD returns further demonstrates the practical advantages of the proposed robust Bayesian framework for financial time series analysis."}
{"id": "2602.06387", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.06387", "abs": "https://arxiv.org/abs/2602.06387", "authors": ["K. S. Chikara", "A. K. Bera", "A. Kumar", "S. M. Yusuf"], "title": "Fermionic Approach to Elementary Excitations and Magnetization Plateaus in an S=1/2 XX Hybrid Trimer-Dimer Chain", "comment": "20 pages, 8 figures", "summary": "We study the elementary excitations and magnetization of a one-dimensional spin-1/2 XX chain comprising trimer-dimer units (the J1-J1-J2-J3-J2 topology) under a transverse magnetic field h. Using Green's function theory and the Jordan-Wigner transformation, we map the system onto spinless fermions and focus on antiferromagnetic (AFM) interactions. At zero temperature, distinct 1/5 and 3/5 magnetization plateaus emerge, determined by the global periodicity Q=5, with the number of plateaus matching the number of excitation gaps above the Fermi level of the spinless fermions. The magnetic phase diagram in the (h-Js) plane features a Luttinger liquid (LL) state, a gapless AFM state, two magnetization plateau states, and a fully polarized gapped magnetic state. The widths of the LL and gapless AFM phases are found to be proportional to the bandwidths gamma = |E(k=0)-E(k=pi)| of the corresponding elementary excitations, whereas the widths of the magnetization plateau states are governed by the excitation gaps. Our study opens new directions for exploring interacting trimer-dimer spin chains in quantum magnetism using experimental techniques such as neutron scattering, as well as theoretical and numerical approaches including quantum Monte Carlo (QMC) and density-matrix renormalization group (DMRG) methods. Furthermore, we extend the Oshikawa-Yamanaka-Affleck (OYA) condition to generalized cluster chains, demonstrating that the allowed magnetization plateaus are governed by the global periodicity of the chain (e.g., Q=5 for a trimer-dimer chain), rather than by the local periodicity of individual units (Q=3 for a trimer or Q=2 for a dimer)."}
{"id": "2602.06262", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.06262", "abs": "https://arxiv.org/abs/2602.06262", "authors": ["Bronner P. Gonçalves"], "title": "Latent variation in pathogen strain-specific effects under multiple-versions-of-treatment theory", "comment": "9 pages, 1 figure", "summary": "Evidence-informed policy on infections requires estimates of their effects on health. However, pathogenic variation, whereby occurrence of adverse outcomes depends on the infecting strain, might complicate the study of many infectious agents. Here, we consider the interpretation of epidemiologic studies on effects of infections on health when there is heterogeneity in strain-specific effects and information on strain composition is unavailable. We use potential outcomes and causal inference theory for analyses in the presence of multiple versions of treatment to argue that oft-reported quantities in these studies have a causal interpretation that depends on population frequencies of infecting strains. Moreover, as in other contexts where the treatment-variation-irrelevance assumption might be violated, transportability requires additional considerations, beyond those needed for non-compound exposures. This discussion, that considers potential heterogeneity in strain-specific effects, will facilitate interpretation of these studies, and for the reasons mentioned above, also highlights the value of pathogen subtype data."}
{"id": "2602.06703", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2602.06703", "abs": "https://arxiv.org/abs/2602.06703", "authors": ["Yishuo Zhou", "Ankit Gupta", "Hideo Aochi", "Alexandre Schubnel", "Satoshi Ide", "Pierpaolo Dubernet", "Harsha S. Bhat"], "title": "Theoretical constraints on tidal triggering of slow earthquakes", "comment": null, "summary": "Tidal stress is a globally acting perturbation driven primarily by the gravitational forcing of the Moon and the Sun. Understanding how tidal stresses can trigger seismic events is essential for constraining tectonic environments that are sensitive to small stress perturbations. Here, employing a spring-block with rate-and-state friction, we investigate tidal triggering on velocity-weakening stable sliding faults with stiffness slightly exceeding the critical stiffness. We first apply idealized step-like and boxcar normal stress perturbations to demonstrate a resonance-like amplification of slip rate when the perturbation period approaches the intrinsic frictional timescale of state evolution. Next, we perform nondimensional analyses and numerical simulations with harmonic tidal-like perturbations to identify the key parameters controlling tidal triggering and their admissible ranges. Triggered slip events are further characterized using physically interpretable quantities, including radiation efficiency and tidal phase. Our results show that even small stress perturbations can trigger periodic as well as complex slip events on stable sliding faults. The triggering behavior is primarily controlled by the normalized perturbation period and the normalized perturbation amplitude. An increase in the normalized period shifts event timing from the peak of tidal stress toward the peak of stress rate, whereas increasing the normalized amplitude promotes a transition from slow to fast events. The parameter space permitting triggered events suggests that the parameter which characterizes the instantaneous frictional strength of an interface, should not exceed tens to hundreds of kilopascals, and that the characteristic slip distance for frictional weakening is likely on the order of micrometers."}
{"id": "2602.06255", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06255", "abs": "https://arxiv.org/abs/2602.06255", "authors": ["Kejun Chen", "Bernard Knueven", "Wesley Jones"], "title": "A hard-constrained NN learning framework for rapidly restoring AC-OPF from DC-OPF", "comment": null, "summary": "This paper proposes a hard-constrained unsupervised learning framework for rapidly solving the non-linear and non-convex AC optimal power flow (AC-OPF) problem in real-time operation. Without requiring ground-truth AC-OPF solutions, feasibility and optimality are ensured through a properly designed learning environment and training loss. Inspired by residual learning, the neural network (NN) learns the correction mapping from the DC-OPF solution to the active power setpoints of the generators through re-dispatch. A subsequent optimization model is utilized to restore the optimal AC-OPF solution, and the resulting projection difference is employed as the training loss. A replay buffer is utilized to enhance learning efficiency by fully leveraging past data pairs. The optimization model is cast as a differentiable optimization layer, where the gradient is derived by applying the implicit function theorem to the KKT conditions at the optimal solution. Tested on IEEE-118 and PEGASE-9241 bus systems, numerical results demonstrate that the proposed NN can obtain strictly feasible and near-optimal solutions with reduced computational time compared to conventional optimization solvers. In addition, aided by the updated DC-OPF solution under varying topologies, the trained NN, together with the PF solver, can rapidly find the corresponding AC solution. The proposed method achieves a $40\\times$ time speedup, while maintaining an average constraint violation on the order of $10^{-4}$ and an optimization gap below $1\\%$."}
{"id": "2602.06604", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2602.06604", "abs": "https://arxiv.org/abs/2602.06604", "authors": ["Antoine Vendeville", "Jimena Royo-Letelier", "Duncan Cassells", "Jean-Philippe Cointet", "Maxime Crépel", "Tim Faverjon", "Théophile Lenoir", "Béatrice Mazoyer", "Benjamin Ooghe-Tabanou", "Armin Pournaki", "Hiroki Yamashita", "Pedro Ramaciotti"], "title": "Mapping the political landscape from data traces: multidimensional opinions of users, politicians and media outlets on X", "comment": null, "summary": "Studying political activity on social media often requires defining and measuring political stances of users or content. Relevant examples include the study of opinion polarization, or the study of political diversity in online content diets. While many research designs rely on operationalizations best suited for the US setting, few allow addressing more general political systems, in which users and media outlets might exhibit stances on multiple ideology and issue dimensions, going beyond traditional Liberal-Conservative or Left-Right scales. To advance the study of more general online ecosystems, we present a dataset pertaining to a population of X/Twitter users, parliamentarians, and media outlets embedded in a political space spanned by dimensions measuring attitudes towards immigration, the EU, liberal values, elites and institutions, nationalism and the environment, in addition to left-right and liberal-conservative scales. We include indicators of individual activity and popularity: mean number of posts per day, number of followers, and number of followees. We provide several benchmarks validating the positions of these entities and discuss several applications for this dataset."}
{"id": "2602.06342", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.06342", "abs": "https://arxiv.org/abs/2602.06342", "authors": ["Zhen Li", "Yuki Izumida"], "title": "Mean-Field Theory for Heider Balance under Heterogeneous Social Temperatures", "comment": "12 pages, 6 figures", "summary": "Heider balance theory provides a fundamental framework for understanding the formation of friendly and hostile relations in social networks. Existing stochastic formulations typically assume a uniform social temperature, implying that all interpersonal relations fluctuate with the same intensity. However, studies show that social interactions are highly heterogeneous, with broad variability in stability, volatility, and susceptibility to change. In this work, we introduce a generalized Heider balance model on a complete graph in which each link is assigned its own social temperature. Within a mean-field formulation, we derive a distribution-dependent self-consistency condition for the collective opinion state and identify the criteria governing the transition between polarized and non-polarized configurations. This framework reveals how the entire distribution of interaction heterogeneity shapes the macroscopic behavior of the system. We show that the functional form of the inverse-temperature distribution, in particular whether it is light-tailed or heavy-tailed, leads to qualitatively distinct phase diagrams. We also establish universal bounds for the critical transition, where the homogeneous-temperature limit provides a universal lower bound for the critical mean of an inverse-temperature distribution governing the transition. Numerical simulations confirm the theoretical predictions and highlight the nontrivial effects introduced by heterogeneity. Our results provide a unified route to understanding structural balance in realistic social systems and lay the groundwork for extensions incorporating fluctuations beyond mean field, external fields, and network topologies beyond the complete graph."}
{"id": "2602.06255", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06255", "abs": "https://arxiv.org/abs/2602.06255", "authors": ["Kejun Chen", "Bernard Knueven", "Wesley Jones"], "title": "A hard-constrained NN learning framework for rapidly restoring AC-OPF from DC-OPF", "comment": null, "summary": "This paper proposes a hard-constrained unsupervised learning framework for rapidly solving the non-linear and non-convex AC optimal power flow (AC-OPF) problem in real-time operation. Without requiring ground-truth AC-OPF solutions, feasibility and optimality are ensured through a properly designed learning environment and training loss. Inspired by residual learning, the neural network (NN) learns the correction mapping from the DC-OPF solution to the active power setpoints of the generators through re-dispatch. A subsequent optimization model is utilized to restore the optimal AC-OPF solution, and the resulting projection difference is employed as the training loss. A replay buffer is utilized to enhance learning efficiency by fully leveraging past data pairs. The optimization model is cast as a differentiable optimization layer, where the gradient is derived by applying the implicit function theorem to the KKT conditions at the optimal solution. Tested on IEEE-118 and PEGASE-9241 bus systems, numerical results demonstrate that the proposed NN can obtain strictly feasible and near-optimal solutions with reduced computational time compared to conventional optimization solvers. In addition, aided by the updated DC-OPF solution under varying topologies, the trained NN, together with the PF solver, can rapidly find the corresponding AC solution. The proposed method achieves a $40\\times$ time speedup, while maintaining an average constraint violation on the order of $10^{-4}$ and an optimization gap below $1\\%$."}
{"id": "2602.06340", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2602.06340", "abs": "https://arxiv.org/abs/2602.06340", "authors": ["Xin Song", "Xiji Shao", "Yanwen Zhu", "Cheng Yang", "Linli He", "Shigeyuki Komura", "Zhanglin Hou"], "title": "Ornstein-Uhlenbeck information particle: A new candidate of active agent", "comment": "8 pages, 5 figures including 3 figures in main text and 2 figures in Appendix", "summary": "An information particle can acquire active-like motion through transforming the information entropy into effective self-propulsion velocity/force using the attached information engine. We consider an underdamped Brownian particle additionally driven by either a constant self-propulsion force or an information engine using Ornstein-Uhlenbeck (OU) bath feedback control, such particles are called self-propelled particle (SPP) or OU information particle (OUIP). Compared to the widely-investigated SPP, the OUIP shows a significant different dynamical pattern, including two types of moving mode: a slow-speed diffusion mode and a high-speed traveling mode. The specific evolution of OUIP can be adjusted flexibly between such two modes through the inertial effect, thus acquiring a rich and non-trivial motion behavior. By tuning the strength of fluctuation of the OU bath, a wide range of net velocity can be achieved for OUIP. We highlight that OUIP could be an exceptional candidate for active agent."}
{"id": "2602.06284", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.06284", "abs": "https://arxiv.org/abs/2602.06284", "authors": ["Patrick Guidotti"], "title": "Geometric Kernel Interpolation and Regression", "comment": "21 pages, 8 figures, 6 tables", "summary": "Exploiting the variational interpretation of kernel interpolation we exhibit a direct connection between interpolation and regression, where interpolation appears as a limiting case of regression. By applying this framework to point clouds or samples of smooth manifolds (hypersurfaces, in particular), we show how fundamental geometric quantities such as tangent plane and principal curvatures can be computed numerically using a kernel based (approximate) level set function (often a defining function) for smooth hypersurfaces. In the case of point clouds, the approach generates an interpolated hypersurface, which is an approximation of the underlying manifold when the cloud is a sample of it. It is shown how the geometric quantities obtained can be used in the numerical approximation/computation of geometric operators like the surface gradient or the Laplace-Beltrami operator in the spirit of kernel based meshfree methods. Kernel based interpolation can be extremely ill-posed, especially when using smooth kernels, and the regression approximation offers a natural regularization that proves also quite useful when dealing with geometric or functional data that are affected by errors or noise."}
{"id": "2602.06186", "categories": ["math.OC", "math.FA"], "pdf": "https://arxiv.org/pdf/2602.06186", "abs": "https://arxiv.org/abs/2602.06186", "authors": ["Fernando García-Castaño", "Miguel Ángel Melguizo-Padial"], "title": "Process-Based Lagrange Multipliers for Nonconvex Set-Valued Optimization", "comment": null, "summary": "We develop a Lagrange multiplier theory for nonconvex set-valued optimization problems under Lipschitz-type regularity conditions. Instead of classical continuous linear functionals, we introduce closed convex processes -- set-valued mappings whose graphs are closed convex cones -- as generalized Lagrange multipliers. This geometric framework extends separation principles beyond convexity and differentiability. We establish the existence of multiplier processes under verifiable assumptions, including Lipschitz regularity at a reference point, the existence of a bounded base of the ordering cone, and a nondegeneracy condition ensuring proper isolation of optimal values. These processes preserve global optimality: nondominated (respectively, minimal) solutions of the primal problem remain nondominated (respectively, minimal) in the penalized problem. In the scalar case, we obtain a one-to-one correspondence between multiplier processes and lower semicontinuous sublinear functions, yielding exact penalty formulations without additional constraint qualifications. An infinite-dimensional example shows that interiority conditions on the ordering cone, while sufficient, are not necessary. Applications to set-valued vector equilibrium problems are also discussed."}
{"id": "2602.06108", "categories": ["quant-ph", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2602.06108", "abs": "https://arxiv.org/abs/2602.06108", "authors": ["Andrei Vrajitoarea", "Gabrielle Roberts", "Kaden R. A. Hazzard", "Jonathan Simon", "David I. Schuster"], "title": "Quantum-controlled synthetic materials", "comment": null, "summary": "Analog quantum simulators and digital quantum computers are two distinct paradigms driving near-term applications in modern quantum science, from probing many-body phenomena to identifying computational advantage over classical systems. A transformative opportunity on the horizon is merging the high-fidelity many-body evolution in analog simulators with the robust control and measurement of digital machines. Such a hybrid platform would unlock new capabilities in state preparation, characterization and dynamical control. Here, we embed digital quantum control in the analog evolution of a synthetic quantum material by entangling the lattice potential landscape of a Bose-Hubbard circuit with an ancilla qubit. This Hamiltonian-level control induces dynamics under a superposition of different lattice configurations and guides the many-body system to novel strongly-correlated states where different phases of matter coexist -- ordering photons into superpositions of solid and fluid eigenstates. Leveraging hybrid control modalities, we adiabatically introduce disorder to localize the photons into an entangled cat state and enhance its coherence using a many-body echo technique. This work illustrates the potential for entangling quantum computers with quantum matter -- synthetic and solid-state -- for advantage in sensing and materials characterization."}
{"id": "2602.06568", "categories": ["math.ST", "math.PR", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.06568", "abs": "https://arxiv.org/abs/2602.06568", "authors": ["Alexandre Chotard"], "title": "Ergodicity of an Adaptive MCMC Sampler under a Probability Bound", "comment": null, "summary": "This paper provides sufficient conditions over the sequence of samples and parameters of an adaptive Markov Chain Monte Carlo (MCMC) algorithm to converge to the target distribution. These conditions aim to make more easily usable classical conditions formulated over the transition kernels, without needing, as was done in other works, to assume the compactness of both sample and parameter spaces. The condition of compactness is replaced here with a probability bound over the sequence of both samples and parameters."}
{"id": "2602.06628", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.06628", "abs": "https://arxiv.org/abs/2602.06628", "authors": ["Anna Sandberg", "Lukas Rødland", "Maria Hermanns"], "title": "3D Spin-orbital liquids", "comment": null, "summary": "Spin-orbital liquids provide an exactly solvable route to three-dimensional Z2 quantum spin liquids beyond the original Kitaev setting. Built from higher-dimensional Clifford-algebra representations, spin-orbital Hamiltonians can be realized on both three- and four-coordinated lattices, giving rise to phases with 3 and 2 itinerant Majorana flavors. We demonstrate that these models host a rich set of gapless Majorana metals, characterized, in particular, by topological Fermi surfaces, nodal lines, and Weyl semimetal phases. We analyze the stability of these structures under physically motivated perturbations and identify generic splitting patterns and topological transitions driven by symmetry breaking and flavor mixing. This yields a unified organizing framework for three-dimensional Majorana metals in fractionalized spin liquids."}
{"id": "2602.06267", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06267", "abs": "https://arxiv.org/abs/2602.06267", "authors": ["Rohan Hore", "Aaditya Ramdas"], "title": "Conformal changepoint localization", "comment": "52 pages, 12 figures", "summary": "We study the problem of offline changepoint localization in a distribution-free setting. One observes a vector of data with a single changepoint, assuming that the data before and after the changepoint are iid (or more generally exchangeable) from arbitrary and unknown distributions. The goal is to produce a finite-sample confidence set for the index at which the change occurs without making any other assumptions. Existing methods often rely on parametric assumptions, tail conditions, or asymptotic approximations, or only produce point estimates. In contrast, our distribution-free algorithm, CONformal CHangepoint localization (CONCH), only leverages exchangeability arguments to construct confidence sets with finite sample coverage. By proving a conformal Neyman-Pearson lemma, we derive principled score functions that yield informative (small) sets. Moreover, with such score functions, the normalized length of the confidence set shrinks to zero under weak assumptions. We also establish a universality result showing that any distribution-free changepoint localization method must be an instance of CONCH. Experiments suggest that CONCH delivers precise confidence sets even in challenging settings involving images or text."}
{"id": "2602.06365", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06365", "abs": "https://arxiv.org/abs/2602.06365", "authors": ["Venkata Rajesh Chundru", "Shreshta Rajakumar Deshpande", "Stanislav A Gankov"], "title": "Advances in Battery Energy Storage Management: Control and Economic Synergies", "comment": "Pre Print", "summary": "The existing literature on Battery Energy Storage Systems (BESS) predominantly focuses on two main areas: control system design aimed at achieving grid stability and the techno-economic analysis of BESS dispatch on power grid. However, with the increasing incorporation of ancillary services into power grids, a more comprehensive approach to energy management systems is required. Such an approach should not only optimize revenue generation from BESS but also ensure the safe, efficient, and reliable operation of lithium-ion batteries. This research seeks to bridge this gap by exploring literature that addresses both the economic and operational dimensions of BESS. Specifically, it examines how economic aspects of grid duty cycles can align with control schemes deployed in BESS systems. This alignment, or synergy, could be instrumental in creating robust digital twins virtual representations of BESS systems that enhance both grid stability and revenue potential.\n  The literature review is organized into five key categories: (1) ancillary services for BESS, exploring support functions that BESS can provide to power grids; (2) control systems developed for real-time BESS power flow management, ensuring smooth operations under dynamic grid conditions; (3) optimization algorithms for BESS dispatch, focusing on efficient energy allocation strategies; (4) techno-economic analyses of BESS and battery systems to assess their financial viability; and (5) digital twin technologies for real-world BESS deployments, enabling advanced predictive maintenance and performance optimization. This review will identify potential synergies, research gaps, and emerging trends, paving the way for future innovations in BESS management and deployment strategies."}
{"id": "2602.06436", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.06436", "abs": "https://arxiv.org/abs/2602.06436", "authors": ["Masaki Chujyo", "Shu Liu", "Fujio Toriumi"], "title": "Impact of seed node position on network robustness under localized attacks", "comment": null, "summary": "Localized attacks (LAs), where damage propagates from a single seed node to its neighbors, pose significant threats to the robustness of complex networks. Although previous studies have extensively analyzed network vulnerability under such attacks, they typically assume random seed node placement and evaluate average robustness. However, the structural position of the seed node can significantly impact the extent of damage. This study proposes the Localized Attack Vulnerability Index (LAVI), a node-level metric that quantifies the potential impact of a LA initiated at a specific node. LAVI quantifies the cumulative number of severed links during attack progression, capturing how local connectivity and topological position amplify the resulting damage. Numerical experiments on synthetic and real-world networks demonstrate that LAVI correlates more strongly with network robustness degradation than standard centrality measures, such as degree, closeness, and betweenness. Our findings highlight that classical centrality metrics fail to capture key dynamics of spatially localized failures, while LAVI provides an accurate and generalizable indicator of node vulnerability under such disruptions."}
{"id": "2602.06436", "categories": ["physics.soc-ph", "cs.SI"], "pdf": "https://arxiv.org/pdf/2602.06436", "abs": "https://arxiv.org/abs/2602.06436", "authors": ["Masaki Chujyo", "Shu Liu", "Fujio Toriumi"], "title": "Impact of seed node position on network robustness under localized attacks", "comment": null, "summary": "Localized attacks (LAs), where damage propagates from a single seed node to its neighbors, pose significant threats to the robustness of complex networks. Although previous studies have extensively analyzed network vulnerability under such attacks, they typically assume random seed node placement and evaluate average robustness. However, the structural position of the seed node can significantly impact the extent of damage. This study proposes the Localized Attack Vulnerability Index (LAVI), a node-level metric that quantifies the potential impact of a LA initiated at a specific node. LAVI quantifies the cumulative number of severed links during attack progression, capturing how local connectivity and topological position amplify the resulting damage. Numerical experiments on synthetic and real-world networks demonstrate that LAVI correlates more strongly with network robustness degradation than standard centrality measures, such as degree, closeness, and betweenness. Our findings highlight that classical centrality metrics fail to capture key dynamics of spatially localized failures, while LAVI provides an accurate and generalizable indicator of node vulnerability under such disruptions."}
{"id": "2602.06365", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06365", "abs": "https://arxiv.org/abs/2602.06365", "authors": ["Venkata Rajesh Chundru", "Shreshta Rajakumar Deshpande", "Stanislav A Gankov"], "title": "Advances in Battery Energy Storage Management: Control and Economic Synergies", "comment": "Pre Print", "summary": "The existing literature on Battery Energy Storage Systems (BESS) predominantly focuses on two main areas: control system design aimed at achieving grid stability and the techno-economic analysis of BESS dispatch on power grid. However, with the increasing incorporation of ancillary services into power grids, a more comprehensive approach to energy management systems is required. Such an approach should not only optimize revenue generation from BESS but also ensure the safe, efficient, and reliable operation of lithium-ion batteries. This research seeks to bridge this gap by exploring literature that addresses both the economic and operational dimensions of BESS. Specifically, it examines how economic aspects of grid duty cycles can align with control schemes deployed in BESS systems. This alignment, or synergy, could be instrumental in creating robust digital twins virtual representations of BESS systems that enhance both grid stability and revenue potential.\n  The literature review is organized into five key categories: (1) ancillary services for BESS, exploring support functions that BESS can provide to power grids; (2) control systems developed for real-time BESS power flow management, ensuring smooth operations under dynamic grid conditions; (3) optimization algorithms for BESS dispatch, focusing on efficient energy allocation strategies; (4) techno-economic analyses of BESS and battery systems to assess their financial viability; and (5) digital twin technologies for real-world BESS deployments, enabling advanced predictive maintenance and performance optimization. This review will identify potential synergies, research gaps, and emerging trends, paving the way for future innovations in BESS management and deployment strategies."}
{"id": "2602.06455", "categories": ["cond-mat.stat-mech", "physics.data-an"], "pdf": "https://arxiv.org/pdf/2602.06455", "abs": "https://arxiv.org/abs/2602.06455", "authors": ["Akihisa Ichiki"], "title": "Relativity of Observation: Operational Intensive Variables in Nonequilibrium Thermodynamics", "comment": null, "summary": "We formulate nonequilibrium thermodynamics in which intensive variables acquire operational meaning through measurement protocols consistent with local reciprocity. Using physical equilibrium as a reference, conjugate observables are constructed by continuously adjusting devices along the local tangent space of the statistical manifold. In this relativity of observation, Onsager reciprocity holds locally, allowing inference-based Lagrange multipliers to be directly measured. This provides a systematic method to extend operational definitions of intensive variables to nonequilibrium states, highlighting their context-dependent nature and offering a concrete experimental strategy."}
{"id": "2602.06491", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.06491", "abs": "https://arxiv.org/abs/2602.06491", "authors": ["Xueqi Wen", "Guozhen Li", "Yuanping Cui", "Xiaoyue Li"], "title": "Strong convergence rate of the explicit adaptive time-stepping methods for stochastic diffusion systems with locally Lipschitz coefficients", "comment": "40 pages, 8 figures, 1 table", "summary": "This paper proposes an adaptive time-stepping mothods for stochastic diffusion systems whose drift and diffusion coefficients are locally Lipschitz continuous and may exhibit polynomial growth. By controlling the growth of both the drift and diffusion coefficients, we give the choice of the state-dependent adaptive timestep and establish strong convergence of the proposed scheme with the optimal order $1/2$. The performance of the adaptive time-stepping scheme is compared with several widely used explicit and implicit schemes, including tamed EM, truncated EM, and backward EM schemes. Numerical experiments on stiff, non-stiff and high-dimensional stochastic diffusion systems verify the improved computational efficiency of the proposed scheme and validate the theoretical results."}
{"id": "2602.06277", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06277", "abs": "https://arxiv.org/abs/2602.06277", "authors": ["Satish Vedula", "Olugbenga Anubi"], "title": "Predictive Energy Management for Hybrid Powertrains", "comment": "To be submitted to IFAC MECC 2026 - ASME Letters in Dynamic Systems and Control Joint Submission", "summary": "Hybrid power trains (HPT) run on multiple energy sources, often involving energy storage systems/batteries (ESS). As a result, the risk of battery degradation and the reliability of energy storage elements pose a major challenge in designing an energy-efficient hybrid power train. This paper presents an energy management strategy that adaptively splits power demand between the engine and the battery pack in a hybrid power train taking into account the battery degradation. Incorporating the battery degradation model directly into the underlying optimization problem is challenging on multiple fronts: 1) Any reasonable degradation model will, due to its complexity, result in a complicated optimization problem that is impractical for real-time implementation 2) the models contain a lot of time-varying parameters that can only be determined through destructive experimental procedures. As a result, it is essential to devise heuristics that reasonably capture the degradation per usage of the batteries. One such heuristic considered in this paper is the absolute power extracted from the battery. A distributed model predictive strategy is then developed to coordinate the power split to maximize efficiency while mitigating the failure risk due to battery degradation. The designed EM strategy is demonstrated through a realistic simulation of three different hybrid power trains: hybrid road vehicles (for example: a hybrid electric vehicle (HEV)), hybrid surface vehicles (for example: dynamically positioned hybrid ships (DPS)), and hybrid aerial vehicles (for example: hybrid electric aircraft (HEA)). The results show the effectiveness of the energy management strategy in managing battery degradation."}
{"id": "2602.06114", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2602.06114", "abs": "https://arxiv.org/abs/2602.06114", "authors": ["Bryce Bullock", "Sean R. Muleady", "Jennifer F. Lilieholm", "Yicheng Zhang", "Robert J. Lewis-Swan", "John J. Bollinger", "Ana Maria Rey", "Allison L. Carter"], "title": "Quantum simulation of the Dicke model in a two-dimensional ion crystal: chaos, quantum thermalization, and revivals", "comment": "8+11 pages, 5+8 figures", "summary": "Quantum many-body systems driven far from equilibrium can exhibit chaos, entanglement, and non-classical correlations, yet directly observing these phenomena in large, closed quantum systems remains challenging. Here we realize the Dicke model -- a fundamental description of light-matter interactions -- in a two-dimensional crystal of approximately 100 trapped ions. The ions' internal state is optically coupled to the center of mass vibrational mode via an optical spin-dependent force, enabling unitary many-body dynamics beyond the mean-field and few-body limits. In the integrable regime, where the phonons can be adiabatically eliminated, we observe a dynamical phase transition between ferromagnetic to paramagnetic spin phases. In contrast, when the spins and phonons are strongly coupled, we observe clear signatures of non-integrable chaotic dynamics, including erratic phase-space trajectories and the exponential growth of excitations and entanglement quantified by the one-body Rényi entropy. By quenching from an unstable fixed point in the near-integrable regime, quantum noise can generate correlated spin-phonon excitations. Our numerical calculations, in clear agreement with experiment, reveal the generation of two-mode spin-phonon squeezing, 2.6 dB below the standard quantum limit (4.6 dB relative to the initial thermal state), followed by generalized vacuum Rabi collapses and revivals. Our results establish large ion crystals as scalable analog quantum simulators of non-equilibrium light-matter dynamics and provide a controlled platform for experimental studies of information scrambling and entanglement in closed many-body systems."}
{"id": "2602.06764", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06764", "abs": "https://arxiv.org/abs/2602.06764", "authors": ["Emil S. Jørgensen", "Michael Sørensen"], "title": "Prediction-based inference for integrated diffusions with high-frequency data", "comment": null, "summary": "We consider parametric inference for an ergodic and stationary diffusion process, when the data are high-frequency observations of the integral of the diffusion process. Such data are obtained via certain measurement devices, or if positions are recorded and speed is modelled by a diffusion. In finance, realized volatility or variations thereof can be used to construct observations of the latent integrated volatility process. Specifically, we assume that the integrated process is observed at equidistant, deterministic time points and consider the high-frequency/infinite horizon asymptotic scenario, where the number of observations, the sampling frequency and the time of the last observation all go to infinity. Subject to mild standard regularity conditions on the diffusion model, we prove the asymptotic existence and uniqueness of a consistent estimator for useful and tractable classes of prediction-based estimating functions. Asymptotic normality of the estimator is obtained under an additional assumption on the rates. The proofs are based on the useful Euler-Ito expansions of transformations of diffusions and integrated diffusions, which we study in some detail."}
{"id": "2602.06705", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.06705", "abs": "https://arxiv.org/abs/2602.06705", "authors": ["Yifan Wang", "David W. Tam", "Weiyi Wang", "R. A. Ewings", "J. Ross Stewart", "Masaaki Matsuda", "Chongde Cao", "Changle Liu", "Rong Yu", "Pengcheng Dai", "Yu Song"], "title": "Quasi-one-dimensional spin excitations in the iron pnictide NaFe$_{0.53}$Cu$_{0.47}$As", "comment": "supplementary information available upon request", "summary": "Spectroscopic measurements in model one-dimensional (1D) correlated systems offer insights for understanding their two-dimensional counterparts, which include the cuprate and iron pnictide/chalcogenide superconductors. A major challenge is the identification of such correlated systems with dominantly 1D physics. In this work, inelastic neutron scattering measurements on NaFe$_{0.53}$Cu$_{0.47}$As single crystal directly reveal quasi-1D spin excitations, resulting from atomic order that lead to magnetic Fe and nonmagnetic Cu chains. The dominant exchange interaction is antiferromagnetic along the chain ($SJ_{\\rm \\parallel}\\approx90.1(3)$~meV), whereas the inter-chain couplings are much weaker ($SJ_{\\rm \\perp}\\approx-2.4(1)$~meV and $SJ_{\\rm c}\\approx0.15(5)$~meV). The quasi-1D spin excitations in NaFe$_{0.53}$Cu$_{0.47}$As stem from both the Néel and stripe vectors, with Néel excitations sensitive to Fe impurities on the Cu site. The spin excitations in quasi-1D NaFe$_{0.53}$Cu$_{0.47}$As and quasi-2D FeSe exhibit a striking resemblance, suggesting a common origin for their coexistent stripe and Néel excitations. Our findings demonstrate magnetic dilution in NaFeAs leads to dimension reduction of its magnetic degree of freedom, presenting a strategy for discovering low-dimensional quantum materials."}
{"id": "2602.06301", "categories": ["stat.ME", "stat.AP", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.06301", "abs": "https://arxiv.org/abs/2602.06301", "authors": ["JoonHo Lee"], "title": "Design-Conditional Prior Elicitation for Dirichlet Process Mixtures: A Unified Framework for Cluster Counts and Weight Control", "comment": null, "summary": "Dirichlet process mixture (DPM) models are widely used for semiparametric Bayesian analysis in educational and behavioral research, yet specifying the concentration parameter remains a critical barrier. Default hyperpriors often impose strong, unintended assumptions about clustering, while existing calibration methods based on cluster counts suffer from computational inefficiency and fail to control the distribution of mixture weights. This article introduces Design-Conditional Elicitation (DCE), a unified framework that translates practitioner beliefs about cluster structure into coherent Gamma hyperpriors for a fixed design size J. DCE makes three contributions. First, it solves the computational bottleneck using Two-Stage Moment Matching (TSMM), which couples a closed-form approximation with an exact Newton refinement to calibrate hyperparameters without grid search. Second, addressing the \"unintended prior\" phenomenon, DCE incorporates a Dual-Anchor protocol to diagnose and optionally constrain the risk of weight dominance while transparently reporting the resulting trade-off against cluster-count fidelity. Third, the complete workflow is implemented in the open-source DPprior R package with reproducible diagnostics and a reporting checklist. Simulation studies demonstrate that common defaults such as Gamma(1, 1) induce posterior collapse rates exceeding 60% regardless of the true cluster structure, while DCE-calibrated priors substantially reduce bias and improve recovery across varying levels of data informativeness."}
{"id": "2602.06569", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06569", "abs": "https://arxiv.org/abs/2602.06569", "authors": ["Omid Akbarzadeh", "MohammadHossein Ashoori", "Amy Nejati", "Abolfazl Lavaei"], "title": "Safety Controller Synthesis for Stochastic Polynomial Time-Delayed Systems", "comment": null, "summary": "This work develops a theoretical framework for safety controller synthesis in discrete-time stochastic nonlinear polynomial systems subject to time-invariant delays (dt-SNPS-td). While safety analysis of stochastic systems using control barrier certificates (CBC) has been widely studied, developing safety controllers for stochastic systems with time delays remains largely unexplored. The main challenge arises from the need to account for the influence of delayed components when formulating and enforcing safety conditions. To address this, we employ Krasovskii control barrier certificates, which extend the conventional CBC framework by augmenting it with an additional summation term that captures the influence of delayed states. This formulation integrates both the current and delayed components into a unified barrier structure, enabling safety synthesis for stochastic systems with time delays. The proposed approach synthesizes safety controllers under input constraints, offering probabilistic safety guarantees robust to such delays: it ensures that all trajectories of the dt-SNPS-td remain within the prescribed safe region while fulfilling a quantified probabilistic bound. To achieve this, our method reformulates the safety constraints as a sum-of-squares optimization program, enabling the systematic construction of Krasovskii CBC together with their associated safety controllers. We validate the proposed framework through three case studies, including two physical systems, demonstrating its effectiveness and practical applicability."}
{"id": "2602.06437", "categories": ["physics.soc-ph", "cs.CY"], "pdf": "https://arxiv.org/pdf/2602.06437", "abs": "https://arxiv.org/abs/2602.06437", "authors": ["Masaki Chujyo", "Isamu Okada", "Hitoshi Yamamoto", "Dongwoo Lim", "Fujio Toriumi"], "title": "An attention economy model of co-evolution between content quality and audience selectivity", "comment": null, "summary": "Human attention has become a scarce and strategically contested resource in digital environments. Content providers increasingly engage in excessive competition for visibility, often prioritizing attention-grabbing tactics over substantive quality. Despite extensive empirical evidence, however, there is a lack of theoretical models that explain the fundamental dynamics of the attention economy. Here, we develop a minimal mathematical framework to explain how content quality and audience attention coevolve under limited attention capacity. Using an evolutionary game approach, we model strategic feedback between providers, who decide how much effort to invest in production, and consumers, who choose whether to search selectively for high-quality content or to engage passively. Analytical and numerical results reveal three characteristic regimes of content dynamics: collapse, boundary, and coexistence. The transitions between these regimes depend on how effectively audiences can distinguish content quality. When audience discriminability is weak, both selective attention and high-quality production vanish, leading to informational collapse. When discriminability is sufficient and incentives are well aligned, high- and low-quality content dynamically coexist through feedback between audience selectivity and providers' effort. These findings identify two key conditions for sustaining a healthy information ecosystem: adequate discriminability among audiences and sufficient incentives for high-effort creation. The model provides a theoretical foundation for understanding how institutional and platform designs can prevent the degradation of content quality in the attention economy."}
{"id": "2602.06569", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06569", "abs": "https://arxiv.org/abs/2602.06569", "authors": ["Omid Akbarzadeh", "MohammadHossein Ashoori", "Amy Nejati", "Abolfazl Lavaei"], "title": "Safety Controller Synthesis for Stochastic Polynomial Time-Delayed Systems", "comment": null, "summary": "This work develops a theoretical framework for safety controller synthesis in discrete-time stochastic nonlinear polynomial systems subject to time-invariant delays (dt-SNPS-td). While safety analysis of stochastic systems using control barrier certificates (CBC) has been widely studied, developing safety controllers for stochastic systems with time delays remains largely unexplored. The main challenge arises from the need to account for the influence of delayed components when formulating and enforcing safety conditions. To address this, we employ Krasovskii control barrier certificates, which extend the conventional CBC framework by augmenting it with an additional summation term that captures the influence of delayed states. This formulation integrates both the current and delayed components into a unified barrier structure, enabling safety synthesis for stochastic systems with time delays. The proposed approach synthesizes safety controllers under input constraints, offering probabilistic safety guarantees robust to such delays: it ensures that all trajectories of the dt-SNPS-td remain within the prescribed safe region while fulfilling a quantified probabilistic bound. To achieve this, our method reformulates the safety constraints as a sum-of-squares optimization program, enabling the systematic construction of Krasovskii CBC together with their associated safety controllers. We validate the proposed framework through three case studies, including two physical systems, demonstrating its effectiveness and practical applicability."}
{"id": "2602.06458", "categories": ["cond-mat.stat-mech", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06458", "abs": "https://arxiv.org/abs/2602.06458", "authors": ["Akihisa Ichiki"], "title": "Inferring Microscopic Explanatory Structures from Observational Constraints via Large Deviations", "comment": null, "summary": "We study how macroscopic observational constraints restrict admissible microscopic explanatory structures when no intrinsic order or dynamics is assumed a priori. Starting from an unordered collection of measurement outcomes, we formulate inference as a constrained large deviation problem, selecting probability assignments that minimize relative entropy with respect to a reference measure determined solely by the measurement setup. We show that among all microscopic structures compatible with a given macroscopic constraint, those rendering the observation statistically most typical are selected. As an explicit illustration, we demonstrate how ordered microscopic structures can emerge purely from inference under constraint, even when the reference measure is fully permutation symmetric. Order is thus not assumed but inferred, serving here only as an illustrative example of a broader class of relational explanatory hypotheses constrained by observation."}
{"id": "2602.06513", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.06513", "abs": "https://arxiv.org/abs/2602.06513", "authors": ["Julio Careaga", "Patrick Ersing", "Julian Koellermeier", "Andrew R. Winters"], "title": "Entropy analysis and entropy stable DG methods for the shallow water moment equations", "comment": null, "summary": "We demonstrate that the shallow water moment equations satisfy an auxiliary entropy conservation law, where the entropy function corresponds to the total energy. Additionally, we show that the classical Newtonian slip friction and Manning friction terms are entropy dissipative with respect to the developed entropy variables. The results from the continuous entropy analysis are used to construct an entropy stable and well-balanced nodal discontinuous Galerkin spectral element method for the spatial approximation. Key to ensure the entropy stability of the scheme is the derivation of entropy conservative numerical fluxes that satisfy a discrete version of the entropy flux compatibility condition. Finally, numerical examples demonstrate the performance of the scheme and validate the theoretical results."}
{"id": "2602.06398", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06398", "abs": "https://arxiv.org/abs/2602.06398", "authors": ["Jiayi Zhu", "Hong Wang", "Ling Liang", "Lei Yang"], "title": "D-ripALM: A Tuning-friendly Decentralized Relative-Type Inexact Proximal Augmented Lagrangian Method", "comment": null, "summary": "This paper proposes D-ripALM, a Decentralized relative-type inexact proximal Augmented Lagrangian Method for consensus convex optimization over multi-agent networks. D-ripALM adopts a double-loop distributed optimization framework that accommodates a wide range of inner solvers, enabling efficient treatment of both smooth and nonsmooth objectives. In contrast to existing double-loop distributed augmented Lagrangian methods, D-ripALM employs a relative-type error criterion to regulate the switching between inner and outer iterations, resulting in a more practical and tuning-friendly algorithmic framework with enhanced numerical robustness. Moreover, we establish rigorous convergence guarantees for D-ripALM under general convexity assumptions, without requiring smoothness or strong convexity conditions commonly imposed in the distributed optimization literature. Numerical experiments further demonstrate the tuning-friendly nature of D-ripALM and its efficiency in attaining high-precision solutions with fewer communication rounds."}
{"id": "2602.06123", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.06123", "abs": "https://arxiv.org/abs/2602.06123", "authors": ["Lisa Bombieri", "Torsten V. Zache", "Hannes Pichler", "Daniel González-Cuadra"], "title": "U(1) lattice gauge theory and string roughening on a triangular Rydberg array", "comment": null, "summary": "Lattice gauge theories (LGTs) describe fundamental interactions in particle physics. A central phenomenon in these theories is confinement, which binds quarks and antiquarks into hadrons through the formation of string-like flux tubes of gauge fields. Simulating confinement dynamics is a challenging task, but recent advances in quantum simulation are enabling the exploration of LGTs in regimes beyond the reach of classical computation. For analog devices, a major difficulty is the realization of strong plaquette interactions, which generate string fluctuations that can drive a roughening transition. Understanding string roughening -- where strong transversal functions lead to an effective restoration of translational symmetry at long distances -- is of central importance in the study of confinement. In this work, we show that string roughening emerges naturally in an analog Rydberg quantum simulator. We first map a triangular Rydberg array onto a (2+1)D U(1) LGT where plaquette terms appear as first-order processes. We study flux strings connecting static charges and demonstrate that, near a deconfined quantum critical point, the string exhibits logarithmic growth of its transverse width as the separation between charges increases, along with the universal Lüscher correction to the confining potential -- both signatures of string roughening. Finally, we investigate the real-time dynamics of an initially rigid string, observing large fluctuations after quenching into the roughening regime, as well as string breaking via particle-pair creation. Our results indicate that rough strings can be realized in experimentally accessible quantum simulators, opening the door to detailed studies of how strong fluctuations influence string-breaking dynamics."}
{"id": "2602.06832", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.06832", "abs": "https://arxiv.org/abs/2602.06832", "authors": ["Nicolas Fraiman", "Michael Nisenzon"], "title": "Exact recovery for seeded graph matching", "comment": "27 pages, 1 figure", "summary": "We study graph matching between two correlated networks in the almost fully seeded regime, where all but a vanishing fraction of vertex correspondences are revealed. Concretely, we consider the correlated stochastic block model and assume that $n^{1-α}$ vertices remain unrevealed for some $α\\in (0,1)$, while the remaining $n - n^{1-α}$ vertices are provided as seed correspondences. Our goal is to determine when the true permutation can be recovered efficiently as the proportion of unrevealed vertices vanishes.\n  We prove that exact recovery of the remaining correspondences is achievable in polynomial time whenever $λs^{2} > 1 - α$, where $λ= (a+b)/2$ is the SBM density parameter and $s$ denotes the edge retention parameter. This condition smoothly interpolates between the fully seeded setting and the classical unseeded threshold $λs^{2} > 1$ for matching in correlated Erdős-Rényi graphs. Our analysis applies to both a simple neighborhood-overlap rule and a bistochastic relaxation followed by projection, establishing matching achievability in the almost fully seeded regime without requiring spectral methods or message passing.\n  On the converse side, we show that below the same threshold, exact recovery is information-theoretically impossible with high probability. Thus, to our knowledge, we obtain the first tight statistical and computational characterization of graph matching when only a vanishing fraction of vertices remain unrevealed. Our results complement recent progress in semi-supervised community detection by demonstrating that revealing all but $n^{1-α}$ correspondences similarly lowers the information threshold for graph matching."}
{"id": "2602.06712", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.06712", "abs": "https://arxiv.org/abs/2602.06712", "authors": ["Shangjie Tian", "Xiangjiang Dong", "Bowen Zhang", "Zhijun Tu", "Runze Yu", "Hechang Lei", "Shouguo Wang"], "title": "Physical properties of RhGe and CoGe single crystals synthesized under high pressure", "comment": "15 pages, 4 figures, 1 table", "summary": "Chiral topological semimetals hosting multifold fermions and exotic surface states represent a frontier in topological materials research. Among them, noncentrosymmetric cubic B20 compounds-notably transition-metal silicides and germanides-offer a unique platform for realizing symmetry-protected topological phases and unconventional optoelectronic responses. Here, we report the physical properties of RhGe and CoGe single crystals with B20 structure in detail. Transport measurements reveal metallic behavior with characteristic Fermi-liquid scaling at low temperatures, while magnetization results confirm paramagnetism in both compounds. In addition, both of materials exhibit low carrier concentrations with small electronic specific heat coefficient, indicating their semimetal feature with weak electronic correlations. Such high-quality CoGe and RhGe single crystals provide a material platform to explore the evolution of multifold fermions and the instability of helicoid-arc surface states with spin-orbit coupling and surface environment in B20 material systems."}
{"id": "2602.06379", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.06379", "abs": "https://arxiv.org/abs/2602.06379", "authors": ["Alexandra Sokolova", "Vadim Sokolov"], "title": "E-values for Adaptive Clinical Trials: Anytime-Valid Monitoring in Practice", "comment": null, "summary": "Adaptive clinical trials rely on interim analyses, flexible stopping, and data-dependent design modifications that complicate statistical guarantees when fixed-horizon test statistics are repeatedly inspected or reused after adaptations. E-values and e-processes provide anytime-valid tests and confidence sequences that remain valid under optional stopping and optional continuation without requiring a prespecified monitoring schedule.\n  This paper is a methodology guide for practitioners. We develop the betting-martingale construction of e-processes for two-arm randomized controlled trials, show how e-values naturally handle composite null hypotheses and support futility monitoring, and provide guidance on when e-values are appropriate, when established alternatives are preferable, and how to integrate e-value monitoring with group sequential and Bayesian adaptive workflows.\n  A numerical study compares five monitoring rules -- naive and calibrated versions of frequentist, Bayesian, and e-value approaches -- in a two-arm binary-endpoint trial. Naive repeated testing and naive posterior thresholds inflate Type I error substantially under frequent interim looks. Among the valid methods, the calibrated group sequential rule achieves the highest power, the e-value rule provides robust anytime-valid control with moderate power, and the calibrated Bayesian rule is the most conservative.\n  Extended simulations show that the power gap between group sequential and e-value methods depends on the monitoring schedule and reverses under continuous monitoring. The methodology, including futility monitoring, platform trial multiplicity control, and hybrid strategies combining e-values with established methods, is implemented in the open-source R package `evalinger` and situated within the regulatory framework of the January 2026 FDA draft guidance on Bayesian methodology."}
{"id": "2602.06618", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06618", "abs": "https://arxiv.org/abs/2602.06618", "authors": ["Antonio Bernardes", "Jasan Zughaibi", "Michael Muehlebach", "Bradley J. Nelson"], "title": "Structured Learning for Electromagnetic Field Modeling and Real-Time Inversion", "comment": null, "summary": "Precise magnetic field modeling is fundamental to the closed-loop control of electromagnetic navigation systems (eMNS) and the analytical Multipole Expansion Model (MPEM) is the current standard. However, the MPEM relies on strict physical assumptions regarding source symmetry and isolation, and requires optimization-based calibration that is highly sensitive to initialization. These constraints limit its applicability to systems with complex or irregular coil geometries. This work introduces an alternative modeling paradigm based on multi-layer perceptrons that learns nonlinear magnetic mappings while strictly preserving the linear dependence on currents. As a result, the field models enable fast, closed-form minimum-norm inversion with evaluation times of approximately 1 ms, which is critical for high-bandwidth magnetic control. For model training and evaluation we use large-scale, high-density datasets collected from the research-grade OctoMag and clinical-grade Navion systems. Our results demonstrate that data-driven models achieve predictive fidelity equivalent to the MPEM while maintaining comparable data efficiency. Furthermore, we demonstrate that straightforward design choices effectively eliminate spurious workspace ill-conditioning frequently reported in MPEM-based calibration. To facilitate future research, we release the complete codebase and datasets open source."}
{"id": "2602.06517", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.06517", "abs": "https://arxiv.org/abs/2602.06517", "authors": ["Enock Ndunda", "Alexandre Nicolas"], "title": "Smart On-Street Parking: Survey of Actual Implementations in Cities and Insights from Practitioners", "comment": null, "summary": "Smart solutions for on-street parking, which collect and leverage real-time information about on-street parking space availability to guide drivers or adjust policies, have attracted considerable attention in academia and in the corporate world, but comprehensive feedback on actual implementations was still missing. Here, we survey around 25 smart parking (SP) implementations in cities across the world using online sources. To get more candid insights, we complement this objective review with case studies centred around interviews that we conducted with practitioners from ten cities across continents (San Francisco, Saint Pete Beach, Penang, Douala, Soissons, Grand Paris Seine Ouest, Montpellier, Frauenfeld, Zurich, Perth). Summing up our observations, we underline the broad diversity of SP implementations in terms of contexts and scales, from 2-to-3-year small-scale pilot studies to large deployments that take centre stage in a city's mobility policy. Technological choices also vary widely, from the ground sensors used in pioneering deployments in the early 2010s and still in use, to static cameras (which cover more spaces per device), and to mobile cameras with automatic licence-plate recognition embarked in roaming cars, a more and more popular solution for parking control. Different attitudes to the role given to smartphone applications are also noticed. But, importantly, not only means, but also goals differ: facilitating parking control and enhancing revenue, or providing data for a curb-pricing strategy, or feeding live data into navigation algorithms to reduce parking search times. Unfortunately, their level of achievement is seldom gauged with robust metrics. Hardware durability issues are mentioned as causes of premature termination, particularly for `first-generation' ground sensors, but so, too, are fluctuating political will and changing priorities. Smaller-scale, geographically isolated implementations and pilots are particularly vulnerable to these fluctuations, to discontinued funding or defaulting start-ups, and to limited public awareness."}
{"id": "2602.06618", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06618", "abs": "https://arxiv.org/abs/2602.06618", "authors": ["Antonio Bernardes", "Jasan Zughaibi", "Michael Muehlebach", "Bradley J. Nelson"], "title": "Structured Learning for Electromagnetic Field Modeling and Real-Time Inversion", "comment": null, "summary": "Precise magnetic field modeling is fundamental to the closed-loop control of electromagnetic navigation systems (eMNS) and the analytical Multipole Expansion Model (MPEM) is the current standard. However, the MPEM relies on strict physical assumptions regarding source symmetry and isolation, and requires optimization-based calibration that is highly sensitive to initialization. These constraints limit its applicability to systems with complex or irregular coil geometries. This work introduces an alternative modeling paradigm based on multi-layer perceptrons that learns nonlinear magnetic mappings while strictly preserving the linear dependence on currents. As a result, the field models enable fast, closed-form minimum-norm inversion with evaluation times of approximately 1 ms, which is critical for high-bandwidth magnetic control. For model training and evaluation we use large-scale, high-density datasets collected from the research-grade OctoMag and clinical-grade Navion systems. Our results demonstrate that data-driven models achieve predictive fidelity equivalent to the MPEM while maintaining comparable data efficiency. Furthermore, we demonstrate that straightforward design choices effectively eliminate spurious workspace ill-conditioning frequently reported in MPEM-based calibration. To facilitate future research, we release the complete codebase and datasets open source."}
{"id": "2602.06497", "categories": ["cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.06497", "abs": "https://arxiv.org/abs/2602.06497", "authors": ["Cheng Ye", "Zi-Song Shen", "Pan Zhang"], "title": "Tensor network dynamical message passing for epidemic models", "comment": null, "summary": "While epidemiological modeling is pivotal for informing public health strategies, a fundamental trade-off limits its predictive fidelity: exact stochastic simulations are often computationally intractable for large-scale systems, whereas efficient analytical approximations typically fail to account for essential short-range correlations and network loops. Here, we resolve this trade-off by introducing Tensor Network Dynamical Message Passing (TNDMP), a framework grounded in a rigorous property we term \\textit{Susceptible-Induced Factorization}. This theoretical insight reveals that a susceptible node acts as a dynamical decoupler, factorizing the global evolution operator into localized components. Leveraging this, TNDMP provides a dual-mode algorithmic suite: an exact algorithm that computes local observables with minimal redundancy on tractable topologies and a scalable and tunable approximation for complex real-world networks. We demonstrate that widely adopted heuristics, such as Dynamical Message Passing (DMP) and Pair Approximation (PA), are mathematically recoverable as low-order limits of our framework. Numerical validation in synthetic and real-world networks confirms that TNDMP significantly outperforms existing methods to predict epidemic thresholds and steady states, offering a rigorous bridge between the efficiency of message passing and the accuracy of tensor network formalisms."}
{"id": "2602.06614", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.06614", "abs": "https://arxiv.org/abs/2602.06614", "authors": ["Fabio Nobile", "Sébastien Riffaud", "Thomas Trigo Trindade"], "title": "Dynamical Low-Rank Ensemble Kalman filter for State/Parameter estimation", "comment": "26 pages, 14 figures, 6 tables", "summary": "We propose a Dynamical Low-Rank Ensemble Kalman Filter (DLR-ENKF) for efficient joint state-parameter estimation in high-dimensional dynamical systems. The method extends the DLR-ENKF formulation of arXiv:2509.11210 to the augmented state-parameter framework, tracking the filtering density within a dynamically evolving low-dimensional subspace. Key developments include a time-integration strategy that combines the Basis Update & Galerkin scheme with forecast/analysis discretisation, and a DEIM-based hyper-reduction technique for efficient evaluation of nonlinear terms. We demonstrate the effectiveness, robustness, and computational advantages of the proposed approach on benchmark problems. The results highlight the potential of dynamically evolving reduced bases to achieve accurate filtering and parameter estimation at reduced computational cost."}
{"id": "2602.06447", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06447", "abs": "https://arxiv.org/abs/2602.06447", "authors": ["Sheetal Dharmatti", "Greeshma K"], "title": "Pointwise Tracking Optimal Control Problem for Cahn Hilliard Navier Stokes system", "comment": null, "summary": "We study a pointwise tracking optimal control problem for the two-dimensional local Cahn Hilliard Navier Stokes system, which models the evolution of two immiscible, incompressible fluids. The source term in the Cahn Hilliard equation acts as a control, and the cost functional measures the deviation of the phase variable from desired values at a finite set of spatial points over time. This setting reflects realistic applications where only a limited number of sensors are available. We also study a variant of the above pointwise tracking control problem where the cost is incorporated with a terminal time pointwise tracking term. The main mathematical difficulty arises from the low regularity of the cost functional due to the pointwise evaluation of the state variables. We prove the existence of strong solutions, establish the existence of an optimal control, and the differentiability of the control to state mapping. We define the adjoint system using a transposition method to characterise optimal control. Moreover, a first-order necessary optimality condition is derived in terms of the adjoint for both problems. Furthermore, we prove that our analysis can be extended to the case of singular potentials."}
{"id": "2602.06137", "categories": ["quant-ph", "cs.LG", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.06137", "abs": "https://arxiv.org/abs/2602.06137", "authors": ["Ricard Puig", "Berta Casas", "Alba Cervera-Lierta", "Zoë Holmes", "Adrián Pérez-Salinas"], "title": "Warm Starts, Cold States: Exploiting Adiabaticity for Variational Ground-States", "comment": "11 + 24 pages, 3 figures", "summary": "Reliable preparation of many-body ground states is an essential task in quantum computing, with applications spanning areas from chemistry and materials modeling to quantum optimization and benchmarking. A variety of approaches have been proposed to tackle this problem, including variational methods. However, variational training often struggle to navigate complex energy landscapes, frequently encountering suboptimal local minima or suffering from barren plateaus. In this work, we introduce an iterative strategy for ground-state preparation based on a stepwise (discretized) Hamiltonian deformation. By complementing the Variational Quantum Eigensolver (VQE) with adiabatic principles, we demonstrate that solving a sequence of intermediate problems facilitates tracking the ground-state manifold toward the target system, even as we scale the system size. We provide a rigorous theoretical foundation for this approach, proving a lower bound on the loss variance that suggests trainability throughout the deformation, provided the system remains away from gap closings. Numerical simulations, including the effects of shot noise, confirm that this path-dependent tracking consistently converges to the target ground state."}
{"id": "2602.06918", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2602.06918", "abs": "https://arxiv.org/abs/2602.06918", "authors": ["Enrique de Amo", "Juan Fernández-Sánchez", "David García-Fernández", "Manuel Úbeda-Flores"], "title": "Convex lineability in copula and quasi-copula sets", "comment": "4 figures", "summary": "In this paper, we investigate several subsets of $n$-copulas and $n$-quasi-copulas from the perspective of convex-lineability and the recently introduced concept of convex-spaceability. Our purpose is to determine when such families contain extremely large algebraic structures, namely linearly independent sets of cardinality of the continuum whose convex hull, and in some cases a closed convex linearly independent subset, remain entirely inside the class under study. These include the families of asymmetric copulas, copulas with maximal asymmetric measure, and proper $n$-quasi-copulas, among others. In contrast, for several other natural classes of copulas we show that (maximal) convex lineability holds while convex spaceability remains an open problem."}
{"id": "2602.06739", "categories": ["cond-mat.str-el", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2602.06739", "abs": "https://arxiv.org/abs/2602.06739", "authors": ["Sayari Ghatak", "Abhishek Das", "Andrei Gloskovskii", "Dinesh Topwal"], "title": "Investigation of the Electronic Structure and Spin-State Crossover in LaCoO3 Using Photoemission Spectroscopy", "comment": "7 pages, 4 figures", "summary": "Photoemission spectroscopy is a powerful technique for studying electronic structure and spin-state transitions, as it reveals changes in the orbital configuration accompanying a spin-state crossover. In this report, we combine excitation-energy-, temperature-, and geometry-dependent photoemission measurements to probe the electronic structure of LaCoO3 across its thermally driven spin-state transition. By systematically comparing valence-band spectra across a wide photon-energy window - from surface-sensitive soft x-ray photoemission spectroscopy (SXPS) to bulk-sensitive hard x-ray photoemission spectroscopy (HAXPES) - we identify the Co 3d-derived feature (A) along with the O 2p-dominated features (B and C), and explain their relative evolution in terms of photon-energy-dependent photo-ionization cross-section ratios. The thermally induced spin-state crossover is demonstrated using temperature-dependent SXPS valence-band spectra, which show a progressive suppression of the feature A with heating. Geometry-dependent HAXPES measurements further clarify how the signature of the spin-state transition in LaCoO3 is intricately linked to the orbital-selective response of the t2g and eg states. Additionally, angular-dependent photo-ionization cross-section analysis provides a consistent description of the polarization dependence observed in HAXPES. Finally, configuration-interaction analysis of the Co 2p core-level spectra reveals that LaCoO3 evolves from a predominantly low-spin ground state at low temperature to a mixed low-spin/high-spin configuration at elevated temperatures, with the high-spin fraction reaching about 30 percent at 400 K. The temperature evolution of the core-level line shape thus establishes Co 2p photoemission as a sensitive quantitative probe of spin-state transitions in LaCoO3."}
{"id": "2602.06435", "categories": ["stat.ME", "econ.EM"], "pdf": "https://arxiv.org/pdf/2602.06435", "abs": "https://arxiv.org/abs/2602.06435", "authors": ["Zhongjian Lin", "Zhentao Shi", "Yapeng Zheng"], "title": "Social Interactions Models with Latent Structures", "comment": null, "summary": "This paper studies estimation and inference of heterogeneous peer effects featuring group fixed effects and slope heterogeneity under latent structure. We adapt the Classifier-Lasso algorithm to consistently discover latent structures and determine the number of clusters. To solve the incidental parameter problem in the binary choice model with social interactions, we propose a parametric bootstrap method to debias and establish its asymptotic validity. Monte Carlo simulations confirm strong finite sample performance of our methods. In an application to students' risky behaviors, the algorithm detects two latent clusters and finds that peer effects are significant within one of the clusters, demonstrating the practical applicability in uncovering heterogeneous social interactions."}
{"id": "2602.06639", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06639", "abs": "https://arxiv.org/abs/2602.06639", "authors": ["Davide Tebaldi", "Roberto Zanasi"], "title": "Efficient and Robust Modeling of Nonlinear Mechanical Systems", "comment": null, "summary": "The development of efficient and robust dynamic models is fundamental in the field of systems and control engineering. In this paper, a new formulation for the dynamic model of nonlinear mechanical systems, that can be applied to different automotive and robotic case studies, is proposed, together with a modeling procedure allowing to automatically obtain the model formulation. Compared with the Euler-Lagrange formulation, the proposed model is shown to give superior performances in terms of robustness against measurement noise for systems exhibiting dependence on some external variables, as well as in terms of execution time when computing the inverse dynamics of the system."}
{"id": "2602.06497", "categories": ["cond-mat.stat-mech", "physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2602.06497", "abs": "https://arxiv.org/abs/2602.06497", "authors": ["Cheng Ye", "Zi-Song Shen", "Pan Zhang"], "title": "Tensor network dynamical message passing for epidemic models", "comment": null, "summary": "While epidemiological modeling is pivotal for informing public health strategies, a fundamental trade-off limits its predictive fidelity: exact stochastic simulations are often computationally intractable for large-scale systems, whereas efficient analytical approximations typically fail to account for essential short-range correlations and network loops. Here, we resolve this trade-off by introducing Tensor Network Dynamical Message Passing (TNDMP), a framework grounded in a rigorous property we term \\textit{Susceptible-Induced Factorization}. This theoretical insight reveals that a susceptible node acts as a dynamical decoupler, factorizing the global evolution operator into localized components. Leveraging this, TNDMP provides a dual-mode algorithmic suite: an exact algorithm that computes local observables with minimal redundancy on tractable topologies and a scalable and tunable approximation for complex real-world networks. We demonstrate that widely adopted heuristics, such as Dynamical Message Passing (DMP) and Pair Approximation (PA), are mathematically recoverable as low-order limits of our framework. Numerical validation in synthetic and real-world networks confirms that TNDMP significantly outperforms existing methods to predict epidemic thresholds and steady states, offering a rigorous bridge between the efficiency of message passing and the accuracy of tensor network formalisms."}
{"id": "2602.06639", "categories": ["eess.SY", "cs.RO"], "pdf": "https://arxiv.org/pdf/2602.06639", "abs": "https://arxiv.org/abs/2602.06639", "authors": ["Davide Tebaldi", "Roberto Zanasi"], "title": "Efficient and Robust Modeling of Nonlinear Mechanical Systems", "comment": null, "summary": "The development of efficient and robust dynamic models is fundamental in the field of systems and control engineering. In this paper, a new formulation for the dynamic model of nonlinear mechanical systems, that can be applied to different automotive and robotic case studies, is proposed, together with a modeling procedure allowing to automatically obtain the model formulation. Compared with the Euler-Lagrange formulation, the proposed model is shown to give superior performances in terms of robustness against measurement noise for systems exhibiting dependence on some external variables, as well as in terms of execution time when computing the inverse dynamics of the system."}
{"id": "2602.06505", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.06505", "abs": "https://arxiv.org/abs/2602.06505", "authors": ["Zheng Zhang"], "title": "Classical Resolution of the Gibbs Paradox from the Equal Probability Principle: An Informational Perspective", "comment": null, "summary": "The Gibbs paradox is a conventional paradox in classical statistical mechanics, typically resolved by invoking quantum indistinguishability through the 1/N! correction. In this letter, we present a resolution within classical ensemble theory, which relies solely on the equal probability principle and does not invoke the 1/N! correction. Our resolution can be naturally interpretated from a purely informational perspective, where the Gibbs entropy is explicitly regarded as the Shannon entropy, quantifying ignorance rather than disorder. From this informational perspective, we also clarify the connection between information and extractable work in the gas mixing processes. Our work opens a new avenue to reconsider the role of information in statistical mechanics."}
{"id": "2602.06677", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.06677", "abs": "https://arxiv.org/abs/2602.06677", "authors": ["Ralf Hielscher", "Erik Wuensche"], "title": "On the Role of the Double Fourier Sphere Method in Fast Algorithms on SO(3)", "comment": "22 pages, 2 figures", "summary": "We analyze the Double Fourier Sphere (DFS) method on the rotation group $\\mathcal{SO}(3)$ in the frequency domain and demonstrate its central role in fast algorithms. Fast Fourier algorithms on $\\mathcal{SO}(3)$ are commonly formulated as a Wigner transform - mapping harmonic to Fourier coefficients - followed by a Fourier transform. We revisit this formulation and interpret the Wigner transform as an explicit realization of the DFS method, lifting functions from $\\mathcal{SO}(3)$ to $\\mathbb{T}^3$. In this context, we analyze the Sobolev regularity loss induced by this lifting. Furthermore, we compare different Wigner transform implementations, examine additional symmetry enhancements, and observe that the direct method is often faster and more stable than the fast polynomial transform approaches."}
{"id": "2602.06472", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06472", "abs": "https://arxiv.org/abs/2602.06472", "authors": ["Chao Zhai"], "title": "Distributed Circumferential Coverage Control in Non-Convex Annulus Environments", "comment": null, "summary": "It has long been a prominent challenge in multi-agent systems to achieve distributed coverage of non-convex annulus environments while ensuring workload equalization among agents. To address this challenge, a distributed circumferential coverage control formulation is developed in this note by constructing a Riemannian metric for the navigation in the non-convex subregion while avoiding collisions with the region boundary. In addition, a distributed partition law is designed to balance the workload on the entire coverage region by endowing each agent with a virtual partition bar that slides along the inner boundary of coverage region. Theoretical analysis is conducted to ensure the exponential convergence of workload partition and asymptotic convergence of each agent towards the local optimum in its subregion. Finally, a case study is presented to demonstrate the effectiveness of the proposed coverage control approach."}
{"id": "2602.06145", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.06145", "abs": "https://arxiv.org/abs/2602.06145", "authors": ["Andrew N. Jordan", "David R. M. Arvidsson-Shukur", "Aephraim M. Steinberg"], "title": "Theory of direct measurement of the quantum pseudo-distribution via its characteristic function", "comment": "9 pages, 1 figure", "summary": "We propose a method for directly measuring the quantum mechanical pseudo-distribution of observable properties via its characteristic function. Vandermonde matrices of the eigenvalues play a central role in the theory. This proposal directly finds the pseudo-distribution using weak measurements of the generator of position moments (momentum translations). While the pseudo-distribution can be extracted from the data in a theory-agnostic way, it is shown that under quantum-mechanical formalism, the predicted pseudo-distribution is identified with the Kirkwood-Dirac pseudo-distribution. We discuss the construction of both the joint pseudo-distribution and a conditional pseudo-distribution, which is closely connected to weak-value physics. By permuting position and momentum measurements, we give a prescription to directly probe the canonical commutation relation and verify it for any quantum state. This work establishes the theory of a characteristic function approach to pseudo-distributions, as well as providing a constructive approach to measuring them directly."}
{"id": "2602.06931", "categories": ["math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2602.06931", "abs": "https://arxiv.org/abs/2602.06931", "authors": ["Sanket Agrawal", "Sebastiano Grazzi", "Gareth O. Roberts"], "title": "On micromodes in Bayesian posterior distributions and their implications for MCMC", "comment": "37 pages, 4 figures", "summary": "We investigate the existence and severity of local modes in posterior distributions from Bayesian analyses. These are known to occur in posterior tails resulting from heavy-tailed error models such as those used in robust regression. To understand this phenomenon clearly, we consider in detail location models with Student-$t$ errors in dimension $d$ with sample size $n$. For sufficiently heavy-tailed data-generating distributions, extreme observations become increasingly isolated as $n \\to \\infty$. We show that each such observation induces a unique local posterior mode with probability tending to $1$. We refer to such a local mode as a micromode. These micromodes are typically small in height but their domains of attraction are large and grow polynomially with $n$. We then connect this posterior geometry to computation. We establish an Arrhenius law for the time taken by one-dimensional piecewise deterministic Monte Carlo algorithms to exit these micromodes. Our analysis identifies a phase transition where a misspecified and overly underdispersed model causes exit times to increase sharply, leading to a pronounced deterioration in sampling performance."}
{"id": "2602.06963", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06963", "abs": "https://arxiv.org/abs/2602.06963", "authors": ["Zhengyan Darius Shi", "Zhaoyu Han", "Srinivas Raghu", "Ashvin Vishwanath"], "title": "Charge-$4e$ superconductor with parafermionic vortices: A path to universal topological quantum computation", "comment": "6 pages, 2 figures, 24 page appendices", "summary": "Topological superconductors (TSCs) provide a promising route to fault-tolerant quantum information processing. However, the canonical Majorana platform based on $2e$ TSCs remains computationally constrained. In this work, we find a $4e$ TSC that overcomes these constraints by combining a charge-$4e$ condensate with an Abelian chiral $\\mathbb{Z}_3$ topological order in an intertwined fashion. Remarkably, this $4e$ TSC can be obtained by proliferating vortex-antivortex pairs in a stack of two $2e$ $p+ip$ TSCs, or by melting a $ν=2/3$ quantum Hall state. Specific to this TSC, the $hc/(4e)$ fluxes act as charge-conjugation defects in the topological order, whose braiding with anyons transmutes anyons into their antiparticles. This symmetry enrichment leads to $\\mathbb{Z}_3$ parafermion zero modes trapped in the elementary vortex cores, which naturally encode qutrits. Braiding the parafermion defects alone generates the full many-qutrit Clifford group. We further show that a simple single-probe interferometric measurement enables topologically protected magic-state preparation, promoting Clifford operations to a universal gate set. Importantly, the non-Abelian excitations in the $4e$ TSC are confined to externally controlled defects, making them uniquely identifiable and amenable to controlled creation and motion with superconducting-circuit technology. Our results establish hierarchical electron aggregation as a complementary principle for engineering topological quantum matter with enhanced computational power."}
{"id": "2602.06482", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06482", "abs": "https://arxiv.org/abs/2602.06482", "authors": ["Alfred Kume", "Stephen G. Walker"], "title": "On Stein's Method of Moments and Generalized Score Matching", "comment": "10 pages, 1 figure", "summary": "We show that a special case of method of moment estimator derived from the Stein class coincides with the class of generalized score matching estimator. Choosing a suitable weight function for generalized score matching is not straightforward. However, by placing it within the method of moment framework we can alleviate this problem by extending the Stein class to generalized method of moments. As a consequence we can work with a number of functions and hence derive generalized score matching estimators with optimal properties."}
{"id": "2602.06780", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06780", "abs": "https://arxiv.org/abs/2602.06780", "authors": ["Yunlu Xiao", "Marina Petrova", "Ljiljana Simić"], "title": "UnifSrv: AP Selection for Achieving Uniformly Good Performance of CF-MIMO in Realistic Urban Networks", "comment": null, "summary": "Under the ideal assumption of uniform propagation, cell-free massive MIMO (CF-mMIMO) provides uniformly high throughput over the network by effectively surrounding each user with its serving access point (AP) set. However, in realistic non-uniform urban propagation environments, it is difficult to consistently select good limited serving AP sets, resulting in significantly degraded throughput, reintroducing \"edge-effect\" for the worst-served users. To restore the uniformly good performance of scalable CF-mMIMO in realistic urban networks, we formulate a novel multi-objective optimization problem to jointly achieve high throughput by maximizing the sum data rate, uniform throughput by maximizing Jain's fairness index of the throughput per user, and scalability by minimizing the serving AP set size. We then propose the UnifSrv AP selection algorithms to solve this optimization problem, consisting of a deep reinforcement learning (DRL)-based algorithm UnifSrv-DRL and a heuristic algorithm UnifSrv-heu. We conduct a comprehensive performance evaluation of scalable CF-mMIMO under realistic urban network distributions, propagation, and mobility patterns, showing that the prior benchmark AP selection schemes fail to provide uniformly high throughput in practice. By contrast, UnifSrv at least doubles the throughput compared to prior benchmarks, or achieves comparable throughput but with half of the serving AP set size. Importantly, our heuristic algorithm achieves equivalent throughput to our DRL one, but with orders of magnitude lower complexity. We thus for the first time propose an AP selection algorithm that achieves uniformly good CF-mMIMO performance in realistic urban networks with low complexity."}
{"id": "2602.06780", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2602.06780", "abs": "https://arxiv.org/abs/2602.06780", "authors": ["Yunlu Xiao", "Marina Petrova", "Ljiljana Simić"], "title": "UnifSrv: AP Selection for Achieving Uniformly Good Performance of CF-MIMO in Realistic Urban Networks", "comment": null, "summary": "Under the ideal assumption of uniform propagation, cell-free massive MIMO (CF-mMIMO) provides uniformly high throughput over the network by effectively surrounding each user with its serving access point (AP) set. However, in realistic non-uniform urban propagation environments, it is difficult to consistently select good limited serving AP sets, resulting in significantly degraded throughput, reintroducing \"edge-effect\" for the worst-served users. To restore the uniformly good performance of scalable CF-mMIMO in realistic urban networks, we formulate a novel multi-objective optimization problem to jointly achieve high throughput by maximizing the sum data rate, uniform throughput by maximizing Jain's fairness index of the throughput per user, and scalability by minimizing the serving AP set size. We then propose the UnifSrv AP selection algorithms to solve this optimization problem, consisting of a deep reinforcement learning (DRL)-based algorithm UnifSrv-DRL and a heuristic algorithm UnifSrv-heu. We conduct a comprehensive performance evaluation of scalable CF-mMIMO under realistic urban network distributions, propagation, and mobility patterns, showing that the prior benchmark AP selection schemes fail to provide uniformly high throughput in practice. By contrast, UnifSrv at least doubles the throughput compared to prior benchmarks, or achieves comparable throughput but with half of the serving AP set size. Importantly, our heuristic algorithm achieves equivalent throughput to our DRL one, but with orders of magnitude lower complexity. We thus for the first time propose an AP selection algorithm that achieves uniformly good CF-mMIMO performance in realistic urban networks with low complexity."}
{"id": "2602.06560", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.06560", "abs": "https://arxiv.org/abs/2602.06560", "authors": ["Salambô Dago", "Ludovic Bellon"], "title": "Fooling the Landauer bound with a demon biased thermal bath", "comment": null, "summary": "The Landauer principle establishes a fundamental lower bound on the energetic cost of the erasure of a one-bit memory in thermal equilibrium. Here, we experimentally demonstrate how this bound can be effectively circumvented by introducing a hysteresis in the feedback-generated virtual potential of a micro-resonator acting as the information bit. By tuning the hysteresis, we engineer a non-equilibrium steady state with an adjustable effective temperature, enabling erasure processes that consume over 20 percents below the Landauer bound. Our results reveal that the hysteresis acts as an embedded Maxwell demon, exploiting temporal and spatial information to reduce the system's entropy and the thermodynamic transformation cost. This approach provides a versatile platform for exploring the interplay between feedback, information, and energy in stochastic systems."}
{"id": "2602.06685", "categories": ["math.NA", "math.CA"], "pdf": "https://arxiv.org/pdf/2602.06685", "abs": "https://arxiv.org/abs/2602.06685", "authors": ["Cleonice F. Bracciali", "Miguel A. Piñar"], "title": "Laguerre-Sobolev orthogonal Polynomials and Boundary Value Problems on a semi-infinite domain", "comment": null, "summary": "We study a family of Laguerre--Sobolev orthogonal polynomials associated with a Sobolev inner product arising from second--order boundary value problems on the semi--infinite interval $(0,+\\infty)$. These polynomials generate an orthogonal basis of test functions vanishing at the endpoints and are especially well suited for the spectral approximation of Schrödinger--type problems with singular potentials. Explicit connection formulas with classical Laguerre polynomials are obtained, together with recurrence relations and asymptotic properties of the corresponding coefficients. A generating function involving Bessel functions is also derived. As an application, we develop a fully diagonalized Laguerre--Sobolev spectral method for Dirichlet problems with singular potentials. The method avoids the solution of linear systems and can be implemented recursively. Numerical experiments for a Schrödinger--type equation with inverse--distance potential confirm spectral accuracy and exponential convergence."}
{"id": "2602.06480", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06480", "abs": "https://arxiv.org/abs/2602.06480", "authors": ["Krishnendu Chatterjee", "David Lurie", "Raimundo Saona", "Bruno Ziliotto"], "title": "Approximating the Uniform Value in Hidden Stochastic Games with Doeblin Conditions", "comment": null, "summary": "In \\emph{zero-sum two-player hidden stochastic games}, players observe partial information about the state. We address: $(i)$ the existence of the \\emph{uniform value}, i.e., a limiting average payoff that both players can guarantee for sufficiently long durations, and $(ii)$ the existence of an algorithm to approximate it. Previous work shows that, in the general case, the uniform value may fail to exist, and, even when it does, there need not exist an algorithm to compute or approximate it. Therefore, we consider the \\emph{Doeblin condition} in hidden stochastic games, requiring that, after a sufficiently long time, the posterior beliefs have a uniformly positive probability of resetting to one of finitely many neighborhoods in the belief space. We prove the existence of the uniform value and provide an algorithm to approximate it. We identify sufficient conditions, namely \\emph{ergodicity} in the blind setting (when the signal is uninformative) and \\emph{primitivity} in the hidden setting (when there are multiple signals). Moreover, we show that, in the hidden setting, ergodicity does not guarantee the Doeblin condition. Our results are new even for the one-player setting, i.e., partially observable Markov decision processes."}
{"id": "2602.06167", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06167", "abs": "https://arxiv.org/abs/2602.06167", "authors": ["Ofelia B. Oña", "Gustavo E. Massaccesi", "Pablo Capuzzi", "Luis Lain", "Alicia Torre", "Juan E. Peralta", "Diego R. Alcoba", "Gustavo E. Scuseria"], "title": "Determining the ensemble N-representability of Reduced Density Matrices", "comment": null, "summary": "The N-representability problem for reduced density matrices remains a fundamental challenge in electronic structure theory. Following our previous work that employs a unitary-evolution algorithm based on an adaptive derivative-assembled pseudo-Trotter variational quantum algorithm to probe pure-state N-representability of reduced density matrices [J. Chem. Theory Comput. 2024, 20, 9968], in this work we propose a practical framework for determining the ensemble N-representability of a p-body matrix. This is accomplished using a purification strategy consisting of embedding an ensemble state into a pure state defined on an extended Hilbert space, such that the reduced density matrices of the purified state reproduce those of the original ensemble. By iteratively applying variational unitaries to an initial purified state, the proposed algorithm minimizes the Hilbert-Schmidt distance between its p-body reduced density matrix and a specified target p-body matrix, which serves as a measure of the N-representability of the target. This methodology facilitates both error correction of defective ensemble reduced density matrices, and quantum-state reconstruction on a quantum computer, offering a route for density-matrix refinement. We validate the algorithm with numerical simulations on systems of two, three, and four electrons in both, simple models as well as molecular systems at finite temperature, demonstrating its robustness."}
{"id": "2602.06123", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.str-el", "hep-lat", "hep-th"], "pdf": "https://arxiv.org/pdf/2602.06123", "abs": "https://arxiv.org/abs/2602.06123", "authors": ["Lisa Bombieri", "Torsten V. Zache", "Hannes Pichler", "Daniel González-Cuadra"], "title": "U(1) lattice gauge theory and string roughening on a triangular Rydberg array", "comment": null, "summary": "Lattice gauge theories (LGTs) describe fundamental interactions in particle physics. A central phenomenon in these theories is confinement, which binds quarks and antiquarks into hadrons through the formation of string-like flux tubes of gauge fields. Simulating confinement dynamics is a challenging task, but recent advances in quantum simulation are enabling the exploration of LGTs in regimes beyond the reach of classical computation. For analog devices, a major difficulty is the realization of strong plaquette interactions, which generate string fluctuations that can drive a roughening transition. Understanding string roughening -- where strong transversal functions lead to an effective restoration of translational symmetry at long distances -- is of central importance in the study of confinement. In this work, we show that string roughening emerges naturally in an analog Rydberg quantum simulator. We first map a triangular Rydberg array onto a (2+1)D U(1) LGT where plaquette terms appear as first-order processes. We study flux strings connecting static charges and demonstrate that, near a deconfined quantum critical point, the string exhibits logarithmic growth of its transverse width as the separation between charges increases, along with the universal Lüscher correction to the confining potential -- both signatures of string roughening. Finally, we investigate the real-time dynamics of an initially rigid string, observing large fluctuations after quenching into the roughening regime, as well as string breaking via particle-pair creation. Our results indicate that rough strings can be realized in experimentally accessible quantum simulators, opening the door to detailed studies of how strong fluctuations influence string-breaking dynamics."}
{"id": "2602.06579", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2602.06579", "abs": "https://arxiv.org/abs/2602.06579", "authors": ["Mathis Chagneux", "Mathias Müller", "Pierre Gloaguen", "Sylvain Le Corff", "Jimmy Olsson"], "title": "Efficient Online Variational Estimation via Monte Carlo Sampling", "comment": null, "summary": "This article addresses online variational estimation in parametric state-space models. We propose a new procedure for efficiently computing the evidence lower bound and its gradient in a streaming-data setting, where observations arrive sequentially. The algorithm allows for the simultaneous training of the model parameters and the distribution of the latent states given the observations. It is based on i.i.d. Monte Carlo sampling, coupled with a well-chosen deep architecture, enabling both computational efficiency and flexibility. The performance of the method is illustrated on both synthetic data and real-world air-quality data. The proposed approach is theoretically motivated by the existence of an asymptotic contrast function and the ergodicity of the underlying Markov chain, and applies more generally to the computation of additive expectations under posterior distributions in state-space models."}
{"id": "2602.06944", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06944", "abs": "https://arxiv.org/abs/2602.06944", "authors": ["Saber Omidi", "Rene Akupan Ebunle", "Se Young Yoon"], "title": "Optimal Derivative Feedback Control for an Active Magnetic Levitation System: An Experimental Study on Data-Driven Approaches", "comment": "10 pages, 9 figures. Preprint; manuscript under journal review", "summary": "This paper presents the design and implementation of data-driven optimal derivative feedback controllers for an active magnetic levitation system. A direct, model-free control design method based on the reinforcement learning framework is compared with an indirect optimal control design derived from a numerically identified mathematical model of the system. For the direct model-free approach, a policy iteration procedure is proposed, which adds an iteration layer called the epoch loop to gather multiple sets of process data, providing a more diverse dataset and helping reduce learning biases. This direct control design method is evaluated against a comparable optimal control solution designed from a plant model obtained through the combined Dynamic Mode Decomposition with Control (DMDc) and Prediction Error Minimization (PEM) system identification. Results show that while both controllers can stabilize and improve the performance of the magnetic levitation system when compared to controllers designed from a nominal model, the direct model-free approach consistently outperforms the indirect solution when multiple epochs are allowed. The iterative refinement of the optimal control law over the epoch loop provides the direct approach a clear advantage over the indirect method, which relies on a single set of system data to determine the identified model and control."}
{"id": "2602.06944", "categories": ["eess.SY", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06944", "abs": "https://arxiv.org/abs/2602.06944", "authors": ["Saber Omidi", "Rene Akupan Ebunle", "Se Young Yoon"], "title": "Optimal Derivative Feedback Control for an Active Magnetic Levitation System: An Experimental Study on Data-Driven Approaches", "comment": "10 pages, 9 figures. Preprint; manuscript under journal review", "summary": "This paper presents the design and implementation of data-driven optimal derivative feedback controllers for an active magnetic levitation system. A direct, model-free control design method based on the reinforcement learning framework is compared with an indirect optimal control design derived from a numerically identified mathematical model of the system. For the direct model-free approach, a policy iteration procedure is proposed, which adds an iteration layer called the epoch loop to gather multiple sets of process data, providing a more diverse dataset and helping reduce learning biases. This direct control design method is evaluated against a comparable optimal control solution designed from a plant model obtained through the combined Dynamic Mode Decomposition with Control (DMDc) and Prediction Error Minimization (PEM) system identification. Results show that while both controllers can stabilize and improve the performance of the magnetic levitation system when compared to controllers designed from a nominal model, the direct model-free approach consistently outperforms the indirect solution when multiple epochs are allowed. The iterative refinement of the optimal control law over the epoch loop provides the direct approach a clear advantage over the indirect method, which relies on a single set of system data to determine the identified model and control."}
{"id": "2602.06571", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.06571", "abs": "https://arxiv.org/abs/2602.06571", "authors": ["P. O. Mchedlov-Petrosyan", "L. N. Davydov", "O. A. Osmaev"], "title": "Sixth order modification of the Cahn-Hilliard equation", "comment": "arXiv admin note: text overlap with arXiv:2412.03156", "summary": "We consider the sixth-order convective-viscous Cahn-Hilliard equation, different from the standard fourth-order Cahn-Hilliard equation due to the modified expression for the thermodynamic potential. In such modified thermodynamic potential the coefficient at the square gradient term is order-parameter-dependent. It also contains the square of the Laplacian. This results in a sixth-order differential equation and additional nonlinear terms in the equation. We obtained several exact static- and traveling wave solutions and studied the dependence of solutions on the parameters of the system."}
{"id": "2602.06808", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.06808", "abs": "https://arxiv.org/abs/2602.06808", "authors": ["Liu Liu", "Limin Xu", "Zhenyi Zhu"], "title": "Dynamical low-rank approximation for the semiclassical Schrodinger equation with uncertainties", "comment": null, "summary": "In this paper, we propose a dynamical low-rank (DLR) approximation framework for solving the semiclassical Schrodinger equation with uncertainties. The primary numerical challenges arise from the dual nature of the oscillations: the spatial oscillations inherent in the semiclassical limit and the high-frequency oscillations in the random space induced by uncertainties. We extend two robust integrators -- the projector-splitting integrator and the unconventional integrator -- to the semiclassical regime to evolve the solution on a low-rank manifold. Through extensive numerical experiments, we demonstrate that the DLR method is significantly more computationally efficient than the standard stochastic Galerkin method, as it captures the essential quantum dynamics using a much smaller number of basis functions. Our findings reveal that despite the complex oscillatory patterns of the wave function, its evolution remains concentrated in a low-rank subspace for the cases investigated. Specifically, we observe that the DLR method achieves high fidelity with a remarkably small numerical rank, which remains robust even as the semiclassical parameter $\\varepsilon$ decreases. Within our problem settings, the results further suggest that the rank growth is primarily driven by the randomness and regularity of the potential. These results provide practical insights into the low-rank structure of uncertain quantum systems and offer an efficient approach for high-dimensional uncertainty quantification in the semiclassical regime."}
{"id": "2602.06567", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06567", "abs": "https://arxiv.org/abs/2602.06567", "authors": ["Nicole Bäuerle", "Athanasios Vasileiadis"], "title": "Markov Decision Processes of the Third Kind: Learning Distributions by Policy Gradient Descent", "comment": null, "summary": "The goal of this paper is to analyze distributional Markov Decision Processes as a class of control problems in which the objective is to learn policies that steer the distribution of a cumulative reward toward a prescribed target law, rather than optimizing an expected value or a risk functional. To solve the resulting distributional control problem in a model-free setting, we propose a policy-gradient algorithm based on neural-network parameterizations of randomized Markov policies, defined on an augmented state space and a sample-based evaluation of the characteristic-function loss. Under mild regularity and growth assumptions, we prove convergence of the algorithm to stationary points using stochastic approximation techniques. Several numerical experiments illustrate the ability of the method to match complex target distributions, recover classical optimal policies when they exist, and reveal intrinsic non-uniqueness phenomena specific to distributional control."}
{"id": "2602.06171", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06171", "abs": "https://arxiv.org/abs/2602.06171", "authors": ["Kate V. Marshall", "Daniel J. Egger", "Michael Garn", "Francesca Schiavello", "Sebastian Brandhofer", "Christa Zoufal", "Stefan Woerner"], "title": "Quantum-enhanced Markov Chain Monte Carlo for Combinatorial Optimization", "comment": null, "summary": "Quantum computing offers an alternative paradigm for addressing combinatorial optimization problems compared to classical computing. Despite recent hardware improvements, the execution of empirical quantum optimization experiments at scales known to be hard for state-of-the-art classical solvers is not yet in reach. In this work, we offer a different way to approach combinatorial optimization with near-term quantum computing. Motivated by the promising results observed in using quantum-enhanced Markov chain Monte Carlo (QeMCMC) for approximating complicated probability distributions, we combine ideas of sampling from the device with QeMCMC together with warm-starting and parallel tempering, in the context of combinatorial optimization. We demonstrate empirically that our algorithm recovers the global optima for instances of the Maximum Independent Set problem (MIS) up to 117 decision variables using 117 qubits on IBM quantum hardware. We show early evidence of a scaling advantage of our algorithm compared to similar classical methods for the chosen instances of MIS. MIS is practically relevant across domains like financial services and molecular biology, and, in some cases, already difficult to solve to optimality classically with only a few hundred decision variables."}
{"id": "2602.06487", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.06487", "abs": "https://arxiv.org/abs/2602.06487", "authors": ["Miguel Frías Pérez", "Antonio Acín"], "title": "Local Certification of Many-Body Steady States", "comment": "6 pages, 4 figures", "summary": "We present a relaxation-based method to bound expectation values on the steady state of dissipative many-body quantum systems described by master equations of the Lindblad form. Instead of targeting to represent the entire state, we promote the reduced density matrices to our variables and enforce the constraints that are imposed on them by consistency with a global steady state. The resulting constraints have the form of a semidefinite program, which allows us to efficiently bound the values a given expectation value can take in the steady state. Our results show fast convergence of the bounds with the size of the reduced density matrices, giving very competitive predictions for the steady state of several one- and two-dimensional models for an arbitrary number of particles."}
{"id": "2602.06828", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06828", "abs": "https://arxiv.org/abs/2602.06828", "authors": ["Remi Luschei", "Werner Brannath"], "title": "A prediction interval for the population-wise error rate", "comment": null, "summary": "We construct an asymptotic prediction interval for the population-wise error rate (PWER), which is a multiple type I error criterion for clinical trials with overlapping patient populations. The PWER is the probability that a randomly selected patient will receive an ineffective treatment. It must usually be estimated due to unknown population strata sizes, such that only an estimate can be controlled at the given significance level. We apply the delta method to find a prediction interval for the resulting true PWER, we demonstrate by simulations that the interval has the required coverage probability, and illustrate the approach with real data examples."}
{"id": "2602.06657", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06657", "abs": "https://arxiv.org/abs/2602.06657", "authors": ["Yuuya Chiba", "Yasushi Yoneta", "Ryusuke Hamazaki", "Akira Shimizu"], "title": "Second law of thermodynamics in closed quantum many-body systems", "comment": "63 pages, 2 figures, 7 tables", "summary": "The second law of thermodynamics for adiabatic operations -- constraints on state transitions in closed systems under external control -- is one of the fundamental principles of thermodynamics. On the other hand, it is recently established that even pure quantum states can represent thermal equilibrium. However, pure quantum states do not satisfy the second law in that they are not passive, i.e., work can be extracted from them if arbitrary unitary operations are allowed. It therefore remains unresolved how quantum mechanics can be reconciled with thermodynamics. Here, based on our key quantum-mechanical notions of thermal equilibrium and adiabatic operations, we address the emergence of the second law for adiabatic operations in the thermodynamics limit. We first introduce infinite-observable macroscopic thermal equilibrium (iMATE); a quantum state, including pure states, is in iMATE if the expectation values of all additive observables agree with their equilibrium values. We also introduce a macroscopic operation as unitary evolution generated by a time-dependent additive Hamiltonian, which is regarded as corresponding to adiabatic operations. Employing these concepts, we show that no extensive work can be extracted from any quantum state in iMATE through any macroscopic operations. Furthermore, we introduce a quantum-mechanical form of entropy density such that it agrees with thermodynamic entropy density for any quantum state in iMATE. We then prove that for any initial state in iMATE, this entropy density cannot be decreased by any macroscopic operations, followed by a time-independent relaxation process. Our theory thus proves two different forms of the second law, by adopting macroscopically reasonable classes of observables, equilibrium states, and operations. We also discuss the time scales of macroscopic operations in these results."}
{"id": "2602.06842", "categories": ["math.NA", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06842", "abs": "https://arxiv.org/abs/2602.06842", "authors": ["Yuhan Wu", "Jan Willem van Beek", "Victorita Dolean", "Alexander Heinlein"], "title": "Are Deep Learning Based Hybrid PDE Solvers Reliable? Why Training Paradigms and Update Strategies Matter", "comment": null, "summary": "Deep learning-based hybrid iterative methods (DL-HIMs) integrate classical numerical solvers with neural operators, utilizing their complementary spectral biases to accelerate convergence. Despite this promise, many DL-HIMs stagnate at false fixed points where neural updates vanish while the physical residual remains large, raising questions about reliability in scientific computing. In this paper, we provide evidence that performance is highly sensitive to training paradigms and update strategies, even when the neural architecture is fixed. Through a detailed study of a DeepONet-based hybrid iterative numerical transferable solver (HINTS) and an FFT-based Fourier neural solver (FNS), we show that significant physical residuals can persist when training objectives are not aligned with solver dynamics and problem physics. We further examine Anderson acceleration (AA) and demonstrate that its classical form is ill-suited for nonlinear neural operators. To overcome this, we introduce physics-aware Anderson acceleration (PA-AA), which minimizes the physical residual rather than the fixed-point update. Numerical experiments confirm that PA-AA restores reliable convergence in substantially fewer iterations. These findings provide a concrete answer to ongoing controversies surrounding AI-based PDE solvers: reliability hinges not only on architectures but on physically informed training and iteration design."}
{"id": "2602.06637", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06637", "abs": "https://arxiv.org/abs/2602.06637", "authors": ["Benjamin Dubois-Taine", "Laurent Pfeiffer", "Nadia Oudjane", "Adrien Seguret", "Francis Bach"], "title": "Two-stage stochastic algorithm for solving large-scale (non)-convex separable optimization problems under affine constraints", "comment": null, "summary": "We consider nonsmooth optimization problems under affine constraints, where the objective consists of the average of the component functions of a large number $N$ of agents, and we only assume access to the Fenchel conjugate of the component functions. The algorithm of choice for solving such problems is the dual subgradient method, also known as dual decomposition, which requires $O(\\frac{1}{ε^2})$ iterations to reach $ε$-optimality in the convex case. However, each iteration requires computing the Fenchel conjugate of each of the $N$ agents, leading to a complexity $O(\\frac{N}{ε^2})$ which might be prohibitive in practical applications. To overcome this, we propose a two-stage algorithm, combining a stochastic subgradient algorithm on the dual problem, followed by a block-coordinate Frank-Wolfe algorithm to obtain primal solutions. The resulting algorithm requires only $O(\\frac{1}{ε^2} + \\frac{N}{ε^{2/3}})$ calls to Fenchel conjugates to obtain an $ε$-optimal primal solution in expectation in the convex case. We extend our results to nonconvex component functions and show that our method still applies and gets (almost) the same convergence rate, this time only to an approximate primal solution recovering the classical duality gap bounds usually obtained using the Shapley-Folkman theorem."}
{"id": "2602.06193", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06193", "abs": "https://arxiv.org/abs/2602.06193", "authors": ["Tanay Roy"], "title": "Experimental Quantum Bernoulli Factories via Bell-Basis Measurements", "comment": "5 pages, 3 figures", "summary": "Randomness processing in the Bernoulli factory framework provides a concrete setting in which quantum resources can outperform classical ones. We experimentally demonstrate an entanglement-assisted quantum Bernoulli factory based on Bell-basis measurements of two identical input quoins prepared on IBM superconducting hardware. Using only the measurement outcomes (and no external classical randomness source), we realize the classically inconstructible Bernoulli doubling primitive $f(p)=2p$ and, as intermediate outputs from the same Bell-measurement statistics, an exact fair coin $f(p)=1/2$ and the classically inconstructible function $f(p)=4p(1-p)$. We benchmark the measured output biases against ideal predictions and discuss the impact of device noise. Our results establish a simple, resource-efficient experimental primitive for quantum-to-classical randomness processing and support the viability of quantum Bernoulli factories for quantum-enhanced stochastic simulation and sampling tasks."}
{"id": "2602.06910", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2602.06910", "abs": "https://arxiv.org/abs/2602.06910", "authors": ["Björn Bornkamp", "Jiarui Lu", "Frank Bretz"], "title": "Assessment of evidence against homogeneity in exhaustive subgroup treatment effect plots", "comment": null, "summary": "Exhaustive subgroup treatment effect plots are constructed by displaying all subgroup treatment effects of interest against subgroup sample size, providing a useful overview of the observed treatment effect heterogeneity in a clinical trial. As in any exploratory subgroup analysis, however, the observed estimates suffer from small sample sizes and multiplicity issues. To facilitate more interpretable exploratory assessments, this paper introduces a computationally efficient method to generate homogeneity regions within exhaustive subgroup treatment effect plots. Using the Doubly Robust (DR) learner, pseudo-outcomes are used to estimate subgroup effects and derive reference distributions, quantifying how surprising observed heterogeneity is under a homogeneous effects model. Explicit formulas are derived for the homogeneity region and different methods for calculation of the critical values are compared. The method is illustrated with a cardiovascular trial and evaluated via simulation, showing well-calibrated inference and improved performance over standard approaches using simple differences of observed group means."}
{"id": "2602.06342", "categories": ["physics.soc-ph", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2602.06342", "abs": "https://arxiv.org/abs/2602.06342", "authors": ["Zhen Li", "Yuki Izumida"], "title": "Mean-Field Theory for Heider Balance under Heterogeneous Social Temperatures", "comment": "12 pages, 6 figures", "summary": "Heider balance theory provides a fundamental framework for understanding the formation of friendly and hostile relations in social networks. Existing stochastic formulations typically assume a uniform social temperature, implying that all interpersonal relations fluctuate with the same intensity. However, studies show that social interactions are highly heterogeneous, with broad variability in stability, volatility, and susceptibility to change. In this work, we introduce a generalized Heider balance model on a complete graph in which each link is assigned its own social temperature. Within a mean-field formulation, we derive a distribution-dependent self-consistency condition for the collective opinion state and identify the criteria governing the transition between polarized and non-polarized configurations. This framework reveals how the entire distribution of interaction heterogeneity shapes the macroscopic behavior of the system. We show that the functional form of the inverse-temperature distribution, in particular whether it is light-tailed or heavy-tailed, leads to qualitatively distinct phase diagrams. We also establish universal bounds for the critical transition, where the homogeneous-temperature limit provides a universal lower bound for the critical mean of an inverse-temperature distribution governing the transition. Numerical simulations confirm the theoretical predictions and highlight the nontrivial effects introduced by heterogeneity. Our results provide a unified route to understanding structural balance in realistic social systems and lay the groundwork for extensions incorporating fluctuations beyond mean field, external fields, and network topologies beyond the complete graph."}
{"id": "2602.06872", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2602.06872", "abs": "https://arxiv.org/abs/2602.06872", "authors": ["Zhaonan Dong", "Alexandre Ern", "Tanvi Wadhawan"], "title": "$hp$-a posteriori error estimates for hybrid high-order methods applied to biharmonic problems", "comment": null, "summary": "We derive a residual-based $hp$-a posteriori error estimator for hybrid high-order (HHO) methods on simplicial meshes applied to the biharmonic problem posed on two- and three-dimensional polytopal Lipschitz domains. The a posteriori error estimator hinges on an error decomposition into conforming and nonconforming components. To bound the nonconforming error, we use a $C^1$-partition of unity constructed via Alfeld splittings, combined with local Helmholtz decompositions on vertex stars. For the conforming error, we design two residual-based estimators, each associated with a specific interpolation operator. In the first setting, the upper bound for the conforming error involves only the stabilization term and the data oscillation. In the second setting, the bound additionally incorporates bulk residuals, normal flux jumps, and tangential jumps. Numerical experiments confirm the theoretical findings and demonstrate the efficiency of the proposed estimators."}
{"id": "2602.06670", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06670", "abs": "https://arxiv.org/abs/2602.06670", "authors": ["Hannes Gernandt", "Till Preuster", "Manuel Schaller"], "title": "Optimization-based control by interconnection of nonlinear port-Hamiltonian systems", "comment": null, "summary": "In this paper, we formulate an optimization-based control-by-interconnection approach to the stabilization problem of nonlinear port-Hamiltonian systems. Motivated by model predictive control, the feedback is defined as an initial part of a suboptimal solution of a finite horizon optimal control problem. To this end, we write the optimization method given by a primal-dual gradient dynamics arising from a possibly control-constrained optimal control problem as a port-Hamiltonian system. Then, using the port-Hamiltonian structure of the plant, we show that the MPC-type feedback law is indeed a structure-preserving interconnection of two port-Hamiltonian systems. We prove that, under an observability assumption, the interconnected system asymptotically stabilizes the plant dynamics. We illustrate the theoretical results by means of a numerical example."}
{"id": "2602.06201", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06201", "abs": "https://arxiv.org/abs/2602.06201", "authors": ["Emad Rezaei Fard Boosari"], "title": "Hybrid Quantum Image Preparation via JPEG Compression", "comment": "24 pages, 12 figures,", "summary": "We present a hybrid classical-quantum image preparation scheme that reduces the quantum implementation cost of image loading for quantum pixel information encoding (QPIE). The proposed method, termed JPEG-assisted QPIE (JQPIE), loads only the quantized JPEG coefficients into a quantum register, leading to substantial reductions in \\texttt{CX} gate count and circuit depth while preserving reconstruction quality comparable to classical JPEG compression. We develop two variants of the hybrid strategy. The first realizes the complete JPEG decompression pipeline coherently by implementing inverse quantization via a block-encoded unitary operator. The second, referred to as \\emph{quantization-free JQPIE} (QF-JQPIE), omits quantization altogether, thereby avoiding the probabilistic nature of block-encoded quantization. Numerical simulations on standard benchmark image datasets (USC--SIPI and Kodak) demonstrate that both variants achieve significant constant-factor reductions in \\texttt{CX} gate count and circuit depth relative to direct QPIE loading, while maintaining high reconstruction quality as measured by PSNR and SSIM."}
{"id": "2602.06458", "categories": ["cond-mat.stat-mech", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06458", "abs": "https://arxiv.org/abs/2602.06458", "authors": ["Akihisa Ichiki"], "title": "Inferring Microscopic Explanatory Structures from Observational Constraints via Large Deviations", "comment": null, "summary": "We study how macroscopic observational constraints restrict admissible microscopic explanatory structures when no intrinsic order or dynamics is assumed a priori. Starting from an unordered collection of measurement outcomes, we formulate inference as a constrained large deviation problem, selecting probability assignments that minimize relative entropy with respect to a reference measure determined solely by the measurement setup. We show that among all microscopic structures compatible with a given macroscopic constraint, those rendering the observation statistically most typical are selected. As an explicit illustration, we demonstrate how ordered microscopic structures can emerge purely from inference under constraint, even when the reference measure is fully permutation symmetric. Order is thus not assumed but inferred, serving here only as an illustrative example of a broader class of relational explanatory hypotheses constrained by observation."}
{"id": "2602.06424", "categories": ["q-fin.CP", "math.NA", "q-fin.MF", "q-fin.RM"], "pdf": "https://arxiv.org/pdf/2602.06424", "abs": "https://arxiv.org/abs/2602.06424", "authors": ["Chiheb Ben Hammouda", "Truong Ngoc Nguyen"], "title": "Single- and Multi-Level Fourier-RQMC Methods for Multivariate Shortfall Risk", "comment": null, "summary": "Multivariate shortfall risk measures provide a principled framework for quantifying systemic risk and determining capital allocations prior to aggregation in interconnected financial systems. Despite their well established theoretical properties, the numerical estimation of multivariate shortfall risk and the corresponding optimal allocations remains computationally challenging, as existing Monte Carlo based approaches can be numerically expensive due to slow convergence.\n  In this work, we develop a new class of single and multilevel numerical algorithms for estimating multivariate shortfall risk and the associated optimal allocations, based on a combination of Fourier inversion techniques and randomized quasi Monte Carlo (RQMC) sampling. Rather than operating in physical space, our approach evaluates the relevant expectations appearing in the risk constraint and its optimization in the frequency domain, where the integrands exhibit enhanced smoothness properties that are well suited for RQMC integration. We establish a rigorous mathematical framework for the resulting Fourier RQMC estimators, including convergence analysis and computational complexity bounds. Beyond the single level method, we introduce a multilevel RQMC scheme that exploits the geometric convergence of the underlying deterministic optimization algorithm to reduce computational cost while preserving accuracy.\n  Numerical experiments demonstrate that the proposed Fourier RQMC methods outperform sample average approximation and stochastic optimization benchmarks in terms of accuracy and computational cost across a range of models for the risk factors and loss structures. Consistent with the theoretical analysis, these results demonstrate improved asymptotic convergence and complexity rates relative to the benchmark methods, with additional savings achieved through the proposed multilevel RQMC construction."}
{"id": "2602.06730", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06730", "abs": "https://arxiv.org/abs/2602.06730", "authors": ["Siyi Wang", "Zifan Wang", "Karl H. Johansson"], "title": "Wasserstein Distributionally Robust Performative Prediction", "comment": null, "summary": "Performativity means that the deployment of a predictive model incentivizes agents to strategically adapt their behavior, thereby inducing a model-dependent distribution shift. Practitioners often repeatedly retrain the model on data samples to adapt to evolving distributions. In this paper, we develop a Wasserstein distributionally robust optimization framework for performative prediction, where the prediction model is optimized over the worst-case distribution within a Wasserstein ambiguity set. We allow the ambiguity radius to depend on the prediction model, which subsumes the constant-radius formulation as a special case. By leveraging strong duality, the intractable robust objective is reformulated as a computationally tractable minimization problem. Based on this formulation, we develop distributionally robust repeated risk minimization (DR-RRM) and repeated gradient descent (DR-RGD), to iteratively find an equilibrium between distributional shifts and model retraining. Theoretical analyses demonstrate that, under standard regularity conditions, both algorithms converge to a unique robust performative stable point. Our analysis explicitly accounts for inner-loop approximation errors and shows convergence to a neighborhood of the stable point in inexact settings. Additionally, we establish theoretical bounds on the suboptimality gap between the stable point and the global performative optimum. Finally, numerical simulations of a dynamic credit scoring problem demonstrate the efficacy of the method."}
{"id": "2602.06202", "categories": ["quant-ph", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2602.06202", "abs": "https://arxiv.org/abs/2602.06202", "authors": ["Paul G. Baity", "Anuj K. Nayak", "Lav R. Varshney", "Nicholas Jeon", "Byung-Jun Yoon", "Peter J. Love", "Adolfy Hoisie"], "title": "Characterizing Quantum Error Correction Performance of Radiation-induced Errors", "comment": null, "summary": "Radiation impacts are a current challenge with computing on superconducting-based quantum devices because they can lead to widespread correlated errors across the device. Such errors can be problematic for quantum error correction (QEC) codes, which are generally designed to correct independent errors. To address this, we have developed a computational model to simulate the effects of radiation impacts on QEC performance. This is achieved by building from recently developed models of quasiparticle density, mapping radiation-induced qubit error rates onto a quantum error channel and simulation of a simple surface code. We also provide a performance metric to quantify the resilience of a QEC code to radiation impacts. Additionally, we sweep various parameters of chip design to test mitigation strategies for improved QEC performance. Our model approach is holistic, allowing for modular performance testing of error mitigation strategies and chip and code designs."}
{"id": "2602.06764", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2602.06764", "abs": "https://arxiv.org/abs/2602.06764", "authors": ["Emil S. Jørgensen", "Michael Sørensen"], "title": "Prediction-based inference for integrated diffusions with high-frequency data", "comment": null, "summary": "We consider parametric inference for an ergodic and stationary diffusion process, when the data are high-frequency observations of the integral of the diffusion process. Such data are obtained via certain measurement devices, or if positions are recorded and speed is modelled by a diffusion. In finance, realized volatility or variations thereof can be used to construct observations of the latent integrated volatility process. Specifically, we assume that the integrated process is observed at equidistant, deterministic time points and consider the high-frequency/infinite horizon asymptotic scenario, where the number of observations, the sampling frequency and the time of the last observation all go to infinity. Subject to mild standard regularity conditions on the diffusion model, we prove the asymptotic existence and uniqueness of a consistent estimator for useful and tractable classes of prediction-based estimating functions. Asymptotic normality of the estimator is obtained under an additional assumption on the rates. The proofs are based on the useful Euler-Ito expansions of transformations of diffusions and integrated diffusions, which we study in some detail."}
{"id": "2602.06750", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06750", "abs": "https://arxiv.org/abs/2602.06750", "authors": ["Diego Morales", "Pedro Pérez-Aros", "Emilio Vilches"], "title": "Convergence Rates for Stochastic Proximal and Projection Estimators", "comment": null, "summary": "In this paper, we establish explicit, non-asymptotic convergence rates for the stochastic smooth approximations of infimal convolutions introduced and developed in \\cite{MR4581306,MR4923371}. In particular, we quantify the convergence of the associated barycentric estimators toward proximal mappings and metric projections. We prove a dimension-explicit $\\sqrtδ$ bound in the $ρ$-weakly convex (possibly nonsmooth) setting and show, by examples, that this order is sharp. Under additional regularity, namely $C^{2}$ smoothness with globally Lipschitz Hessian, we derive an improved linear $O(δ)$ rate with explicit constants, and we obtain refined projection estimates for convex sets with local $C^{2,1}$ boundary."}
{"id": "2602.06308", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06308", "abs": "https://arxiv.org/abs/2602.06308", "authors": ["Sebastián C. Carrasco", "Michael H. Goerz", "Zeyang Li", "Simone Colombo", "Vladan Vuletic", "Wolfgang P. Schleich", "Vladimir S. Malinovsky"], "title": "Time-reversal Interferometry Using Cat States with Scalable Entangling Resources", "comment": null, "summary": "We propose a novel method for generating Schrödinger-cat states -- defined as equal superpositions of arbitrary coherent states -- using a concise sequence of rapid twist-and-turn pulses. We demonstrate that the required shearing strength for the protocol, which scales linearly with time, decreases with increasing number of atoms ($N$) in proportion to $1/\\sqrt{N}$. The resulting states exhibit optimal quantum Fisher information, making them ideal for surpassing the classical limit of phase sensitivity in quantum metrology applications. Notably, our protocol is compatible with a time-reversal strategy for quantum metrology, ensuring its practical viability. Furthermore, we demonstrate that the Heisenberg limit scaling remains intact even when reducing the twisting employed in tandem with the number of atoms, thereby mitigating realistic losses such as photon scattering."}
{"id": "2602.06824", "categories": ["math.OC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06824", "abs": "https://arxiv.org/abs/2602.06824", "authors": ["El Mahdi Chayti"], "title": "RanSOM: Second-Order Momentum with Randomized Scaling for Constrained and Unconstrained Optimization", "comment": null, "summary": "Momentum methods, such as Polyak's Heavy Ball, are the standard for training deep networks but suffer from curvature-induced bias in stochastic settings, limiting convergence to suboptimal $\\mathcal{O}(ε^{-4})$ rates. Existing corrections typically require expensive auxiliary sampling or restrictive smoothness assumptions. We propose \\textbf{RanSOM}, a unified framework that eliminates this bias by replacing deterministic step sizes with randomized steps drawn from distributions with mean $η_t$. This modification allows us to leverage Stein-type identities to compute an exact, unbiased estimate of the momentum bias using a single Hessian-vector product computed jointly with the gradient, avoiding auxiliary queries. We instantiate this framework in two algorithms: \\textbf{RanSOM-E} for unconstrained optimization (using exponentially distributed steps) and \\textbf{RanSOM-B} for constrained optimization (using beta-distributed steps to strictly preserve feasibility). Theoretical analysis confirms that RanSOM recovers the optimal $\\mathcal{O}(ε^{-3})$ convergence rate under standard bounded noise, and achieves optimal rates for heavy-tailed noise settings ($p \\in (1, 2]$) without requiring gradient clipping."}
{"id": "2602.06352", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.06352", "abs": "https://arxiv.org/abs/2602.06352", "authors": ["Jun Ye", "Zoey Z. Hu", "Ben Lewis", "Wei Zhang", "Fritz Riehle", "Uwe Sterr", "Yiqi Ni", "Julian Struck"], "title": "Lunar Silicon Cavity", "comment": null, "summary": "The Moon's permanently shadowed regions (PSRs) are among the coldest places in the Solar System and are expected to become key landing sites for upcoming international space agency missions. Their proximity to peaks of perpetual solar power and potential resource richness makes them prime candidates for lunar exploration and future Moon bases. Here we propose to deploy a passive, ultrastable optical resonator in these regions that will enable laser systems with unprecedented phase-coherence. The unique physical environment of lunar PSRs greatly benefits the construction of a cryogenic monolithic silicon cavity that exhibits low $10^{-18}$ thermal noise-limited stability and coherence time exceeding 1 minute, more than a decade better than the current best terrestrial system. Such a stable laser will form a basic quantum technology infrastructure in space to serve many applications, including establishing a lunar time standard, building long-baseline optical interferometry, distribution of stable optical signals across networks of satellites, testing general relativity and gravitational physics, and forming the backbone for space-based quantum networks."}
{"id": "2602.06840", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2602.06840", "abs": "https://arxiv.org/abs/2602.06840", "authors": ["Ahmed Najjar", "Hajar El Hassani", "Marco Di Renzo", "Kezhi Wang", "Merouane Debbah"], "title": "A Mode-Matching Approach to the Design of RIS-Aided Communications", "comment": "Asilomar 2025", "summary": "Reconfigurable intelligent surface (RIS) is an emerging technology for application to wireless communications. In this paper, we consider the problem of anomalous reflection and model the RIS as a periodic surface impedance boundary. We utilize the mode matching method and Floquets expansion representation to compute the field reflected from a spatially periodic RIS, and evaluate the performance versus implementation complexity tradeoffs of RIS aided communications based on the global design criterion. This allows us to maximize the power reflected towards the intended direction of propagation, while minimizing the power reradiated towards undesired directions of propagation. In addition, we discuss the advantages of the proposed electromagnetically consistent approach to the design of RIS aided wireless systems."}
{"id": "2602.06362", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06362", "abs": "https://arxiv.org/abs/2602.06362", "authors": ["Zhenguo Lu", "Jundong Wu", "Yu Zhang", "Shaobo Ren", "Xuyang Wang", "Hongyi Zhou", "Yongmin Li"], "title": "Semi-Device-Independent Quantum Random Number Generator Resistant to General Attacks", "comment": null, "summary": "Quantum random number generators (QRNGs) produce true random numbers based on the inherent randomness of quantum theory, rendering them a foundational segment of quantum cryptography. Distinguished from trusted-device QRNGs whose security depends on characterized devices, semi-device-independent (semi-DI) QRNGs permit partial devices to be defective or even maliciously manipulated, which achieves a good trade-off between generation rate and security. In this paper, we propose a semi-DI QRNG that resists general attacks while accounting for finite-size effects. The protocol requires no rigorous characterization of the source and measurement devices other than limiting the energy of the emitted states, significantly reducing the demands on practical QRNG systems. Leveraging the tight Kato inequality for correlated variables, we show that our protocol generates more randomness than it consumes. Furthermore, we demonstrate the scheme on a continuous-variable system with ternary inputs of states. Heterodyne detection is employed to enable phase compensation through data postprocessing, alleviating the stringent requirement on system stability. The system operates at 100 MHz, achieving a net random number generation rate of 1.165 Mbps at 5.3x10^9 rounds. Our work offers a promising approach to achieve both the robust security and high generation rate with a simple experimental setup."}
{"id": "2602.06958", "categories": ["math.OC", "cs.DS"], "pdf": "https://arxiv.org/pdf/2602.06958", "abs": "https://arxiv.org/abs/2602.06958", "authors": ["Bento Natura"], "title": "Circuit Diameter of Polyhedra is Strongly Polynomial", "comment": null, "summary": "We prove a strongly polynomial bound on the circuit diameter of polyhedra, resolving the circuit analogue of the polynomial Hirsch conjecture. Specifically, we show that the circuit diameter of a polyhedron $P = \\{x\\in \\mathbb{R}^n:\\, A x = b, \\, x \\ge 0\\}$ with $A\\in\\mathbb{R}^{m\\times n}$ is $O(m^2 \\log m)$. Our construction yields monotone circuit walks, giving the same bound for the monotone circuit diameter.\n  The circuit diameter, introduced by Borgwardt, Finhold, and Hemmecke (SIDMA 2015), is a natural relaxation of the combinatorial diameter that allows steps along circuit directions rather than only along edges. All prior upper bounds on the circuit diameter were only weakly polynomial. Finding a circuit augmentation algorithm that matches this bound would yield a strongly polynomial time algorithm for linear programming, resolving Smale's 9th problem."}
{"id": "2602.06367", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06367", "abs": "https://arxiv.org/abs/2602.06367", "authors": ["Kieran Hymas", "Hiu Ming Lau", "Kareem Raslan", "Qiang Sun", "Azhar Iqbal", "Derek Abbott", "Andrew D. Greentree", "James Q. Quach"], "title": "Quenching Speculation in Quantum Markets via Entangled Neural Traders", "comment": "9 pages, 5 figures", "summary": "Speculative trading can drive pronounced market instabilities, yet existing regulatory and macroprudential tools intervene only after such dynamics emerge. Quantum technologies offer a fundamentally new means of shaping economic behavior by introducing non-classical correlations between decision-makers. Here we demonstrate a prototype quantum stock market in which entanglement between traders' valuations mitigates the runaway devaluation characteristic of speculative busts. Using reinforcement-learning agents trading a single commodity, we show that replacing classical valuations with quantum-correlated qubit-encoded valuations stabilizes prices and increases the AI traders' net worth relative to a classical market, where instead agents rapidly converge to liquidation strategies that collapse the asset value. To explain this behavior, we formulate and analyze a quantized version of the $p$-guessing game, a canonical model of speculative dynamics. Quantum entanglement and phase coherence reshape the strategic landscape, eliminating the pathological pure-strategy Nash equilibrium that drives market collapse in the classical game, while mixed-strategy equilibria remain non-degenerate and avoid bust-type outcomes. These results identify quantum correlations as a novel, endogenous mechanism for market stabilization and, more broadly, demonstrate the utility of multi-agent reinforcement learning algorithms for uncovering optimal strategies in complex decision-making frameworks with quantum degrees of freedom."}
{"id": "2602.06381", "categories": ["quant-ph", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06381", "abs": "https://arxiv.org/abs/2602.06381", "authors": ["Semin Park", "Chae-Yeun Park"], "title": "HyQuRP: Hybrid quantum-classical neural network with rotational and permutational equivariance for 3D point clouds", "comment": "8+28 pages; 2 figures", "summary": "We introduce HyQuRP, a hybrid quantum-classical neural network equivariant to rotational and permutational symmetries. While existing equivariant quantum machine learning models often rely on ad hoc constructions, HyQuRP is built upon the formal foundations of group representation theory. In the sparse-point regime, HyQuRP consistently outperforms strong classical and quantum baselines across multiple benchmarks. For example, when six subsampled points are used, HyQuRP ($\\sim$1.5K parameters) achieves 76.13% accuracy on the 5-class ModelNet benchmark, compared to approximately 71% for PointNet, PointMamba, and PointTransformer with similar parameter counts. These results highlight HyQuRP's exceptional data efficiency and suggest the potential of quantum machine learning models for processing 3D point cloud data."}
{"id": "2602.06420", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06420", "abs": "https://arxiv.org/abs/2602.06420", "authors": ["Ying-Wei Tseng", "Yu-Ting Kao", "Yeong-Jar Chang", "Jia-Han Ou", "Wen-Zhi Zhang"], "title": "Achieving Sub-Exponential Speedup in Gate-Based Quantum Computing for Quadratic Unconstrained Binary Optimization", "comment": "12 pages, 6 figures", "summary": "Recent quantum-inspired methods based on the Simulated Annealing algorithm have shown strong potential for solving combinatorial optimization problems. However, Grover's algorithm in gate-based quantum computing offers only a quadratic speedup, which remains impractical for large problem sizes. This paper proposes a hybrid approach that integrates Simulated Annealing with Grover's algorithm to achieve sub-exponential speedup, thereby improving its industrial applicability.\n  In enzyme fermentation, variables such as temperature, stirring, wait time, pH, tryptophan, rice flour and others are encoded by 625 binary parameters, defining the space of possible enzyme formulations. We aim to find a binary configuration that maximizes the active ingredient, formulated as a 625-bit Quadratic Unconstrained Binary Optimization problem generated from historical experiments and artificial intelligence techniques. Minimizing the QUBO cost corresponds to maximizing the active ingredient. This case study demonstrates that the proposed hybrid method achieves sub-exponential speedup using gate-based quantum computing."}
{"id": "2602.06421", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06421", "abs": "https://arxiv.org/abs/2602.06421", "authors": ["Zhen-Xuan He", "Gergő Thiering", "Rui-Jian Liang", "Ji-Yang Zhou", "Shuo Ren", "Wu-Xi Lin", "Zhi-He Hao", "Qi-Cheng Hu", "Jun-Feng Wang", "Adam Gali", "Jin-Shi Xu", "Chuan-Feng Li", "Guang-Can Guo"], "title": "Coherent Spin-Photon Interface of single PL6 Color Centers in Silicon Carbide", "comment": "7 pages,4 figures", "summary": "The PL6 color center in silicon carbide has recently emerged as a promising platform for quantum information processing, yet its coherent spin--photon interface has remained largely unexplored. Here we present a comprehensive investigation of single PL6 centers, combining spectroscopy with theoretical analysis. The excited-state fine structure is fully resolved using group-theoretical modeling and strain-dependent measurements. Under resonant excitation, we achieve a spin initialization fidelity of $99.69 \\pm 0.03\\%$ and a readout contrast of $98.31 \\pm 1.03\\%$. The spin--photon--entangled $A_2$ transition exhibits narrow optical linewidths ($\\sim 180$~MHz) and a polarization visibility of $\\sim 82\\%$. Coherent optical driving enables Rabi frequencies up to $2.895$~GHz, while dynamical decoupling extends the spin coherence time from $0.5$~ms to $5.70$~ms. Our results establish PL6 as a competitive solid-state spin--photon interface hosted in a commercially available semiconductor platform."}
{"id": "2602.06469", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06469", "abs": "https://arxiv.org/abs/2602.06469", "authors": ["Muhammad Waqas Haseeb", "Mohamad Toutounji"], "title": "Quantum Dynamics of Vibrationally-Assisted Electron Transfer beyond Condon approximation in the Ligand-Receptor Complex", "comment": null, "summary": "We investigate the quantum dynamics of ligand--receptor electron transfer and conformational response in a prototypical viral binding complex, using the SARS-CoV-2 Spike protein bound to the human ACE2 receptor as a model system. Treating the ACE2--Spike interface as an open quantum system embedded in a biological environment, we simulate how vibrational interactions and environmental memory reshape the coupled receptor--ligand dynamics and modulate vibrationally assisted electron transfer (VA-ET). Using a Non-Markovian Stochastic Schr\"odinger Equation (NMSSE) approach, we simulate electron transfer between donor and acceptor states in ACE2 modulated by a specific vibrational mode of the Spike protein. The influence of environmental memory (non-Markovian dynamics) and non-Condon effects (vibrational modulation of electronic coupling) are analyzed in detail. In the Markovian limit with an Ohmic bath, population dynamics reduce to exponential kinetics, and extracted transfer rates agree with semiclassical Marcus--Jortner predictions in the appropriate regime. Beyond the Markovian, high-temperature limit, we observe clear deviations: non-exponential decay, coherent oscillatory features, and enhanced sensitivity to the vibrational frequency. Incorporating off-diagonal system--bath coupling alongside diagonal coupling shows that nuclear motion can dynamically gate electron tunneling, sharpening the frequency selectivity of the VA-ET mechanism. Finally, a structured (sub-Ohmic) environmental spectral density with long-lived correlations (``memory'') preserves electronic--vibrational coherence over longer times, amplifying vibrational selectivity under non-Condon coupling. Our results support the proposition that ACE2--Spike binding may exploit vibrational assistance and quantum coherence as a molecular recognition mechanism."}
{"id": "2602.06487", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2602.06487", "abs": "https://arxiv.org/abs/2602.06487", "authors": ["Miguel Frías Pérez", "Antonio Acín"], "title": "Local Certification of Many-Body Steady States", "comment": "6 pages, 4 figures", "summary": "We present a relaxation-based method to bound expectation values on the steady state of dissipative many-body quantum systems described by master equations of the Lindblad form. Instead of targeting to represent the entire state, we promote the reduced density matrices to our variables and enforce the constraints that are imposed on them by consistency with a global steady state. The resulting constraints have the form of a semidefinite program, which allows us to efficiently bound the values a given expectation value can take in the steady state. Our results show fast convergence of the bounds with the size of the reduced density matrices, giving very competitive predictions for the steady state of several one- and two-dimensional models for an arbitrary number of particles."}
{"id": "2602.06535", "categories": ["quant-ph", "cs.DS", "cs.ET"], "pdf": "https://arxiv.org/pdf/2602.06535", "abs": "https://arxiv.org/abs/2602.06535", "authors": ["Giacomo Belli", "Michele Amoretti"], "title": "Algebraic Reduction to Improve an Optimally Bounded Quantum State Preparation Algorithm", "comment": "15 pages, 13 figures, 5 tables", "summary": "The preparation of $n$-qubit quantum states is a cross-cutting subroutine for many quantum algorithms, and the effort to reduce its circuit complexity is a significant challenge. In the literature, the quantum state preparation algorithm by Sun et al. is known to be optimally bounded, defining the asymptotically optimal width-depth trade-off bounds with and without ancillary qubits. In this work, a simpler algebraic decomposition is proposed to separate the preparation of the real part of the desired state from the complex one, resulting in a reduction in terms of circuit depth, total gates, and CNOT count when $m$ ancillary qubits are available. The reduction in complexity is due to the use of a single operator $Λ$ for each uniformly controlled gate, instead of the three in the original decomposition. Using the PennyLane library, this new algorithm for state preparation has been implemented and tested in a simulated environment for both dense and sparse quantum states, including those that are random and of physical interest. Furthermore, its performance has been compared with that of Möttönen et al.'s algorithm, which is a de facto standard for preparing quantum states in cases where no ancillary qubits are used, highlighting interesting lines of development."}
{"id": "2602.06544", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06544", "abs": "https://arxiv.org/abs/2602.06544", "authors": ["Shang Yu", "Jinzhao Sun", "Kuan-Cheng Chen", "Zhi-Huai Yang", "Zhenghao Li", "Ewan Mer", "Yazeed K. Alwehaibi", "Shana H. Winston", "Dayne Marcus D. Lopena", "Zi-Cheng Zhang", "Guang Yang", "Runxia Tao", "Mingti Zhou", "Gerard J. Machado", "Ying Dong", "Roberto Bondesan", "Vlatko Vedral", "M. S. Kim", "Ian A. Walmsley", "Raj B. Patel"], "title": "Extensible universal photonic quantum computing with nonlinearity", "comment": "9 pages, 4 figures", "summary": "Universal quantum computing requires an architecture that supports both linear circuits and, crucially, strong nonlinear resources. For quantum photonic systems, integrating such nonlinearities with scalable linear circuitry has been a major bottleneck, leaving most optical experiments without nonlinear operations and, consequently, incapable of achieving universality. Here, we report an extensible photonic computer that supports a universal gate set by seamlessly combining fully programmable, scalable linear optical networks with integrated nonlinear modules. This platform enables a broad range of quantum computing and simulation tasks. We demonstrate the quasi-deterministic generation of optical Gottesman-Kitaev-Preskill states, which are essential resources for bosonic error correction, yet had previously been realized only probabilistically. Furthermore, we simulate complex many-body quantum dynamics, exemplified by the Bose-Hubbard model. Such quantum simulation tasks have long been considered beyond the reach of photonic hardware limited to linear operations. These capabilities, enabled by our extensible architecture, establish a viable route towards photonic quantum simulation and fault-tolerant quantum computing."}
{"id": "2602.06624", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06624", "abs": "https://arxiv.org/abs/2602.06624", "authors": ["Ze-Zhou Sun", "Yuan-Bin Cheng", "Yu-Chen Liu", "Jianxing Guo", "Xiao-Tian Song", "Wei Zhang", "Dong Pan", "Gui-Lu long"], "title": "High-speed phase-encoded quantum secure direct communication over 11.4 km heterogeneous free-space and fiber links", "comment": null, "summary": "Robust quantum transmission is driving a new paradigm in space-ground quantum networking. Although phase encoding has been widely adopted in terrestrial fiber channels, it has long been considered unsuitable for free-space quantum communication. Here, we demonstrate phase-encoded quantum communication over 1400 m of urban free space. The system maintained stable operation for nearly one hour, achieving 99.07% interference visibility and an average quantum bit error rate of 2.38%. The free-space quantum states were directly coupled into the fiber and transmitted over an additional 10 km, confirming seamless interoperability across different media. We further show that turbulence-induced phase drifts between successive picosecond pulses can be effectively compensated. A cascaded-link model and numerical simulations indicate feasibility over free-space distances exceeding 30 km, underscoring the potential for satellite-to-ground quantum links. This work establishes the viability of phase encoding in free-space quantum networks, simplifying cross-medium integration and enabling compatibility with existing classical infrastructures."}
{"id": "2602.06632", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06632", "abs": "https://arxiv.org/abs/2602.06632", "authors": ["Nissi Thomas", "M. Senthilvelan"], "title": "Normal mode splitting induced synchronization blockade in coupled quantum van der Pol oscillators", "comment": "6 pages, 5 figures, accepted for publication in Physical Review A as a letter", "summary": "We report a normal-mode induced synchronization blockade in coupled quantum van der Pol oscillators under the influence of external drive. In this mechanism, the coupling hybridizes the oscillator modes into spectrally split normal modes. The destructive interference between the transitions to these modes blocks synchronization. We find that this blockade can be controlled simply by tuning the coupling strength and detuning allowing dynamic manipulation of quantum synchronization through collective mode dynamics. We analyze the phase-locking behaviour using perturbation analysis. Further, by deriving steady-state probability amplitudes we show how the energy redistribution and spectral splitting forms the basis of the blockade. Our results might provide new insights into how synchronization can be controlled in quantum systems."}
{"id": "2602.06644", "categories": ["quant-ph", "cs.LO"], "pdf": "https://arxiv.org/pdf/2602.06644", "abs": "https://arxiv.org/abs/2602.06644", "authors": ["Alexandre Clément"], "title": "A Complete Equational Theory for Real-Clifford+CH Quantum Circuits", "comment": "Main body: 13 pages, appendix: 264 pages", "summary": "We introduce a complete equational theory for the fragment of quantum circuits generated by the real Clifford gates plus the two-qubit controlled-Hadamard gate. That is, we give a simple set of equalities between circuits of this fragment, and prove that any other true equation can be derived from these. This is the first such completeness result for a finitely-generated, universal fragment of quantum circuits, with no parameterized gates and no need for ancillas."}
{"id": "2602.06699", "categories": ["quant-ph", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06699", "abs": "https://arxiv.org/abs/2602.06699", "authors": ["Alessio Pecilli", "Matteo Rosati"], "title": "Quantum Attention by Overlap Interference: Predicting Sequences from Classical and Many-Body Quantum Data", "comment": "4 + 1 pages, 2 figures", "summary": "We propose a variational quantum implementation of self-attention (QSA), the core operation in transformers and large language models, which predicts future elements of a sequence by forming overlap-weighted combinations of past data. At variance with previous approaches, our QSA realizes the required nonlinearity through interference of state overlaps and returns a Renyi-1/2 cross-entropy loss directly as the expectation value of an observable, avoiding the need to decode amplitude-encoded predictions into classical logits. Furthermore, QSA naturally accommodates a constrained, trainable data-embedding that ties quantum state overlaps to data-level similarities. We find a gate complexity dominant scaling O(T d^2) for QSA, versus O(T^2 d) classically, suggesting an advantage in the practical regime where the sequence length T dominates the embedding size d. In simulations, we show that our QSA-based quantum transformer learns sequence prediction on classical data and on many-body transverse-field Ising quantum trajectories, establishing trainable attention as a practical primitive for quantum dynamical modeling."}
{"id": "2602.06716", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06716", "abs": "https://arxiv.org/abs/2602.06716", "authors": ["Tiago Pernambuco", "Lucas Chibebe Céleri"], "title": "Geometry of restricted information: the case of quantum thermodynamics", "comment": "Comments are Welcome!", "summary": "We formulate a geometric framework in which physical laws emerge from restricted access to microscopic information. Measurement constraints are modeled as a gauge symmetry acting on density operators, inducing a gauge-reduced space of physically distinguishable states. In the case of quantum thermodynamics, this construction leads to a gauge-invariant formulation in which the invariant entropy admits a stochastic description and satisfies a general detailed fluctuation theorem. From this result, we derive an integrated fluctuation theorem and a Clausius-like inequality that unifies the first and second laws in terms of invariant work and coherent heat. Entropy production is identified with the relative entropy between forward and backward probability measures on the gauge-reduced space of thermodynamic trajectories, revealing irreversibility as a geometric consequence of limited observability. The third law emerges as a singular zero-temperature limit in which thermodynamic orbits collapse and entropy production vanishes. Since the framework applies to arbitrary information constraints, it encompasses energy-based thermodynamics as a particular case of more general measurement scenarios."}
{"id": "2602.06744", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06744", "abs": "https://arxiv.org/abs/2602.06744", "authors": ["Marcelo Janovitch", "Sander Stammbach", "Matteo Brunelli", "Patrick P. Potts"], "title": "Bridging Quantum and Semi-Classical Thermodynamics in Cavity QED", "comment": null, "summary": "In cavity quantum electrodynamics (QED), photons leaving the cavity can be irreversibly lost or reused as a power source. This dichotomy is reflected in two different thermodynamic bookkeepings of the light field, both corresponding to valid thermodynamic frameworks. In this work, we formulate a rigorous semi-classical limit of cavity QED and show that the resulting thermodynamic description may qualitatively differ from that of the fully quantised model. We find that violations of the thermodynamic uncertainty relations are recovered in the semi-classical limit only by one of the two thermodynamic frameworks: the one which treats part of the photon flux as a power source. We illustrate our findings in a three-level system coupled to a driven cavity."}
{"id": "2602.06790", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06790", "abs": "https://arxiv.org/abs/2602.06790", "authors": ["Nathan Moses", "Marcus J. Clark", "Alex S. Clark", "Siddarth K. Joshi", "Imad I. Frauque"], "title": "Heralding efficiency and brightness optimization of a micro-ring resonator via tunable coupling", "comment": "7 pages, 2 figures", "summary": "Efficient and bright single photon sources on photonic chips are key to scaling quantum technologies. Spontaneous four wave mixing in micro-ring resonators creates excellent narrowband and tunable photon sources. We experimentally demonstrate the optimization of heralding efficiency and brightness by tuning the coupling of the pump, signal and idler modes into the resonator whilst operating in a pulsed pump regime. We observe a maximum detected pair rate of over 93,000~coincidences per second in a moderately over-coupled regime, alongside a high intrinsic idler heralding efficiency of 97.87$\\pm$8.97\\% when operating close to maximal over-coupling. The measured dependence on coupling strength is in strong agreement with theoretical predictions, experimentally validating the predicted trade-off between brightness and heralding efficiency."}
{"id": "2602.06796", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2602.06796", "abs": "https://arxiv.org/abs/2602.06796", "authors": ["Mateusz J Olszewski", "Kasper Hecht Alexander", "Michael T M Woodley", "Leah R Murphy", "Peter J Mosley", "Alex O C Davis"], "title": "Phase-sensitive characterization of a quantum frequency converter by spectral interferometry", "comment": "14 pages, 17 figures", "summary": "We introduce an experimental technique for complete phase-sensitive characterization of arbitrary unitary spectral-temporal transformations of optical modes. Our method recovers the complex spectral transfer function, or Green's function, of a frequency converter by analyzing spectral interference in the response to a tunable bichromatic probe. We perform a proof-of-concept experiment on a frequency conversion module based on Bragg-scattering four-wave mixing in photonic crystal fiber. Our results validate our technique by recovering useful information in the phase of the Green's function, revealing the relative positions of regions of active frequency conversion and passive dispersive propagation within the module. Our work introduces a new approach to characterizing the performance of a variety of active devices with diverse applications in emerging quantum technologies."}
{"id": "2602.06812", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06812", "abs": "https://arxiv.org/abs/2602.06812", "authors": ["Uday Sannigrahi", "Amlan Chakrabarti", "Swapnil Saha", "Shrinjita Biswas"], "title": "Hybrid Coupling Topology with Dynamic ZZ Suppression for Optimizing Circuit Depth during Runtime in Superconducting Quantum Processor", "comment": "6 pages, 8 figures", "summary": "To reduce circuit depth when executing Quantum algorithms, it is necessary to maximize qubit connectivity on a near-term quantum processor. While addressing this, we also need to ensure high gate fidelity, suppression of unwanted ZZ cross-talk, a compact layout footprint, and minimal control hardware complexity to support scalability. In current superconducting quantum chips, fixed coupling is used as it is easier to scale, but it is limited by unwanted static ZZ interaction during single qubit operations, which degrades system performance. To overcome these challenges, we have introduced a first-of-its-kind hybrid tunable-coupling architecture that connects four fixed-frequency transmon qubits using a single coupler. This hybrid coupler uses off-resonant Stark drives to tune ZZ strength between qubit pairs. Experimentally backed simulation results indicate that our proposed hybrid design maximizes the qubit connectivity while reducing control overhead. This design achieves a near 20% reduction in circuit depth compared to IBM's Heavy-Hexagonal layout, showing its potential for scalability."}
{"id": "2602.06845", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06845", "abs": "https://arxiv.org/abs/2602.06845", "authors": ["Lajos Diósi"], "title": "Comment on \"Relativistic covariance and nonlinear quantum mechanics: Tomonaga-Schwinger analysis''", "comment": "2pp, Comment on arXiv:2511.15935 [Phys.Lett.B872,140053(2026)]", "summary": "Contrary to the central claim (Hsu, 2026) published in Physics Letters B, the Tomonaga--Schwinger equation remains covariant despite the nonlinear modification of it. The proof of covariance becomes simple after the loopholes and mistakes in Hsu's arguments are identified."}
{"id": "2602.06847", "categories": ["quant-ph", "cs.NI"], "pdf": "https://arxiv.org/pdf/2602.06847", "abs": "https://arxiv.org/abs/2602.06847", "authors": ["Kuan-Cheng Chen", "Samuel Yen-Chi Chen", "Mahdi Chehimi", "Felix Burt", "Kin K. Leung"], "title": "Consensus Protocols for Entanglement-Aware Scheduling in Distributed Quantum Neural Networks", "comment": null, "summary": "The realization of distributed quantum neural networks (DQNNs) over quantum internet infrastructures faces fundamental challenges arising from the fragile nature of entanglement and the demanding synchronization requirements of distributed learning. We introduce a Consensus-Entanglement-Aware Scheduling (CEAS) framework that co-designs quantum consensus protocols with adaptive entanglement management to enable robust synchronous training across distributed quantum processors. CEAS integrates fidelity-weighted aggregation, in which parameter updates are weighted by quantum Fisher information to suppress noisy contributions, with decoherence-aware entanglement scheduling that treats Bell pairs as perishable resources subject to exponential decay. The framework incorporates quantum-authenticated Byzantine fault tolerance, ensuring security against malicious nodes while maintaining compatibility with noisy intermediate-scale quantum (NISQ) constraints. Our theoretical analysis establishes convergence guarantees under heterogeneous noise conditions, while numerical simulations demonstrate that CEAS maintains 10-15 percentage points higher accuracy compared to entanglement-oblivious baselines under coordinated Byzantine attacks, achieving 90 percent Bell-pair utilization despite coherence time limitations. This work provides a foundational architecture for scalable distributed quantum machine learning, bridging quantum networking, distributed optimization, and early fault-tolerant quantum computation."}
{"id": "2602.06852", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.06852", "abs": "https://arxiv.org/abs/2602.06852", "authors": ["Jonathan Pan"], "title": "The Quantum Sieve Tracer: A Hybrid Framework for Layer-Wise Activation Tracing in Large Language Models", "comment": "4 pages, 4 figures", "summary": "Mechanistic interpretability aims to reverse-engineer the internal computations of Large Language Models (LLMs), yet separating sparse semantic signals from high-dimensional polysemantic noise remains a significant challenge. This paper introduces the Quantum Sieve Tracer, a hybrid quantum-classical framework designed to characterize factual recall circuits. We implement a modular pipeline that first localizes critical layers using classical causal tracing, then maps specific attention head activations into an exponentially large quantum Hilbert space. Using open-weight models (Meta Llama-3.2-1B and Alibaba Qwen2.5-1.5B-Instruct), we perform a two-stage analysis that reveals a fundamental architectural divergence. While Qwen's layer 7 circuit functions as a classic Recall Hub, we discover that Llama's layer 9 acts as an Interference Suppression circuit, where ablating the identified heads paradoxically improves factual recall. Our results demonstrate that quantum kernels can distinguish between these constructive (recall) and reductive (suppression) mechanisms, offering a high-resolution tool for analyzing the fine-grained topology of attention."}
{"id": "2602.06913", "categories": ["quant-ph", "cond-mat.other", "math-ph"], "pdf": "https://arxiv.org/pdf/2602.06913", "abs": "https://arxiv.org/abs/2602.06913", "authors": ["Marcell D. Kovács", "Christopher J. Turner", "Lluís Masanes"], "title": "Symmetry and localisation in causally constrained quantum operator dynamics", "comment": "21 pages, 8 figures", "summary": "This paper explores the connection between causality and many-body dynamics by studying the algebraic structure of tri-partite unitaries ('walls') which permanently arrest local operator spreading in their time-periodic evolution. We show that the resulting causally independent subsystems arise from the invariance of an embedded sub-algebra in the system (ie. a generalised symmetry) that leads to the splitting of operator space into commuting sub-algebras. The commutant structure of the invariant algebra is then used to construct local conserved quantities. Using representation theory of finite matrix algebras, the general form of wall gates is derived as unitary automorphisms. Taking causal independence as a minimal model for non-ergodic dynamics, we study its effect on probes of many-body quantum chaos. We prove an entanglement area-law due to local constraints and we study its stability against projective measurements. In a random ensemble exhibiting causal independence, we compare spectral correlations with the universal (chaotic) ensemble using the spectral form factor. Our results offer a rigorous understanding of locally constrained quantum dynamics from a quantum information perspective."}
{"id": "2602.06657", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06657", "abs": "https://arxiv.org/abs/2602.06657", "authors": ["Yuuya Chiba", "Yasushi Yoneta", "Ryusuke Hamazaki", "Akira Shimizu"], "title": "Second law of thermodynamics in closed quantum many-body systems", "comment": "63 pages, 2 figures, 7 tables", "summary": "The second law of thermodynamics for adiabatic operations -- constraints on state transitions in closed systems under external control -- is one of the fundamental principles of thermodynamics. On the other hand, it is recently established that even pure quantum states can represent thermal equilibrium. However, pure quantum states do not satisfy the second law in that they are not passive, i.e., work can be extracted from them if arbitrary unitary operations are allowed. It therefore remains unresolved how quantum mechanics can be reconciled with thermodynamics. Here, based on our key quantum-mechanical notions of thermal equilibrium and adiabatic operations, we address the emergence of the second law for adiabatic operations in the thermodynamics limit. We first introduce infinite-observable macroscopic thermal equilibrium (iMATE); a quantum state, including pure states, is in iMATE if the expectation values of all additive observables agree with their equilibrium values. We also introduce a macroscopic operation as unitary evolution generated by a time-dependent additive Hamiltonian, which is regarded as corresponding to adiabatic operations. Employing these concepts, we show that no extensive work can be extracted from any quantum state in iMATE through any macroscopic operations. Furthermore, we introduce a quantum-mechanical form of entropy density such that it agrees with thermodynamic entropy density for any quantum state in iMATE. We then prove that for any initial state in iMATE, this entropy density cannot be decreased by any macroscopic operations, followed by a time-independent relaxation process. Our theory thus proves two different forms of the second law, by adopting macroscopically reasonable classes of observables, equilibrium states, and operations. We also discuss the time scales of macroscopic operations in these results."}
{"id": "2602.06963", "categories": ["cond-mat.str-el", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2602.06963", "abs": "https://arxiv.org/abs/2602.06963", "authors": ["Zhengyan Darius Shi", "Zhaoyu Han", "Srinivas Raghu", "Ashvin Vishwanath"], "title": "Charge-$4e$ superconductor with parafermionic vortices: A path to universal topological quantum computation", "comment": "6 pages, 2 figures, 24 page appendices", "summary": "Topological superconductors (TSCs) provide a promising route to fault-tolerant quantum information processing. However, the canonical Majorana platform based on $2e$ TSCs remains computationally constrained. In this work, we find a $4e$ TSC that overcomes these constraints by combining a charge-$4e$ condensate with an Abelian chiral $\\mathbb{Z}_3$ topological order in an intertwined fashion. Remarkably, this $4e$ TSC can be obtained by proliferating vortex-antivortex pairs in a stack of two $2e$ $p+ip$ TSCs, or by melting a $ν=2/3$ quantum Hall state. Specific to this TSC, the $hc/(4e)$ fluxes act as charge-conjugation defects in the topological order, whose braiding with anyons transmutes anyons into their antiparticles. This symmetry enrichment leads to $\\mathbb{Z}_3$ parafermion zero modes trapped in the elementary vortex cores, which naturally encode qutrits. Braiding the parafermion defects alone generates the full many-qutrit Clifford group. We further show that a simple single-probe interferometric measurement enables topologically protected magic-state preparation, promoting Clifford operations to a universal gate set. Importantly, the non-Abelian excitations in the $4e$ TSC are confined to externally controlled defects, making them uniquely identifiable and amenable to controlled creation and motion with superconducting-circuit technology. Our results establish hierarchical electron aggregation as a complementary principle for engineering topological quantum matter with enhanced computational power."}
