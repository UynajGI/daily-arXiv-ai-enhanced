{"id": "2601.09917", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09917", "abs": "https://arxiv.org/abs/2601.09917", "authors": ["Karolina Schmidt", "Luis Rodrigues"], "title": "Collision Avoidance for Non-Cooperative Multi-Swarm Coverage Control with Bounded Disturbance Measurements", "comment": null, "summary": "This paper proposes a new algorithm for collision-free coverage control of multiple non-cooperating swarms in the presence of bounded disturbances. A new methodology is introduced that accounts for uncertainties in disturbance measurements. The proposed methodology is used to develop an algorithm that ensures collision-free motion in multi-swarm coverage control, specifically for cases where disturbances are present and their measurements are subject to bounded uncertainty. The theoretical results are validated through simulations of multiple swarms that independently aim to cover a given region in an environment with disturbances."}
{"id": "2601.09998", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09998", "abs": "https://arxiv.org/abs/2601.09998", "authors": ["Kaixin Lu", "Ziliang Lyu", "Yanfang Mo", "Yiguang Hong", "Haoyong Yu"], "title": "Extremum Seeking Nonovershooting Control of Strict-Feedback Systems Under Unknown Control Direction", "comment": null, "summary": "This paper addresses the nonovershooting control problem for strict-feedback nonlinear systems with unknown control direction. We propose a method that integrates extremum seeking with Lie bracket-based design to achieve approximately nonovershooting tracking. The approach ensures that arbitrary reference trajectories can be tracked from below for any initial condition, with the overshoot reducible to arbitrarily small levels through parameter tuning. The method further provides a mechanism for enforcing high-relative-degree nonovershooting constraints in safety-critical scenarios involving unknown control directions."}
{"id": "2601.10044", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10044", "abs": "https://arxiv.org/abs/2601.10044", "authors": ["Farshad Amani", "Faezeh Ardali", "Amin Kargarian"], "title": "Event-Driven Deep RL Dispatcher for Post-Storm Distribution System Restoration", "comment": null, "summary": "Natural hazards such as hurricanes and floods damage power grid equipment, forcing operators to replan restoration repeatedly as new information becomes available. This paper develops a deep reinforcement learning (DRL) dispatcher that serves as a real-time decision engine for crew-to-repair assignments. We model restoration as a sequential, information-revealing process and learn an actor-critic policy over compact features such as component status, travel/repair times, crew availability, and marginal restoration value. A feasibility mask blocks unsafe or inoperable actions, such as power flow limits, switching rules, and crew-time constraints, before they are applied. To provide realistic runtime inputs without relying on heavy solvers, we use lightweight surrogates for wind and flood intensities, fragility-based failure, spatial clustering of damage, access impairments, and progressive ticket arrivals. In simulated hurricane and flood events, the learned policy updates crew decisions in real time as new field reports arrive. Because the runtime logic is lightweight, it improves online performance (energy-not-supplied, critical-load restoration time, and travel distance) compared with mixed-integer programs and standard heuristics. The proposed approach is tested on the IEEE 13- and 123-bus feeders with mixed hurricane/flood scenarios."}
{"id": "2601.10095", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10095", "abs": "https://arxiv.org/abs/2601.10095", "authors": ["Yuda Li", "Shaoyuan Li", "Xiang Yin"], "title": "On the Computation and Approximation of Backward Reachable Sets for Max-Plus Linear Systems using Polyhedras", "comment": null, "summary": "This paper investigates reachability analysis for max-plus linear systems (MPLS), an important class of dynamical systems that model synchronization and delay phenomena in timed discrete-event systems. We specifically focus on backward reachability analysis, i.e., determining the set of states that can reach a given target set within a certain number of steps. Computing backward reachable sets presents significant challenges due to the non-convexity of max-plus dynamics and the complexity of set complement operations. To address these challenges, we propose a novel approximation framework that efficiently computes backward reachable sets by exploiting the structure of tropical polyhedra. Our approach reformulates the problem as a sequence of symbolic operations and approximates non-convex target sets through closure operations on unions of tropical polyhedra. We develop a systematic algorithm that constructs both outer (M-form) and inner (V-form) representations of the resulting sets, incorporating extremal filtering to reduce computational complexity. The proposed method offers a scalable alternative to traditional DBM-based approaches, enabling reliable approximate backward reachability analysis for general target regions in MPLS."}
{"id": "2601.09754", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.09754", "abs": "https://arxiv.org/abs/2601.09754", "authors": ["Seungbeom Choi"], "title": "Limits of Rank Recovery in Bilinear Observation Problems", "comment": "10 pages, 5 figures", "summary": "Bilinear observation problems arise in many physical and information-theoretic settings, where observables and states enter multiplicatively. Rank-based diagnostics are commonly used in such problems to assess the effective dimensionality accessible to observation, often under the implicit assumption that rank deficiency can be resolved through numerical refinement. Here we examine this assumption by analyzing the rank and nullity of a bilinear observation operator under systematic tolerance variation. Rather than focusing on a specific reconstruction algorithm, we study the operator directly and identify extended rank plateaus that persist across broad tolerance ranges. These plateaus indicate stable dimensional deficits that are not removed by refinement procedures applied within a fixed problem definition. To investigate the origin of this behavior, we resolve the nullspace into algebraic sectors defined by the block structure of the variables. The nullspace exhibits a pronounced but nonexclusive concentration in specific sectors, revealing an organized internal structure rather than uniform dimensional loss. Comparing refinement with explicit modification of the problem formulation further shows that rank recovery in the reported setting requires a change in the structure of the observation problem itself. Here, \"problem modification\" refers to changes that alter the bilinear observation structure (e.g., admissible operator/state families or coupling constraints), in contrast to refinements that preserve the original formulation such as tolerance adjustment and numerical reparameterizations. Together, these results delineate limits of rank recovery in bilinear observation problems and clarify the distinction between numerical refinement and problem modification in accessing effective dimensional structure."}
{"id": "2601.09942", "categories": ["cs.SI", "cs.CY"], "pdf": "https://arxiv.org/pdf/2601.09942", "abs": "https://arxiv.org/abs/2601.09942", "authors": ["Hunjun Shin", "Hoonbae Moon", "Mohit Singhal"], "title": "How Diplomacy Reshapes Online Discourse:Asymmetric Persistence in Online Framing of North Korea", "comment": null, "summary": "Public opinion toward foreign adversaries shapes and constrains diplomatic options. Prior research has largely relied on sentiment analysis and survey based measures, providing limited insight into how sustained narrative changes (beyond transient emotional reactions) might follow diplomatic engagement. This study examines the extent to which high stakes diplomatic summits shape how adversaries are framed in online discourse. We analyze U.S.-North Korea summit diplomacy (2018-2019) using a Difference-in-Difference(DiD) design on Reddit discussions. Using multiple control groups (China, Iran, Russia) to adjust for concurrent geopolitical shocks, we integrate a validated Codebook LLM framework for framing classification with graph based discourse network analysis that examines both edge level relationships and community level narrative structures. Our results reveal short term asymmetric persistence in framing responses to diplomacy. While both post level and comment level sentiment proved transient (improving during the Singapore Summit but fully reverting after the Hanoi failure),framing exhibited significant stability: the shift from threat oriented to diplomacy oriented framing was only partially reversed. Structurally, the proportion of threat oriented edges decreased substantially (48% -> 28%) while diplomacy oriented structures expanded, and these shifts resisted complete reversion after diplomatic failure. These findings suggest that diplomatic success can leave a short-term but lasting imprint on how adversaries are framed in online discourse, even when subsequent negotiations fail."}
{"id": "2601.09927", "categories": ["q-fin.RM"], "pdf": "https://arxiv.org/pdf/2601.09927", "abs": "https://arxiv.org/abs/2601.09927", "authors": ["Aditri"], "title": "Efficiency versus Robustness under Tail Misspecification: Importance Sampling and Moment-Based VaR Bracketing", "comment": "22 pages, 7 figures. Simulation study of importance sampling and discrete moment matching for Value-at-Risk under tail misspecification", "summary": "Value-at-Risk (VaR) estimation at high confidence levels is inherently a rare-event problem and is particularly sensitive to tail behavior and model misspecification. This paper studies the performance of two simulation-based VaR estimation approaches, importance sampling and discrete moment matching, under controlled tail misspecification. The analysis separates the nominal model used for estimator construction from the true data-generating process used for evaluation, allowing the effects of heavy-tailed returns to be examined in a transparent and reproducible setting. Daily returns of a broad equity market proxy are used to calibrate a nominal Gaussian model, while true returns are generated from Student-t distributions with varying degrees of freedom to represent increasingly heavy tails. Importance sampling is implemented via exponential tilting of the Gaussian model, and VaR is estimated through likelihood-weighted root-finding. Discrete moment matching constructs deterministic lower and upper VaR bounds by enforcing a finite number of moment constraints on a discretized loss distribution. The results demonstrate a clear trade-off between efficiency and robustness. Importance sampling produces low-variance VaR estimates under the nominal model but systematically underestimates the true VaR under heavy-tailed returns, with bias increasing at higher confidence levels and for thicker tails. In contrast, discrete moment matching yields conservative VaR bracketing that remains robust under tail misspecification. These findings highlight that variance reduction alone is insufficient for reliable tail risk estimation when model uncertainty is significant."}
{"id": "2601.10065", "categories": ["hep-lat", "hep-ph", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10065", "abs": "https://arxiv.org/abs/2601.10065", "authors": ["Vincent Chen", "Berndt Müller", "Xiaojun Yao"], "title": "Minimally Truncated SU(3) Lattice Gauge Theory and String Tension", "comment": "15 pages, 26 figures", "summary": "We study SU(3) gauge theory on small lattices in the minimal (qutrit) electric field truncation retaining only the ${\\bf 1}, {\\bf 3}, {\\bf \\overline{3}}$ representations for the link variables. Explicit expressions are given for the Kogut-Susskind Hamiltonian for the square plaquette chain and the two-dimensional honeycomb lattice. Our formalism can be easily extended to the minimally truncated general SU($N_c$) gauge theory. The addition of (static) quarks is discussed. We present results for the energy spectrum of the gauge field on these lattices by exact diagonalization of the Hamiltonian and analyze its statistical properties. We also compute the SU(3) string tension and discuss how it is modified by vacuum fluctuations. Finally, we calculate the potential energies of a static quark-antiquark pair and three static quarks and study their screening at finite temperature."}
{"id": "2601.09903", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.09903", "abs": "https://arxiv.org/abs/2601.09903", "authors": ["Adrien Renaudineau", "Mamadou Hawa Diallo", "Théo Dupuis", "Bastien Imbert", "Mohammed Akib Iftakher", "Kamel-Eddine Harabi", "Clément Turck", "Tifenn Hirtzlin", "Djohan Bonnet", "Franck Melul", "Jorge-Daniel Aguirre-Morales", "Elisa Vianello", "Marc Bocquet", "Jean-Michel Portal", "Damien Querlioz"], "title": "Forward-only learning in memristor arrays with month-scale stability", "comment": null, "summary": "Turning memristor arrays from efficient inference engines into systems capable of on-chip learning has proved difficult. Weight updates have a high energy cost and cause device wear, analog states drift, and backpropagation requires a backward pass with reversed signal flow. Here we experimentally demonstrate learning on standard filamentary HfOx/Ti arrays that addresses these challenges with two design choices. First, we realize that standard filamentary HfOx/Ti memristors support sub-1 V reset-only pulses that cut energy, improve endurance, and yield stable analog states. Second, we rely on forward-only training algorithms derived from Hinton's Forward-Forward that use only inference-style operations. We train two-layer classifiers on an ImageNet-resolution four-class task using arrays up to 8,064 devices. Two forward-only variants, the double-pass supervised Forward-Forward and a single-pass competitive rule, achieve test accuracies of 89.5% and 89.6%, respectively; a reference experiment using backpropagation reaches 90.0%. Across five independent runs per method, these accuracies match within statistical uncertainty. Trained models retain accuracy for at least one month under ambient conditions, consistent with the stability of reset-only states. Sub-1 V reset updates use 460 times less energy than conventional program-and-verify programming and require just 46% more energy than inference-only operation. Together, these results establish forward-only, sub-1 V learning on standard filamentary stacks at array scale, outlining a practical, pulse-aware route to adaptive edge intelligence."}
{"id": "2601.09826", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.09826", "abs": "https://arxiv.org/abs/2601.09826", "authors": ["Andreas A. Malikopoulos"], "title": "When an Approximate Model Suffices for Optimal Control", "comment": "26 pages, 3 figures", "summary": "In this paper, we develop an optimal control framework for dynamical systems when only an approximate model of the underlying plant is available. We consider a setting in which the control strategy is synthesized using a model-based optimal control problem that includes a penalty term capturing deviation from the plant trajectory, while the same control input is applied to both the model and the actual system. For a general class of optimal control problems, we establish conditions under which the control minimizing the model-based Hamiltonian coincides with the plant-optimal control, despite mismatch between the model and the true dynamics. We further specialize these results to problems with quadratic control effort, where explicit and easily verifiable sufficient conditions guarantee equivalence and uniqueness of the resulting optimal control. These results show that accurate control synthesis does not require an exact model of the underlying system, but rather alignment of the optimality conditions that govern control selection. From a learning perspective, this suggests that data-driven efforts can focus on identifying regimes in which model-based and plant-based Hamiltonian minimizers coincide, thereby providing a theoretical basis for robust model-based decision making and the effective use of digital twins under modeling error. We provide examples to illustrate the theoretical findings and demonstrate equivalence of the resulting control trajectories even in the presence of significant model mismatch."}
{"id": "2601.10608", "categories": ["physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2601.10608", "abs": "https://arxiv.org/abs/2601.10608", "authors": ["Axel Seifert", "Christoph Siewert", "Fabian Jakub", "Leonie von Terzi", "Stefan Kneifel"], "title": "On the geometry of aggregate snowflakes", "comment": null, "summary": "Snowflakes play a crucial role in weather and climate. A significant portion of precipitation that reaches the surface originates as ice, even when it ultimately falls as rain. Contrary to the popular image of symmetric, dendritic crystals, most large snowflakes are irregular aggregates formed through the collision of primary ice crystals, such as hexagonal plates, columns, and dendrites. These aggregates exhibit complex, fractal-like structures, particularly at large sizes. Despite this structural complexity, each aggregate snowflake is unique, with properties that vary significantly around the mean - variability that is typically neglected in weather and climate models. Using a physically based aggregation model, we generate millions of synthetic snowflakes to investigate their geometric properties. The resulting dataset reveals that, for a given monomer number (cluster size) and mass, the maximum dimension follows approximately a lognormal distribution. We present a parameterization of aggregate geometry that captures key statistical properties, including maximum dimension, aspect ratio, cross-sectional area, and their joint correlations. This formulation enables a stochastic representation of aggregate snowflakes in Lagrangian particle models. Incorporating this variability improves the realism of simulated fall velocities, enhances growth rates by aggregation, and broadens Doppler radar spectra in closer agreement with observations."}
{"id": "2601.09917", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09917", "abs": "https://arxiv.org/abs/2601.09917", "authors": ["Karolina Schmidt", "Luis Rodrigues"], "title": "Collision Avoidance for Non-Cooperative Multi-Swarm Coverage Control with Bounded Disturbance Measurements", "comment": null, "summary": "This paper proposes a new algorithm for collision-free coverage control of multiple non-cooperating swarms in the presence of bounded disturbances. A new methodology is introduced that accounts for uncertainties in disturbance measurements. The proposed methodology is used to develop an algorithm that ensures collision-free motion in multi-swarm coverage control, specifically for cases where disturbances are present and their measurements are subject to bounded uncertainty. The theoretical results are validated through simulations of multiple swarms that independently aim to cover a given region in an environment with disturbances."}
{"id": "2601.10522", "categories": ["physics.soc-ph"], "pdf": "https://arxiv.org/pdf/2601.10522", "abs": "https://arxiv.org/abs/2601.10522", "authors": ["Federico Malizia", "Andrés Guzmán", "Federico Battiston", "István Z. Kiss"], "title": "Nested hyperedges promote the onset of collective transitions but suppress explosive behavior", "comment": null, "summary": "Higher-order interactions can dramatically reshape collective dynamics, yet how their microscopic organization controls macroscopic critical behavior remains unclear. Here we develop a new theory to study contagion dynamics on hypergraphs and show that nested hyperedges not only facilitate the onset of spreading, but also suppress backward bifurcations, thereby inhibiting explosive behavior. By disentangling contagion pathways, we find that overlap redirects transmission from external links to internal, group-embedded routes -- boosting early activation but making dyadic and triadic channels increasingly redundant. This loss of structural independence quenches the nonlinear amplification required for bistability, progressively smoothing the transition as hyperedges become nested. We observe the same phenomenology in Kuramoto dynamics, pointing to a broadly universal mechanism by which nested higher-order structure governs critical transitions in complex systems."}
{"id": "2601.10100", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10100", "abs": "https://arxiv.org/abs/2601.10100", "authors": ["Guo Liu"], "title": "Admissibility Breakdown in High-Dimensional Sparse Regression with L1 Regularization", "comment": "19 pages", "summary": "The choice of the tuning parameter in the Lasso is central to its statistical performance in high-dimensional linear regression. Classical consistency theory identifies the rate of the Lasso tuning parameter, and numerous studies have established non-asymptotic guarantees. Nevertheless, the question of optimal tuning within a non-asymptotic framework has not yet been fully resolved. We establish tuning criteria above which the Lasso becomes inadmissible under mean squared prediction error. More specifically, we establish thresholds showing that certain classical tuning choices yield Lasso estimators strictly dominated by a simple Lasso-Ridge refinement. We also address how the structure of the design matrix and the noise vector influences the inadmissibility phenomenon."}
{"id": "2601.10043", "categories": ["q-fin.CP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10043", "abs": "https://arxiv.org/abs/2601.10043", "authors": ["Zhiming Lian"], "title": "Instruction Finetuning LLaMA-3-8B Model Using LoRA for Financial Named Entity Recognition", "comment": null, "summary": "Particularly, financial named-entity recognition (NER) is one of the many important approaches to translate unformatted reports and news into structured knowledge graphs. However, free, easy-to-use large language models (LLMs) often fail to differentiate organisations as people, or disregard an actual monetary amount entirely. This paper takes Meta's Llama 3 8B and applies it to financial NER by combining instruction fine-tuning and Low-Rank Adaptation (LoRA). Each annotated sentence is converted into an instruction-input-output triple, enabling the model to learn task descriptions while fine-tuning with small low-rank matrices instead of updating all weights. Using a corpus of 1,693 sentences, our method obtains a micro-F1 score of 0.894 compared with Qwen3-8B, Baichuan2-7B, T5, and BERT-Base. We present dataset statistics, describe training hyperparameters, and perform visualizations of entity density, learning curves, and evaluation metrics. Our results show that instruction tuning combined with parameter-efficient fine-tuning enables state-of-the-art performance on domain-sensitive NER."}
{"id": "2601.10128", "categories": ["cs.CE", "cond-mat.mtrl-sci", "cs.SE"], "pdf": "https://arxiv.org/pdf/2601.10128", "abs": "https://arxiv.org/abs/2601.10128", "authors": ["Di Wang", "Zhenhua Wu", "Yu Liu", "Kai Chang", "Shaohua Wu"], "title": "A Generalizable Framework for Building Executable Domain-Specific LLMs under Data Scarcity: Demonstration on Semiconductor TCAD Simulation", "comment": "Submitted to Nature Computational Science", "summary": "Scientific and engineering verticals often suffer from data scarcity and strict executability requirements: models must generate not only fluent text, but also syntactically valid, tool-compilable scripts. We present a schema-first alignment framework for building compact, executable domain-specific LLMs in low-resource settings. The framework integrates three core components: (i) large-scale synthetic QA data generation from expert documentation to instill foundational domain knowledge; (ii) a code-centric IR->DPO workflow that converts verified tool decks into interpretable intermediate representations (IR), performs equivalence-preserving diversification, and constructs preference pairs to directly optimize instruction compliance and code executability; and (iii) a controlled evaluation of Retrieval-Augmented Generation (RAG), showing that while RAG benefits general LLMs, it can marginally degrade the performance of already domain-aligned models.\n  We demonstrate the framework by instantiating TcadGPT for semiconductor Technology Computer-Aided Design (TCAD). Using 1.5M synthetic QA pairs and an IR-driven DPO dataset, TcadGPT attains 85.6% semantic accuracy and an 80.0% syntax pass rate on SDE executability tests, substantially outperforming state-of-the-art general LLMs such as GPT-4o. To probe portability beyond TCAD, we apply the same recipe to the open-source FEM solver Elmer, observing consistent improvements in script-level success rates over general-purpose baselines. All datasets, benchmarks, and code (including P1, P2, and IR->DPO) are released for reproducibility. Together, these results suggest that the proposed framework provides a robust and reproducible path toward executable LLMs in specialized, data-scarce professional domains."}
{"id": "2601.09811", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.09811", "abs": "https://arxiv.org/abs/2601.09811", "authors": ["Maria Vasilyeva", "Zheng Wei", "Kelum Gajamannage", "Hyangim Ji", "Aleksei Krasnikov", "Alexey Sadovski"], "title": "Learning Ecological and Epidemic Processes using Neural ODEs, Kolmogorov-Arnold Network ODEs and SINDy", "comment": null, "summary": "We consider epidemic and ecological models to investigate their coupled dynamics. Starting with the classical Susceptible-Infected-Recovered (SIR) model for basic epidemic behavior and the predator-prey (Lotka-Volterra, LV) system for ecological interactions, we then combine these frameworks into a coupled Lotka-Volterra-Susceptible-Infected-Susceptible (LVSIS) model. The resulting system consists of four differential equations describing the evolution of susceptible and infected prey and predator populations, incorporating ecological interactions, disease transmission, and spatial dispersal. To learn the underlying dynamics directly from data, we employ several data-driven modeling frameworks: Neural Ordinary Differential Equations (Neural ODEs), Kolmogorov-Arnold Network Ordinary Differential Equations (KANODEs), and Sparse Identification of Nonlinear Dynamics (SINDy). Numerical experiments based on synthetic data are conducted to investigate the learning ability of these models in capturing the epidemic and ecological behavior. We further extend our approach to spatio-temporal models, aiming to uncover hidden local couplings."}
{"id": "2601.09847", "categories": ["cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09847", "abs": "https://arxiv.org/abs/2601.09847", "authors": ["Zohar Komargodski", "Fedor K. Popov"], "title": "Trapping $\\tfrac{h}{2e}$ Flux in Metals", "comment": "27 pages, 11 figures", "summary": "We report on a new flux quantization phenomenon in metals. We study the response of normal metals to the presence of localized magnetic flux. We find that, due to backreaction effects, the metal traps 0 flux or $\\tfrac{h}{2e}$ flux (half flux). We exhibit this effect both for metals pierced by magnetic solenoids and metals wrapping a magnetic solenoid. In the latter case we demonstrate the trapping of magnetic flux analytically. Furthermore, we find that as the solenoid is adiabatically turned off, a logarithmically enhanced localized equilibrium current persists, reflecting perfect defect-diamagnetism of the Fermi gas."}
{"id": "2601.09829", "categories": ["physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.09829", "abs": "https://arxiv.org/abs/2601.09829", "authors": ["Marc Boulé"], "title": "RLC Parameters of a Two-Wire Line with the Finite Element Method", "comment": "11 pages, 16 figures (includes code listings)", "summary": "This tutorial paper shows how to compute the DC (or low-frequency) resistance, inductance and capacitance of a pair of parallel wires using the finite element method. A three-dimensional infinite domain (open boundary) modeling of electrostatic and magnetostatic fields is presented, along with the electrokinetic formulation for the current flow inside the wires. The effects of the insulation and of a proposed physical defect in the wires are also considered. The open-source ONELAB software is used to perform the simulations and the code listing is provided. Comparisons using analytical models (when applicable) and the Altair Flux software are performed to help validate the simulations."}
{"id": "2601.10517", "categories": ["q-fin.ST"], "pdf": "https://arxiv.org/pdf/2601.10517", "abs": "https://arxiv.org/abs/2601.10517", "authors": ["Othmane Zarhali", "Emmanuel Bacry", "Jean-François Muzy"], "title": "From rough to multifractal multidimensional volatility: A multidimensional Log S-fBM model", "comment": null, "summary": "We introduce the multivariate Log S-fBM model (mLog S-fBM), extending the univariate framework proposed by Wu \\textit{et al.} to the multidimensional setting. We define the multidimensional Stationary fractional Brownian motion (mS-fBM), characterized by marginals following S-fBM dynamics and a specific cross-covariance structure. It is parametrized by a correlation scale $T$, marginal-specific intermittency parameters and Hurst exponents, as well as their multidimensional counterparts: the co-intermittency matrix and the co-Hurst matrix. The mLog S-fBM is constructed by modeling volatility components as exponentials of the mS-fBM, preserving the dependence structure of the Gaussian core. We demonstrate that the model is well-defined for any co-Hurst matrix with entries in $[0, \\frac{1}{2}[$, supporting vanishing co-Hurst parameters to bridge rough volatility and multifractal regimes. We generalize the small intermittency approximation technique to the multivariate setting to develop an efficient Generalized Method of Moments calibration procedure, estimating cross-covariance parameters for pairs of marginals. We validate it on synthetic data and apply it to S\\&P 500 market data, modeling stock return fluctuations. Diagonal estimates of the stock Hurst matrix, corresponding to single-stock log-volatility Hurst exponents, are close to 0, indicating multifractal behavior, while co-Hurst off-diagonal entries are close to the Hurst exponent of the S\\&P 500 index ($H \\approx 0.12$), and co-intermittency off-diagonal entries align with univariate intermittency estimates."}
{"id": "2601.10284", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2601.10284", "abs": "https://arxiv.org/abs/2601.10284", "authors": ["Huilin Zhou", "Xin Liu", "Kexiang Wang", "Shufan Hu"], "title": "Model-Driven GPR Inversion Network With Surrogate Forward Solver", "comment": "13 pages, 13 figures. Preprint", "summary": "Data-driven deep learning is considered a promising solution for ground-penetrating radar (GPR) full-waveform inversion (FWI), while its generalization ability is limited due to the heavy reliance on abundant labeled samples. In contrast, Deep unfolding network (DUN) usually exhibits better generalization by integrating model-driven and data-driven approaches, yet its application to GPR FWI remains challenging due to the high computational cost associated with forward simulations. In this paper, we integrate a deep learning-based (DL-based) forward solver within an unfolding framework to form a fully neural-network-based architecture, UA-Net, for GPR FWI. The forward solver rapidly predicts B-scans given permittivity and conductivity models and enables automatic differentiation to compute gradients for inversion. In the inversion stage, an optimization process based on the Alternating Direction Method of Multipliers (ADMM) is unfolded into a multi-stage network with three interconnected modules: data fitting, regularization, and multiplier update. Specifically, the regularization module is trained end-to-end for adaptive learning of sparse target features. Experimental results demonstrate that UA-Net outperforms classical FWI and data-driven methods in reconstruction accuracy. Moreover, by employing transfer learning to fine-tune the network, UA-Net can be effectively applied to field data and produce reliable results."}
{"id": "2601.09874", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.09874", "abs": "https://arxiv.org/abs/2601.09874", "authors": ["Bilel Bousselmi", "Gabriela Ciuperca"], "title": "Model selection by cross-validation in an expectile linear regression", "comment": null, "summary": "For linear models that may have asymmetric errors, we study variable selection by cross-validation. The data are split into training and validation sets, with the number of observations in the validation set much larger than in the training set. For the model coefficients, the expectile or adaptive LASSO expectile estimators are calculated on the training set. These estimators will be used to calculate the cross-validation mean score (CVS) on the validation set. We show that the model that minimizes CVS is consistent in two cases: when the number of explanatory variables is fixed or when it depends on the number of observations. Monte Carlo simulations confirm the theoretical results and demonstrate the superiority of our estimation method compared to two others in the literature. The usefulness of the CV expectile model selection technique is illustrated by applying it to real data sets."}
{"id": "2601.10153", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10153", "abs": "https://arxiv.org/abs/2601.10153", "authors": ["Hideki Nishizawa", "Kazuya Anazawa", "Tetsuro Inui", "Toru Mano", "Takeo Sasai", "Giacomo Borraccini", "Tatsuya Matsumura", "Hiroyuki Ishihara", "Sae Kojima", "Yoshiaki Sone", "Koichi Takasugi"], "title": "Leveraging Digital Twin Technologies: All-Photonics Networks-as-a-Service for Data Center Xchange in the Era of AI [Invited Tutorial]", "comment": null, "summary": "This paper presents a data center exchange (Data Center Xchange, DCX) architecture for all-photonics networks-as-a-service in distributed data center infrastructures, enabling the creation of a virtual large-scale data center by directly interconnecting distributed data centers in metropolitan areas. Key requirements for such an architecture are identified: support for low-latency operations, scalability, reliability, and flexibility within a single network architecture; the ability to add new operator-driven automation functionalities based on an open networking approach; and the ability to control and manage remotely deployed transponders connected via access links with unknown physical parameters. We propose a set of technologies that enable digital twin operations for optical networks, including a cloud-native architecture for coherent transceivers, remote transponder control, fast end-to-end optical path provisioning, transceiver-based physical-parameter estimation incorporating digital longitudinal monitoring, and optical line system calibration, demonstrating their feasibility through field validations."}
{"id": "2601.09763", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09763", "abs": "https://arxiv.org/abs/2601.09763", "authors": ["Ashish Kumar Patra", "Saikumar Krithivasan"], "title": "Fractional Revival Dynamics in Kerr-Type Systems: Angular Momentum Moments and Classical Analogs", "comment": "42 pages, 24 figures", "summary": "Wave packet revivals and fractional revivals are hallmark quantum interference phenomena that arise in systems with nonlinear energy spectra, and their signatures in expectation values of observables have been studied extensively in earlier work. In this article, we build on these studies and extend the analysis in two important directions. First, we investigate fractional revival dynamics in angular momentum observables, deriving explicit expressions for the time evolution of their moments and demonstrating that higher-order angular momentum moments provide clear and selective signatures of fractional revivals. Second, we examine classical analogs of quantum revival phenomena and elucidate structural similarities between quantum fractional revivals and recurrence behavior in representative classical systems. Using the Kerr-type nonlinear Hamiltonian as a paradigmatic model, we analyze the autocorrelation function, moment dynamics, and phase-space structures, supported by visualizations such as quantum carpets. Our results broaden the range of experimentally accessible diagnostics of fractional revivals and provide a unified perspective on revival phenomena across quantum and classical dynamical systems."}
{"id": "2601.10502", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.10502", "abs": "https://arxiv.org/abs/2601.10502", "authors": ["Jiaze Li", "Michael T. Schaub", "Leto Peel"], "title": "Higher order trade-offs in hypergraph community detection", "comment": "70 pages, 18 figures", "summary": "Extending community detection from pairwise networks to hypergraphs introduces fundamental theoretical challenges. Hypergraphs exhibit structural heterogeneity with no direct graph analogue: hyperedges of varying orders can connect nodes across communities in diverse configurations, introducing new trade-offs in defining and detecting community structure. We address these challenges by developing a unified framework for community detection in non-uniform hypergraphs under the Hypergraph Stochastic Block Model. We introduce a general signal-to-noise ratio that enables a quantitative analysis of trade-offs unique to higher-order networks, such as which hypergedges we choose to split across communities and how we choose to split them. Building on this framework, we derive a Bethe Hessian operator for non-uniform hypergraphs that provides efficient spectral clustering with principled model selection. We characterize the resulting spectral detectability threshold and compare it to belief propagation limits, showing the methods coincide for uniform hypergraphs but diverge in non-uniform settings. Synthetic experiments confirm our analytical predictions and reveal systematic biases toward preserving higher-order and balanced-shape hyperedges. Application to empirical data demonstrates the practical relevance of these higher-order detectability trade-offs in real-world systems."}
{"id": "2601.10375", "categories": ["q-fin.RM", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10375", "abs": "https://arxiv.org/abs/2601.10375", "authors": ["Beatrice Acciaio", "Brandon Garcia Flores", "Antonio Marini", "Gudmund Pammer"], "title": "Dynamic reinsurance via martingale transport", "comment": "16 pages, 12 figures", "summary": "We formulate a dynamic reinsurance problem in which the insurer seeks to control the terminal distribution of its surplus while minimizing the L2-norm of the ceded risk. Using techniques from martingale optimal transport, we show that, under suitable assumptions, the problem admits a tractable solution analogous to the Bass martingale. We first consider the case where the insurer wants to match a given terminal distribution of the surplus process, and then relax this condition by only requiring certain moment or risk-based constraints."}
{"id": "2601.10091", "categories": ["hep-lat"], "pdf": "https://arxiv.org/pdf/2601.10091", "abs": "https://arxiv.org/abs/2601.10091", "authors": ["Kai-Wen Kelvin-Lee", "Noriyoshi Ishii"], "title": "Diquark mass and quark-diquark potential by lattice QCD using an extended HAL QCD method with a static quark", "comment": "11 pages, 4 figures, HADRON2025 conference", "summary": "We will calculate the diquark mass together with the quark-diquark potential. We apply an extended HAL QCD potential method to a baryonic system made up from a static quark and a diquark. Numerical calculations are performed by employing 2+1 flavor QCD gaugeconfigurations generated by CP-PACS and JLQCD Collaborations on a $16^{3} \\times 32$ lattice with $a^{-1} \\approx 1.6$ GeV. To improve the statistical noise in the propagators of the static quark, the HYP smearing is employed on the gauge links. Two-point correlators of quark-diquark baryonic system are then computed to obtain their ground-state energies where various types of diquarks are considered (eg: scalar diquark, axial-vector diquark etc). We apply an extended HAL QCD method on a baryonic system made up from a scalar diquark and a static quark to study the scalar diquark mass and the quark-diquark potential. In order to determine the diquark mass self-consistently in this HALQCD method, we demand that the baryonic spectrum in the p-wave sector obtained from the two-point correlators should be reproduced by the potential obtained from the baryonic system in the s-wave sector. We obtain the scalar diquark mass of roughly $(2/3) m_{N}$ , i.e., twice the naïve estimates of a constituent quark mass together with the quark-diquark potential of Cornell type (Coulomb + linear)."}
{"id": "2601.10037", "categories": ["cs.ET"], "pdf": "https://arxiv.org/pdf/2601.10037", "abs": "https://arxiv.org/abs/2601.10037", "authors": ["Ning Lin", "Jichang Yang", "Yangu He", "Zijian Ye", "Kwun Hang Wong", "Xinyuan Zhang", "Songqi Wang", "Yi Li", "Kemi Xu", "Leo Yu Zhang", "Xiaoming Chen", "Dashan Shang", "Han Wang", "Xiaojuan Qi", "Zhongrui Wang"], "title": "Resistive Memory based Efficient Machine Unlearning and Continual Learning", "comment": null, "summary": "Resistive memory (RM) based neuromorphic systems can emulate synaptic plasticity and thus support continual learning, but they generally lack biologically inspired mechanisms for active forgetting, which are critical for meeting modern data privacy requirements. Algorithmic forgetting, or machine unlearning, seeks to remove the influence of specific data from trained models to prevent memorization of sensitive information and the generation of harmful content, yet existing exact and approximate unlearning schemes incur prohibitive programming overheads on RM hardware owing to device variability and iterative write-verify cycles. Analogue implementations of continual learning face similar barriers. Here we present a hardware-software co-design that enables an efficient training, deployment and inference pipeline for machine unlearning and continual learning on RM accelerators. At the software level, we introduce a low-rank adaptation (LoRA) framework that confines updates to compact parameter branches, substantially reducing the number of trainable parameters and therefore the training cost. At the hardware level, we develop a hybrid analogue-digital compute-in-memory system in which well-trained weights are stored in analogue RM arrays, whereas dynamic LoRA updates are implemented in a digital computing unit with SRAM buffer. This hybrid architecture avoids costly reprogramming of analogue weights and maintains high energy efficiency during inference. Fabricated in a 180 nm CMOS process, the prototype achieves up to a 147.76-fold reduction in training cost, a 387.95-fold reduction in deployment overhead and a 48.44-fold reduction in inference energy across privacy-sensitive tasks including face recognition, speaker authentication and stylized image generation, paving the way for secure and efficient neuromorphic intelligence at the edge."}
{"id": "2601.10062", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.10062", "abs": "https://arxiv.org/abs/2601.10062", "authors": ["Zesheng Cai", "Lexiao Lai", "Tiansheng Li"], "title": "Global convergence of the subgradient method for robust signal recovery", "comment": "23 pages, 2 figures", "summary": "We study the subgradient method for factorized robust signal recovery problems, including robust PCA, robust phase retrieval, and robust matrix sensing. These objectives are nonsmooth and nonconvex, and may have unbounded sublevel sets, so standard arguments for analyzing first-order optimization algorithms based on descent and coercivity do not apply. For locally Lipschitz semialgebraic objectives, we develop a convergence framework under the assumption that continuous-time subgradient trajectories are bounded: for sufficiently small step sizes of order \\(1/k\\), any subgradient sequence remains bounded and converges to a critical point. We verify this trajectory boundedness assumption for the robust objectives by adapting and extending existing trajectory analyses, requiring only a mild nondegeneracy condition in the matrix sensing case. Finally, for rank-one symmetric robust PCA, we show that the subgradient method avoids spurious critical points for almost every initialization, and therefore converges to a global minimum under the same step-size regime."}
{"id": "2601.09998", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09998", "abs": "https://arxiv.org/abs/2601.09998", "authors": ["Kaixin Lu", "Ziliang Lyu", "Yanfang Mo", "Yiguang Hong", "Haoyong Yu"], "title": "Extremum Seeking Nonovershooting Control of Strict-Feedback Systems Under Unknown Control Direction", "comment": null, "summary": "This paper addresses the nonovershooting control problem for strict-feedback nonlinear systems with unknown control direction. We propose a method that integrates extremum seeking with Lie bracket-based design to achieve approximately nonovershooting tracking. The approach ensures that arbitrary reference trajectories can be tracked from below for any initial condition, with the overshoot reducible to arbitrarily small levels through parameter tuning. The method further provides a mechanism for enforcing high-relative-degree nonovershooting constraints in safety-critical scenarios involving unknown control directions."}
{"id": "2601.10658", "categories": ["physics.soc-ph", "cs.CY", "econ.GN", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10658", "abs": "https://arxiv.org/abs/2601.10658", "authors": ["Joseph Uguet", "Nicola Tollin", "Jordi Morato"], "title": "Transforming Crises into Opportunities: From Chaos to Urban Antifragility", "comment": "32 pages, 20 figures, 4 tables", "summary": "Urban crises - floods, pandemics, economic shocks, and conflicts - function as accelerators of urban change, exposing structural vulnerabilities while creating windows for reinvention. Building on a prior theoretical contribution that identified fifteen principles of urban antifragility, this paper tests and operationalizes the framework through an empirical assessment of 26 cities selected for their post-crisis adaptation trajectories. Using a tailored diagnostic methodology, we benchmark cities' Stress Response Strategies (SRS) and then evaluate Urban Development Trajectories (UDT) across four weighted dimensions, positioning each case along a fragility-robustness-resilience-antifragility continuum and applying a balanced-threshold rule to confirm antifragile status. Results show that \"resilience enhanced by innovation and technology\" is the most effective response typology (86.9/100), and that six cities meet the antifragile trajectory criteria. By mapping best practices to activated principles and analysing co-activations, the study identifies a robust \"hard core\" of principles - Sustainable Resilience (O), Strategic Diversity (F), Proactive Innovation (I), and Active Prevention (N) - supplemented by operational enablers (e.g., anticipation, mobilization, shock absorption). The paper concludes by proposing an evidence-based, SDG-aligned operational model that links high-impact principle pairings to measurable indicators, offering a practical roadmap for cities seeking to convert crises into sustained transformation. Keywords: Post-crisis strategies, Urban antifragility, Sustainable cities and communities, Disaster resilience and urban regeneration, Risk governance and Black Swan adaptation."}
{"id": "2601.10133", "categories": ["math.ST"], "pdf": "https://arxiv.org/pdf/2601.10133", "abs": "https://arxiv.org/abs/2601.10133", "authors": ["Ruowei Li", "Zhigang Yao"], "title": "Curvature-driven manifold fitting under unbounded isotropic noise", "comment": "40 pages, 9 figures", "summary": "Manifold fitting aims to reconstruct a low-dimensional manifold from high-dimensional data, whose framework is established by Fefferman et al. \\cite{fefferman2020reconstruction,fefferman2021reconstruction}. This paper studies the recovery of a compact $C^3$ submanifold $\\mathcal{M} \\subset \\mathbb{R}^D$ with dimension $d<D$ and positive reach $τ$ from observations $Y = X + ξ$, where $X$ is uniformly distributed on $\\mathcal{M}$ and $ξ\\sim \\mathcal{N}(0, σ^2 I_D)$ denotes isotropic Gaussian noise. To project any points $z$ in a tubular neighborhood $Γ$ of $\\mathcal{M}$ onto $\\mathcal{M}$, we construct a sample-based estimator $F:Γ\\to\\mathbb{R}^D$ by a normalized local kernel with the theoretically derived bandwidth $r = c_Dσ$. Under a sample size of $O(σ^{-3d-5})$, we establish with high probability the uniform asymptotic expansion \\[ F(z) = π(z) + \\frac{d}{2} H_{π(z)} σ^2 + O(σ^3), \\qquad z \\in Γ, \\] where $π(z)$ is the projection of $z$ onto $\\mathcal{M}$ and $H_{π(z)}$ is the mean curvature vector of $\\mathcal{M}$ at $π(z)$. The resulting manifold $F(Γ)$ has reach bounded below by $c τ$ for $c>0$ and achieves a state-of-the-art Hausdorff distance of $O(σ^2)$ to $\\mathcal{M}$. Numerical experiments confirm the quadratic decay of the reconstruction error and demonstrate the computational efficiency of the estimator $F$. Our work provides a curvature-driven framework for denoising and reconstructing manifolds with second-order accuracy."}
{"id": "2601.10142", "categories": ["cs.CE"], "pdf": "https://arxiv.org/pdf/2601.10142", "abs": "https://arxiv.org/abs/2601.10142", "authors": ["Ruiran Su", "Janet B. Pierrehumbert", "Markus Leippold"], "title": "Actors, Frames and Arguments: A Multi-Decade Computational Analysis of Climate Discourse in Financial News using Large Language Models", "comment": null, "summary": "Financial news media shapes trillion-dollar climate investment decisions, yet discourse in this elite domain remains underexplored. We analyze two decades of climate-related articles (2000-2023) from Dow Jones Newswire using an Actor-Frame-Argument (AFA) pipeline that extracts who speaks, how issues are framed, and which arguments are deployed. We validate extractions against 2,000 human-annotated articles using a Decompositional Verification Framework that evaluates completeness, faithfulness, coherence, and relevance. Our longitudinal analysis uncovers a structural transformation: pre-2015 coverage emphasized risk and regulatory burden; post-Paris Agreement, discourse shifted toward economic opportunity and innovation, with financial institutions becoming dominant voices. Methodologically, we provide a replicable paradigm for longitudinal media analysis with LLMs; substantively, we reveal how financial elites have internalized and reframed the climate crisis across two decades."}
{"id": "2601.09882", "categories": ["math.NA", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09882", "abs": "https://arxiv.org/abs/2601.09882", "authors": ["Minglei Yang", "Diego del-Castillo-Negrete", "Guannan Zhang"], "title": "An efficient probabilistic scheme for the exit time probability of $α$-stable Lévy process", "comment": null, "summary": "The α-stable Lévy process, commonly used to describe Lévy flight, is characterized by discontinuous jumps and is widely used to model anomalous transport phenomena. In this study, we investigate the associated exit problem and propose a method to compute the exit time probability, which quantifies the likelihood that a trajectory starting from an initial condition exits a bounded region in phase space within a given time. This estimation plays a key role in understanding anomalous diffusion behavior. The proposed method approximates the α-stable process by combining a Brownian motion with a compound Poisson process. The exit time probability is then modeled using a framework based on partial integro-differential equations (PIDEs). The Feynman-Kac formula provides a probabilistic representation of the solution, involving conditional expectations over stochastic differential equations. These expectations are computed via tailored quadrature rules and interpolation techniques. The proposed method achieves first-order convergence in time and offers significant computational advantages over standard Monte Carlo and deterministic approaches. In particular, it avoids assembling and solving large dense linear systems, resulting in improved efficiency. We demonstrate the method's accuracy and performance through two numerical examples, highlighting its applicability to physical transport problems."}
{"id": "2601.09924", "categories": ["cond-mat.str-el", "cond-mat.supr-con"], "pdf": "https://arxiv.org/pdf/2601.09924", "abs": "https://arxiv.org/abs/2601.09924", "authors": ["Zhengyan Darius Shi", "Pavel A. Nosov"], "title": "Composite Bogoliubov Fermi liquid in a half-filled Chern band", "comment": "5 pages, 4 figures, 22 page appendix", "summary": "The composite Fermi liquid (CFL) in the half-filled Landau level is a cornerstone of the quantum Hall phase diagram. Recent experiments and numerics indicate that an anomalous composite Fermi liquid (ACFL) can also arise at half filling of a Chern band without any external magnetic field, opening new possibilities for paired states of composite fermions beyond the fully gapped Pfaffian phase. We argue that in inversion-asymmetric Chern bands with lattice rotational symmetry reduced to $C_3$, as realized in experimental platforms where signatures of the ACFL have been observed, composite fermions can form a superconductor with neutral gapless Bogoliubov Fermi surfaces. We term the resulting electronic state {\\it the composite Bogoliubov Fermi liquid (CBFL)}. This phase has a number of remarkable properties that make it distinct from both the ACFL and the fully gapped Pfaffian. For instance, it is incompressible, has quantized Hall conductance, shows no quantum oscillations as a function of magnetic field or doping, and has topological ground state degeneracy on a torus despite the presence of gapless quasiparticles. At the same time, the neutral Bogoliubov Fermi surface yields metallic $T$-linear specific heat, non-quantized thermal conductance, Landau damping of density fluctuations, and a non-analytic $|\\mathbf{q}|^3$ contribution to the equal-time structure factor $S(\\mathbf{q})$. We also briefly discuss vortex physics and possible fractionalized daughter states induced by doping or external magnetic fields. Our results pave the way for a broader understanding of gapless topological phases arising from paired composite fermions in Chern bands that go beyond the conventional Landau level paradigm."}
{"id": "2601.09939", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.09939", "abs": "https://arxiv.org/abs/2601.09939", "authors": ["Jinjin He", "Taiyuan Zhang", "Zhiqi Li", "Junwei Zhou", "Duowen Chen", "Bo Zhu"], "title": "A Level Set Method on Particle Flow Maps", "comment": null, "summary": "This paper introduces a Particle Flow Map Level Set (PFM-LS) method for high-fidelity interface tracking. We store level-set values, gradients, and Hessians on particles concentrated in a narrow band around the interface, advecting them via bidirectional flow maps while using a conventional grid-based representation elsewhere. By interpreting the level set value as a 3-form and its gradient as a 1-form, PFM-LS achieves exceptional geometric fidelity during complex deformations and preserves sub-grid features that traditional methods cannot capture. Our dual-timescale approach utilizes long-range maps for values and gradients, with frequent reinitialization of short-range maps for the distortion-sensitive Hessian, alongside adaptive particle control that maintains sufficient density within the narrow band. We also develop a hybrid particle-grid quasi-Newton redistancing scheme that preserves fine-scale features while enforcing the signed-distance property. Benchmark comparisons in 2D and 3D demonstrate that PFM-LS achieves state-of-the-art volume preservation and shape fidelity against a broad range of existing level-set methods."}
{"id": "2601.10344", "categories": ["physics.geo-ph"], "pdf": "https://arxiv.org/pdf/2601.10344", "abs": "https://arxiv.org/abs/2601.10344", "authors": ["Andreas Nilsson", "Neil Suttie", "Marie Troyano", "Nicolas Gillet", "Julien Aubert", "Anders Irbäck"], "title": "Joint Bayesian inference of Earth's magnetic field and core surface flow on millennial timescales", "comment": null, "summary": "Understanding Earth's core dynamics over millennial timescales requires models that jointly describe the evolution of the geomagnetic field and core surface flow, while accommodating the sparse, irregular, and uncertain nature of archaeomagnetic and palaeomagnetic data. We present a new Bayesian core field and core flow modelling framework that utilises archaeo/palaeomagnetic data directly, combining a reduced stochastic representation of core surface dynamics derived from numerical geodynamo statistics with a probabilistic treatment of observational and chronological uncertainties. A key innovation is an efficient discrete marginalisation of age uncertainties, which avoids the convergence difficulties associated with co-estimating ages in high-dimensional Hamiltonian Monte Carlo inversions. The framework aims to reconstruct the coupled evolution of the geomagnetic field and core surface flow over the past 9000 years while preserving dynamical correlations implied by the prior geodynamo time series. Tests using synthetic data generated from an Earth-like geodynamo demonstrate that the method reliably recovers large-scale geomagnetic field variations and key aspects of core dynamics, including long-term westward drift and the evolution of planetary-scale eccentric gyres. These results show that, when combined with physically informed priors, archaeo/palaeomagnetic data can constrain millennial-scale core flow, paving the way for reconstructions based on real data."}
{"id": "2601.09925", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.09925", "abs": "https://arxiv.org/abs/2601.09925", "authors": ["Mayukh Choudhury", "Debraj Das"], "title": "High Dimensional Gaussian and Bootstrap Approximations in Generalized Linear Models", "comment": null, "summary": "Generalized Linear Models (GLMs) extend ordinary linear regression by linking the mean of the response variable to covariates through appropriate link functions. This paper investigates the asymptotic behavior of GLM estimators when the parameter dimension $d$ grows with the sample size $n$. In the first part, we establish Gaussian approximation results for the distribution of a properly centered and scaled GLM estimator uniformly over class of convex sets and Euclidean balls. Using high-dimensional results from Fang and Koike (2024) for the leading Bahadur term, bounding remainder terms as in He and Shao (2000), and applying Nazarov's (2003) Gaussian isoperimetric inequality, we show that Gaussian approximation holds when $d = o(n^{2/5})$ for convex sets and $d = o(n^{1/2})$ for Euclidean balls-the best possible rates matching those for high-dimensional sample means. We further extend these results to the bootstrap approximation when the covariance matrix is unknown. In the second part, when $d>>n$, a natural question is to answer whether all covariates are equally important. To answer that, we employ sparsity in GLM through the Lasso estimator. While Lasso is widely used for variable selection, it cannot achieve both Variable Selection Consistency (VSC) and $n^{1/2}$-consistency simultaneously (Lahiri, 2021). Under the regime ensuring VSC, we show that Gaussian approximation for the Lasso estimator fails. To overcome this, we propose a Perturbation Bootstrap (PB) approach and establish a Berry-Esseen type bound for its approximation uniformly over class of convex sets. Simulation studies confirm the strong finite-sample performance of the proposed method."}
{"id": "2601.09793", "categories": ["cond-mat.dis-nn", "cond-mat.other", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09793", "abs": "https://arxiv.org/abs/2601.09793", "authors": ["Soumadip Pakrashi", "Atanu Rajak", "Sambuddha Sanyal"], "title": "Emergent Nonperturbative Universal Floquet Localization", "comment": "4.5+2+6 pages, 2+5 figures", "summary": "We show that a robust, nonperturbative localization plateau emerges in periodically driven quasiperiodic lattices, independent of the static localization properties and drive protocol. Using exact Floquet dynamics, Floquet perturbation theory, and optimal-order van Vleck analysis, we identify a fine-tuned amplitude-to-frequency ratio where all Floquet states become localized despite dense resonances. The van Vleck expansion achieves superasymptotic accuracy up to an optimal orde; it ultimately breaks down due to resonant hybridization at a weak quasiperiodic potential, revealing that the observed localization is nonperturbative."}
{"id": "2601.09861", "categories": ["cond-mat.stat-mech", "cond-mat.soft"], "pdf": "https://arxiv.org/pdf/2601.09861", "abs": "https://arxiv.org/abs/2601.09861", "authors": ["Roland R. Netz"], "title": "Barrier-crossing and energy relaxation dynamics of non-Markovian inertial systems connected via analytical Green-Fokker-Planck approach", "comment": null, "summary": "From numerical simulations it is known that the barrier-crossing time of a non-Markovian one-dimensional reaction coordinate with a single exponentially decaying memory function exhibits a memory-turnover: for intermediate values of the memory decay time the barrier-crossing time is reduced compared to the Markovian limit and for long memory times increases quadratically with the memory time when keeping the total integrated friction and the mass constant. The intermediate memory acceleration regime is accurately predicted by Grote-Hynes theory, for the asymptotic long-memory slow-down behavior no systematic analytically tractable theory is available. Starting from the Green function for a general inertial (i.e. finite-mass) non-Markovian Gaussian reaction coordinate in a harmonic well, we derive by an exact mapping a generalized Fokker-Planck equation with a time-dependent effective diffusion constant. To first order in a systematic cumulant expansion we derive an analytical Arrhenius expression for the barrier-crossing time with the pre-exponential factor given by the energy relaxation time, which can be used to robustly predict barrier-crossing times from simulation or experimental trajectory data of general non-Markovian inertial systems without the need to extract memory functions. For a single exponential memory kernel we give a closed-form expression for the barrier-crossing time, which reproduces the Kramers turnover between the high-friction and high-mass limits as well as the memory turnover from the intermediate memory acceleration to the asymptotic long-memory slow-down regime. We also show that non-Markovian systems are singular in the zero-mass limit, which suggests that the long-memory barrier-crossing slow-down reflects the interplay between mass and memory effects. Thus, physically sound models for non-Markovian systems have to include a finite mass."}
{"id": "2601.09743", "categories": ["nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.09743", "abs": "https://arxiv.org/abs/2601.09743", "authors": ["Jianhua Yang", "Litai Lou", "Shangyuan Li", "Zhongqiu Wang", "Miguel A. F. Sanjuán"], "title": "Vibrational resonance in coupled self-learning Duffing oscillators and its application in noisy radio frequency signal processing", "comment": null, "summary": "This work presents a new coupled array of frequency-adaptive Duffing oscillators. Based on learning rules, the natural frequency of each oscillator changes with the external excitation to achieve the frequency-adaptive capability in the response. The frequency range of vibrational resonance in the response is greatly extended through the frequency-adaptive learning rule. Moreover, the theoretical condition for vibrational resonance is derived and its validity is verified numerically. The coupled self-learning Duffing oscillators can also perform signal denoising in strong noise environment, and its performance in signal denoising has been verified through processing the simulated signal and the wireless radio frequency signal under two scenarios. The superiority of vibrational resonance to the conventional denosing methods such as wavelet transform and Kalman filter has also been illustrated by experimental radio frequency signal processing. The combination of broadband frequency adaptability and strong noise-reduction capability suggests that these oscillators hold considerable potential for engineering applications."}
{"id": "2601.10178", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10178", "abs": "https://arxiv.org/abs/2601.10178", "authors": ["Andres Intriago", "Rongxing Hu", "Nabil Mohammed", "S. Gokul Krishnan", "Konstantinos Kotsovos", "Issam Gereige", "Nesren Attiah", "Ali Basaheeh", "Sarah Aqeel", "Hamad A. Saiari", "Shehab Ahmed", "Charalambos Konstantinou"], "title": "HyMGP: A Customized MILP-Based Tool for Techno-Economic Planning of Islanded Microgrids", "comment": "2026 IEEE Power & Energy Society (PES) International Meeting (IM)", "summary": "This paper presents a customized microgrid planning algorithm and tool, HyMGP, for remote sites in arid regions, which is formulated as a Mixed Integer Linear Programming (MILP) problem. HyMGP is compared with HOMER Pro to evaluate its performance in optimizing the sizing of microgrid components, including photovoltaic panels (PVs), vertical axis wind turbines (VAWTs), and battery energy storage systems (BESS), for remote and off-grid applications. The study focuses on a standalone microgrid in the Saudi Arabia, considering high solar irradiance, limited wind availability, and a constant load profile composed of continuous cathodic protection and daytime cooling. In the simulation environment, comparisons with HOMER solutions demonstrate the advantages of HyMGP, which provides optimal and more flexible solutions by allowing user-defined component specifications and strictly enforcing all constraints. Further analysis shows that incorporating wind turbines reduces the Net Present Cost (NPC) by decreasing the required PV and battery capacities. Increasing battery autonomy leads to a higher NPC in both PV-only and hybrid systems due to the need for larger storage. Finally, lithium iron phosphate (Li-ion LFP) batteries are found to be more cost effective than lead acid, offering lower NPCs due to their longer lifespan, deeper discharge capability, and fewer replacement cycles."}
{"id": "2601.09769", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09769", "abs": "https://arxiv.org/abs/2601.09769", "authors": ["S. Radenkovic", "M. Dugic", "I. Radojevic"], "title": "Three questions on the future of quantum science and technology", "comment": "The Editorial Board of the Kragujevac Journal of Science decided to ask the prominent researchers and scholars to take part in the poll on the status and the future of Quantum Science and Technology", "summary": "The answers on the current status and future development of Quantum Science and Technology are presented."}
{"id": "2601.10565", "categories": ["cs.SI"], "pdf": "https://arxiv.org/pdf/2601.10565", "abs": "https://arxiv.org/abs/2601.10565", "authors": ["Dávid Ferenczi", "Jean-Gabriel Young", "Leto Peel"], "title": "Inferring signed social networks from contact patterns", "comment": "12 pages, 5 figures", "summary": "Social networks are typically inferred from indirect observations, such as proximity data; yet, most methods cannot distinguish between absent relationships and actual negative ties, as both can result in few or no interactions. We address the challenge of inferring signed networks from contact patterns while accounting for whether lack of interactions reflect a lack of opportunity as opposed to active avoidance. We develop a Bayesian framework with MCMC inference that models interaction groups to separate chance from choice when no interactions are observed. Validation on synthetic data demonstrates superior performance compared to natural baselines, particularly in detecting negative edges. We apply our method to French high school contact data to reveal a structure consistent with friendship surveys and demonstrate the model's adequacy through posterior predictive checks."}
{"id": "2601.10086", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.10086", "abs": "https://arxiv.org/abs/2601.10086", "authors": ["Bohao Ma", "Nachuan Xiao", "Junyu Zhang"], "title": "Line-search and Adaptive Step Sizes for Nonconvex-strongly-concave Minimax Optimization", "comment": "25 pages", "summary": "In this paper, we propose a novel reformulation of the smooth nonconvex-strongly-concave (NC-SC) minimax problems that casts the problem as a joint minimization. We show that our reformulation preserves not only first-order stationarity, but also global and local optimality, second-order stationarity, and the Kurdyka-Łojasiewicz (KL) property, of the original NC-SC problem, which is substantially stronger than its nonsmooth counterpart in the literature. With these enhanced structures, we design a versatile parameter-free and nonmonotone line-search framework that does not require evaluating the inner maximization. Under mild conditions, global convergence rates can be obtained, and, with KL property, full sequence convergence with asymptotic rates is also established. In particular, we show our framework is compatible with the gradient descent-ascent (GDA) algorithm. By equipping GDA with Barzilai-Borwein (BB) step sizes and nonmonotone line-search, our method exhibits superior numerical performance against the compared benchmarks."}
{"id": "2601.10044", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10044", "abs": "https://arxiv.org/abs/2601.10044", "authors": ["Farshad Amani", "Faezeh Ardali", "Amin Kargarian"], "title": "Event-Driven Deep RL Dispatcher for Post-Storm Distribution System Restoration", "comment": null, "summary": "Natural hazards such as hurricanes and floods damage power grid equipment, forcing operators to replan restoration repeatedly as new information becomes available. This paper develops a deep reinforcement learning (DRL) dispatcher that serves as a real-time decision engine for crew-to-repair assignments. We model restoration as a sequential, information-revealing process and learn an actor-critic policy over compact features such as component status, travel/repair times, crew availability, and marginal restoration value. A feasibility mask blocks unsafe or inoperable actions, such as power flow limits, switching rules, and crew-time constraints, before they are applied. To provide realistic runtime inputs without relying on heavy solvers, we use lightweight surrogates for wind and flood intensities, fragility-based failure, spatial clustering of damage, access impairments, and progressive ticket arrivals. In simulated hurricane and flood events, the learned policy updates crew decisions in real time as new field reports arrive. Because the runtime logic is lightweight, it improves online performance (energy-not-supplied, critical-load restoration time, and travel distance) compared with mixed-integer programs and standard heuristics. The proposed approach is tested on the IEEE 13- and 123-bus feeders with mixed hurricane/flood scenarios."}
{"id": "2601.10326", "categories": ["math.ST", "math.AP", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10326", "abs": "https://arxiv.org/abs/2601.10326", "authors": ["Aurélien Castre", "Richard Nickl"], "title": "On gradient stability in nonlinear PDE models and inference in interacting particle systems", "comment": "36 pages", "summary": "We consider general parameter to solution maps $θ\\mapsto \\mathcal G(θ)$ of non-linear partial differential equations and describe an approach based on a Banach space version of the implicit function theorem to verify the gradient stability condition of Nickl&Wang (JEMS 2024) for the underlying non-linear inverse problem, providing also injectivity estimates and corresponding statistical identifiability results. We illustrate our methods in two examples involving a non-linear reaction diffusion system as well as a McKean--Vlasov interacting particle model, both with periodic boundary conditions. We apply our results to prove the polynomial time convergence of a Langevin-type algorithm sampling the posterior measure of the interaction potential arising from a discrete aggregate measurement of the interacting particle system."}
{"id": "2601.10557", "categories": ["math.NA", "cs.CE", "cs.DC", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.10557", "abs": "https://arxiv.org/abs/2601.10557", "authors": ["Edoardo Di Napoli", "Clément Richefort", "Xinzhe Wu"], "title": "Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians", "comment": "To be submitted to SISC", "summary": "Studying the optoelectronic structure of materials can require the computation of up to several thousands of the smallest eigenpairs of a pseudo-hermitian Hamiltonian. Iterative eigensolvers may be preferred over direct methods for this task since their complexity is a function of the desired fraction of the spectrum. In addition, they generally rely on highly optimized and scalable kernels such as matrix-vector multiplications that leverage the massive parallelism and the computational power of modern exascale systems. \\textit{Chebyshev Accelerated Subspace iteration Eigensolver} (ChASE) is able to compute several thousands of the most extreme eigenpairs of dense hermitian matrices with proven scalability over massive parallel accelerated clusters. This work presents an extension of ChASE to solve for a portion of the spectrum of pseudo-hermitian Hamiltonians as they appear in the treatment of excitonic materials. The new pseudo-hermitian solver achieves similar convergence and performance as the hermitian one. By exploiting the numerical structure and spectral properties of the Hamiltonian matrix, we propose an oblique variant of Rayleigh-Ritz projection featuring quadratic convergence of the Ritz-values with no explicit construction of the dual basis set. Additionally, we introduce a parallel implementation of the recursive matrix-product operation appearing in the Chebyshev filter with limited amount of global communications. Our development is supported by a full numerical analysis and experimental tests."}
{"id": "2601.09900", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.09900", "abs": "https://arxiv.org/abs/2601.09900", "authors": ["Kiyuob Jung"], "title": "Nonlinear numerical schemes using specular differentiation for initial value problems of first-order ordinary differential equations", "comment": null, "summary": "This paper proposes specular differentiation in one-dimensional Euclidean space and provides its fundamental analysis, including quasi-Fermat's theorem and the quasi-Mean Value Theorem. As an application, this paper develops several numerical schemes for solving initial value problems for first-order ordinary differential equations. Based on numerical simulations, we select one scheme and prove its first-order consistency and second-order local convergence."}
{"id": "2601.10146", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10146", "abs": "https://arxiv.org/abs/2601.10146", "authors": ["Seungha Ju", "Sooran Kim"], "title": "Comparison of SCAN+U and r2SCAN+U for Charge Density Wave Instability and Lattice Dynamics in CuTe", "comment": null, "summary": "Identifying an appropriate exchange-correlation functional and computational conditions is essential for explaining the fundamental physics of materials and predicting their properties. Here, we investigate the performance of the meta-GGA functionals SCAN and r2SCAN, with and without a Hubbard U, for describing the charge density wave (CDW) in the quasi-one-dimensional material CuTe. By examining the Te-Te bond modulation, phonon dispersions, and electronic structures, we identify clear differences in how the two functionals capture the structural and dynamical properties of the CDW formation. r2SCAN+U reproduces the experimentally observed Te-chain distortions in the CDW phase and the phonon soft mode at qCDW=(0.4, 0.0, 0.5) in the non-CDW phase, whereas SCAN exhibits unphysical phonon behavior. The atomic displacements of the soft mode agree well with the experimental Te modulation. Despite their similar electronic structures and optimized lattice constants, our results demonstrate that r2SCAN is a more suitable choice than SCAN for describing CDW formation and lattice dynamics in CuTe."}
{"id": "2601.10134", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.10134", "abs": "https://arxiv.org/abs/2601.10134", "authors": ["Ming Liu", "Yosuke Hasegawa"], "title": "A volume penalization method for solving conjugate scalar transport with interfacial jump conditions", "comment": null, "summary": "Conjugate scalar transport with interfacial jump conditions on complex interfacial geometries is common in thermal and chemical processes, while its accurate and efficient simulations are still quite challenging. In the present study, a novel treatment of a two-phase interface in the volume penalization method, a kind of immersed boundary method, for solving conjugate scalar transport with general interfacial boundary conditions is developed. We first propose an interfacial treatment for solving an advection-diffusion equation with a Neumann boundary condition, and then extend it to general conjugate scalar transport with both interfacial flux and scalar jumps. A one-dimensional diffusion problem is solved to verify the present scheme and demonstrate the advantage of the present scheme in improving accuracy and unifying the governing equations in the two phases with an additional source term representing the local jump condition of the interfacial scalar flux. Then, the present scheme is further applied to fluid-solid coupled scalar diffusion and advection-diffusion problems with the scalar and its flux jumps across the interface. The simulation results of the present scheme generally show good agreement with reference results obtained by body-fitted mesh simulations with average relative deviations less than 3.0%."}
{"id": "2601.09941", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.09941", "abs": "https://arxiv.org/abs/2601.09941", "authors": ["Jacob A. Turner", "Monnie McGee", "Bianca A. Luedeker"], "title": "Tree Estimation and Saddlepoint-Based Diagnostics for the Nested Dirichlet Distribution: Application to Compositional Behavioral Data", "comment": "main document 34 pages, 8 figures; supplement 9 pages, 2 figures", "summary": "The Nested Dirichlet Distribution (NDD) provides a flexible alternative to the Dirichlet distribution for modeling compositional data, relaxing constraints on component variances and correlations through a hierarchical tree structure. While theoretically appealing, the NDD is underused in practice due to two main limitations: the need to predefine the tree structure and the lack of diagnostics for evaluating model fit. This paper addresses both issues. First, we introduce a data-driven, greedy tree-finding algorithm that identifies plausible NDD tree structures from observed data. Second, we propose novel diagnostic tools, including pseudo-residuals based on a saddlepoint approximation to the marginal distributions and a likelihood displacement measure to detect influential observations. These tools provide accurate and computationally tractable assessments of model fit, even when marginal distributions are analytically intractable. We demonstrate our approach through simulation studies and apply it to data from a Morris water maze experiment, where the goal is to detect differences in spatial learning strategies among cognitively impaired and unimpaired mice. Our methods yield interpretable structures and improved model evaluation in a realistic compositional setting. An accompanying R package is provided to support reproducibility and application to new datasets."}
{"id": "2601.10226", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.10226", "abs": "https://arxiv.org/abs/2601.10226", "authors": ["Chenxin Qin", "Chenyan Wang", "Mouyang Cheng", "Ji Chen"], "title": "Integral Variable Range Hopping for Modeling Electrical Transport in Disordered Systems", "comment": "7 pages, 4 figures", "summary": "The variable range hopping (VRH) model has been widely applied to describe electrical transport in disordered systems, providing theoretical formulas to fit temperature-dependent electric conductivity. These models rely on oversimplified assumptions that restrict their applicability and result in problematic fitting behaviors, yet their overusing situation is becoming increasingly serious. In this work we formulate an integral variable range hopping (IVRH) model, which replaces the empirical temperature power-law dependence in standard VRH theories with a physics-inspired integral formulation. The model builds upon the standard hopping probability $ω(R)$ w.r.t. hopping distance $R$ and incorporates the density of accessible electronic states through an effective volume function $V(R)$, which reflects the influence of system geometry. The IVRH formulation inherently reproduces both the Mott behavior at low temperatures and the Arrhenius behavior at high temperatures, respectively, and enables a smooth transition between the two regimes. We apply the IVRH model to two-dimensional, three-dimensional, and multi-layered systems. Monte Carlo simulations validate the model's predictions and yield consistent values for the fitting parameters, with substantially reduced variances compared to fitting using the standard VRH model. Furthermore, the improved robustness of IVRH also extends to the transport measurements in monolayer MoS$_2$ system and monolayer WS$_2$ system, enabling more physically meaningful interpretation.IVRH model offers a more stable and physically sound framework for interpreting hopping transport in low-dimensional amorphous materials, providing deeper insights into the universal geometric scaling factors that govern charge transport in disordered systems."}
{"id": "2601.09907", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.09907", "abs": "https://arxiv.org/abs/2601.09907", "authors": ["Geyao Gu", "Drew Alvarez", "John Strahan", "Alex Albaugh", "Emanuele Penocchio", "Todd R. Gingrich"], "title": "It Takes Two to Make a Thing Go Right: Boosting Current in Coupled Motors", "comment": null, "summary": "Catalysis-driven synthetic molecular motors operate in a loose mechanochemical coupling regime, one in which a decomposition of a fuel molecule does not reliably produce a forward step. In that regime, stochastic backward steps can significantly degrade the motor's current, prompting us to ask whether mechanically coupling multiple such motors can boost their averaged current. By simulating rotaxane-based motors with two classes of models--particle-based nonequilibrium molecular dynamics and jump-diffusion models--we show that current boosts are physically achievable. Our observed boosts, which amplify current by single-digit factors, emerge when coupling between motors can increase the activity, speeding up the rate of both forward and backward steps. In doing so, the bias for preferring forward steps actually degrades, but the lost bias can be largely recovered by raising the fuel concentration, demonstrating a general design strategy: amplify activity through coupling and restore bias through stronger driving."}
{"id": "2601.10646", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.10646", "abs": "https://arxiv.org/abs/2601.10646", "authors": ["Rupak Majumder", "Shamik Gupta"], "title": "Synchronization with Annealed Disorder and Higher-Harmonic Interactions in Arbitrary Dimensions: When Two Dimensions Are Special", "comment": null, "summary": "The impact of disorder on collective phenomena depends crucially on whether it is quenched or annealed. In synchronization problems, quenched disorder in higher dimensional Kuramoto models is known to produce unconventional dimensional effects, including a striking odd even dichotomy: synchronization transitions are continuous in even dimensions and discontinuous in odd dimensions. By contrast, the impact of annealed disorder has received comparatively little attention. Here we study a D dimensional Kuramoto model with both fundamental and higher-harmonic interactions under annealed disorder, and develop an arbitrary dimensional center-manifold framework to analyze the nonlinear dynamics near the onset of collective behavior. We show that annealed disorder fundamentally alters the role of dimensionality. With fundamental coupling alone, it completely removes the odd even dichotomy, yielding continuous synchronization transitions with universal mean-field scaling in all dimensions. Higher-harmonic interactions preserve this universality while rendering the synchronization transition tunable between continuous and discontinuous. At the same time, they give rise to a novel, correlation-driven transition between a symmetry-protected incoherent phase and a symmetry broken state lacking global synchronization, which is therefore invisible to the conventional Kuramoto order parameter. This transition is continuous in two dimensions but discontinuous in higher dimensions, revealing an emergent and previously-unrecognized special role of two dimensions."}
{"id": "2601.10189", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10189", "abs": "https://arxiv.org/abs/2601.10189", "authors": ["Jonathan Vieth", "Annika Eichler", "Arne Speerforck"], "title": "Model Predictive Control of Thermo-Hydraulic Systems Using Primal Decomposition", "comment": "This work has been submitted to the IFAC World Congress 2026 for possible publication", "summary": "Decarbonizing the global energy supply requires more efficient heating and cooling systems. Model predictive control enhances the operation of cooling and heating systems but depends on accurate system models, often based on control volumes. We present an automated framework including time discretization to generate model predictive controllers for such models. To ensure scalability, a primal decomposition exploiting the model structure is applied. The approach is validated on an underground heating system with varying numbers of states, demonstrating the primal decomposition's advantage regarding scalability."}
{"id": "2601.09779", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09779", "abs": "https://arxiv.org/abs/2601.09779", "authors": ["Jan Carlo Schumann", "Igor Lesanovsky", "Parvinder Solanki"], "title": "Hierarchical time crystals", "comment": null, "summary": "Spontaneous symmetry breaking is one of the central organizing principles in physics. Time crystals have emerged as an exotic phase of matter, spontaneously breaking the time translational symmetry, and are mainly categorized as discrete or continuous. While these distinct types of time crystals have been extensively explored as standalone systems, intriguing effects can arise from their mutual interaction. Here, we demonstrate that a time-independent coupled system of discrete and continuous time crystals induces a simultaneous two-fold temporal symmetry breaking, resulting in a hierarchical time crystal phase. Interestingly, one of the subsystems breaks an emergent discrete temporal symmetry that does not exist in the dynamical generator but rather emerges dynamically, leading to a convoluted non-equilibrium phase. We demonstrate that hierarchical time crystals are robust, emerging for fundamentally different coupling schemes and persisting across wide ranges of system parameters."}
{"id": "2601.10260", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.10260", "abs": "https://arxiv.org/abs/2601.10260", "authors": ["Kota Umezu", "Kazuhiro Sato"], "title": "Controllability score for linear time-invariant systems on an infinite time horizon", "comment": null, "summary": "We introduce a scaled controllability Gramian that can be computed reliably even for unstable systems. Using this scaled Gramian, we reformulate the controllability scoring problems into equivalent but numerically stable optimization problems. Their optimal solutions define dynamics-aware network centrality measures, referred to as the volumetric controllability score (VCS) and the average energy controllability score (AECS). We then formulate controllability scoring problems on an infinite time horizon. Under suitable assumptions, we prove that the resulting VCS and AECS are unique and that the finite-horizon scores converge to them. We further show that VCS and AECS can differ markedly in this limit, because VCS enforces controllability of the full system, whereas AECS accounts only for the stable modes. Finally, using Laplacian dynamics as a representative example, we present numerical experiments that illustrate this convergence."}
{"id": "2601.10095", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10095", "abs": "https://arxiv.org/abs/2601.10095", "authors": ["Yuda Li", "Shaoyuan Li", "Xiang Yin"], "title": "On the Computation and Approximation of Backward Reachable Sets for Max-Plus Linear Systems using Polyhedras", "comment": null, "summary": "This paper investigates reachability analysis for max-plus linear systems (MPLS), an important class of dynamical systems that model synchronization and delay phenomena in timed discrete-event systems. We specifically focus on backward reachability analysis, i.e., determining the set of states that can reach a given target set within a certain number of steps. Computing backward reachable sets presents significant challenges due to the non-convexity of max-plus dynamics and the complexity of set complement operations. To address these challenges, we propose a novel approximation framework that efficiently computes backward reachable sets by exploiting the structure of tropical polyhedra. Our approach reformulates the problem as a sequence of symbolic operations and approximates non-convex target sets through closure operations on unions of tropical polyhedra. We develop a systematic algorithm that constructs both outer (M-form) and inner (V-form) representations of the resulting sets, incorporating extremal filtering to reduce computational complexity. The proposed method offers a scalable alternative to traditional DBM-based approaches, enabling reliable approximate backward reachability analysis for general target regions in MPLS."}
{"id": "2601.10626", "categories": ["math.ST", "cs.CR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10626", "abs": "https://arxiv.org/abs/2601.10626", "authors": ["Getoar Sopa", "Marco Avella Medina", "Cynthia Rush"], "title": "Differentially Private Inference for Longitudinal Linear Regression", "comment": "68 pages, 3 figures", "summary": "Differential Privacy (DP) provides a rigorous framework for releasing statistics while protecting individual information present in a dataset. Although substantial progress has been made on differentially private linear regression, existing methods almost exclusively address the item-level DP setting, where each user contributes a single observation. Many scientific and economic applications instead involve longitudinal or panel data, in which each user contributes multiple dependent observations. In these settings, item-level DP offers inadequate protection, and user-level DP - shielding an individual's entire trajectory - is the appropriate privacy notion. We develop a comprehensive framework for estimation and inference in longitudinal linear regression under user-level DP. We propose a user-level private regression estimator based on aggregating local regressions, and we establish finite-sample guarantees and asymptotic normality under short-range dependence. For inference, we develop a privatized, bias-corrected covariance estimator that is automatically heteroskedasticity- and autocorrelation-consistent. These results provide the first unified framework for practical user-level DP estimation and inference in longitudinal linear regression under dependence, with strong theoretical guarantees and promising empirical performance."}
{"id": "2601.10057", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10057", "abs": "https://arxiv.org/abs/2601.10057", "authors": ["Zhiwei Zhang", "Shuwang Li", "John Lowengrub", "Steven M. Wise"], "title": "An Efficient Constant-Coefficient MSAV Scheme for Computing Vesicle Growth and Shrinkage", "comment": "Submitted to Communications in Computational Physics", "summary": "We present a fast, unconditionally energy-stable numerical scheme for simulating vesicle deformation under osmotic pressure using a phase-field approach. The model couples an Allen-Cahn equation for the biomembrane interface with a variable-mobility Cahn-Hilliard equation governing mass exchange across the membrane. Classical approaches, including nonlinear multigrid and Multiple Scalar Auxiliary Variable (MSAV) methods, require iterative solution of variable-coefficient systems at each time step, resulting in substantial computational cost. We introduce a constant-coefficient MSAV (CC-MSAV) scheme that incorporates stabilization directly into the Cahn-Hilliard evolution equation rather than the chemical potential. This reformulation yields fully decoupled constant-coefficient elliptic problems solvable via fast discrete cosine transform (DCT), eliminating iterative solvers entirely. The method achieves O(N^2 log N) complexity per time step while preserving unconditional energy stability and discrete mass conservation. Numerical experiments verify second-order temporal and spatial accuracy, mass conservation to relative errors below 5 x 10^-11, and close agreement with nonlinear multigrid benchmarks. On grids with N >= 2048, CC-MSAV achieves 6-15x overall speedup compared to classical MSAV with optimized preconditioning, while the dominant Cahn-Hilliard subsystem is accelerated by up to two orders of magnitude. These efficiency gains, achieved without sacrificing accuracy, make CC-MSAV particularly well suited for large-scale simulations of vesicle dynamics."}
{"id": "2601.10158", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10158", "abs": "https://arxiv.org/abs/2601.10158", "authors": ["Wang Yang", "Helin Wang", "Chao Xu"], "title": "Electric field effects in one-dimensional spin-1/2 $K_1J_1Γ_1Γ_1^\\prime K_2J_2$ model with ferromagnetic Kitaev coupling", "comment": "18 pages, 6 figures", "summary": "We perform a systematic study on the effects of electric fields in the Luttinger liquid phase of the one-dimensional spin-$1/2$ $K_1J_1Γ_1Γ_1^\\prime K_2J_2$ model in the region of ferromagnetic nearest-neighboring Kitaev coupling. We find that while electric fields along $(1,1,1)$-direction maintain the Luttinger liquid behavior, fields along other directions drive the system to a dimerized state. An estimation is made on how effective a $(1,1,1)$-field is for tuning the Luttinger parameter in real materials. Our work is useful for understanding the effects of electric fields in one-dimensional generalized Kitaev spin models, and provides a starting point for exploring the electric-field-related physics in two dimensions based on a quasi-one-dimensional approach."}
{"id": "2601.10166", "categories": ["quant-ph", "physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.10166", "abs": "https://arxiv.org/abs/2601.10166", "authors": ["Miriam Goldack", "Yosi Atia", "Ori Alberton", "Karl Jansen"], "title": "Computing Statistical Properties of Velocity Fields on Current Quantum Hardware", "comment": "25 pages, 16 figures", "summary": "Quantum algorithms are gaining attention in Computational Fluid Dynamics (CFD) for their favorable scaling, as encoding physical fields into quantum probability amplitudes enables representation of two to the power of n spatial points with only n qubits. A key challenge in Quantum CFD is the efficient readout of simulation results, a topic that has received limited attention in literature. This work presents methods to extract statistical properties of spatial velocity fields, such as central moments and structure functions, directly from parameterized ansatz circuits, avoiding full quantum state tomography. As a proof of concept, we implement our approach for 1D velocity fields, encoding 16 spatial points with 4 qubits, and analyze both a sine wave signal and four snapshots from Burgers' equation evolution. Using Qedma's error mitigation software QESEM, we demonstrate that such computations achieve high accuracy on current quantum devices, specifically IBMQ's Heron2 system ibm_fez."}
{"id": "2601.09968", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.09968", "abs": "https://arxiv.org/abs/2601.09968", "authors": ["Faruk Muritala", "Austin Brown", "Dhrubajyoti Ghosh", "Sherry Ni"], "title": "Derivations for the Cumulative Standardized Binomial EWMA (CSB-EWMA) Control Chart", "comment": null, "summary": "This paper presents the exact mathematical derivation of the mean and variance properties for the Exponentially Weighted Moving Average (EWMA) statistic applied to binomial proportion monitoring in Multiple Stream Processes (MSPs). We develop a Cumulative Standardized Binomial EWMA (CSB-EWMA) formulation that provides adaptive control limits based on exact time-varying variance calculations, overcoming the limitations of asymptotic approximations during early-phase monitoring. The derivations are rigorously validated through Monte Carlo simulations, demonstrating remarkable agreement between theoretical predictions and empirical results. This work establishes a theoretical foundation for distribution-free monitoring of binary outcomes across parallel data streams, with applications in statistical process control across diverse domains including manufacturing, healthcare, and cybersecurity."}
{"id": "2601.10333", "categories": ["cond-mat.dis-nn"], "pdf": "https://arxiv.org/pdf/2601.10333", "abs": "https://arxiv.org/abs/2601.10333", "authors": ["Florin Hemmann", "Vincent Glauser", "Ullrich Steiner", "Matthias Saba"], "title": "Computer Generation of Disordered Networks with Targeted Structural Properties", "comment": null, "summary": "Disordered spatial networks are model systems that describe structures and interactions across multiple length scales. Scattering and interference of waves in these networks can give rise to structural phase transitions, localization, diffusion, and band gaps. The study of these complex phenomena requires efficient numerical methods to computer-generate disordered networks with targeted structural properties. In the established Wooten-Weaire-Winer algorithm, a series of bond switch moves introduces disorder into an initial network. Conventional strain energies that govern this evolution are limited to 3D networks with coordination numbers of no more than four. We extend the algorithm to arbitrary coordination number statistics by introducing bond repulsion in the Keating strain energy. We tune the degree and type of disorder introduced into initially crystalline networks by varying the bond-bending force constant in the strain energy and the temperature profile. The effects of these variables are analyzed using a list of order metrics that capture both direct and reciprocal space. A feedforward neural network is trained to predict the structural characteristics from the algorithm inputs, enabling targeted network generation. As a case study, we statistically reproduce four disordered biophotonic networks exhibiting structural color. This work presents a versatile method for generating disordered networks with tailored structural properties. It will enable new insights into structure-property relations, such as photonic band gaps in disordered networks."}
{"id": "2601.09962", "categories": ["cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.09962", "abs": "https://arxiv.org/abs/2601.09962", "authors": ["Swastik Majumder", "Mustansir Barma"], "title": "Stochastic systems with Bose-Hubbard interactions: Effects of bias on particles on a random comb", "comment": "5 pages, 3 figures", "summary": "We study stochastic transport of interacting particles on a disordered network described by the random comb geometry. The model is defined on a one-dimensional backbone from which branches of random lengths emanate, providing a minimal model of percolation networks beyond the critical percolation probability. The dynamics obeys local detailed balance with respect to a Bose-Hubbard Hamiltonian containing both an external bias and on-site repulsion. This choice yields an analytically tractable steady state through a mapping to the zero-range-process. We compute the backbone current, branch density profiles, and macroscopic drift velocity, and analyze how bias and interactions compete to shape transport. The backbone current increases monotonically with density, while the drift velocity displays a non-monotonic dependence on the external field, remaining finite for any nonzero bias, in contrast to the vanishing drift velocity of noninteracting particles beyond a threshold bias. Density profiles along branches exhibit stepwise plateaus governed by the ratio of interaction to bias energy. These results highlight how repulsive interactions suppress trapping and restore transport in disordered geometries, bridging earlier studies of field induced drift in random networks with the physics of disordered Bose-Hubbard systems."}
{"id": "2601.10292", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10292", "abs": "https://arxiv.org/abs/2601.10292", "authors": ["Georgia Psychogiou", "Donal P. Lynch", "Spyridon N. Daskalakis", "Manos M. Tentzeris", "George Goussetis", "Stylianos D. Asimonis"], "title": "Single-Feed Circularly Polarized Super Realized Gain Antenna", "comment": null, "summary": "This paper presents a super realized gain, circularly polarized strip-crossed dipole antenna operating at 3.5 GHz. Superdirective behavior is achieved by leveraging strong inter-element mutual coupling through careful adjustment of the strip dimensions. The antenna features a single driven element, with the other element passively loaded with a reactive impedance. The structure is optimized to maximize left-hand circularly polarized (LHCP) realized gain, ensuring high polarization purity and good impedance matching. The optimized design exhibits a 50 $Ω$ impedance bandwidth of 3.29 - 4.17 GHz (23.75%) and an axial-ratio bandwidth of 3.43 - 3.57 GHz (4%). At 3.5 GHz, the antenna achieves a peak realized gain of 6.1 dB ($ka \\approx 1.65$), with an axial ratio of 1.4 dB. These results demonstrate that circular polarization and superdirectivity can be simultaneously realized in a geometrically simple, low-profile ($0.15λ$) antenna, rendering it suitable for integration into compact sub-6~GHz wireless and sensing platforms."}
{"id": "2601.09786", "categories": ["quant-ph", "cs.IT", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09786", "abs": "https://arxiv.org/abs/2601.09786", "authors": ["Marco Dalai", "Filippo Girardi", "Ludovico Lami"], "title": "Zero-Error List Decoding for Classical-Quantum Channels", "comment": "5+1 pages, 1 figure", "summary": "The aim of this work is to study the zero-error capacity of pure-state classical-quantum channels in the setting of list decoding. We provide an achievability bound for list-size two and a converse bound holding for every fixed list size. The two bounds coincide for channels whose pairwise absolute state overlaps form a positive semi-definite matrix. Finally, we discuss a remarkable peculiarity of the classical-quantum case: differently from the fully classical setting, the rate at which the sphere-packing bound diverges might not be achievable by zero-error list codes, even when we take the limit of fixed but arbitrarily large list size."}
{"id": "2601.10370", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.10370", "abs": "https://arxiv.org/abs/2601.10370", "authors": ["Jian-Wen Peng", "Jun-Jie Luo", "Abubakar Adamu"], "title": "A two-step inertial method with a new step-size rule for variational inequalities in hilbert spaces", "comment": null, "summary": "In this paper, a two-step inertial Tseng extragradient method involving self-adaptive and Armijo-like step sizes is introduced for solving variational inequalities with a quasimonotone cost function in the setting of a real Hilbert space. Weak convergence of the sequence generated by the proposed algorithm is proved without assuming the Lipschitz condition. An interesting feature of the proposed algorithm is its ability to select the better step size between the self-adaptive and Armijo-like options at each iteration step. Moreover, removing the requirement for the Lipschitz condition on the cost function broadens the applicability of the proposed method. Finally, the algorithm accelerates and complements several existing iterative algorithms for solving variational inequalities in Hilbert spaces."}
{"id": "2601.10153", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10153", "abs": "https://arxiv.org/abs/2601.10153", "authors": ["Hideki Nishizawa", "Kazuya Anazawa", "Tetsuro Inui", "Toru Mano", "Takeo Sasai", "Giacomo Borraccini", "Tatsuya Matsumura", "Hiroyuki Ishihara", "Sae Kojima", "Yoshiaki Sone", "Koichi Takasugi"], "title": "Leveraging Digital Twin Technologies: All-Photonics Networks-as-a-Service for Data Center Xchange in the Era of AI [Invited Tutorial]", "comment": null, "summary": "This paper presents a data center exchange (Data Center Xchange, DCX) architecture for all-photonics networks-as-a-service in distributed data center infrastructures, enabling the creation of a virtual large-scale data center by directly interconnecting distributed data centers in metropolitan areas. Key requirements for such an architecture are identified: support for low-latency operations, scalability, reliability, and flexibility within a single network architecture; the ability to add new operator-driven automation functionalities based on an open networking approach; and the ability to control and manage remotely deployed transponders connected via access links with unknown physical parameters. We propose a set of technologies that enable digital twin operations for optical networks, including a cloud-native architecture for coherent transceivers, remote transponder control, fast end-to-end optical path provisioning, transceiver-based physical-parameter estimation incorporating digital longitudinal monitoring, and optical line system calibration, demonstrating their feasibility through field validations."}
{"id": "2601.09874", "categories": ["stat.ME", "math.ST", "stat.CO"], "pdf": "https://arxiv.org/pdf/2601.09874", "abs": "https://arxiv.org/abs/2601.09874", "authors": ["Bilel Bousselmi", "Gabriela Ciuperca"], "title": "Model selection by cross-validation in an expectile linear regression", "comment": null, "summary": "For linear models that may have asymmetric errors, we study variable selection by cross-validation. The data are split into training and validation sets, with the number of observations in the validation set much larger than in the training set. For the model coefficients, the expectile or adaptive LASSO expectile estimators are calculated on the training set. These estimators will be used to calculate the cross-validation mean score (CVS) on the validation set. We show that the model that minimizes CVS is consistent in two cases: when the number of explanatory variables is fixed or when it depends on the number of observations. Monte Carlo simulations confirm the theoretical results and demonstrate the superiority of our estimation method compared to two others in the literature. The usefulness of the CV expectile model selection technique is illustrated by applying it to real data sets."}
{"id": "2601.10149", "categories": ["math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10149", "abs": "https://arxiv.org/abs/2601.10149", "authors": ["Wenbo Wang", "Guangyan Jia"], "title": "New Second-order Convergent Schemes for Solving decoupled FBSDEs", "comment": null, "summary": "This paper proposes a new second-order symmetric algorithm for solving decoupled forward-backward stochastic differential equations. Inspired by the alternating direction implicit splitting method for partial differential equations, we split the generator into the sum of two functions. In the computation of the value process Y, explicit and implicit schemes are alternately applied to these two generators, while the algorithms from \\citep{ZhaoLi2014} are used for the control process Z. We rigorously prove that the two new schemes have second-order convergence rate. The proposed splitting methods show clear advantages for equations whose generator consists of a linear part plus a nonlinear part, as they reduce the number of iterations required for solving implicit schemes, thereby decreasing computational cost while maintaining second-order convergence. Two numerical examples are provided, including the backward stochastic Riccati equation arising in mean-variance hedging. The numerical results verify the theoretical error analysis and demonstrate the advantage of reduced computational cost compared to the algorithm in \\citep{ZhaoLi2014}."}
{"id": "2601.10414", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10414", "abs": "https://arxiv.org/abs/2601.10414", "authors": ["Konstantin Semeniuk", "Burkhard Schmidt", "Christophe Marcenat", "Meike Pfeiffer", "Albin Demuer", "Lipsa Behera", "Thierry Klein", "Seunghyun Khim", "Elena Hassinger"], "title": "Basal-plane anisotropy of field-induced multipolar order in tetragonal CeRh$_2$As$_2$", "comment": "Includes Supplemental Material", "summary": "Unconventional superconductivity in Ce-based Kondo-lattice materials emerges almost exclusively in the vicinity of weak dipolar magnetic orders, while higher multipolar orders are only known to occur in a few Pr-based unconventional superconductors and possibly URu$_2$Si$_2$. The multiphase superconductor CeRh$_2$As$_2$ appears to be a notable exception from this trend. Showing clear signatures of magnetism, this tetragonal system is suspected to host a concomitant quadrupolar order, which could be causing the strong enhancement of the ordering temperature when a magnetic field is applied perpendicular to the fourfold ($c$) axis of the lattice. In this work, we show that the field-temperature phase diagram of CeRh$_2$As$_2$ has a remarkable basal-plane anisotropy. This finding supports the scenario of coupled magnetic and multipolar ordering, which may have implications for the pairing mechanism of the superconductivity, and guides the development of the next iteration of theoretical models."}
{"id": "2601.10557", "categories": ["math.NA", "cs.CE", "cs.DC", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.10557", "abs": "https://arxiv.org/abs/2601.10557", "authors": ["Edoardo Di Napoli", "Clément Richefort", "Xinzhe Wu"], "title": "Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians", "comment": "To be submitted to SISC", "summary": "Studying the optoelectronic structure of materials can require the computation of up to several thousands of the smallest eigenpairs of a pseudo-hermitian Hamiltonian. Iterative eigensolvers may be preferred over direct methods for this task since their complexity is a function of the desired fraction of the spectrum. In addition, they generally rely on highly optimized and scalable kernels such as matrix-vector multiplications that leverage the massive parallelism and the computational power of modern exascale systems. \\textit{Chebyshev Accelerated Subspace iteration Eigensolver} (ChASE) is able to compute several thousands of the most extreme eigenpairs of dense hermitian matrices with proven scalability over massive parallel accelerated clusters. This work presents an extension of ChASE to solve for a portion of the spectrum of pseudo-hermitian Hamiltonians as they appear in the treatment of excitonic materials. The new pseudo-hermitian solver achieves similar convergence and performance as the hermitian one. By exploiting the numerical structure and spectral properties of the Hamiltonian matrix, we propose an oblique variant of Rayleigh-Ritz projection featuring quadratic convergence of the Ritz-values with no explicit construction of the dual basis set. Additionally, we introduce a parallel implementation of the recursive matrix-product operation appearing in the Chebyshev filter with limited amount of global communications. Our development is supported by a full numerical analysis and experimental tests."}
{"id": "2601.09984", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.09984", "abs": "https://arxiv.org/abs/2601.09984", "authors": ["Yang Ou", "Lan Xue", "Carmen Tekwe", "Kedir N. Turi", "Roger S. Zoh"], "title": "Estimating the effect of lymphovascular invasion on 2-year survival probability under endogeneity: a recursive copula-based approach", "comment": "19 pages,4 figures", "summary": "Lymphovascular invasion (LVI) is an important prognostic marker for head and neck squamous cell carcinoma (HNSC), but the true effect of LVI on survival may be distorted by endogeneity arising from unmeasured confounding. Conventional one-stage conditional models and instrument-based two-stage estimators are prone to bias under endogeneity, and sufficiently strong instruments are often unavailable in practice. To address these challenges, we propose a semiparametric recursive copula framework that jointly specifies marginal models for both LVI, treated as an endogenous exposure, and a binary 2-year survival outcome, and links them through a flexible copula to account for latent confounding and accommodate censoring without requiring strong instruments. In two simulation studies, we systematically varied sample sizes, censoring rates from 0% to 60%, and endogeneity strengths, and assessed robustness under moderate model misspecification. The proposed copula framework exhibited reduced bias and improved interval coverage compared with both one-stage and two-stage approaches while maintaining robustness to moderate misspecification. We applied the method to HNSC cases with associated clinical and microRNA data from The Cancer Genome Atlas (n = 215), and found that LVI significantly reduced 2-year survival probability by approximately 47%, with a 95% confidence interval of -0.61 to -0.29 on the probability scale. The estimated positive dependence parameter indicates that the attenuation is driven by residual dependence between unobserved components of LVI and survival. Overall, the proposed copula framework yields more credible effect estimates for survival outcomes in the absence of strong instruments, mitigating biases due to endogeneity and censoring and strengthening quantitative evidence for HNSC research."}
{"id": "2601.10427", "categories": ["cond-mat.dis-nn", "math-ph", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10427", "abs": "https://arxiv.org/abs/2601.10427", "authors": ["Pierre Bousseyroux", "Marc Potters"], "title": "The eigenvalues and eigenvectors of finite-rank normal perturbations of large rotationally invariant non-Hermitian matrices", "comment": null, "summary": "We study finite-rank normal deformations of rotationally invariant non-Hermitian random matrices. Extending the classical Baik-Ben Arous-Péché (BBP) framework, we characterize the emergence and fluctuations of outlier eigenvalues in models of the form $\\mathbf{A} + \\mathbf{T}$, where $\\mathbf{A}$ is a large rotationally invariant non-Hermitian random matrix and $\\mathbf{T}$ is a finite-rank normal perturbation. We also describe the corresponding eigenvector behavior. Our results provide a unified framework encompassing both Hermitian and non-Hermitian settings, thereby generalizing several known cases."}
{"id": "2601.10022", "categories": ["cond-mat.stat-mech", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.10022", "abs": "https://arxiv.org/abs/2601.10022", "authors": ["Dilipkumar N. Asthagiri", "Dmitry V. Matyushov"], "title": "Rotational Memory Function of SPC/E water", "comment": "7 pp, 5 figs", "summary": "Memory effects are essential for dynamics of condensed materials and are responsible for non-exponential relaxation of correlation functions of dynamic variables through the memory function. Memory functions of dipole rotations for polar liquids have never been calculated. We present here calculations of memory functions for single-dipole rotations and for the overall dipole moment of the sample for SPC/E water. The memory functions for single-particle and collective dipole dynamics turn out to be nearly identical. This result validates theories of dielectric spectroscopy in terms of single-particle time correlation functions and the connection between the collective and single-particle relaxation times through the Kirkwood factor. The dielectric function in this formalism contains no new dynamic information that does not exist in the single-dipole correlation function. A short memory time, $\\lesssim 1$ fs, justifies the use of rotational diffusion model to describe dynamics of a single molecular dipole moment in bulk water."}
{"id": "2601.10671", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10671", "abs": "https://arxiv.org/abs/2601.10671", "authors": ["Trager Joswig-Jones", "Baosen Zhang"], "title": "Safe Trajectory Gradient Flow Control of a Grid-Interfacing Inverter", "comment": "5 pages, 4 figures, Submitted to PES-GM 2026", "summary": "Grid-interfacing inverters serve as the interface between renewable energy resources and the electric power grid, offering fast, programmable control capabilities. However, their operation is constrained by hardware limitations, such as bounds on the current magnitude. Existing control methods for these systems often neglect these constraints during controller design and instead rely on ad hoc limiters, which can introduce instability or degrade performance. In this work, we present a control framework that directly incorporates constraints into the control of a voltage-source inverter. We propose a safe trajectory gradient flow controller, which applies the safe gradient flow method to a rolling horizon trajectory optimization problem to ensure that the states remain within a safe set defined by the constraints while directing the trajectory towards an optimal equilibrium point of a nonlinear program. Simulation results demonstrate that our approach can drive the outputs of a simulated inverter system to optimal values and maintain state constraints, even when using a limited number of optimization steps per control cycle."}
{"id": "2601.09792", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09792", "abs": "https://arxiv.org/abs/2601.09792", "authors": ["Ricard Puig", "Nathan Constantinides", "Bharath Hebbe Madhusudhana", "Daniel Bowring", "C. Huerta Alderete", "Andrew T. Sornborger"], "title": "Background cancellation for frequency-selective quantum sensing", "comment": "5 + 11 pages, 3 figures", "summary": "A key challenge in quantum sensing is the detection of weak time dependent signals, particularly those that arise as specific frequency perturbations over a background field. Conventional methods usually demand complex dynamical control of the quantum sensor and heavy classical post-processing. We propose a quantum sensor that leverages time independent interactions and entanglement to function as a passive, tunable, thresholded frequency filter. By encoding the frequency selectivity and thresholding behavior directly into the dynamics, the sensor is responsive only to a target frequency of choice whose amplitude is above a threshold. This approach circumvents the need for complex control schemes and reduces the post-processing overhead."}
{"id": "2601.10390", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.10390", "abs": "https://arxiv.org/abs/2601.10390", "authors": ["P. D. Khanh", "V. V. H. Khoa", "T. H. Mo"], "title": "Algebraic Farkas Lemma and Strong Duality for Perturbed Conic Linear Programming", "comment": null, "summary": "This paper addresses the study of algebraic versions of Farkas lemma and strong duality results in the very broad setting of infinite-dimensional conic linear programming in dual pairs of vector spaces. To this end, purely algebraic properties of perturbed optimal value functions of both primal and dual problems and their corresponding hypergraph/epigraph are investigated. The newly developed hypergraphical/epigraphical sets, inspired by Kretschmer's closedness conditions \\cite{Kretschmer61}, together with their novel convex separation-type characterizations, give rise to various perturbed Farkas-type lemmas which allow us to derive complete characterizations of ``zero duality gap''. Principally, when certain structures of algebraic or topological duals are imposed, illuminating implications of the developed condition are also explored."}
{"id": "2601.10178", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10178", "abs": "https://arxiv.org/abs/2601.10178", "authors": ["Andres Intriago", "Rongxing Hu", "Nabil Mohammed", "S. Gokul Krishnan", "Konstantinos Kotsovos", "Issam Gereige", "Nesren Attiah", "Ali Basaheeh", "Sarah Aqeel", "Hamad A. Saiari", "Shehab Ahmed", "Charalambos Konstantinou"], "title": "HyMGP: A Customized MILP-Based Tool for Techno-Economic Planning of Islanded Microgrids", "comment": "2026 IEEE Power & Energy Society (PES) International Meeting (IM)", "summary": "This paper presents a customized microgrid planning algorithm and tool, HyMGP, for remote sites in arid regions, which is formulated as a Mixed Integer Linear Programming (MILP) problem. HyMGP is compared with HOMER Pro to evaluate its performance in optimizing the sizing of microgrid components, including photovoltaic panels (PVs), vertical axis wind turbines (VAWTs), and battery energy storage systems (BESS), for remote and off-grid applications. The study focuses on a standalone microgrid in the Saudi Arabia, considering high solar irradiance, limited wind availability, and a constant load profile composed of continuous cathodic protection and daytime cooling. In the simulation environment, comparisons with HOMER solutions demonstrate the advantages of HyMGP, which provides optimal and more flexible solutions by allowing user-defined component specifications and strictly enforcing all constraints. Further analysis shows that incorporating wind turbines reduces the Net Present Cost (NPC) by decreasing the required PV and battery capacities. Increasing battery autonomy leads to a higher NPC in both PV-only and hybrid systems due to the need for larger storage. Finally, lithium iron phosphate (Li-ion LFP) batteries are found to be more cost effective than lead acid, offering lower NPCs due to their longer lifespan, deeper discharge capability, and fewer replacement cycles."}
{"id": "2601.10357", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10357", "abs": "https://arxiv.org/abs/2601.10357", "authors": ["Yue Yu", "Guanghui Wang", "Liu Liu", "Changliang Zou"], "title": "Model-Agnostic and Uncertainty-Aware Dimensionality Reduction in Supervised Learning", "comment": null, "summary": "Dimension reduction is a fundamental tool for analyzing high-dimensional data in supervised learning. Traditional methods for estimating intrinsic order often prioritize model-specific structural assumptions over predictive utility. This paper introduces predictive order determination (POD), a model-agnostic framework that determines the minimal predictively sufficient dimension by directly evaluating out-of-sample predictiveness. POD quantifies uncertainty via error bounds for over- and underestimation and achieves consistency under mild conditions. By unifying dimension reduction with predictive performance, POD applies flexibly across diverse reduction tasks and supervised learners. Simulations and real-data analyses show that POD delivers accurate, uncertainty-aware order estimates, making it a versatile component for prediction-centric pipelines."}
{"id": "2601.10222", "categories": ["math.NA", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10222", "abs": "https://arxiv.org/abs/2601.10222", "authors": ["Alena Kopaničáková", "Elisa Riccietti"], "title": "Introduction to optimization methods for training SciML models", "comment": null, "summary": "Optimization is central to both modern machine learning (ML) and scientific machine learning (SciML), yet the structure of the underlying optimization problems differs substantially across these domains. Classical ML typically relies on stochastic, sample-separable objectives that favor first-order and adaptive gradient methods. In contrast, SciML often involves physics-informed or operator-constrained formulations in which differential operators induce global coupling, stiffness, and strong anisotropy in the loss landscape. As a result, optimization behavior in SciML is governed by the spectral properties of the underlying physical models rather than by data statistics, frequently limiting the effectiveness of standard stochastic methods and motivating deterministic or curvature-aware approaches. This document provides a unified introduction to optimization methods in ML and SciML, emphasizing how problem structure shapes algorithmic choices. We review first- and second-order optimization techniques in both deterministic and stochastic settings, discuss their adaptation to physics-constrained and data-driven SciML models, and illustrate practical strategies through tutorial examples, while highlighting open research directions at the interface of scientific computing and scientific machine learning."}
{"id": "2601.10489", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10489", "abs": "https://arxiv.org/abs/2601.10489", "authors": ["I. Jakovac", "M. S. Grbić", "M. Dupont", "N. Laflorencie", "S. Capponi", "Y. Hosokoshi", "S. Krämer", "Y. Skourski", "S. Luther M. Takigawa", "M. Horvatić"], "title": "Magnetic field-induced phases in a model S=1 Haldane chain system", "comment": "8 pages, 3 figures", "summary": "An $S=1$ Haldane chain is a one-dimensional (1D) quantum magnet where strong fluctuations result in quantum disordered singlet ground state with a gapped excitation spectrum. The gap magnitude is primarily set by the dominant intrachain interaction ($J_\\text{1D}$). An applied magnetic field closes the gap at $B_\\text{c1}$ and drives the system into a gapless Tomonaga-Luttinger liquid (TLL) regime, followed by, at lower temperatures, a Bose-Einstein condensate (BEC) ground state, persisting up to $B_\\text{c2} \\propto 4 J_\\text{1D}/gμ_B$. Almost all previously studied experimental realizations of such systems were based on transition-metal complexes which typically suffer from intrinsic anisotropies or large $J_\\text{1D}$ values, limiting the access to the full theoretical phase diagram. We report a comprehensive study of TLL and BEC phases in the organic Haldane chain system 3,5-bis(N-tert-butylaminoxyl)-3'-nitrobiphenyl (BoNO). The absence of anisotropy and a moderate $J_\\text{1D}$ enable exploration of the complete $B-T$ phase diagram. Through $^1$H nuclear magnetic resonance, combined with theoretical analysis, we characterize the TLL properties, map the BEC phase boundary $T_c (B)$, determine the associated critical exponent $ν\\approx 0.66$ at $B_\\text{c2}$, and demonstrate universal quasiparticle scaling in the quantum-critical regime. These results provide full experimental validation of theoretical predictions for field-induced phases in an $S=1$ Haldane chain, made over two decades ago."}
{"id": "2601.10049", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10049", "abs": "https://arxiv.org/abs/2601.10049", "authors": ["Lei Huang", "Chengyue Liu", "Li Wang"], "title": "Weighted least squares estimation by multivariate-dependent weights for linear regression models", "comment": null, "summary": "Multivariate linear regression models often face the problem of heteroscedasticity caused by multiple explanatory variables. The weighted least squares estimation with univariate-dependent weights has limitations in constructing weight functions. Therefore, this paper proposes a multivariate dependent weighted least squares estimation method. By constructing a linear combination of explanatory variables and maximizing their Spearman rank correlation coefficient with the absolute residual value, combined with maximum likelihood method to depict heteroscedasticity, it can comprehensively reflect the trend of variance changes in the random error and improve the accuracy of the model. This paper demonstrates that the optimal linear combination exponent estimator for heteroscedastic volatility obtained by our algorithm possesses consistency and asymptotic normality. In the simulation experiment, three scenarios of heteroscedasticity were designed, and the comparison showed that the proposed method was superior to the univariate-dependent weighting method in parameter estimation and model prediction. In the real data applications, the proposed method was applied to two real-world datasets about consumer spending in China and housing prices in Boston. From the perspectives of MAE, RSE, cross-validation, and fitting performance, its accuracy and stability were verified in terms of model prediction, interval estimation, and generalization ability. Additionally, the proposed method demonstrated relative advantages in fitting data with large fluctuations. This study provides an effective new approach for dealing with heteroscedasticity in multivariate linear regression."}
{"id": "2601.10483", "categories": ["math.OC", "cond-mat.dis-nn", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10483", "abs": "https://arxiv.org/abs/2601.10483", "authors": ["Simon Martin", "Giulio Biroli", "Francis Bach"], "title": "High-Dimensional Analysis of Gradient Flow for Extensive-Width Quadratic Neural Networks", "comment": null, "summary": "We study the high-dimensional training dynamics of a shallow neural network with quadratic activation in a teacher-student setup. We focus on the extensive-width regime, where the teacher and student network widths scale proportionally with the input dimension, and the sample size grows quadratically. This scaling aims to describe overparameterized neural networks in which feature learning still plays a central role. In the high-dimensional limit, we derive a dynamical characterization of the gradient flow, in the spirit of dynamical mean-field theory (DMFT). Under l2-regularization, we analyze these equations at long times and characterize the performance and spectral properties of the resulting estimator. This result provides a quantitative understanding of the effect of overparameterization on learning and generalization, and reveals a double descent phenomenon in the presence of label noise, where generalization improves beyond interpolation. In the small regularization limit, we obtain an exact expression for the perfect recovery threshold as a function of the network widths, providing a precise characterization of how overparameterization influences recovery."}
{"id": "2601.10211", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10211", "abs": "https://arxiv.org/abs/2601.10211", "authors": ["Mariel Kempa", "Markus Kraft", "Robin Steinigeweg", "Jochen Gemmer", "Jiaozi Wang"], "title": "Random matrix theory universality of current operators in spin-$S$ Heisenberg chains", "comment": "7 pages, 3 figures", "summary": "Quantum chaotic systems exhibit certain universal statistical properties that closely resemble predictions from random matrix theory (RMT). With respect to observables, it has recently been conjectured that, when truncated to a sufficiently narrow energy window, their statistical properties can be described by an unitarily invariant ensemble, and testable criteria have been introduced, which are based on the scaling behavior of free cumulants. In this paper, we investigate the conjecture numerically in translationally invariant Heisenberg spin chains with spin quantum number $S =\\frac{1}{2},1,\\frac{3}{2}$. Combining a quantum-typicality-based numerical method with the exploitation of the system's symmetries, we study the spin current operator and find clear evidence of consistency with the proposed criteria in chaotic cases. Our findings further support the conjecture of the existence of RMT universality as manifest in the observable properties in quantum chaotic systems."}
{"id": "2601.09817", "categories": ["quant-ph", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.09817", "abs": "https://arxiv.org/abs/2601.09817", "authors": ["L. L. Salcedo"], "title": "Localization of quantum states within subspaces", "comment": "15 pages, 4 figures, 1 table", "summary": "A precise definition is proposed for the localization probability of a quantum state within a given subspace of the full Hilbert space of a quantum system. The corresponding localized component of the state is explicitly identified, and several mathematical properties are established. Applications and interpretations in the context of quantum information are also discussed."}
{"id": "2601.10475", "categories": ["math.OC"], "pdf": "https://arxiv.org/pdf/2601.10475", "abs": "https://arxiv.org/abs/2601.10475", "authors": ["Xiaoyu Peng", "Xi Ru", "Zhongze Li", "Jianxin Zhang", "Xinghua Chen", "Feng Liu"], "title": "Positive Damping Region: A Graphic Tool for Passivization Analysis with Passivity Index", "comment": "8 pages, 7 figures", "summary": "This paper presents a geometric framework for analyzing output-feedback and input-feedforward passivization of linear time-invariant systems. We reveal that a system is passivizable with a given passivity index when the Nyquist plot for SISO systems or the Rayleigh quotient of the transfer function for MIMO systems lies within a specific, index-dependent region in the complex plane, termed the positive damping region. The criteria enable a convenient graphic tool for analyzing the passivization, the associated frequency bands, the maximum achievable passivity index, and the waterbed effect between them. Additionally, the tool can be encoded into classical tools such as the Nyquist plot, the Nichols plot, and the generalized KYP lemma to aid control design. Finally, we demonstrate its application in passivity-based power system stability analysis and discuss its implications for electrical engineers regarding device controller design trade-offs."}
{"id": "2601.10189", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10189", "abs": "https://arxiv.org/abs/2601.10189", "authors": ["Jonathan Vieth", "Annika Eichler", "Arne Speerforck"], "title": "Model Predictive Control of Thermo-Hydraulic Systems Using Primal Decomposition", "comment": "This work has been submitted to the IFAC World Congress 2026 for possible publication", "summary": "Decarbonizing the global energy supply requires more efficient heating and cooling systems. Model predictive control enhances the operation of cooling and heating systems but depends on accurate system models, often based on control volumes. We present an automated framework including time discretization to generate model predictive controllers for such models. To ensure scalability, a primal decomposition exploiting the model structure is applied. The approach is validated on an underground heating system with varying numbers of states, demonstrating the primal decomposition's advantage regarding scalability."}
{"id": "2601.10641", "categories": ["stat.ME", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10641", "abs": "https://arxiv.org/abs/2601.10641", "authors": ["William L. Lippitt", "Edward J. Bedrick", "Nichole E. Carlson"], "title": "Adjusted Similarity Measures and a Violation of Expectations", "comment": "12 pages, 1 figure", "summary": "Adjusted similarity measures, such as Cohen's kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewed interest in considering other null models more appropriate for context, such as clustering ensembles permitting a random number of identified clusters. The purpose of this work is two -- fold: (1) to generalize the study of the adjustment operator to general null models and to a more general procedure which includes statistical standardization as a special case and (2) to identify sufficient conditions for the adjustment operator to produce the intended properties, where sufficient conditions are related to whether and how observed data are incorporated into null distributions. We demonstrate how violations of the sufficient conditions may lead to substantial breakdown, such as by producing a non-positive measure under traditional adjustment rather than one with mean 0, or by producing a measure which is deterministically 0 under statistical standardization."}
{"id": "2601.10248", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10248", "abs": "https://arxiv.org/abs/2601.10248", "authors": ["Laura Grigori", "Daniel Kressner", "Nian Shao", "Igor Simunec"], "title": "Restoring similarity in randomized Krylov methods with applications to eigenvalue problems and matrix functions", "comment": null, "summary": "The randomized Arnoldi process has been used in large-scale scientific computing because it produces a well-conditioned basis for the Krylov subspace more quickly than the standard Arnoldi process. However, the resulting Hessenberg matrix is generally not similar to the one produced by the standard Arnoldi process, which can lead to delays or spike-like irregularities in convergence. In this paper, we introduce a modification of the randomized Arnoldi process that restores similarity with the Hessenberg matrix generated by the standard Arnoldi process. This is accomplished by enforcing orthogonality between the last Arnoldi vector and the previously generated subspace, which requires solving only one additional least-squares problem. When applied to eigenvalue problems and matrix function evaluations, the modified randomized Arnoldi process produces approximations that are identical to those obtained with the standard Arnoldi process. Numerical experiments demonstrate that our approach is as fast as the randomized Arnoldi process and as robust as the standard Arnoldi process."}
{"id": "2601.10530", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10530", "abs": "https://arxiv.org/abs/2601.10530", "authors": ["Yanran Shi", "Min Li", "Xin Lu", "Jianpeng Liu"], "title": "Correlated states in charge-transfer heterostructures based on rhombohedral multilayer graphene", "comment": "5 pages main text, 10 pages Supplemental Materials", "summary": "Charge transfer is a common phenomenon in van der Waals heterostructures with proper work function mismatch, which enables electrostatic gating to control band alignment and interlayer charge distributions. This provides a tunable platform for studying coupled bilayer correlated electronic systems. Here, we theoretically investigate heterostructures of rhombohedral multilayer graphene (RMG) and an insulating substrate with gate-tunable band alignment. We first develop a self-consistent electrostatic theory for layer charge densities incorporating charge transfer, which reproduces the experimentally observed broadened and bent charge neutrality region. When the substrate's band edge has a much larger effective mass than RMG, its carriers can form a Wigner crystal at low densities. This creates a quantum superlattice that induces topological flat bands in the RMG layer, which may lead to Chern insulators driven by intralayer Coulomb interactions. Conversely, with comparable effective masses, we find an interlayer excitonic insulator state at charge neutrality stabilized by interlayer Coulomb coupling. Our work establishes these charge-transfer heterostructures as a rich platform for topological and excitonic correlated states, opening an avenue for ``charge-transferonics''."}
{"id": "2601.10252", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10252", "abs": "https://arxiv.org/abs/2601.10252", "authors": ["Mayukh Choudhury", "Debraj Das", "Sujit Ghosh"], "title": "Asymptotic Theory of Tail Dependence Measures for Checkerboard Copula and the Validity of Multiplier Bootstrap", "comment": null, "summary": "Nonparametric estimation and inference for lower and upper tail copulas under unknown marginal distributions are considered. To mitigate the inherent discreteness and boundary irregularities of the empirical tail copula, a checkerboard smoothed tail copula estimator based on local bilinear interpolation is introduced. Almost sure uniform consistency and weak convergence of the centered and scaled empirical checkerboard tail copula process are established in the space of bounded functions. The resulting Gaussian limit differs from its known-marginal counterpart and incorporates additional correction terms that account for first-order stochastic errors arising from marginal estimation. Since the limiting covariance structure depends on the unknown tail copula and its partial derivatives, direct asymptotic inference is generally infeasible. To address this challenge, a direct multiplier bootstrap procedure tailored to the checkerboard tail copula is developed. By combining multiplier reweighting with checkerboard smoothing, the bootstrap preserves the extremal dependence structure of the data and consistently captures both joint tail variability and the effects of marginal estimation. Conditional weak convergence of the bootstrap process to the same Gaussian limit as the original estimator is established, yielding asymptotically valid inference for smooth functionals of the tail copula, including the lower and upper tail dependence coefficient. The proposed approach provides a fully feasible framework for confidence regions and hypothesis testing in tail dependence analysis without requiring explicit estimation of the limiting covariance structure. A simulation study illustrates the finite-sample performance of the proposed estimator and demonstrates the accuracy and reliability of the bootstrap confidence intervals under various dependence structures and tuning parameter choices."}
{"id": "2601.10646", "categories": ["cond-mat.stat-mech", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2601.10646", "abs": "https://arxiv.org/abs/2601.10646", "authors": ["Rupak Majumder", "Shamik Gupta"], "title": "Synchronization with Annealed Disorder and Higher-Harmonic Interactions in Arbitrary Dimensions: When Two Dimensions Are Special", "comment": null, "summary": "The impact of disorder on collective phenomena depends crucially on whether it is quenched or annealed. In synchronization problems, quenched disorder in higher dimensional Kuramoto models is known to produce unconventional dimensional effects, including a striking odd even dichotomy: synchronization transitions are continuous in even dimensions and discontinuous in odd dimensions. By contrast, the impact of annealed disorder has received comparatively little attention. Here we study a D dimensional Kuramoto model with both fundamental and higher-harmonic interactions under annealed disorder, and develop an arbitrary dimensional center-manifold framework to analyze the nonlinear dynamics near the onset of collective behavior. We show that annealed disorder fundamentally alters the role of dimensionality. With fundamental coupling alone, it completely removes the odd even dichotomy, yielding continuous synchronization transitions with universal mean-field scaling in all dimensions. Higher-harmonic interactions preserve this universality while rendering the synchronization transition tunable between continuous and discontinuous. At the same time, they give rise to a novel, correlation-driven transition between a symmetry-protected incoherent phase and a symmetry broken state lacking global synchronization, which is therefore invisible to the conventional Kuramoto order parameter. This transition is continuous in two dimensions but discontinuous in higher dimensions, revealing an emergent and previously-unrecognized special role of two dimensions."}
{"id": "2601.09850", "categories": ["quant-ph", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09850", "abs": "https://arxiv.org/abs/2601.09850", "authors": ["Meng-Yuan Li", "Yue Wu"], "title": "Fragmented Topological Excitations in Generalized Hypergraph Product Codes", "comment": "12 pages, 10 figures", "summary": "Product code construction is a powerful tool for constructing quantum stabilizer codes, which serve as a promising paradigm for realizing fault-tolerant quantum computation. Furthermore, the natural mapping between stabilizer codes and the ground states of exactly solvable spin models also motivates the exploration of many-body orders in the stabilizer codes. In this work, we investigate the fracton topological orders in a family of codes obtained by a recently proposed general construction. More specifically, this code family can be regarded as a class of generalized hypergraph product (HGP) codes. We term the corresponding exactly solvable spin models \\textit{orthoplex models}, based on the geometry of the stabilizers. In the 3D orthoplex model, we identify a series of intriguing properties within this model family, including non-monotonic ground state degeneracy (GSD) as a function of system size and non-Abelian lattice defects. Most remarkably, in 4D we discover \\textit{fragmented topological excitations}: while such excitations manifest as discrete, isolated points in real space, their projections onto lower-dimensional subsystems form connected objects such as loops, revealing the intrinsic topological nature of these excitations. Therefore, fragmented excitations constitute an intriguing intermediate class between point-like and spatially extended topological excitations. In addition, these rich features establish the generalized HGP codes as a versatile and analytically tractable platform for studying the physics of fracton orders."}
{"id": "2601.10483", "categories": ["math.OC", "cond-mat.dis-nn", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10483", "abs": "https://arxiv.org/abs/2601.10483", "authors": ["Simon Martin", "Giulio Biroli", "Francis Bach"], "title": "High-Dimensional Analysis of Gradient Flow for Extensive-Width Quadratic Neural Networks", "comment": null, "summary": "We study the high-dimensional training dynamics of a shallow neural network with quadratic activation in a teacher-student setup. We focus on the extensive-width regime, where the teacher and student network widths scale proportionally with the input dimension, and the sample size grows quadratically. This scaling aims to describe overparameterized neural networks in which feature learning still plays a central role. In the high-dimensional limit, we derive a dynamical characterization of the gradient flow, in the spirit of dynamical mean-field theory (DMFT). Under l2-regularization, we analyze these equations at long times and characterize the performance and spectral properties of the resulting estimator. This result provides a quantitative understanding of the effect of overparameterization on learning and generalization, and reveals a double descent phenomenon in the presence of label noise, where generalization improves beyond interpolation. In the small regularization limit, we obtain an exact expression for the perfect recovery threshold as a function of the network widths, providing a precise characterization of how overparameterization influences recovery."}
{"id": "2601.10292", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10292", "abs": "https://arxiv.org/abs/2601.10292", "authors": ["Georgia Psychogiou", "Donal P. Lynch", "Spyridon N. Daskalakis", "Manos M. Tentzeris", "George Goussetis", "Stylianos D. Asimonis"], "title": "Single-Feed Circularly Polarized Super Realized Gain Antenna", "comment": null, "summary": "This paper presents a super realized gain, circularly polarized strip-crossed dipole antenna operating at 3.5 GHz. Superdirective behavior is achieved by leveraging strong inter-element mutual coupling through careful adjustment of the strip dimensions. The antenna features a single driven element, with the other element passively loaded with a reactive impedance. The structure is optimized to maximize left-hand circularly polarized (LHCP) realized gain, ensuring high polarization purity and good impedance matching. The optimized design exhibits a 50 $Ω$ impedance bandwidth of 3.29 - 4.17 GHz (23.75%) and an axial-ratio bandwidth of 3.43 - 3.57 GHz (4%). At 3.5 GHz, the antenna achieves a peak realized gain of 6.1 dB ($ka \\approx 1.65$), with an axial ratio of 1.4 dB. These results demonstrate that circular polarization and superdirectivity can be simultaneously realized in a geometrically simple, low-profile ($0.15λ$) antenna, rendering it suitable for integration into compact sub-6~GHz wireless and sensing platforms."}
{"id": "2601.10658", "categories": ["physics.soc-ph", "cs.CY", "econ.GN", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10658", "abs": "https://arxiv.org/abs/2601.10658", "authors": ["Joseph Uguet", "Nicola Tollin", "Jordi Morato"], "title": "Transforming Crises into Opportunities: From Chaos to Urban Antifragility", "comment": "32 pages, 20 figures, 4 tables", "summary": "Urban crises - floods, pandemics, economic shocks, and conflicts - function as accelerators of urban change, exposing structural vulnerabilities while creating windows for reinvention. Building on a prior theoretical contribution that identified fifteen principles of urban antifragility, this paper tests and operationalizes the framework through an empirical assessment of 26 cities selected for their post-crisis adaptation trajectories. Using a tailored diagnostic methodology, we benchmark cities' Stress Response Strategies (SRS) and then evaluate Urban Development Trajectories (UDT) across four weighted dimensions, positioning each case along a fragility-robustness-resilience-antifragility continuum and applying a balanced-threshold rule to confirm antifragile status. Results show that \"resilience enhanced by innovation and technology\" is the most effective response typology (86.9/100), and that six cities meet the antifragile trajectory criteria. By mapping best practices to activated principles and analysing co-activations, the study identifies a robust \"hard core\" of principles - Sustainable Resilience (O), Strategic Diversity (F), Proactive Innovation (I), and Active Prevention (N) - supplemented by operational enablers (e.g., anticipation, mobilization, shock absorption). The paper concludes by proposing an evidence-based, SDG-aligned operational model that links high-impact principle pairings to measurable indicators, offering a practical roadmap for cities seeking to convert crises into sustained transformation. Keywords: Post-crisis strategies, Urban antifragility, Sustainable cities and communities, Disaster resilience and urban regeneration, Risk governance and Black Swan adaptation."}
{"id": "2601.10322", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10322", "abs": "https://arxiv.org/abs/2601.10322", "authors": ["Ulrich Rüde"], "title": "Conjugate Gradient Methods are Not Efficient: Experimental Study of the Locality Limitation", "comment": "24 pages, 20 figures", "summary": "The convergence of the Conjugate Gradient method is subject to a locality limitation which imposes a lower bound on the number of iterations required before a qualitatively accurate approximation can be obtained. This limitation originates from the restricted transport of information in the graph induced by the sparsity pattern of the system matrix. In each iteration, information from the right-hand side can propagate only across directly connected graph nodes. The diameter of this graph therefore determines a minimum number of iterations that is necessary to achieve an acceptable level of accuracy."}
{"id": "2601.10549", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10549", "abs": "https://arxiv.org/abs/2601.10549", "authors": ["Hao Jin", "Wenxing Nie"], "title": "Flat-band Ferromagnetism of SU$(N)$ Hubbard Model on the Kagome Lattices", "comment": "7 pages, 5 figures", "summary": "The kagome lattice, a well known example of the geometrically frustrated system, hosts a dispersionless flat band that offers a unique platform for studying correlation-driven quantum phenomena. At appropriate particle concentrations, the existence of a flat band allows a representation of percolation with nontrivial weights. In this work, we investigate the paramagnetic-ferromagnetic transition in the repulsive SU($N$) Hubbard model on the kagome lattice within this percolation framework. In this representation, the model can be rigorously mapped to a classical $N$-state site-percolation problem on a triangular lattice, with the SU($N$) symmetry reflected in the nontrivial weights. By large-scale Monte Carlo simulations for SU($3$), SU($4$), and SU($10$) symmetries, we demonstrate that the critical particle concentration for ferromagnetism exceeds the standard percolation threshold and increases with $N$, indicating a strengthening of the effective entropic repulsion."}
{"id": "2601.10357", "categories": ["stat.ME", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10357", "abs": "https://arxiv.org/abs/2601.10357", "authors": ["Yue Yu", "Guanghui Wang", "Liu Liu", "Changliang Zou"], "title": "Model-Agnostic and Uncertainty-Aware Dimensionality Reduction in Supervised Learning", "comment": null, "summary": "Dimension reduction is a fundamental tool for analyzing high-dimensional data in supervised learning. Traditional methods for estimating intrinsic order often prioritize model-specific structural assumptions over predictive utility. This paper introduces predictive order determination (POD), a model-agnostic framework that determines the minimal predictively sufficient dimension by directly evaluating out-of-sample predictiveness. POD quantifies uncertainty via error bounds for over- and underestimation and achieves consistency under mild conditions. By unifying dimension reduction with predictive performance, POD applies flexibly across diverse reduction tasks and supervised learners. Simulations and real-data analyses show that POD delivers accurate, uncertainty-aware order estimates, making it a versatile component for prediction-centric pipelines."}
{"id": "2601.09793", "categories": ["cond-mat.dis-nn", "cond-mat.other", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09793", "abs": "https://arxiv.org/abs/2601.09793", "authors": ["Soumadip Pakrashi", "Atanu Rajak", "Sambuddha Sanyal"], "title": "Emergent Nonperturbative Universal Floquet Localization", "comment": "4.5+2+6 pages, 2+5 figures", "summary": "We show that a robust, nonperturbative localization plateau emerges in periodically driven quasiperiodic lattices, independent of the static localization properties and drive protocol. Using exact Floquet dynamics, Floquet perturbation theory, and optimal-order van Vleck analysis, we identify a fine-tuned amplitude-to-frequency ratio where all Floquet states become localized despite dense resonances. The van Vleck expansion achieves superasymptotic accuracy up to an optimal orde; it ultimately breaks down due to resonant hybridization at a weak quasiperiodic potential, revealing that the observed localization is nonperturbative."}
{"id": "2601.09854", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09854", "abs": "https://arxiv.org/abs/2601.09854", "authors": ["Ben Lang"], "title": "Multi-level quantum emitter in an optical waveguide: paradoxes and resolutions", "comment": "15 pages, 4 figures", "summary": "We theoretically investigate the optical dipole interaction between a multi-level quantum system and a single-mode optical waveguide of any local polarisation. We investigate several paradoxical seeming situations, for example we find a situation in which there exist two non-orthogonal quantum states, each of which results in a photon flux in the opposite direction to the other. We show how, despite appearances, this does not break the unitary requirements of quantum mechanics. We also find that an isotropic quantum emitter can be either reflective or transmissive to light depending on the waveguide polarisation at the emitter location, indeed in the zero loss limit such a system changes from 100% transmission to 100% reflection due to an infinitesimal polarisation rotation. An example case for a four level system is also considered, which is found to operate as a non-destructive parity measurement of the photon number."}
{"id": "2601.06540", "categories": ["eess.SY", "cs.AI", "cs.LG", "cs.RO", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.06540", "abs": "https://arxiv.org/abs/2601.06540", "authors": ["Roya Khalili Amirabadi", "Mohsen Jalaeian Farimani", "Omid Solaymani Fard"], "title": "Self-Organizing Dual-Buffer Adaptive Clustering Experience Replay (SODASER) for Safe Reinforcement Learning in Optimal Control", "comment": "Also available at SSRN: https://ssrn.com/abstract=5191427 or http://dx.doi.org/10.2139/ssrn.5191427", "summary": "This paper proposes a novel reinforcement learning framework, named Self-Organizing Dual-buffer Adaptive Clustering Experience Replay (SODACER), designed to achieve safe and scalable optimal control of nonlinear systems. The proposed SODACER mechanism consisting of a Fast-Buffer for rapid adaptation to recent experiences and a Slow-Buffer equipped with a self-organizing adaptive clustering mechanism to maintain diverse and non-redundant historical experiences. The adaptive clustering mechanism dynamically prunes redundant samples, optimizing memory efficiency while retaining critical environmental patterns. The approach integrates SODASER with Control Barrier Functions (CBFs) to guarantee safety by enforcing state and input constraints throughout the learning process. To enhance convergence and stability, the framework is combined with the Sophia optimizer, enabling adaptive second-order gradient updates. The proposed SODACER-Sophia's architecture ensures reliable, effective, and robust learning in dynamic, safety-critical environments, offering a generalizable solution for applications in robotics, healthcare, and large-scale system optimization. The proposed approach is validated on a nonlinear Human Papillomavirus (HPV) transmission model with multiple control inputs and safety constraints. Comparative evaluations against random and clustering-based experience replay methods demonstrate that SODACER achieves faster convergence, improved sample efficiency, and a superior bias-variance trade-off, while maintaining safe system trajectories, validated via the Friedman test."}
{"id": "2601.10671", "categories": ["eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10671", "abs": "https://arxiv.org/abs/2601.10671", "authors": ["Trager Joswig-Jones", "Baosen Zhang"], "title": "Safe Trajectory Gradient Flow Control of a Grid-Interfacing Inverter", "comment": "5 pages, 4 figures, Submitted to PES-GM 2026", "summary": "Grid-interfacing inverters serve as the interface between renewable energy resources and the electric power grid, offering fast, programmable control capabilities. However, their operation is constrained by hardware limitations, such as bounds on the current magnitude. Existing control methods for these systems often neglect these constraints during controller design and instead rely on ad hoc limiters, which can introduce instability or degrade performance. In this work, we present a control framework that directly incorporates constraints into the control of a voltage-source inverter. We propose a safe trajectory gradient flow controller, which applies the safe gradient flow method to a rolling horizon trajectory optimization problem to ensure that the states remain within a safe set defined by the constraints while directing the trajectory towards an optimal equilibrium point of a nonlinear program. Simulation results demonstrate that our approach can drive the outputs of a simulated inverter system to optimal values and maintain state constraints, even when using a limited number of optimization steps per control cycle."}
{"id": "2601.10389", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10389", "abs": "https://arxiv.org/abs/2601.10389", "authors": ["Stefan Kindermann"], "title": "Regularization of linear inverse problems by rational Krylov methods", "comment": null, "summary": "For approximately solving linear ill-posed problems in Hilbert spaces, we investigate the regularization properties of the aggregation method and the RatCG method. These recent algorithms use previously calculated solutions of Tikhonov regularization (respectively, Landweber iterations) to set up a new search space on which the least-squares functional is minimized. We outline how these methods can be understood as rational Krylov space methods, i.e., based on the space of rational functions of the forward operator. The main result is that these methods form an optimal-order regularization schemes when combined with the discrepancy principle as stopping rule and when the underlying regularization parameters are sufficiently large."}
{"id": "2601.10619", "categories": ["cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10619", "abs": "https://arxiv.org/abs/2601.10619", "authors": ["Karol I. Wysokiński", "Marcin M. Wysokiński"], "title": "Beyond Hubbard: the role of correlated hopping interaction in superconductors and quantum dot devices", "comment": "14 pages, 11 single figures, requires class file appolb (attached)", "summary": "We investigate the role of strong Coulomb interactions beyond the standard Hubbard model in two distinct physical contexts. First, we analyze the superconducting phase transition occurring near the Mott metal-insulator transition. Second, we study transport properties of artificial nano-scale structures containing quantum dots coupled to external electrodes. In both cases, we focus on the impact of the correlated (assisted) hopping (CH) interaction. For superconductors, CH acts as a driving mechanism for the phase transition and modifies the spectral properties of the system. We present the evolution of the spectral function as the system approaches the Mott-type transition under varying model parameters. In quantum-dot-based devices, CH influences the tunneling amplitude between the dot and metallic leads. We demonstrate that the characteristic changes in the conductance of a normal metal-quantum dot-normal metal structure provide a clear signature of the presence and sign of CH interaction."}
{"id": "2601.10533", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10533", "abs": "https://arxiv.org/abs/2601.10533", "authors": ["Yingying Ma", "Chenlei Leng"], "title": "A Propagation Framework for Network Regression", "comment": null, "summary": "We introduce a unified and computationally efficient framework for regression on network data, addressing limitations of existing models that require specialized estimation procedures or impose restrictive decay assumptions. Our Network Propagation Regression (NPR) models outcomes as functions of covariates propagated through network connections, capturing both direct and indirect effects. NPR is estimable via ordinary least squares for continuous outcomes and standard routines for binary, categorical, and time-to-event data, all within a single interpretable framework. We establish consistency and asymptotic normality under weak conditions and develop valid hypothesis tests for the order of network influence. Simulation studies demonstrate that NPR consistently outperforms established approaches, such as the linear-in-means model and regression with network cohesion, especially under model misspecification. An application to social media sentiment analysis highlights the practical utility and robustness of NPR in real-world settings."}
{"id": "2601.10465", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.10465", "abs": "https://arxiv.org/abs/2601.10465", "authors": ["Johannes N. Kriel", "Emma C. King", "Michael Kastner"], "title": "Nonlinear quantum Kibble-Zurek ramps in open systems at finite temperature", "comment": "21 pages, 5+1 figures", "summary": "We analyze quantum systems under a broad class of protocols in which the temperature and a Hamiltonian control parameter are ramped simultaneously and, in general, in a nonlinear fashion toward a quantum critical point. Using an open-system version of a Kitaev quantum wire as an example, we show that, unlike finite-temperature protocols at fixed temperature, these protocols allow us to probe, in an out-of-equilibrium situation and at finite temperature, the universality class (characterized by the critical exponents $ν$ and $z$) of an equilibrium quantum phase transition at zero temperature. Key to this is the identification of ramps in which both coherent and incoherent parts of the open-system dynamics affect the excitation density in a non-negligible way. We also identify the specific ramps for which subleading corrections to the asymptotic scaling laws are suppressed, which serves as a guide to dynamically probing quantum critical exponents in experimentally realistic finite-temperature situations."}
{"id": "2601.09911", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09911", "abs": "https://arxiv.org/abs/2601.09911", "authors": ["Younghun Kim", "Spiro Gicev", "Martin Sevior", "Muhammad Usman"], "title": "Time-Dynamic Circuits for Fault-Tolerant Shift Automorphisms in Quantum LDPC Codes", "comment": "16 pages, 8 figures", "summary": "Quantum low-density parity-check (qLDPC) codes have emerged as a promising approach for realizing low-overhead logical quantum memories. Recent theoretical developments have established shift automorphisms as a fundamental building block for completing the universal set of logical gates for qLDPC codes. However, practical challenges remain because the existing SWAP-based shift automorphism yields logical error rates that are orders of magnitude higher than those for fault-tolerant idle operations. In this work, we address this issue by dynamically varying the syndrome measurement circuits to implement the shift automorphisms without reducing the circuit distance. We benchmark our approach on both twisted and untwisted weight-6 generalized toric codes, including the gross code family. Our time-dynamic circuits for shift automorphisms achieve performance comparable to the idle operations under the circuit-level noise model (SI1000). Specifically, the dynamic circuits achieve more than an order of magnitude reduction in logical error rates relative to the SWAP-based scheme for the gross code at a physical error rate of $10^{-3}$, employing the BP-OSD decoder. Our findings improve both the error resilience and the time overhead of the shift automorphisms in qLDPC codes. Furthermore, our work can lead to alternative syndrome extraction circuit designs, such as leakage removal protocols, providing a practical pathway to utilizing dynamic circuits that extend beyond surface codes towards qLDPC codes."}
{"id": "2601.10222", "categories": ["math.NA", "cs.AI", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10222", "abs": "https://arxiv.org/abs/2601.10222", "authors": ["Alena Kopaničáková", "Elisa Riccietti"], "title": "Introduction to optimization methods for training SciML models", "comment": null, "summary": "Optimization is central to both modern machine learning (ML) and scientific machine learning (SciML), yet the structure of the underlying optimization problems differs substantially across these domains. Classical ML typically relies on stochastic, sample-separable objectives that favor first-order and adaptive gradient methods. In contrast, SciML often involves physics-informed or operator-constrained formulations in which differential operators induce global coupling, stiffness, and strong anisotropy in the loss landscape. As a result, optimization behavior in SciML is governed by the spectral properties of the underlying physical models rather than by data statistics, frequently limiting the effectiveness of standard stochastic methods and motivating deterministic or curvature-aware approaches. This document provides a unified introduction to optimization methods in ML and SciML, emphasizing how problem structure shapes algorithmic choices. We review first- and second-order optimization techniques in both deterministic and stochastic settings, discuss their adaptation to physics-constrained and data-driven SciML models, and illustrate practical strategies through tutorial examples, while highlighting open research directions at the interface of scientific computing and scientific machine learning."}
{"id": "2601.10399", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10399", "abs": "https://arxiv.org/abs/2601.10399", "authors": ["Michał Wichrowski", "Ajay Ajith"], "title": "A Geometric Multigrid Preconditioner for Shifted Boundary Method", "comment": "arXiv admin note: substantial text overlap with arXiv:2506.12899", "summary": "The Shifted Boundary Method (SBM) trades some part of the burden of body-fitted meshing for increased algebraic complexity. While the resulting linear systems retain the standard $\\mathcal{O}(h^{-2})$ conditioning of second-order operators, the non-symmetry and non-local boundary coupling render them resistant to standard Algebraic Multigrid (AMG) and simple smoothers for high-order discretisations. We present a geometric multigrid preconditioner that effectively tames these systems. At its core lies the \\emph{Full-Residual Shy Patch} smoother: a subspace correction strategy that filters out some patches while capturing the full physics of the shifted boundary. Unlike previous cell-wise approaches that falter at high polynomial degrees, our method delivers convergence with low mesh dependence. We demonstrate performance for Continuous Galerkin approximations, maintaining low and stable iteration counts up to polynomial degree $p=3$ in 3D, proving that SBM can be both geometrically flexible and algebraically efficient."}
{"id": "2601.10717", "categories": ["cond-mat.str-el", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10717", "abs": "https://arxiv.org/abs/2601.10717", "authors": ["Bo Peng", "Yuzhu Wang", "Bo Yang"], "title": "Emergence and transition of incompressible phases in decorated Landau levels", "comment": "comments very welcome", "summary": "We show a single Landau level (LL) dressed with periodic electrostatic potentials can realize a plethora of interacting topological phases where the Hall conductivity generally does not equal to the LL filling factor. Their physics can be captured by a minimal model of a delta potential lattice within a single LL, realizing exact zero energy Chern bands (denoted as decorated Landau levels or dLL) gapped from dispersive bands with rich geometric properties. With $p/q$ magnetic fluxes per unit cell, there are $q$ dispersive bands and $p-q$ zero energy bands forming the dLL. When the one-body potential strength dominates the electron-electron interaction, band mixing is suppressed and the dispersion bands consist of ``localized states\" with vanishing total Chern number. Nevertheless these dispersive bands can have highly nontrivial Berry curvature distribution, and even non-zero Chern numbers when $q>1$. Interestingly even in the limit of large short range interaction, band mixing between dLL and dispersion bands can be strongly suppressed at low filling factor, leading to robust topological phases within the dLL stabilized by the one-body potential. The dLL and the associated dispersive bands can serve as minimal theoretical models for correlated physics in lattice or moire systems; they are also highly tunable experimental platforms for realizing rich phase diagrams of exotic 2D quantum fluids."}
{"id": "2601.10590", "categories": ["stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10590", "abs": "https://arxiv.org/abs/2601.10590", "authors": ["Zhangyi He", "Feng Yu", "Suzie Cro", "Laurent Billot"], "title": "From aggressive to conservative early stopping in Bayesian group sequential designs", "comment": null, "summary": "Group sequential designs (GSDs) are widely used in confirmatory trials to allow interim monitoring while preserving control of the type I error rate. In the frequentist framework, O'Brien-Fleming-type stopping boundaries dominate practice because they impose highly conservative early stopping while allowing more liberal decisions as information accumulates. Bayesian GSDs, in contrast, are most often implemented using fixed posterior probability thresholds applied uniformly at all analyses. While such designs can be calibrated to control the overall type I error rate, they do not penalise early analyses and can therefore lead to substantially more aggressive early stopping. Such behaviour can risk premature conclusions and inflation of treatment effect estimates, raising concerns for confirmatory trials. We introduce two practically implementable refinements that restore conservative early stopping in Bayesian GSDs. The first introduces a two-phase structure for posterior probability thresholds, applying more stringent criteria in the early phase of the trial and relaxing them later to preserve power. The second replaces posterior probability monitoring at interim looks with predictive probability criteria, which naturally account for uncertainty in future data and therefore suppress premature stopping. Both strategies require only one additional tuning parameter and can be efficiently calibrated. In the HYPRESS setting, both approaches achieve higher power than the conventional Bayesian design while producing alpha-spending profiles closely aligned with O'Brien-Fleming-type behaviour at early looks. These refinements provide a principled and tractable way to align Bayesian GSDs with accepted frequentist practice and regulatory expectations, supporting their robust application in confirmatory trials."}
{"id": "2601.09921", "categories": ["quant-ph", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09921", "abs": "https://arxiv.org/abs/2601.09921", "authors": ["Kai Zhang", "Zhengzhong Yi", "Shaojun Guo", "Linghang Kong", "Situ Wang", "Xiaoyu Zhan", "Tan He", "Weiping Lin", "Tao Jiang", "Dongxin Gao", "Yiming Zhang", "Fangming Liu", "Fang Zhang", "Zhengfeng Ji", "Fusheng Chen", "Jianxin Chen"], "title": "Learning to Decode in Parallel: Self-Coordinating Neural Network for Real-Time Quantum Error Correction", "comment": "The main text consists of 25 pages and 9 figures, extending our prior work (arXiv:2509.03815) with new results on surface code decoding in superconducting qubit systems and real-time performance benchmarks on TPU v6e", "summary": "Fast, reliable decoders are pivotal components for enabling fault-tolerant quantum computation (FTQC). Neural network decoders like AlphaQubit have demonstrated potential, achieving higher accuracy than traditional human-designed decoding algorithms. However, existing implementations of neural network decoders lack the parallelism required to decode the syndrome stream generated by a superconducting logical qubit in real time. Moreover, integrating AlphaQubit with sliding window-based parallel decoding schemes presents non-trivial challenges: AlphaQubit is trained solely to output a single bit corresponding to the global logical correction for an entire memory experiment, rather than local physical corrections that can be easily integrated. We address this issue by training a recurrent, transformer-based neural network specifically tailored for parallel window decoding. While it still outputs a single bit, we derive training labels from a consistent set of local corrections and train on various types of decoding windows simultaneously. This approach enables the network to self-coordinate across neighboring windows, facilitating high-accuracy parallel decoding of arbitrarily long memory experiments.\n  As a result, we overcome the throughput bottleneck that previously precluded the use of AlphaQubit-type decoders in FTQC. Our work presents the first scalable, neural-network-based parallel decoding framework that simultaneously achieves SOTA accuracy and the stringent throughput required for real-time quantum error correction. Using an end-to-end experimental workflow, we benchmark our decoder on the Zuchongzhi 3.2 superconducting quantum processor on surface codes with distances up to 7, demonstrating its superior accuracy. Moreover, we demonstrate that, using our approach, a single TPU v6e is capable of decoding surface codes with distances up to 25 within 1us per decoding round."}
{"id": "2601.10375", "categories": ["q-fin.RM", "math.OC", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10375", "abs": "https://arxiv.org/abs/2601.10375", "authors": ["Beatrice Acciaio", "Brandon Garcia Flores", "Antonio Marini", "Gudmund Pammer"], "title": "Dynamic reinsurance via martingale transport", "comment": "16 pages, 12 figures", "summary": "We formulate a dynamic reinsurance problem in which the insurer seeks to control the terminal distribution of its surplus while minimizing the L2-norm of the ceded risk. Using techniques from martingale optimal transport, we show that, under suitable assumptions, the problem admits a tractable solution analogous to the Bass martingale. We first consider the case where the insurer wants to match a given terminal distribution of the surplus process, and then relax this condition by only requiring certain moment or risk-based constraints."}
{"id": "2601.10474", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10474", "abs": "https://arxiv.org/abs/2601.10474", "authors": ["Adérito Araújo", "Milene Santos"], "title": "Optimal error estimates for a discontinuous Galerkin method on curved boundaries with polygonal meshes", "comment": "42 pages, 6 figures", "summary": "We consider a discontinuous Galerkin method for the numerical solution of boundary value problems in two-dimensional domains with curved boundaries. A key challenge in this setting is the potential loss of convergence order due to approximating the physical domain by a polygonal mesh. Unless boundary conditions can be accurately transferred from the true boundary to the computational one, such geometric approximation errors generally lead to suboptimal convergence. To overcome this limitation, a higher-order strategy based on polynomial reconstruction of boundary data was introduced for classical finite element methods in [28, 29] and in the finite volume context in [7, 11]. More recently, this approach was extended to discontinuous Galerkin methods in [32], leading to the DG-ROD method, which restores optimal convergence rates on polygonal approximations of domains with curved boundaries. In this work, we provide a rigorous theoretical analysis of the DG-ROD method, establishing existence and uniqueness of the discrete solution and deriving error estimates for a two-dimensional linear advection-diffusion-reaction problem with homogeneous Dirichlet boundary conditions on both convex and non-convex domains. Following and extending techniques from classical finite element methods [29], we prove that, under suitable regularity assumptions on the exact solution, the DG-ROD method achieves optimal convergence despite polygonal approximations. Finally, we illustrate and confirm the theoretical results with a numerical benchmark."}
{"id": "2601.09759", "categories": ["physics.hist-ph", "cond-mat.mes-hall", "cond-mat.mtrl-sci", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.09759", "abs": "https://arxiv.org/abs/2601.09759", "authors": ["Je-Geun Park"], "title": "Viewpoint: On the Emergence of van der Waals Magnets: A Personal Reflection", "comment": "J. Phys. Condens. Matter (in press)", "summary": "The observation of magnetism in atomically thin van der Waals (vdW) antiferromagnets (FePS$_3$, NiPS$_3$, and MnPS$_3$) in 2016 marked an important moment in the development of two-dimensional (2D) physics. In this personal reflection, I describe how a simple question, posed in the early 2010s, motivated experimental efforts that culminated in the demonstration of antiferromagnetic order in monolayer FePS$_3$. Alongside subsequent reports of vdW ferromagnets in 2017, these developments helped establish intrinsic magnetism as a viable degree of freedom in atomically thin materials. I close with personal lessons drawn from this period and a perspective on the opportunities that now shape the field's second decade and beyond."}
{"id": "2601.10615", "categories": ["stat.ME", "stat.AP"], "pdf": "https://arxiv.org/pdf/2601.10615", "abs": "https://arxiv.org/abs/2601.10615", "authors": ["Paramahansa Pramanik", "Arnab Kumar Maity", "Anjan Mandal", "Haley Kate Robinson"], "title": "A Bayesian Discrete Framework for Enhancing Decision-Making Processes in Clinical Trial Designs and Evaluations", "comment": "44 pages, 5 figures, 4 tables", "summary": "This study examines the application of Bayesian approach in the context of clinical trials, emphasizing their increasing importance in contemporary biomedical research. While conventional frequentist approach provides a foundational basis for analysis, it often lacks the flexibility to integrate prior knowledge, which can constrain its effectiveness in adaptive settings. In contrast, Bayesian methods enable continual refinement of statistical inferences through the assimilation of accumulating evidence, thereby supporting more informed decision-making and improving the reliability of trial findings. This paper also considers persistent challenges in clinical investigations, including replication difficulties and the misinterpretation of statistical results, suggesting that Bayesian strategies may offer a path toward enhanced analytical robustness. Moreover, discrete probability models, specifically the Binomial, Poisson, and Negative Binomial distributions are explored for their suitability in modeling clinical endpoints, particularly in trials involving binary responses or data with overdispersion. The discussion further incorporates Bayesian networks and Bayesian estimation techniques, with a comparative evaluation against maximum likelihood estimation to elucidate differences in inferential behavior and practical implementation."}
{"id": "2601.09938", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09938", "abs": "https://arxiv.org/abs/2601.09938", "authors": ["Akitada Sakurai", "Aoi Hayashi", "Tadayoshi Matumori", "Daisuke Kaji", "Tadashi Kadowaki", "Kae Nemoto"], "title": "Beyond Optimization: Harnessing Quantum Annealer Dynamics for Machine Learning", "comment": "6pages, 3 figures", "summary": "Quantum annealing is typically regarded as a tool for combinatorial optimization, but its coherent dynamics also offer potential for machine learning. We present a model that encodes classical data into an Ising Hamiltonian, evolves it on a quantum annealer, and uses the resulting probability distributions as feature maps for classification. Experiments on the quantum annealer machine with the Digits dataset, together with simulations on MNIST, demonstrate that short annealing times yield higher classification accuracy, while longer times reduce accuracy but lower sampling costs. We introduce the participation ratio as a measure of the effective model size and show its strong correlation with generalization."}
{"id": "2601.10558", "categories": ["quant-ph", "cs.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10558", "abs": "https://arxiv.org/abs/2601.10558", "authors": ["Yu-Hong Lai", "Hao-Chung Cheng"], "title": "A Mirror-Descent Algorithm for Computing the Petz-Rényi Capacity of Classical-Quantum Channels", "comment": "This paper is independent and concurrent to arXiv:2601.06492", "summary": "We study the computation of the $α$-Rényi capacity of a classical-quantum (c-q) channel for $α\\in(0,1)$. We propose an exponentiated-gradient (mirror descent) iteration that generalizes the Blahut-Arimoto algorithm. Our analysis establishes relative smoothness with respect to the entropy geometry, guaranteeing a global sublinear convergence of the objective values. Furthermore, under a natural tangent-space nondegeneracy condition (and a mild spectral lower bound in one regime), we prove local linear (geometric) convergence in Kullback-Leibler divergence on a truncated probability simplex, with an explicit contraction factor once the local curvature constants are bounded."}
{"id": "2601.10557", "categories": ["math.NA", "cs.CE", "cs.DC", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.10557", "abs": "https://arxiv.org/abs/2601.10557", "authors": ["Edoardo Di Napoli", "Clément Richefort", "Xinzhe Wu"], "title": "Chebyshev Accelerated Subspsace Eigensolver for Pseudo-hermitian Hamiltonians", "comment": "To be submitted to SISC", "summary": "Studying the optoelectronic structure of materials can require the computation of up to several thousands of the smallest eigenpairs of a pseudo-hermitian Hamiltonian. Iterative eigensolvers may be preferred over direct methods for this task since their complexity is a function of the desired fraction of the spectrum. In addition, they generally rely on highly optimized and scalable kernels such as matrix-vector multiplications that leverage the massive parallelism and the computational power of modern exascale systems. \\textit{Chebyshev Accelerated Subspace iteration Eigensolver} (ChASE) is able to compute several thousands of the most extreme eigenpairs of dense hermitian matrices with proven scalability over massive parallel accelerated clusters. This work presents an extension of ChASE to solve for a portion of the spectrum of pseudo-hermitian Hamiltonians as they appear in the treatment of excitonic materials. The new pseudo-hermitian solver achieves similar convergence and performance as the hermitian one. By exploiting the numerical structure and spectral properties of the Hamiltonian matrix, we propose an oblique variant of Rayleigh-Ritz projection featuring quadratic convergence of the Ritz-values with no explicit construction of the dual basis set. Additionally, we introduce a parallel implementation of the recursive matrix-product operation appearing in the Chebyshev filter with limited amount of global communications. Our development is supported by a full numerical analysis and experimental tests."}
{"id": "2601.09850", "categories": ["quant-ph", "cond-mat.str-el", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.09850", "abs": "https://arxiv.org/abs/2601.09850", "authors": ["Meng-Yuan Li", "Yue Wu"], "title": "Fragmented Topological Excitations in Generalized Hypergraph Product Codes", "comment": "12 pages, 10 figures", "summary": "Product code construction is a powerful tool for constructing quantum stabilizer codes, which serve as a promising paradigm for realizing fault-tolerant quantum computation. Furthermore, the natural mapping between stabilizer codes and the ground states of exactly solvable spin models also motivates the exploration of many-body orders in the stabilizer codes. In this work, we investigate the fracton topological orders in a family of codes obtained by a recently proposed general construction. More specifically, this code family can be regarded as a class of generalized hypergraph product (HGP) codes. We term the corresponding exactly solvable spin models \\textit{orthoplex models}, based on the geometry of the stabilizers. In the 3D orthoplex model, we identify a series of intriguing properties within this model family, including non-monotonic ground state degeneracy (GSD) as a function of system size and non-Abelian lattice defects. Most remarkably, in 4D we discover \\textit{fragmented topological excitations}: while such excitations manifest as discrete, isolated points in real space, their projections onto lower-dimensional subsystems form connected objects such as loops, revealing the intrinsic topological nature of these excitations. Therefore, fragmented excitations constitute an intriguing intermediate class between point-like and spatially extended topological excitations. In addition, these rich features establish the generalized HGP codes as a versatile and analytically tractable platform for studying the physics of fracton orders."}
{"id": "2601.10623", "categories": ["stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10623", "abs": "https://arxiv.org/abs/2601.10623", "authors": ["Yongzhen Feng", "Weiwei Wang", "Raymond K. W. Wong", "Xianyang Zhang"], "title": "Fair Regression under Demographic Parity: A Unified Framework", "comment": "48 pages, 4 figures", "summary": "We propose a unified framework for fair regression tasks formulated as risk minimization problems subject to a demographic parity constraint. Unlike many existing approaches that are limited to specific loss functions or rely on challenging non-convex optimization, our framework is applicable to a broad spectrum of regression tasks. Examples include linear regression with squared loss, binary classification with cross-entropy loss, quantile regression with pinball loss, and robust regression with Huber loss. We derive a novel characterization of the fair risk minimizer, which yields a computationally efficient estimation procedure for general loss functions. Theoretically, we establish the asymptotic consistency of the proposed estimator and derive its convergence rates under mild assumptions. We illustrate the method's versatility through detailed discussions of several common loss functions. Numerical results demonstrate that our approach effectively minimizes risk while satisfying fairness constraints across various regression settings."}
{"id": "2601.09943", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09943", "abs": "https://arxiv.org/abs/2601.09943", "authors": ["Darrell Teegarden", "Allison Casey", "F. Gino Serpa", "Patrick Becker", "Asmita Brahme", "Saanvi Kataria", "Paul Lopata"], "title": "Three Months in the Life of Cloud Quantum Computing", "comment": null, "summary": "Quantum Computing (QC) has evolved from a few custom quantum computers, which were only accessible to their creators, to an array of commercial quantum computers that can be accessed on the cloud by anyone. Accessing these cloud quantum computers requires a complex chain of tools that facilitate connecting, programming, simulating algorithms, estimating resources, submitting quantum computing jobs, retrieving results, and more. Some steps in the chain are hardware dependent and subject to change as both hardware and software tools, such as available gate sets and optimizing compilers, evolve. Understanding the trade-offs inherent in this process is essential for evaluating the power and utility of quantum computers. ARLIS has been systematically investigating these environments to understand these complexities. The work presented here is a detailed summary of three months of using such quantum programming environments. We show metadata obtained from these environments, including the connection metrics to the different services, the execution of algorithms, the testing of the effects of varying the number of qubits, comparisons to simulations, execution times, and cost. Our objective is to provide concrete data and insights for those who are exploring the potential of quantum computing. It is not our objective to present any new algorithms or optimize performance on any particular machine or cloud platform; rather, this work is focused on providing a consistent view of a single algorithm executed using out-of-the-box settings and tools across machines, cloud platforms, and time. We present insights only available from these carefully curated data."}
{"id": "2601.10667", "categories": ["math.NA"], "pdf": "https://arxiv.org/pdf/2601.10667", "abs": "https://arxiv.org/abs/2601.10667", "authors": ["Tobin A. Driscoll", "Yuxing Zhou"], "title": "Stable evaluation of derivatives for barycentric and continued fraction representations of rational functions", "comment": "9 pages, 1 figure, 6 tables. Preprint version; software implementation available in https://github.com/complexvariables/RationalFunctionApproximation.jl", "summary": "Fast algorithms for approximation by rational functions exist for both barycentric and Thiele continued fraction (TCF) representations. We present the first numerically stable methods for derivative evaluation in the barycentric representation, including an $O(n)$ algorithm for all derivatives. We also extend an earlier $O(n)$ algorithm for evaluation of the TCF first derivative to higher orders. Numerical experiments confirm the robustness and efficiency of the proposed methods."}
{"id": "2601.10210", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10210", "abs": "https://arxiv.org/abs/2601.10210", "authors": ["J. Leibig", "M. Hörmann", "A. Langheld", "A. Schellenberger", "K. P. Schmidt"], "title": "Quantitative approach for the Dicke-Ising chain with an effective self-consistent matter Hamiltonian", "comment": "23 pages, 8 figures", "summary": "In the thermodynamic limit, the Dicke-Ising chain maps exactly onto an effective self-consistent matter Hamiltonian with the photon field acting solely as a self-consistent effective field. As a consequence, no quantum correlations between photons and spins are needed to understand the quantum phase diagram. This enables us to determine the quantum phase diagram in the thermodynamic limit using numerical linked-cluster expansions combined with density matrix renormalization group calculations (NLCE+DMRG) to solve the resulting self-consistent matter Hamiltonian. This includes magnetically ordered phases with significantly improved accuracy compared to previous estimates. For ferromagnetic Ising couplings, we refine the location of the multicritical point governing the change in the order of the superradiant phase transition, reaching a relative accuracy of $10^{-4}$. For antiferromagnetic Ising couplings, we confirm the existence of the narrow antiferromagnetic superradiant phase in the thermodynamic limit. The effective matter Hamiltonian framework identifies the antiferromagnetic superradiant phase as the many-body ground state of an antiferromagnetic transverse-field Ising model with longitudinal field. This phase emerges through continuous Dicke-type polariton condensation from the antiferromagnetic normal phase, followed by a first-order transition to the paramagnetic superradiant phase. Thus, NLCE+DMRG provides a precise determination of the Dicke-Ising phase diagram in one dimension by solving the self-consistent effective matter Hamiltonian."}
{"id": "2601.10641", "categories": ["stat.ME", "cs.LG", "math.ST"], "pdf": "https://arxiv.org/pdf/2601.10641", "abs": "https://arxiv.org/abs/2601.10641", "authors": ["William L. Lippitt", "Edward J. Bedrick", "Nichole E. Carlson"], "title": "Adjusted Similarity Measures and a Violation of Expectations", "comment": "12 pages, 1 figure", "summary": "Adjusted similarity measures, such as Cohen's kappa for inter-rater reliability and the adjusted Rand index used to compare clustering algorithms, are a vital tool for comparing discrete labellings. These measures are intended to have the property of 0 expectation under a null distribution and maximum value 1 under maximal similarity to aid in interpretation. Measures are frequently adjusted with respect to the permutation distribution for historic and analytic reasons. There is currently renewed interest in considering other null models more appropriate for context, such as clustering ensembles permitting a random number of identified clusters. The purpose of this work is two -- fold: (1) to generalize the study of the adjustment operator to general null models and to a more general procedure which includes statistical standardization as a special case and (2) to identify sufficient conditions for the adjustment operator to produce the intended properties, where sufficient conditions are related to whether and how observed data are incorporated into null distributions. We demonstrate how violations of the sufficient conditions may lead to substantial breakdown, such as by producing a non-positive measure under traditional adjustment rather than one with mean 0, or by producing a measure which is deterministically 0 under statistical standardization."}
{"id": "2601.09951", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09951", "abs": "https://arxiv.org/abs/2601.09951", "authors": ["Rylan Malarchick", "Ashton Steed"], "title": "Parallelizing the Variational Quantum Eigensolver: From JIT Compilation to Multi-GPU Scaling", "comment": null, "summary": "The Variational Quantum Eigensolver (VQE) is a hybrid quantum-classical algorithm for computing ground state energies of molecular systems. We implement VQE to calculate the potential energy surface of the hydrogen molecule (H$_2$) across 100 bond lengths using the PennyLane quantum computing framework on an HPC cluster featuring 4$\\times$ NVIDIA H100 GPUs (80GB each). We present a comprehensive parallelization study with four phases: (1) Optimizer + JIT compilation achieving 4.13$\\times$ speedup, (2) GPU device acceleration achieving 3.60$\\times$ speedup at 4 qubits scaling to 80.5$\\times$ at 26 qubits, (3) MPI parallelization achieving 28.5$\\times$ speedup, and (4) Multi-GPU scaling achieving 3.98$\\times$ speedup with 99.4% parallel efficiency across 4 H100 GPUs. The combined effect yields 117$\\times$ total speedup for the H$_2$ potential energy surface (593.95s $\\rightarrow$ 5.04s). We conduct a CPU vs GPU scaling study from 4--26 qubits, finding GPU advantage at all scales with speedups ranging from 10.5$\\times$ to 80.5$\\times$. Multi-GPU benchmarks demonstrate near-perfect scaling with 99.4% efficiency and establish that a single H100 can simulate up to 29 qubits before hitting memory limits. The optimized implementation reduces runtime from nearly 10 minutes to 5 seconds, enabling interactive quantum chemistry exploration."}
{"id": "2601.09939", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.09939", "abs": "https://arxiv.org/abs/2601.09939", "authors": ["Jinjin He", "Taiyuan Zhang", "Zhiqi Li", "Junwei Zhou", "Duowen Chen", "Bo Zhu"], "title": "A Level Set Method on Particle Flow Maps", "comment": null, "summary": "This paper introduces a Particle Flow Map Level Set (PFM-LS) method for high-fidelity interface tracking. We store level-set values, gradients, and Hessians on particles concentrated in a narrow band around the interface, advecting them via bidirectional flow maps while using a conventional grid-based representation elsewhere. By interpreting the level set value as a 3-form and its gradient as a 1-form, PFM-LS achieves exceptional geometric fidelity during complex deformations and preserves sub-grid features that traditional methods cannot capture. Our dual-timescale approach utilizes long-range maps for values and gradients, with frequent reinitialization of short-range maps for the distortion-sensitive Hessian, alongside adaptive particle control that maintains sufficient density within the narrow band. We also develop a hybrid particle-grid quasi-Newton redistancing scheme that preserves fine-scale features while enforcing the signed-distance property. Benchmark comparisons in 2D and 3D demonstrate that PFM-LS achieves state-of-the-art volume preservation and shape fidelity against a broad range of existing level-set methods."}
{"id": "2601.10100", "categories": ["math.ST", "stat.ME"], "pdf": "https://arxiv.org/pdf/2601.10100", "abs": "https://arxiv.org/abs/2601.10100", "authors": ["Guo Liu"], "title": "Admissibility Breakdown in High-Dimensional Sparse Regression with L1 Regularization", "comment": "19 pages", "summary": "The choice of the tuning parameter in the Lasso is central to its statistical performance in high-dimensional linear regression. Classical consistency theory identifies the rate of the Lasso tuning parameter, and numerous studies have established non-asymptotic guarantees. Nevertheless, the question of optimal tuning within a non-asymptotic framework has not yet been fully resolved. We establish tuning criteria above which the Lasso becomes inadmissible under mean squared prediction error. More specifically, we establish thresholds showing that certain classical tuning choices yield Lasso estimators strictly dominated by a simple Lasso-Ridge refinement. We also address how the structure of the design matrix and the noise vector influences the inadmissibility phenomenon."}
{"id": "2601.09977", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.09977", "abs": "https://arxiv.org/abs/2601.09977", "authors": ["Rikizo Ikuta"], "title": "Statistical-noise-enhanced multi-photon interference", "comment": "11 pages, 6 figures", "summary": "Photon statistics plays a governing role in multi-photon interference. While interference visibility in the standard two-photon case, known as Hong-Ou-Mandel interference, monotonically degrades with higher intensity correlation functions, we show that this monotonicity does not hold for three-photon interference in symmetric circuits. We reveal that, in the discrete Fourier transform circuit, engineered super-Poissonian photon-number fluctuations, realized using a modulated laser, maximize the visibility, surpassing the magnitude of the single-photon signature. In addition, by tuning the symmetric circuit parameters, we demonstrate that the visibility hierarchy inverts relative to the benchmark of Poissonian statistics. This trade-off implies that quantum and classical advantages are mutually exclusive resources for interference, indicating a form of statistical complementarity."}
{"id": "2601.10134", "categories": ["physics.comp-ph", "math.NA"], "pdf": "https://arxiv.org/pdf/2601.10134", "abs": "https://arxiv.org/abs/2601.10134", "authors": ["Ming Liu", "Yosuke Hasegawa"], "title": "A volume penalization method for solving conjugate scalar transport with interfacial jump conditions", "comment": null, "summary": "Conjugate scalar transport with interfacial jump conditions on complex interfacial geometries is common in thermal and chemical processes, while its accurate and efficient simulations are still quite challenging. In the present study, a novel treatment of a two-phase interface in the volume penalization method, a kind of immersed boundary method, for solving conjugate scalar transport with general interfacial boundary conditions is developed. We first propose an interfacial treatment for solving an advection-diffusion equation with a Neumann boundary condition, and then extend it to general conjugate scalar transport with both interfacial flux and scalar jumps. A one-dimensional diffusion problem is solved to verify the present scheme and demonstrate the advantage of the present scheme in improving accuracy and unifying the governing equations in the two phases with an additional source term representing the local jump condition of the interfacial scalar flux. Then, the present scheme is further applied to fluid-solid coupled scalar diffusion and advection-diffusion problems with the scalar and its flux jumps across the interface. The simulation results of the present scheme generally show good agreement with reference results obtained by body-fitted mesh simulations with average relative deviations less than 3.0%."}
{"id": "2601.10626", "categories": ["math.ST", "cs.CR", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2601.10626", "abs": "https://arxiv.org/abs/2601.10626", "authors": ["Getoar Sopa", "Marco Avella Medina", "Cynthia Rush"], "title": "Differentially Private Inference for Longitudinal Linear Regression", "comment": "68 pages, 3 figures", "summary": "Differential Privacy (DP) provides a rigorous framework for releasing statistics while protecting individual information present in a dataset. Although substantial progress has been made on differentially private linear regression, existing methods almost exclusively address the item-level DP setting, where each user contributes a single observation. Many scientific and economic applications instead involve longitudinal or panel data, in which each user contributes multiple dependent observations. In these settings, item-level DP offers inadequate protection, and user-level DP - shielding an individual's entire trajectory - is the appropriate privacy notion. We develop a comprehensive framework for estimation and inference in longitudinal linear regression under user-level DP. We propose a user-level private regression estimator based on aggregating local regressions, and we establish finite-sample guarantees and asymptotic normality under short-range dependence. For inference, we develop a privatized, bias-corrected covariance estimator that is automatically heteroskedasticity- and autocorrelation-consistent. These results provide the first unified framework for practical user-level DP estimation and inference in longitudinal linear regression under dependence, with strong theoretical guarantees and promising empirical performance."}
{"id": "2601.09995", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09995", "abs": "https://arxiv.org/abs/2601.09995", "authors": ["Masahito Hayashi", "Jinpei Zhao"], "title": "Double Markovity for quantum systems", "comment": null, "summary": "The subadditivity-doubling-rotation (SDR) technique is a powerful route to Gaussian optimality in classical information theory and relies on strict subadditivity and its equality-case analysis, where double Markovity is a standard tool. We establish quantum analogues of double Markovity. For tripartite states, we characterize the simultaneous Markov conditions A-B-C and A-C-B via compatible projective measurements on B and C that induce a common classical label J yielding A-J-(BC). For strictly positive four-party states, we show that A-(BD)-C and A-(CD)-B hold if and only if A-D-(BC) holds. These results remove a key bottleneck in extending SDR-type arguments to quantum systems."}
{"id": "2601.10326", "categories": ["math.ST", "math.AP", "math.NA", "math.PR"], "pdf": "https://arxiv.org/pdf/2601.10326", "abs": "https://arxiv.org/abs/2601.10326", "authors": ["Aurélien Castre", "Richard Nickl"], "title": "On gradient stability in nonlinear PDE models and inference in interacting particle systems", "comment": "36 pages", "summary": "We consider general parameter to solution maps $θ\\mapsto \\mathcal G(θ)$ of non-linear partial differential equations and describe an approach based on a Banach space version of the implicit function theorem to verify the gradient stability condition of Nickl&Wang (JEMS 2024) for the underlying non-linear inverse problem, providing also injectivity estimates and corresponding statistical identifiability results. We illustrate our methods in two examples involving a non-linear reaction diffusion system as well as a McKean--Vlasov interacting particle model, both with periodic boundary conditions. We apply our results to prove the polynomial time convergence of a Langevin-type algorithm sampling the posterior measure of the interaction potential arising from a discrete aggregate measurement of the interacting particle system."}
{"id": "2601.09997", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.09997", "abs": "https://arxiv.org/abs/2601.09997", "authors": ["Guo-Qing Zhang", "L. F. Quezada", "Shi-Hai Dong"], "title": "Reentrant topological phases and entanglement scalings in moiré-modulated extended Su-Schrieffer-Heeger Model", "comment": "10 pages, 7 figures", "summary": "Recent studies of moiré physics have unveiled a wealth of opportunities for significantly advancing the field of quantum phase transitions. However, properties of reentrant phase transitions driven by moiré strength are poorly understood. Here, we investigate the reentrant sequence of phase transitions and the invariant of universality class in moiré-modulated extended Su-Schrieffer-Heeger (SSH) model. For the simplified case with intercell hopping $w=0$, we analytically derive renormalization relations of Hamiltonian parameters to explain the reentrant phenomenon. For the general case, numerical phase boundaries are calculated in the thermodynamic limit. The bulk boundary correspondence between zero-energy edge modes and entanglement spectrum is revealed from the degeneracy of both quantities. We also address the correspondence between the central charge obtained from entanglement entropy and the change in winding number during the phase transition. Our results shed light on the understanding of universal characteristics and bulk-boundary correspondence for moiré induced reentrant phase transitions in 1D condensed-matter systems."}
{"id": "2601.10034", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10034", "abs": "https://arxiv.org/abs/2601.10034", "authors": ["Song-Ju Kim"], "title": "Contextuality Derived from Minimal Decision Dynamics: Quantum Tug-of-War Decision Making", "comment": "This work addresses contextuality and non-Kolmogorovian probability as structural properties of decision dynamics, without assuming quantum physical substrates", "summary": "Decision making often exhibits context dependence that challenges classical probability theory. While quantum cognition has successfully modeled such phenomena, it remains unclear whether quantum probability is merely a convenient assumption or a necessary consequence of decision dynamics. Here we present a theoretical framework in which contextuality arises generatively from physically grounded constraints on decision making. By developing a quantum extension of the Tug-of-War (TOW) model, we show that conservation-based internal state updates and measurement-induced disturbance preclude any non-contextual classical description with a single, unified internal state. Contextuality therefore emerges as a structural consequence of adaptive learning dynamics. We further show that the resulting measurement structure admits Klyachko-Can-Binicioglu-Shumovsky (KCBS)-type contextuality witnesses in a minimal single-system setting. These results indicate that quantum probability is not merely a descriptive convenience, but an unavoidable effective theory for adaptive decision dynamics."}
{"id": "2601.10042", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10042", "abs": "https://arxiv.org/abs/2601.10042", "authors": ["Sha Shi", "Xiao-Yang Xu", "Min-Quan Cheng", "Dong-Sheng Wang", "Yun-Jiang Wang"], "title": "Towards Minimal Fault-tolerant Error-Correction Sequence with Quantum Hamming Codes", "comment": "11pages, 1 figure", "summary": "The high overhead of fault-tolerant measurement sequences (FTMSs) poses a major challenge for implementing quantum stabilizer codes. Here, we address this problem by constructing efficient FTMSs for the class of quantum Hamming codes $[\\![2^r-1, 2^r-1-2r, 3]\\!]$ with $r=3k+1$ ($k \\in \\mathbb{Z}^+$). Our key result demonstrates that the sequence length can be reduced to exactly $2r+1$-only one additional measurement beyond the original non-fault-tolerant sequence, establishing a tight lower bound. The proposed method leverages cyclic matrix transformations to systematically combine rows of the initial stabilizer matrix and preserving a self-dual CSS-like symmetry analogous to that of the original quantum Hamming codes. This induced symmetry enables hardware-efficient circuit reuse: the measurement circuits for the first $r$ stabilizers are transformed into circuits for the remaining $r$ stabilizers simply by toggling boundary Hadamard gates, eliminating redundant hardware. For distance-3 fault-tolerant error correction, our approach simultaneously reduces the time overhead via shorting the FTMS length and the hardware overhead through symmetry-enabled circuit multiplexing. These results provide an important advance towards the important open problem regarding the design of minimal FTMSs for quantum Hamming codes and may shed light on similar challenges in other quantum stabilizer codes."}
{"id": "2601.10059", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10059", "abs": "https://arxiv.org/abs/2601.10059", "authors": ["Shuowei Ma", "Qianfan Wang", "Lvzhou Li", "Fei Shi"], "title": "Optimal qudit overlapping tomography and optimal measurement order", "comment": null, "summary": "Quantum state tomography is essential for characterizing quantum systems, but it becomes infeasible for large systems due to exponential resource scaling. Overlapping tomography addresses this challenge by reconstructing all $k$-body marginals using few measurement settings, enabling the efficient extraction of key information for many quantum tasks. While optimal schemes are known for qubits, the extension to higher-dimensional qudit systems remains largely unexplored. Here, we investigate optimal qudit overlapping tomography, constructing local measurement settings from generalized Gell-Mann matrices. By establishing a correspondence with combinatorial covering arrays, we present two explicit constructions of optimal measurement schemes. For $n$-qutrit systems, we prove that pairwise tomography requires at most $8 + 56\\left\\lceil \\log_{8} n \\right\\rceil$ measurement settings, and provide an explicit scheme achieving this bound. Furthermore, we develop an efficient algorithm to determine the optimal order of these measurement settings, minimizing the experimental overhead associated with switching configurations. Compared to the worst-case ordering, our optimized schedule reduces switching costs by approximately 50\\%. These results provide a practical pathway for efficient characterization of qudit systems, facilitating their application in quantum communication and computation."}
{"id": "2601.10066", "categories": ["quant-ph", "physics.app-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.10066", "abs": "https://arxiv.org/abs/2601.10066", "authors": ["Awanish Pandey"], "title": "Geometric Criteria for Complete Mode Conversion in Detuned Systems via Piecewise-Coherent Modulation", "comment": "6 pages, 4 figures", "summary": "Static phase detuning fundamentally constrains coherent state transfer in asymmetric classical and quantum systems. We introduce a Bloch-sphere formulation for piecewise-coherent modulation that recasts coupled-mode dynamics as geometric trajectories, transforming algebraic control into path optimization. The approach reveals a cone of inaccessibility at the target pole and yields exact geodesic criteria for complete mode conversion in detuned systems. Leveraging this framework, we break time-reversal symmetry to realize a magnet-free optical isolator with near-unity contrast. Furthermore, for detuning larger than coupling between modes, we develop a recursive multi-step protocol enabling deterministic transfer for arbitrary detunings and derive a universal geometric lower bound on the required number of coupling-switching events."}
{"id": "2601.10087", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10087", "abs": "https://arxiv.org/abs/2601.10087", "authors": ["Kazuki Kobayashi", "Tatsuro Yuge"], "title": "Pseudomode approach to Fano effect in dissipative cavity quantum electrodynamics", "comment": "9 pages, 2 figures", "summary": "We study the Fano effect in dissipative cavity quantum electrodynamics, which originates from the interference between the emitter's direct radiation and that mediated by a cavity mode. Starting from a two-level system coupled to a structured reservoir, we show that a quantum master equation previously derived within the Born-Markov approximation can be rederived by introducing a single auxiliary mode via pseudomode approach. We identify the corresponding spectral function of the system--environment interaction and demonstrate that it consists of a constant and a non-Lorentzian contribution forming the Fano profile. The constant term is shown to be essential for obtaining a Lindblad master equation and is directly related to the rate associated with this Fano interference. Furthermore, by applying Fano diagonalization to a common-environment setup including an explicit cavity mode, we independently derive the same spectral function in the strongest-interference regime. Our results establish a unified framework for describing the Fano effect in single-mode cavity QED systems and clarify its non-Markovian origin encoded in the spectral function."}
{"id": "2601.10111", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10111", "abs": "https://arxiv.org/abs/2601.10111", "authors": ["Jiwon Heo", "Sojeong Park", "Changhun Oh"], "title": "Classical simulation of a quantum circuit with noisy magic inputs", "comment": "21 pages, 5 figures", "summary": "Magic states are essential for universal quantum computation and are widely viewed as a key source of quantum advantage, yet in realistic devices they are inevitably noisy. In this work, we characterize how noise on injected magic resources changes the classical simulability of quantum circuits and when it induces a transition from classically intractable behavior to efficient classical simulation. We adopt a resource-centric noise model in which only the injected magic components are noisy, while the baseline states, operations, and measurements belong to an efficiently simulable family. Within this setting, we develop an approximate classical sampling algorithm with controlled error and prove explicit noise-dependent conditions under which the algorithm runs in polynomial time. Our framework applies to both qubit circuits with Clifford baselines and fermionic circuits with matchgate baselines, covering representative noise channels such as dephasing and particle loss. We complement the analysis with numerical estimates of the simulation cost, providing concrete thresholds and runtime scaling across practically relevant parameter regimes."}
{"id": "2601.10118", "categories": ["quant-ph", "physics.app-ph"], "pdf": "https://arxiv.org/pdf/2601.10118", "abs": "https://arxiv.org/abs/2601.10118", "authors": ["Calum F. Shelden", "Jeremy N. Munday"], "title": "Casimir interactions as a probe of broadband optical response", "comment": "13 pages, 4 figures", "summary": "Casimir forces arise from quantum electromagnetic fluctuations and depend on the dielectric response of interacting materials across the entire frequency spectrum. Although this dependence is central to Lifshitz theory of the Casimir effect, the formulation of the force in terms of dielectric functions evaluated at imaginary frequencies has largely obscured its connection to real-frequency optical properties, limiting the use of Casimir interactions as a probe of materials. Here we demonstrate that Casimir force measurements encode sufficient information to reconstruct a material's broadband optical response. Using supervised machine learning to invert Lifshitz theory, we determine the complex permittivity of a material over more than seven orders of magnitude in frequency from a single force-distance curve. We show that measurements at different separations selectively constrain distinct frequency ranges of the dielectric response, providing direct physical insight into how quantum fluctuations sample the electromagnetic spectrum. These results establish Casimir interactions as a physically constrained, broadband spectroscopic tool and open new opportunities for optical characterization in regimes inaccessible to conventional techniques."}
{"id": "2601.10144", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10144", "abs": "https://arxiv.org/abs/2601.10144", "authors": ["Xiang Fang", "Jixuan Ruan", "Sharanya Prabhu", "Ang Li", "Travis Humble", "Dean Tullsen", "Yufei Ding"], "title": "Bridging Superconducting and Neutral-Atom Platforms for Efficient Fault-Tolerant Quantum Architectures", "comment": "15 pages, 7 figures", "summary": "The transition to the fault-tolerant era exposes the limitations of homogeneous quantum systems, where no single qubit modality simultaneously offers optimal operation speed, connectivity, and scalability. In this work, we propose a strategic approach to Heterogeneous Quantum Architectures (HQA) that synthesizes the distinct advantages of the superconducting (SC) and neutral atom (NA) platforms. We explore two architectural role assignment strategies based on hardware characteristics: (1) We offload the latency-critical Magic State Factory (MSF) to fast SC devices while performing computation on scalable NA arrays, a design we term MagicAcc, which effectively mitigates the resource-preparation bottleneck. (2) We explore a Memory-Compute Separation (MCSep) paradigm that utilizes NA arrays for high-density qLDPC memory storage and SC devices for fast surface-code processing. Our evaluation, based on a comprehensive end-to-end cost model, demonstrates that principled heterogeneity yields significant performance gains. Specifically, our designs achieve $752\\times$ speedup over NA-only baselines on average and reduce the physical qubit footprint by over $10\\times$ compared to SC-only systems. These results chart a clear pathway for leveraging cross-modality interconnects to optimize the space-time efficiency of future fault-tolerant quantum computers."}
{"id": "2601.10147", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10147", "abs": "https://arxiv.org/abs/2601.10147", "authors": ["Mei-Qi Gao", "Song-hai Li", "Xun Li", "Xingli Li", "Jiong Cheng", "Wenlin Li"], "title": "Fluctuation-induced quenching of chaos in quantum optics", "comment": null, "summary": "Recent studies have extensively explored chaotic dynamics in quantum optical systems through the mean-field approximation, which corresponds to an ideal, fluctuation-free scenario. However, the inherent sensitivity of chaos to initial conditions implies that even minute fluctuations can be amplified, thereby questioning the applicability of this approximation. Here, we analyze these chaotic effects using stochastic Langevin equations or the Lindblad master equation. For systems operating at frequencies of $10^5$ to $10^7$ Hz, we demonstrate that room-temperature thermal fluctuations are sufficient to suppress chaos at the level of expectation values, even under weak nonlinearity. Furthermore, nonlinearity induces deviations from Gaussian phase-space distributions of the quantum state, revealing attractor-like features in the Wigner function. With increasing nonlinearity, the noise threshold for chaos suppression decreases, approaching the scale of vacuum fluctuations. These results provide a bidirectional validation of the quantum mechanical suppression of chaos."}
{"id": "2601.10166", "categories": ["quant-ph", "physics.comp-ph", "physics.flu-dyn"], "pdf": "https://arxiv.org/pdf/2601.10166", "abs": "https://arxiv.org/abs/2601.10166", "authors": ["Miriam Goldack", "Yosi Atia", "Ori Alberton", "Karl Jansen"], "title": "Computing Statistical Properties of Velocity Fields on Current Quantum Hardware", "comment": "25 pages, 16 figures", "summary": "Quantum algorithms are gaining attention in Computational Fluid Dynamics (CFD) for their favorable scaling, as encoding physical fields into quantum probability amplitudes enables representation of two to the power of n spatial points with only n qubits. A key challenge in Quantum CFD is the efficient readout of simulation results, a topic that has received limited attention in literature. This work presents methods to extract statistical properties of spatial velocity fields, such as central moments and structure functions, directly from parameterized ansatz circuits, avoiding full quantum state tomography. As a proof of concept, we implement our approach for 1D velocity fields, encoding 16 spatial points with 4 qubits, and analyze both a sine wave signal and four snapshots from Burgers' equation evolution. Using Qedma's error mitigation software QESEM, we demonstrate that such computations achieve high accuracy on current quantum devices, specifically IBMQ's Heron2 system ibm_fez."}
{"id": "2601.10190", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10190", "abs": "https://arxiv.org/abs/2601.10190", "authors": ["Zhiwen Lin", "Ke Li", "Kun Fang"], "title": "Exponential Analysis for Entanglement Distillation", "comment": null, "summary": "Historically, the focus in entanglement distillation has predominantly been on the distillable entanglement, and the framework assumes complete knowledge of the initial state. In this paper, we study the reliability function of entanglement distillation, which specifies the optimal exponent of the decay of the distillation error when the distillation rate is below the distillable entanglement. Furthermore, to capture greater operational significance, we extend the framework from the standard setting of known states to a black-box setting, where distillation is performed from a set of possible states. We establish an exact finite blocklength result connecting to composite correlated hypothesis testing without any redundant correction terms. Based on this, the reliability function of entanglement distillation is characterized by the regularized quantum Hoeffding divergence. In the special case of a pure initial state, our result reduces to the error exponent for entanglement concentration derived by Hayashi et al. in 2003. Given full prior knowledge of the state, we construct a concrete optimal distillation protocol. Additionally, we analyze the strong converse exponent of entanglement distillation. While all the above results assume the free operations to be non-entangling, we also investigate other free operation classes, including PPT-preserving, dually non-entangling, and dually PPT-preserving operations."}
{"id": "2601.10194", "categories": ["quant-ph", "physics.chem-ph"], "pdf": "https://arxiv.org/pdf/2601.10194", "abs": "https://arxiv.org/abs/2601.10194", "authors": ["Weitang Li", "Jiajun Ren", "Lixue Cheng", "Cunxi Gong"], "title": "Autonomous Quantum Simulation through Large Language Model Agents", "comment": null, "summary": "We demonstrate that large language model (LLM) agents can autonomously perform tensor network simulations of quantum many-body systems, achieving approximately 90% success rate across representative benchmark tasks. Tensor network methods are powerful tools for quantum simulation, but their effective use requires expertise typically acquired through years of graduate training. By combining in-context learning with curated documentation and multi-agent decomposition, we create autonomous AI agents that can be trained in specialized computational domains within minutes. We benchmark three configurations (baseline, single-agent with in-context learning, and multi-agent with in-context learning) on problems spanning quantum phase transitions, open quantum system dynamics, and photochemical reactions. Systematic evaluation using DeepSeek-V3.2, Gemini 2.5 Pro, and Claude Opus 4.5 demonstrates that both in-context learning and multi-agent architecture are essential. Analysis of failure modes reveals characteristic patterns across models, with the multi-agent configuration substantially reducing implementation errors and hallucinations compared to simpler architectures."}
{"id": "2601.10197", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10197", "abs": "https://arxiv.org/abs/2601.10197", "authors": ["Maxwell West"], "title": "On the average-case complexity of learning states from the circular and Gaussian ensembles", "comment": "22 pages", "summary": "Studying the complexity of states sampled from various ensembles is a central component of quantum information theory. In this work we establish the average-case hardness of learning, in the statistical query model, the Born distributions of states sampled uniformly from the circular and (fermionic) Gaussian ensembles. These ensembles of states are induced variously by the uniform measures on the compact symmetric spaces of type AI, AII, and DIII. This finding complements analogous recent results for states sampled from the classical compact groups. On the technical side, we employ a somewhat unconventional approach to integrating over the compact groups which may be of some independent interest. For example, our approach allows us to exactly evaluate the total variation distances between the output distributions of Haar random unitary and orthogonal circuits and the constant distribution, which were previously known only approximately."}
{"id": "2601.10203", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10203", "abs": "https://arxiv.org/abs/2601.10203", "authors": ["Zheng Zhao", "Weifeng Zhuang", "Yanwu Gu", "Peng Qian", "Xiao Xiao", "Dong E. Liu"], "title": "Topology-Aware Block Coordinate Descent for Qubit Frequency Calibration of Superconducting Quantum Processors", "comment": "17 pages,6 figures", "summary": "Pre-execution calibration is a major bottleneck for operating superconducting quantum processors, and qubit frequency allocation is especially challenging due to crosstalk-coupled objectives. We establish that the widely-used Snake optimizer is mathematically equivalent to Block Coordinate Descent (BCD), providing a rigorous theoretical foundation for this calibration strategy. Building on this formalization, we present a topology-aware block ordering obtained by casting order selection as a Sequence-Dependent Traveling Salesman Problem (SD-TSP) and solving it efficiently with a nearest-neighbor heuristic. The SD-TSP cost reflects how a given block choice expands the reduced-circuit footprint required to evaluate the block-local objective, enabling orders that minimize per-epoch evaluation time. Under local crosstalk/bounded-degree assumptions, the method achieves linear complexity in qubit count per epoch, while retaining calibration quality. We formalize the calibration objective, clarify when reduced experiments are equivalent or approximate to the full objective, and analyze convergence of the resulting inexact BCD with noisy measurements. Simulations on multi-qubit models show that the proposed BCD-NNA ordering attains the same optimization accuracy at markedly lower runtime than graph-based heuristics (BFS, DFS) and random orders, and is robust to measurement noise and tolerant to moderate non-local crosstalk. These results provide a scalable, implementation-ready workflow for frequency calibration on NISQ-era processors."}
{"id": "2601.10206", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10206", "abs": "https://arxiv.org/abs/2601.10206", "authors": ["Nirupam Basak", "Goutam Paul", "Pritam Chattopadhyay"], "title": "Noise-Resilient Quantum Evolution in Open Systems through Error-Correcting Frameworks", "comment": null, "summary": "We analyze quantum state preservation in open quantum systems using quantum error-correcting (QEC) codes that are explicitly embedded into microscopic system-bath models. Instead of abstract quantum channels, we consider multi-qubit registers coupled to bosonic thermal environments, derive a second-order master equation for the reduced dynamics, and use it to benchmark the five-qubit, Steane, and toric codes under local and collective noise. We compute state fidelities for logical qubits as functions of coupling strength, bath temperature, and the number of correction cycles. In the low-temperature regime, we find that repeated error-correction with the five-qubit code strongly suppresses decoherence and relaxation, while in the high-temperature regime, thermal excitations dominate the dynamics and reduce the benefit of all codes, though the five-qubit code still outperforms the Steane and toric codes. For two-qubit Werner states, we identify a critical evolution time before which QEC does not improve fidelity, and this time increases as entanglement grows. After this critical time, QEC does improve fidelity. Comparative analysis further reveals that the five-qubit code (the smallest perfect code) offers consistently higher fidelities than topological and concatenated architectures in these open-system settings. These findings establish a quantitative framework for evaluating QEC under realistic noise environments and provide guidance for developing noise-resilient quantum architectures in near-term quantum technologies."}
{"id": "2601.10209", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10209", "abs": "https://arxiv.org/abs/2601.10209", "authors": ["S. Messelot", "A. Leblanc", "J. -S. Tettekpoe", "F. Lefloch", "Q. Ficheux", "J. Renard", "É. Dumur"], "title": "Coherence Limits in Interference-Based cos(2$\\varphi$) Qubits", "comment": "19 pages, 14 figures", "summary": "We investigate the coherence properties of parity-protected $\\cos(2\\varphi)$ qubits based on interferences between two Josephson elements in a superconducting loop. We show that qubit implementations of a $\\cos(2\\varphi)$ potential using a single loop, such as those employing semiconducting junctions, rhombus circuits, flowermon and KITE structures, can be described by the same Hamiltonian as two multi-harmonic Josephson junctions in a SQUID geometry. We find that, despite the parity protection arising from the suppression of single Cooper pair tunneling, there exists a fundamental trade-off between charge and flux noise dephasing channels. Using numerical simulations, we examine how relaxation and dephasing rates depend on external flux and circuit parameters, and we identify the best compromise for maximum coherence. With currently existing circuit parameters, the qubit lifetime $T_1$ can exceed milliseconds while the dephasing time $T_\\varphi$ remains limited to only a few microseconds due to either flux or charge noise. Our findings establish practical limits on the coherence of this class of qubits and raise questions about the long-term potential of this approach."}
{"id": "2601.10210", "categories": ["quant-ph", "cond-mat.str-el"], "pdf": "https://arxiv.org/pdf/2601.10210", "abs": "https://arxiv.org/abs/2601.10210", "authors": ["J. Leibig", "M. Hörmann", "A. Langheld", "A. Schellenberger", "K. P. Schmidt"], "title": "Quantitative approach for the Dicke-Ising chain with an effective self-consistent matter Hamiltonian", "comment": "23 pages, 8 figures", "summary": "In the thermodynamic limit, the Dicke-Ising chain maps exactly onto an effective self-consistent matter Hamiltonian with the photon field acting solely as a self-consistent effective field. As a consequence, no quantum correlations between photons and spins are needed to understand the quantum phase diagram. This enables us to determine the quantum phase diagram in the thermodynamic limit using numerical linked-cluster expansions combined with density matrix renormalization group calculations (NLCE+DMRG) to solve the resulting self-consistent matter Hamiltonian. This includes magnetically ordered phases with significantly improved accuracy compared to previous estimates. For ferromagnetic Ising couplings, we refine the location of the multicritical point governing the change in the order of the superradiant phase transition, reaching a relative accuracy of $10^{-4}$. For antiferromagnetic Ising couplings, we confirm the existence of the narrow antiferromagnetic superradiant phase in the thermodynamic limit. The effective matter Hamiltonian framework identifies the antiferromagnetic superradiant phase as the many-body ground state of an antiferromagnetic transverse-field Ising model with longitudinal field. This phase emerges through continuous Dicke-type polariton condensation from the antiferromagnetic normal phase, followed by a first-order transition to the paramagnetic superradiant phase. Thus, NLCE+DMRG provides a precise determination of the Dicke-Ising phase diagram in one dimension by solving the self-consistent effective matter Hamiltonian."}
{"id": "2601.10243", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10243", "abs": "https://arxiv.org/abs/2601.10243", "authors": ["Masahito Hayashi", "Hao-Chung Cheng", "Li Gao"], "title": "Adversarial Hypothesis Testing for Quantum Channels", "comment": "15 pages. Comments are welcome", "summary": "This paper presents a systematic study of adversarial hypothesis testing for both quantum-quantum (QQ) and classical-quantum (CQ) channels. Unlike conventional channel discrimination, we consider a framework where the sender, Alice, selects the channel input adversarially to minimize Bob's distinguishability. We analyze this problem across four settings based on whether Alice employs i.i.d. or general inputs and whether the receiver, Bob, is informed of the specific input choice (allowing his measurement to depend on the input). We characterize the Stein exponents for each setting and reveal a striking distinction in behavior: for QQ channels with i.i.d. inputs, Bob's knowledge of the input significantly enhances distinguishability, yet this advantage vanishes when general inputs are permitted. In contrast, for CQ channels, Bob being informed provides a consistent advantage over the corresponding entanglement-breaking channels for both i.i.d. and general inputs. These results demonstrate a unique phenomenon in adversarial hypothesis testing where the CQ channel does not merely behave as a special case of the QQ channel."}
{"id": "2601.10281", "categories": ["quant-ph", "cond-mat.mes-hall"], "pdf": "https://arxiv.org/pdf/2601.10281", "abs": "https://arxiv.org/abs/2601.10281", "authors": ["Maristella Crotti", "Luca Razzoli", "Luigi Giannelli", "Giuseppe A. Falci", "Giuliano Benenti"], "title": "Optimal control of a dissipative micromaser quantum battery in the ultrastrong coupling regime", "comment": "13 pages, 6 figures", "summary": "We investigate the open system dynamics of a micromaser quantum battery operating in the ultrastrong coupling (USC) regime under environmental dissipation. The battery consists of a single-mode electromagnetic cavity sequentially interacting, via the Rabi Hamiltonian, with a stream of qubits acting as chargers. Dissipative effects arise from the weak coupling of the qubit-cavity system to a thermal bath. Non-negligible in the USC regime, the counter-rotating terms substantially improve the charging speed, but also lead, in the absence of dissipation, to unbounded energy growth and highly mixed cavity states. Dissipation during each qubit-cavity interaction mitigates these detrimental effects, yielding steady-state of finite energy and ergotropy. Optimal control on qubit preparation and interaction times enhances battery's performance in: (i) Maximizing the stored ergotropy trhough an optimized charging protocol; (ii) Stabilizing the stored ergotropy against dissipative losses through an optimized measurement-based passive-feedback strategy. Overall, our numerical results demonstrate that the interplay of ultrastrong light-matter coupling, controlled dissipation, and optimized control strategies enables micromaser quantum batteries to achieve both enhanced charging performance and long-term stability under realistic conditions."}
{"id": "2601.10289", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10289", "abs": "https://arxiv.org/abs/2601.10289", "authors": ["Rodrigo M. Sanz", "Emilio Annoni", "Stephen C. Wein", "Carmen G. Almudever", "Shane Mansfield", "Ellen Derbyshire", "Rawad Mezher"], "title": "Exponential improvement in benchmarking multiphoton interference", "comment": "7 pages + 20 pages appendix, comments welcome !", "summary": "Several photonic quantum technologies rely on the ability to generate multiple indistinguishable photons. Benchmarking the level of indistinguishability of these photons is essential for scalability. The Hong-Ou-Mandel dip provides a benchmark for the indistinguishability between two photons, and extending this test to the multi-photon setting has so far resulted in a protocol that computes the genuine n-photon indistinguishability (GI). However, this protocol has a sample complexity that increases exponentially with the number of input photons for an estimation of GI up to a given additive error. To address this problem, we introduce new theorems that strengthen our understanding of the relationship between distinguishability and the suppression laws of the quantum Fourier transform interferometer (QFT). Building on this, we propose a protocol using the QFT for benchmarking GI that achieves constant sample complexity for the estimation of GI up to a given additive error for prime photon numbers, and sub-polynomial scaling otherwise, representing an exponential improvement over the state of the art. We prove the optimality of our protocol in many relevant scenarios and validate our approach experimentally on Quandela's reconfigurable photonic quantum processor, where we observe a clear advantage in runtime and precision over the state of the art. We therefore establish the first scalable method for computing multi-photon indistinguishability, which applies naturally to current and near-term photonic quantum hardware."}
{"id": "2601.10302", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10302", "abs": "https://arxiv.org/abs/2601.10302", "authors": ["Yu. M. Poluektov"], "title": "Complex scalar relativistic field as a probability amplitude", "comment": "11 pages", "summary": "A relativistic equation for a neutral complex field as a probability amplitude is proposed. The continuity equation for the probability density is obtained. It is shown that there are two types of excitations of this field, which describe particles with positive energy and different dispersion laws. Based on the Lagrangian formalism, conservation laws are obtained. The transition to secondary quantization is considered."}
{"id": "2601.10319", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10319", "abs": "https://arxiv.org/abs/2601.10319", "authors": ["Gavriil Voloshin", "Konstantin Barantsev", "Andrey Litvinov"], "title": "Addition to the dynamic Stark shift of the coherent population trapping resonance", "comment": "11 pages, 7 figures", "summary": "This paper presents a theoretical study of the light-induced shift of the coherent population trapping resonance. An analytical model is proposed that describes the interaction of two radiation components with an atomic system using a $Λ$ scheme and takes into account an additional level of excited state. Both weak and strong coupling regimes with off-resonant transitions are considered. It is shown that, in addition to the conventional dynamic Stark shift, an extra shift arises due to the distortion of the resonance line shape when bichromatic laser radiation interacts with off-resonant atomic transitions. An analytical expression for this additional shift is derived in the weak-coupling limit, and its significant impact on the resonance shape and sensitivity to the intensities of the laser field components is demonstrated. It is found that under strong coupling conditions, the additional shift can deviate substantially from a linear dependence on light intensity, suggesting new opportunities for controlling light shifts in precision atomic devices such as quantum frequency standards."}
{"id": "2601.10325", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10325", "abs": "https://arxiv.org/abs/2601.10325", "authors": ["Yifang Xu", "Yilong Zhou", "Ziyue Hua", "Lida Sun", "Jie Zhou", "Weiting Wang", "Weizhou Cai", "Hongwei Huang", "Lintao Xiao", "Guangming Xue", "Haifeng Yu", "Ming Li", "Chang-Ling Zou", "Luyan Sun"], "title": "Principles of Optics in the Fock Space: Scalable Manipulation of Giant Quantum States", "comment": "25 pages, 15 figures, 1 table", "summary": "The manipulation of distinct degrees of freedom of photons plays a critical role in both classical and quantum information processing. While the principles of wave optics provide elegant and scalable control over classical light in spatial and temporal domains, engineering quantum states in Fock space has been largely restricted to few-photon regimes, hindered by the computational and experimental challenges of large Hilbert spaces. Here, we introduce ``Fock-space optics\", establishing a conceptual framework of wave propagation in the quantum domain by treating photon number as a synthetic dimension. Using a superconducting microwave resonator, we experimentally demonstrate Fock-space analogues of optical propagation, refraction, lensing, dispersion, and interference with up to 180 photons. These results establish a fundamental correspondence between Schrödinger evolution in a single bosonic mode and classical paraxial wave propagation. By mapping intuitive optical concepts onto high-dimensional quantum state engineering, our work opens a path toward scalable control of large-scale quantum systems with thousands of photons and advanced bosonic information processing."}
{"id": "2601.10354", "categories": ["quant-ph", "hep-th"], "pdf": "https://arxiv.org/pdf/2601.10354", "abs": "https://arxiv.org/abs/2601.10354", "authors": ["Riccardo Falcone", "Claudio Conti"], "title": "Realistic prospects for testing a relativistic local quantum measurement inequality", "comment": null, "summary": "We investigate the experimental prospects for testing a relativistic local quantum measurement inequality that quantifies the trade-off between vacuum insensitivity and responsiveness to excitations for finite-size detectors. Building on the Reeh--Schlieder approximation for coherent states, we derive an explicit and practically applicable bound for arbitrary coherent states. To connect with realistic photodetection scenarios, we model the detection region as a square prism operating over a finite time window and consider a normally incident single-mode coherent state. Numerical results exhibit the expected qualitative behavior: suppressing dark counts necessarily tightens the achievable click probability."}
{"id": "2601.10380", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10380", "abs": "https://arxiv.org/abs/2601.10380", "authors": ["Shrigyan Brahmachari", "Shuchen Zhu", "Iman Marvian", "Yu Tong"], "title": "Learning Hamiltonians in the Heisenberg limit with static single-qubit fields", "comment": null, "summary": "Learning the Hamiltonian governing a quantum system is a central task in quantum metrology, sensing, and device characterization. Existing Heisenberg-limited Hamiltonian learning protocols either require multi-qubit operations that are prone to noise, or single-qubit operations whose frequency or strength increases with the desired precision. These two requirements limit the applicability of Hamiltonian learning on near-term quantum platforms. We present a protocol that learns a quantum Hamiltonian with the optimal Heisenberg-limited scaling using only single-qubit control in the form of static fields with strengths that are independent of the target precision. Our protocol is robust against the state preparation and measurement (SPAM) error. By overcoming these limitations, our protocol provides new tools for device characterization and quantum sensing. We demonstrate that our method achieves the Heisenberg-limited scaling through rigorous mathematical proof and numerical experiments. We also prove an information-theoretic lower bound showing that a non-vanishing static field strength is necessary for achieving the Heisenberg limit unless one employs an extensive number of discrete control operations."}
{"id": "2601.10385", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10385", "abs": "https://arxiv.org/abs/2601.10385", "authors": ["Eliya Blumenthal", "Natan Karaev", "Shay Hacohen-Gourgy"], "title": "Experimental Realization of Rabi-Driven Reset for Fast Cooling of a High-Q Cavity", "comment": null, "summary": "High-Q bosonic memories are central to hardware-efficient quantum error correction, but their isolation makes fast, high-fidelity reset a persistent bottleneck. Existing approaches either rely on weak intermode cross-Kerr conversion or on measurement-based sequences with substantial latency. Here we demonstrate a hardware-efficient Rabi-Driven Reset (RDR) that implements continuous, measurement-free cooling of a superconducting cavity mode. A strong resonant Rabi drive on a transmon, together with sideband drives on the memory and readout modes detuned by the Rabi frequency, converts the dispersive interaction into an effective Jaynes-Cummings coupling between the qubit dressed states and each mode. This realizes a tunable dissipation channel from the memory to the cold readout bath. Crucially, the engineered coupling scales with the qubit-mode dispersive interaction and the drive amplitude, rather than with the intermode cross-Kerr, enabling fast cooling even in very weakly coupled architectures that deliberately suppress direct mode-mode coupling. We demonstrate RDR of a single photon with a decay time of $1.2 μs$, more than two orders of magnitude faster than the intrinsic lifetime. Furthermore, we reset about 30 thermal photons in about $80 μs$ to a steady-state average photon number of $\\bar{n} = 0.045 \\pm 0.025$."}
{"id": "2601.10395", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10395", "abs": "https://arxiv.org/abs/2601.10395", "authors": ["Kläre Wienecke", "Gereon Koßmann", "René Schwonnek"], "title": "A Collection of Pinsker-type Inequalities for Quantum Divergences", "comment": "14 pages, 7 figures", "summary": "Pinsker's inequality sets a lower bound on the Umegaki divergence of two quantum states in terms of their trace distance. In this work, we formulate corresponding estimates for a variety of quantum and classical divergences including $f$-divergences like Hellinger and $χ^2$-divergences as well as Rényi divergences and special cases thereof like the Umegaki divergence, collision divergence, max divergence. We further provide a strategy on how to adapt these bounds to smoothed divergences."}
{"id": "2601.10408", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10408", "abs": "https://arxiv.org/abs/2601.10408", "authors": ["Luke Mortimer", "Leonardo Zambrano", "Antonio Acín", "Donato Farina"], "title": "Bounding many-body properties under partial information and finite measurement statistics", "comment": "12 pages, 7 figures", "summary": "Calculating bounds of properties of many-body quantum systems is of paramount importance, since they guide our understanding of emergent quantum phenomena and complement the insights obtained from estimation methods. Recent semidefinite programming approaches enable probabilistic bounds from finite-shot measurements of easily accessible, yet informationally incomplete, observables. Here we render these methods scalable in the number of qubits by instead utilizing moment-matrix relaxations. After introducing the general formalism, we show how the approach can be adapted with specific knowledge of the system, such as it being the ground state of a given Hamiltonian, possessing specific symmetries or being the steady state of a given Lindbladian. Our approach defines a scalable real-world certification scheme leveraging semidefinite programming relaxations and experimental estimations which, unavoidably, contain shot noise."}
{"id": "2601.10409", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10409", "abs": "https://arxiv.org/abs/2601.10409", "authors": ["Marcin Kotowski", "Michał Oszmaniec"], "title": "Tight bounds on recurrence time in closed quantum systems", "comment": null, "summary": "The evolution of an isolated quantum system inevitably exhibits recurrence: the state returns to the vicinity of its initial condition after finite time. Despite its fundamental nature, a rigorous quantitative understanding of recurrence has been lacking. We establish upper bounds on the recurrence time, $t_{\\mathrm{rec}} \\lesssim t_{\\mathrm{exit}}(ε)(1/ε)^d$, where $d$ is the Hilbert-space dimension, $ε$ the neighborhood size, and $t_{\\mathrm{exit}}(ε)$ the escape time from this neighborhood. For pure states evolving under a Hamiltonian $H$, estimating $t_{\\mathrm{exit}}$ is equivalent to an inverse quantum speed limit problem: finding upper bounds on the time a time-evolved state $ψ_t$ needs to depart from the $ε$-vicinity of the initial state $ψ_0$. We provide a partial solution, showing that under mild assumptions $t_{\\mathrm{exit}}(ε) \\approx ε/\\sqrt{ Δ(H^2)}$, with $Δ(H^2)$ the Hamiltonian variance in $ψ_0$. We show that our upper bound on $t_{\\mathrm{rec}}$ is generically saturated for random Hamiltonians. Finally, we analyze the impact of coherence of the initial state in the eigenbasis of $H$ on recurrence behavior."}
{"id": "2601.10423", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10423", "abs": "https://arxiv.org/abs/2601.10423", "authors": ["Abdul Rahaman Shaikh", "Tabish Qureshi"], "title": "Unifying Quantum and Classical Dynamics", "comment": "4 pages", "summary": "Classical and quantum physics represent two distinct theories; however, quantum physics is regarded as the more fundamental of the two. It is posited that classical mechanics should arise from quantum mechanics under certain limiting conditions. Nevertheless, this remains a challenging objective. In this work, we explore the potential for unifying the dynamics of classical and quantum physics. This discussion does not suggest that classical behavior emerges from quantum mechanics; rather, it demonstrates the exact equivalence between the dynamics of quantum observables and their classical counterparts. It is shown that the Heisenberg equations of motion can be cast in a form that is identical to Newton's equations of motion, with $\\hbar$ being absent from the formulation. This implies that both quantum and classical dynamics are governed by the same equations, with the Heisenberg operators substituting the classical observables."}
{"id": "2601.10429", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10429", "abs": "https://arxiv.org/abs/2601.10429", "authors": ["Yang Li", "Fu-Lin Zhang"], "title": "Reduction of thermodynamic uncertainty by a virtual qubit", "comment": "23 pages (including 13 pages of appendices), 7 figures", "summary": "The thermodynamic uncertainty relation (TUR) imposes a fundamental constraint between current fluctuations and entropy production, providing a refined formulation of the second law for micro- and nanoscale systems. Quantum violations of the classical TUR reveal genuinely quantum thermodynamic effects, which are essential for improving performance and enabling optimization in quantum technologies. In this work, we analyze the TUR in a class of paradigmatic quantum thermal-machine models whose operation is enabled by coherent coupling between two energy levels forming a virtual qubit. Steady-state coherences are confined to this virtual-qubit subspace, while in the absence of coherent coupling the system satisfies detailed balance with the thermal reservoirs and supports no steady-state heat currents. We show that the steady-state currents and entropy production can be fully reproduced by an effective classical Markov process, whereas current fluctuations acquire an additional purely quantum correction originating from coherence. As a result, the thermodynamic uncertainty naturally decomposes into a classical (diagonal) contribution and a coherent contribution. The latter becomes negative under resonant conditions and reaches its minimum at the coupling strength that maximizes steady-state coherence. We further identify the optimization conditions and the criteria for surpassing the classical TUR bound in the vicinity of the reversible limit."}
{"id": "2601.10435", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10435", "abs": "https://arxiv.org/abs/2601.10435", "authors": ["Benoît Vermersch", "Oscar Gravier", "Nathan Miscopein", "Julia Guignon", "Carlos Ramos Marimón", "Jonathan Durandau", "Matthieu Dartiailh", "Tristan Meunier", "Valentin Savin"], "title": "The SpinPulse library for transpilation and noise-accurate simulation of spin qubit quantum computers", "comment": "Code available at https://quobly-sw.github.io/SpinPulse/", "summary": "We introduce SpinPulse, an open-source python package for simulating spin qubit-based quantum computers at the pulse-level. SpinPulse models the specific physics of spin qubits, particularly through the inclusion of classical non-Markovian noise. This enables realistic simulations of native gates and quantum circuits, in order to support hardware development. In SpinPulse, a quantum circuit is first transpiled into the native gate set of our model and then converted to a pulse sequence. This pulse sequence is subsequently integrated numerically in the presence of a simulated noisy experimental environment. We showcase workflows including transpilation, pulse-level compilation, hardware benchmarking, quantum error mitigation, and large-scale simulations via integration with the tensor-network library quimb. We expect SpinPulse to be a valuable open-source tool for the quantum computing community, fostering efforts to devise high-fidelity quantum circuits and improved strategies for quantum error mitigation and correction."}
{"id": "2601.10446", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10446", "abs": "https://arxiv.org/abs/2601.10446", "authors": ["Adonai Hilário da Silva", "Octávio da Motta", "Leonardo Kleber Castelano", "Reginaldo de Jesus Napolitano"], "title": "Minimal-Energy Optimal Control of Tunable Two-Qubit Gates in Superconducting Platforms Using Continuous Dynamical Decoupling", "comment": "17 pages, 4 figures, 1 table", "summary": "We present a unified scheme for generating high-fidelity entangling gates in superconducting platforms by continuous dynamical decoupling (CDD) combined with variational minimal-energy optimal control. During the CDD stage, we suppress residual couplings, calibration drifting, and quasistatic noise, resulting in a stable effective Hamiltonian that preserves the designed ZZ interaction intended for producing tunable couplers. In this stable $\\mathrm{SU}(4)$ manifold, we calculate smooth low-energy single-quibt control functions using a variational geodesic optimization process that directly minimizes gate infidelity. We illustrate the methodology by applying it to CZ, CX, and generic engangling gates, achieving virtually unit fidelity and robustness under restricted single-qubit action, with experimentally realistic control fields. These results establish CDD-enhanced variational geometric optimal control as a practical and noise-resilient scheme for designing superconducting entangling gates."}
{"id": "2601.10451", "categories": ["quant-ph", "cond-mat.other"], "pdf": "https://arxiv.org/pdf/2601.10451", "abs": "https://arxiv.org/abs/2601.10451", "authors": ["David Guéry-Odelin", "François Impens"], "title": "Localization Landscape in Non-Hermitian and Floquet quantum systems", "comment": null, "summary": "We propose a generalization of the Filoche--Mayboroda localization landscape that extends the theory well beyond the static, elliptic and Hermitian settings while preserving its geometric interpretability. Using the positive operator $H^\\dagger H$, we obtain a landscape that predicts localization across non-Hermitian, Floquet, and topological systems without computing eigenstates. Singular-value collapse reveals spectral instabilities and skin effects, the Sambe formulation captures coherent destruction of tunneling, and topological zero modes emerge directly from the landscape. Applications to Hatano--Nelson chains, driven two-level systems, and driven Aubry--André--Harper models confirm quantitative accuracy, establishing a unified predictor for localization in equilibrium and driven quantum matter."}
{"id": "2601.10461", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10461", "abs": "https://arxiv.org/abs/2601.10461", "authors": ["Adam Siegel", "Simon Benjamin"], "title": "Erasure conversion for singlet-triplet spin qubits enables high-performance shuttling-based quantum error correction", "comment": null, "summary": "Fast and high fidelity shuttling of spin qubits has been demonstrated in semiconductor quantum dot devices. Several architectures based on shuttling have been proposed; it has been suggested that singlet-triplet (dual-spin) qubits could be optimal for the highest shuttling fidelities. Here we present a fault-tolerant framework for quantum error correction based on such dual-spin qubits, establishing them as a natural realisation of erasure qubits within semiconductor architectures. We introduce a hardware-efficient leakage-detection protocol that automatically projects leaked qubits back onto the computational subspace, without the need for measurement feedback or increased classical control overheads. When combined with the XZZX surface code and leakage-aware decoding, we demonstrate a twofold increase in the error correction threshold and achieve orders-of-magnitude reductions in logical error rates. This establishes the singlet-triplet encoding as a practical route toward high-fidelity shuttling and erasure-based, fault-tolerant quantum computation in semiconductor devices."}
{"id": "2601.10465", "categories": ["quant-ph", "cond-mat.quant-gas", "cond-mat.stat-mech"], "pdf": "https://arxiv.org/pdf/2601.10465", "abs": "https://arxiv.org/abs/2601.10465", "authors": ["Johannes N. Kriel", "Emma C. King", "Michael Kastner"], "title": "Nonlinear quantum Kibble-Zurek ramps in open systems at finite temperature", "comment": "21 pages, 5+1 figures", "summary": "We analyze quantum systems under a broad class of protocols in which the temperature and a Hamiltonian control parameter are ramped simultaneously and, in general, in a nonlinear fashion toward a quantum critical point. Using an open-system version of a Kitaev quantum wire as an example, we show that, unlike finite-temperature protocols at fixed temperature, these protocols allow us to probe, in an out-of-equilibrium situation and at finite temperature, the universality class (characterized by the critical exponents $ν$ and $z$) of an equilibrium quantum phase transition at zero temperature. Key to this is the identification of ramps in which both coherent and incoherent parts of the open-system dynamics affect the excitation density in a non-negligible way. We also identify the specific ramps for which subleading corrections to the asymptotic scaling laws are suppressed, which serves as a guide to dynamically probing quantum critical exponents in experimentally realistic finite-temperature situations."}
{"id": "2601.10473", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10473", "abs": "https://arxiv.org/abs/2601.10473", "authors": ["Daniel Koch", "Brian Pardo", "Kip Nieman"], "title": "Analysis and Experimental Demonstration of Amplitude Amplification for Combinatorial Optimization", "comment": null, "summary": "Quantum Amplitude Amplification (QAA), the generalization of Grover's algorithm, is capable of yielding optimal solutions to combinatorial optimization problems with high probabilities. In this work we extend the conventional 2-dimensional representation of Grover's (orthogonal collective states) to oracles which encode cost functions such as QUBO, and show that linear cost functions are a special case whereby an exact formula exists for determining optimal oracle parameter settings. Using simulations of problem sizes up to 40 qubits we demonstrate QAA's algorithmic performance across all possible solutions, with an emphasis on the closeness in Grover-like performance for solutions near the global optimum. We conclude with experimental demonstrations of generalized QAA on both IBMQ (superconducting) and IonQ (trapped ion) qubits, showing that the observed probabilities of each basis state match our equations as a function of varying the free parameters in the oracle and diffusion operators."}
{"id": "2601.10479", "categories": ["quant-ph", "cs.LG", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10479", "abs": "https://arxiv.org/abs/2601.10479", "authors": ["Eyad I. B Hamid"], "title": "H-EFT-VA: An Effective-Field-Theory Variational Ansatz with Provable Barren Plateau Avoidance", "comment": "7 pages, 5 figuers, Appendix", "summary": "Variational Quantum Algorithms (VQAs) are critically threatened by the Barren Plateau (BP) phenomenon. In this work, we introduce the H-EFT Variational Ansatz (H-EFT-VA), an architecture inspired by Effective Field Theory (EFT). By enforcing a hierarchical \"UV-cutoff\" on initialization, we theoretically restrict the circuit's state exploration, preventing the formation of approximate unitary 2-designs. We provide a rigorous proof that this localization guarantees an inverse-polynomial lower bound on the gradient variance: $Var[\\partial θ] \\in Ω(1/poly(N))$. Crucially, unlike approaches that avoid BPs by limiting entanglement, we demonstrate that H-EFT-VA maintains volume-law entanglement and near-Haar purity, ensuring sufficient expressibility for complex quantum states. Extensive benchmarking across 16 experiments -- including Transverse Field Ising and Heisenberg XXZ models -- confirms a 109x improvement in energy convergence and a 10.7x increase in ground-state fidelity over standard Hardware-Efficient Ansatze (HEA), with a statistical significance of $p < 10^{-88}$."}
{"id": "2601.10492", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10492", "abs": "https://arxiv.org/abs/2601.10492", "authors": ["Liang Chen", "Wen-Yi Zhu", "Zi-Jie Chen", "Zhu-Bo Wang", "Ya-Dong Hu", "Qing-Xuan Jie", "Guang-Can Guo", "Chang-Ling Zou"], "title": "Optimized readout strategies for neutral atom quantum processors", "comment": null, "summary": "Neutral atom quantum processors have emerged as a promising platform for scalable quantum information processing, offering high-fidelity operations and exceptional qubit scalability. A key challenge in realizing practical applications is efficiently extracting readout outcomes while maintaining high system throughput, i.e., the rate of quantum task executions. In this work, we develop a theoretical framework to quantify the trade-off between readout fidelity and atomic retention. Moreover, we introduce a metric of quantum circuit iteration rate (qCIR) and employ normalized quantum Fisher information to characterize system overall performance. Further, by carefully balancing fidelity and retention, we demonstrate a readout strategy for optimizing information acquisition efficiency. Considering the experimentally feasible parameters for 87Rb atoms, we demonstrate that qCIRs of 197.2Hz and 154.5Hz are achievable using single photon detectors and cameras, respectively. These results provide practical guidance for constructing scalable and high-throughput neutral atom quantum processors for applications in sensing, simulation, and near-term algorithm implementation."}
{"id": "2601.10558", "categories": ["quant-ph", "cs.IT", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10558", "abs": "https://arxiv.org/abs/2601.10558", "authors": ["Yu-Hong Lai", "Hao-Chung Cheng"], "title": "A Mirror-Descent Algorithm for Computing the Petz-Rényi Capacity of Classical-Quantum Channels", "comment": "This paper is independent and concurrent to arXiv:2601.06492", "summary": "We study the computation of the $α$-Rényi capacity of a classical-quantum (c-q) channel for $α\\in(0,1)$. We propose an exponentiated-gradient (mirror descent) iteration that generalizes the Blahut-Arimoto algorithm. Our analysis establishes relative smoothness with respect to the entropy geometry, guaranteeing a global sublinear convergence of the objective values. Furthermore, under a natural tangent-space nondegeneracy condition (and a mild spectral lower bound in one regime), we prove local linear (geometric) convergence in Kullback-Leibler divergence on a truncated probability simplex, with an explicit contraction factor once the local curvature constants are bounded."}
{"id": "2601.10559", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10559", "abs": "https://arxiv.org/abs/2601.10559", "authors": ["Mo Xiong", "Jize Han", "Chuanzhen Cao", "Jinbin Li", "Qi Liu", "Zhiguo Huang", "Ming Xue"], "title": "Deterministic and scalable generation of large Fock states", "comment": "(6+2) pages, comments are welcome", "summary": "The scalable and deterministic preparation of large Fock-number states represents a long-standing frontier in quantum science, with direct implications for quantum metrology, communication, and simulation. Despite significant progress in small-scale implementations, extending such state generation to large excitation numbers while maintaining high fidelity remains a formidable challenge. Here, we present a scalable protocol for generating large Fock states with fidelities exceeding 0.9 up to photon numbers on the order of 100, achieved using only native control operations and, when desired, further enhanced by an optional post-selection step. Our method employs a hybrid Genetic-Adam optimization framework that combines the global search efficiency of genetic algorithms with the adaptive convergence of Adam to optimize multi-pulse control sequences comprising Jaynes-Cummings interactions and displacement operations, both of which are native to leading experimental platforms. The resulting control protocols achieve high fidelities with shallow circuit depths and strong robustness against parameter variations. These results establish an efficient and scalable pathway toward high-fidelity non-classical state generation for precision metrology and fault-tolerant quantum technologies."}
{"id": "2601.10588", "categories": ["quant-ph", "cs.LG", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2601.10588", "abs": "https://arxiv.org/abs/2601.10588", "authors": ["I. K. Kominis", "C. Xie", "S. Li", "M. Skotiniotis", "G. P. Tsironis"], "title": "Searching for Quantum Effects in the Brain: A Bell-Type Test for Nonclassical Latent Representations in Autoencoders", "comment": "6 pages, 2 figures", "summary": "Whether neural information processing is entirely classical or involves quantum-mechanical elements remains an open question. Here we propose a model-agnostic, information-theoretic test of nonclassicality that bypasses microscopic assumptions and instead probes the structure of neural representations themselves. Using autoencoders as a transparent model system, we introduce a Bell-type consistency test in latent space, and ask whether decoding statistics obtained under multiple readout contexts can be jointly explained by a single positive latent-variable distribution. By shifting the search for quantum-like signatures in neural systems from microscopic dynamics to experimentally testable constraints on information processing, this work opens a new route for probing the fundamental physics of neural computation."}
{"id": "2601.10594", "categories": ["quant-ph", "cond-mat.mtrl-sci"], "pdf": "https://arxiv.org/pdf/2601.10594", "abs": "https://arxiv.org/abs/2601.10594", "authors": ["Mariia Karabin", "Tanvir Sohail", "Dmytro Bykov", "Eduardo Antonio Coello Pérez", "Swarnava Ghosh", "Murali Gopalakrishnan Meena", "Seongmin Kim", "Amir Shehata", "In-Saeng Suh", "Hanna Terletska", "Markus Eisenbach"], "title": "Quantum solver for single-impurity Anderson models with particle-hole symmetry", "comment": null, "summary": "Quantum embedding methods, such as dynamical mean-field theory (DMFT), provide a powerful framework for investigating strongly correlated materials. A central computational bottleneck in DMFT is in solving the Anderson impurity model (AIM), whose exact solution is classically intractable for large bath sizes. In this work, we develop and benchmark a quantum-classical hybrid solver tailored for DMFT applications, using the variational quantum eigensolver (VQE) to prepare the ground state of the AIM with shallow quantum circuits. The solver uses a unified ansatz framework to prepare the particle and hole excitations of the ground-state from parameter-shifted circuits, enabling the reconstruction of the impurity Green's function through a continued-fraction expansion. We evaluate the performance of this approach across a few bath sizes and interaction strengths under noisy, shot-limited conditions. We compare three optimization routines (COBYLA, Adam, and L-BFGS-B) in terms of convergence and fidelity, assess the benefits of estimating a quantum-computed moment (QCM) correction to the variational energies, and benchmark the approach by comparing the reconstructed density of states (DOS) against that obtained using a classical pipeline. Our results demonstrate the feasibility of Green's function reconstruction on near-term devices and establish practical benchmarks for quantum impurity solvers embedded within self-consistent DMFT loops."}
{"id": "2601.10650", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10650", "abs": "https://arxiv.org/abs/2601.10650", "authors": ["M. P. Tonne", "Kh. P. Gnatenko"], "title": "Quantifying the properties of evolutionary quantum states of the XXZ spin model using quantum computing", "comment": null, "summary": "The entanglement distance of evolutionary quantum states of a two-spin system with the XXZ model has been studied. The analysis has been conducted both analytically and using quantum computing. An analytical dependence of the entanglement distance on the values of the model coupling constants and the parameters of the initial states has been obtained. The speed of evolution of a two-spin system has been investigated. The analysis has been performed analytically and using quantum computing. An explicit dependence of the speed of evolution on the coupling constants and on the parameters of the initial state has been obtained. The results of quantum computations are in good agreement with the theoretical predictions."}
{"id": "2601.10655", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10655", "abs": "https://arxiv.org/abs/2601.10655", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Symmetry-based Perspectives on Hamiltonian Quantum Search Algorithms and Schrodinger's Dynamics between Orthogonal States", "comment": "21 pages, 3 figures, 2 tables", "summary": "It is known that the continuous-time variant of Grover's search algorithm is characterized by quantum search frameworks that are governed by stationary Hamiltonians, which result in search trajectories confined to the two-dimensional subspace of the complete Hilbert space formed by the source and target states. Specifically, the search approach is ineffective when the source and target states are orthogonal. In this paper, we employ normalization, orthogonality, and energy limitations to demonstrate that it is unfeasible to breach time-optimality between orthogonal states with constant Hamiltonians when the evolution is limited to the two-dimensional space spanned by the initial and final states. Deviations from time-optimality for unitary evolutions between orthogonal states can only occur with time-dependent Hamiltonian evolutions or, alternatively, with constant Hamiltonian evolutions in higher-dimensional subspaces of the entire Hilbert space. Ultimately, we employ our quantitative analysis to provide meaningful insights regarding the relationship between time-optimal evolutions and analog quantum search methods. We determine that the challenge of transitioning between orthogonal states with a constant Hamiltonian in a sub-optimal time is closely linked to the shortcomings of analog quantum search when the source and target states are orthogonal and not interconnected by the search Hamiltonian. In both scenarios, the fundamental cause of the failure lies in the existence of an inherent symmetry within the system."}
{"id": "2601.10659", "categories": ["quant-ph", "physics.atom-ph"], "pdf": "https://arxiv.org/pdf/2601.10659", "abs": "https://arxiv.org/abs/2601.10659", "authors": ["Georgios Theologou", "Mikkel F. Andersen", "Sandro Wimberger"], "title": "Counterdiabatic driving for random-gap Landau-Zener transitions", "comment": "Keywords: Shortcuts to adiabaticity; Landau-Zener problem; quantum control; random-gap distribution; adiabatic quantum computing", "summary": "The Landau--Zener (LZ) model describes a two-level quantum system that undergoes an avoided crossing. In the adiabatic limit, the transition probability vanishes. An auxiliary control field $H_\\text{CD}$ can be reverse-engineered so that the full Hamiltonian $H_0 + H_\\text{CD}$ reproduces adiabaticity for all parameter values. Our aim is to construct a single control field $H_1$ that drives an ensemble of LZ-type Hamiltonians with a distribution of energy gaps. $H_1$ works best statistically, minimizing the average transition probability. We restrict our attention to a special class of $H_1$ controls, motivated by $H_\\text{CD}$. We found a systematic trade-off between instantaneous adiabaticity and the final transition probability. Certain limiting cases with a linear sweep can be treated analytically; one of them being the LZ system with Dirac $δ(t)$ function. Comprehensive and systematic numerical simulations support and extend the analytic results."}
{"id": "2601.10662", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10662", "abs": "https://arxiv.org/abs/2601.10662", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Geometric Aspects of Entanglement Generating Hamiltonian Evolutions", "comment": "24 pages, 2 figures, 3 tables", "summary": "We examine the pertinent geometric characteristics of entanglement that arise from stationary Hamiltonian evolutions transitioning from separable to maximally entangled two-qubit quantum states. From a geometric perspective, each evolution is characterized by means of geodesic efficiency, speed efficiency, and curvature coefficient. Conversely, from the standpoint of entanglement, these evolutions are quantified using various metrics, such as concurrence, entanglement power, and entangling capability. Overall, our findings indicate that time-optimal evolution trajectories are marked by high geodesic efficiency, with no energy resource wastage, no curvature (i.e., zero bending), and an average path entanglement that is less than that observed in time-suboptimal evolutions. Additionally, when analyzing separable-to-maximally entangled evolutions between nonorthogonal states, time-optimal evolutions demonstrate a greater short-time degree of nonlocality compared to time-suboptimal evolutions between the same initial and final states. Interestingly, the reverse is generally true for separable-to-maximally entangled evolutions involving orthogonal states. Our investigation suggests that this phenomenon arises because suboptimal trajectories between orthogonal states are characterized by longer path lengths with smaller curvature, which are traversed with a higher energy resource wastage compared to suboptimal trajectories between nonorthogonal states. Consequently, a higher initial degree of nonlocality in the unitary time propagators appears to be essential for achieving the maximally entangled state from a separable state. Furthermore, when assessing optimal and suboptimal evolutions..."}
{"id": "2601.10672", "categories": ["quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10672", "abs": "https://arxiv.org/abs/2601.10672", "authors": ["Carlo Cafaro", "James Schneeloch"], "title": "Efficiency, Curvature, and Complexity of Quantum Evolutions for Qubits in Nonstationary Magnetic Fields", "comment": "27 pages, 4 figures, 1 table", "summary": "In optimal quantum-mechanical evolutions, motion can take place along paths of minimal length within an optimal time frame. Alternatively, optimal evolutions may occur along established paths without any waste of energy resources and achieving 100% speed efficiency. Unfortunately, realistic physical scenarios often lead to less-than-ideal evolutions that demonstrate suboptimal efficiency, nonzero curvature, and a high level of complexity. In this paper, we provide an exact analytical expression for the curvature of a quantum evolution pertaining to a two-level quantum system subjected to various time-dependent magnetic fields. Specifically, we examine the dynamics produced by a two-parameter nonstationary Hermitian Hamiltonian with unit speed efficiency. To enhance our understanding of the physical implications of the curvature coefficient, we analyze the curvature behavior in relation to geodesic efficiency, speed efficiency, and the complexity of the quantum evolution (as described by the ratio of the difference between accessible and accessed Bloch-sphere volumes for the evolution from initial to final state to the accessible volume for the given quantum evolution). Our findings indicate that, generally, efficient quantum evolutions exhibit lower complexity compared to inefficient ones. However, we also note that complexity transcends mere length. In fact, longer paths that are sufficiently curved can demonstrate a complexity that is less than that of shorter paths with a lower curvature coefficient."}
{"id": "2601.10683", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10683", "abs": "https://arxiv.org/abs/2601.10683", "authors": ["Kean Chen", "Zhicheng Zhang", "Nengkun Yu"], "title": "Optimal lower bound for quantum channel tomography in away-from-boundary regime", "comment": "23 pages", "summary": "Consider quantum channels with input dimension $d_1$, output dimension $d_2$ and Kraus rank at most $r$. Any such channel must satisfy the constraint $rd_2\\geq d_1$, and the parameter regime $rd_2=d_1$ is called the boundary regime. In this paper, we show an optimal query lower bound $Ω(rd_1d_2/\\varepsilon^2)$ for quantum channel tomography to within diamond norm error $\\varepsilon$ in the away-from-boundary regime $rd_2\\geq 2d_1$, matching the existing upper bound $O(rd_1d_2/\\varepsilon^2)$. In particular, this lower bound fully settles the query complexity for the commonly studied case of equal input and output dimensions $d_1=d_2=d$ with $r\\geq 2$, in sharp contrast to the unitary case $r=1$ where Heisenberg scaling $Θ(d^2/\\varepsilon)$ is achievable."}
{"id": "2601.10689", "categories": ["quant-ph", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.10689", "abs": "https://arxiv.org/abs/2601.10689", "authors": ["Daniel Allepuz-Requena", "Zohran Ali", "Dennis Høj", "Yingxuan Chen", "Luiz Couto Correa Pinto Filho", "Alexander Huck", "Ulrik L. Andersen"], "title": "Mitigating nonlinear transduction noise in high-cooperativity cavity optomechanics", "comment": null, "summary": "Coupling mechanical motion to an optical resonator enables displacement measurements approaching the standard quantum limit (SQL). However, increasing the optomechanical coupling strength will inevitably lead to probing of the nonlinear response of the optical resonator. Thermal intermodulation noise (TIN) arising from the nonlinear mixing of thermomechanical motion can further increase the imprecision well above the SQL and has hitherto been canceled up to second order of nonlinearity via operation at the \"magic detuning\". In this work, we record the output of a membrane-in-the-middle microcavity system operating at room temperature and achieving high cooperativity, $C>n_\\text{th}$, and apply a nonlinear transform that removes all orders of TIN, improving the mechanical signal-to-noise ratio by nearly 10 dB. Our results can be applied to experiments affected by third-order TIN, which we expect to be the dominating intrinsic source of noise in high-cooperativity room-temperature cavity optomechanical systems."}
{"id": "2601.10693", "categories": ["quant-ph", "cs.CC"], "pdf": "https://arxiv.org/pdf/2601.10693", "abs": "https://arxiv.org/abs/2601.10693", "authors": ["Francisca Vasconcelos", "Malvika Raj Joshi"], "title": "Constant-Depth Unitary Preparation of Dicke States", "comment": null, "summary": "Dicke states serve as a critical resource in quantum metrology, communication, and computation. However, unitary preparation of Dicke states is limited to logarithmic depth in standard circuit models and existing constant-depth protocols require measurement and feed-forward. In this work, we present the first unitary, constant-depth protocols for exact Dicke state preparation. We overcome the logarithmic-depth barrier by moving beyond the standard circuit model and leveraging global interactions (native to architectures such as neutral atoms and trapped ions). Specifically, utilizing unbounded CZ gates (i.e. within the QAC$^0$ circuit class), we offer circuits for exact computation of constant-weight Dicke states, using polynomial ancillae, and approximation of weight-1 Dicke states (i.e. $W$ states), using only constant ancillae. Granted additional access to the quantum FAN-OUT operation (i.e. upgrading to the QAC$_f^0$ circuit class), we also achieve exact preparation of arbitrary-weight Dicke states, with polynomial ancillae. These protocols distinguish the constant-depth capabilities of quantum architectures based on connectivity and offer a novel path toward resolving a long-standing quantum complexity conjecture."}
{"id": "2601.10698", "categories": ["quant-ph", "cond-mat.other", "math-ph"], "pdf": "https://arxiv.org/pdf/2601.10698", "abs": "https://arxiv.org/abs/2601.10698", "authors": ["Cesare Tronci"], "title": "Madelung hydrodynamics of spin-orbit coupling: action principles, currents, and correlations", "comment": "First version. Comments welcome", "summary": "We exploit the variational and Hamiltonian structures of quantum hydrodynamics with spin to unfold the correlation and torque mechanisms accompanying spin-orbit coupling (SOC) in electronic motion. Using Hamilton's action principle for the Pauli equation, we isolate SOC-induced quantum forces that act on the orbital Madelung--Bohm trajectories and complement the usual force terms known to appear in quantum hydrodynamics with spin. While the latter spin-hydrodynamic forces relate to the quantum geometric tensor (QGT), SOC-induced orbital forces originate from a particular current operator that contributes prominently to the spin current and whose contribution was overlooked in the past. The distinction between different force terms reveals two fundamentally different mechanisms generating quantum spin-orbit correlations. Leveraging the Hamiltonian structure of the hydrodynamic system, we also elucidate spin transport features such as the current shift in the spin Hall effect and the correlation-induced quantum torques. Finally, we illustrate the framework via the Madelung--Rashba equations for planar SOC configurations and propose a particle-based scheme for numerical implementation."}
{"id": "2601.10703", "categories": ["quant-ph", "cond-mat.mes-hall", "cond-mat.quant-gas"], "pdf": "https://arxiv.org/pdf/2601.10703", "abs": "https://arxiv.org/abs/2601.10703", "authors": ["Samuel E. Begg", "Bishal K. Ghosh", "Chong Zu", "Chuanwei Zhang", "Michael Kolodrubetz"], "title": "Scalable Spin Squeezing in Power-Law Interacting XXZ Models with Disorder", "comment": "5 + 4 pages", "summary": "While spin squeezing has been traditionally considered in all-to-all interacting models, recent works have shown that spin squeezing can occur in systems with power-law interactions, leading to direct testing in Rydberg atoms, trapped ions, ultracold atoms and nitrogen vacancy (NV) centers in diamond. For the latter, Wu. et al. Nature 646 (2025) demonstrated that spin squeezing is heavily affected by positional disorder, reducing any capacity for a practical squeezing advantage, which requires scalability with the system size. In this Letter we explore the robustness of spin-squeezing in two-dimensional lattices with a fraction of unoccupied lattice sites. Using semi-classical modeling, we demonstrate the existence of scalable squeezing in power-law interacting XXZ models up to a disorder threshold, above which squeezing is not scalable. We produce a phase diagram for scalable squeezing, and explain its absence in the aforementioned NV experiment. Our work illustrates the maximum disorder allowed for realizing scalable spin squeezing in a host of quantum simulators, highlights a regime with substantial tolerance to disorder, and identifies controlled defect creation as a promising route for scalable squeezing in solid-state systems."}
{"id": "2601.10713", "categories": ["quant-ph", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10713", "abs": "https://arxiv.org/abs/2601.10713", "authors": ["Bruno Costa Alves Freire", "François-Marie Le Régent", "Anthony Leverrier"], "title": "Quantum Maxwell Erasure Decoder for qLDPC codes", "comment": "8 pages, 3 figures, submitted to the IEEE ISIT 2026", "summary": "We introduce a quantum Maxwell erasure decoder for CSS quantum low-density parity-check (qLDPC) codes that extends peeling with bounded guessing. Guesses are tracked symbolically and can be eliminated by restrictive checks, giving a tunable tradeoff between complexity and performance via a guessing budget: an unconstrained budget recovers Maximum-Likelihood (ML) performance, while a constant budget yields linear-time decoding and approximates ML. We provide theoretical guarantees on asymptotic performance and demonstrate strong performance on bivariate bicycle and quantum Tanner codes."}
{"id": "2601.09793", "categories": ["cond-mat.dis-nn", "cond-mat.other", "cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.09793", "abs": "https://arxiv.org/abs/2601.09793", "authors": ["Soumadip Pakrashi", "Atanu Rajak", "Sambuddha Sanyal"], "title": "Emergent Nonperturbative Universal Floquet Localization", "comment": "4.5+2+6 pages, 2+5 figures", "summary": "We show that a robust, nonperturbative localization plateau emerges in periodically driven quasiperiodic lattices, independent of the static localization properties and drive protocol. Using exact Floquet dynamics, Floquet perturbation theory, and optimal-order van Vleck analysis, we identify a fine-tuned amplitude-to-frequency ratio where all Floquet states become localized despite dense resonances. The van Vleck expansion achieves superasymptotic accuracy up to an optimal orde; it ultimately breaks down due to resonant hybridization at a weak quasiperiodic potential, revealing that the observed localization is nonperturbative."}
{"id": "2601.10065", "categories": ["hep-lat", "hep-ph", "hep-th", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10065", "abs": "https://arxiv.org/abs/2601.10065", "authors": ["Vincent Chen", "Berndt Müller", "Xiaojun Yao"], "title": "Minimally Truncated SU(3) Lattice Gauge Theory and String Tension", "comment": "15 pages, 26 figures", "summary": "We study SU(3) gauge theory on small lattices in the minimal (qutrit) electric field truncation retaining only the ${\\bf 1}, {\\bf 3}, {\\bf \\overline{3}}$ representations for the link variables. Explicit expressions are given for the Kogut-Susskind Hamiltonian for the square plaquette chain and the two-dimensional honeycomb lattice. Our formalism can be easily extended to the minimally truncated general SU($N_c$) gauge theory. The addition of (static) quarks is discussed. We present results for the energy spectrum of the gauge field on these lattices by exact diagonalization of the Hamiltonian and analyze its statistical properties. We also compute the SU(3) string tension and discuss how it is modified by vacuum fluctuations. Finally, we calculate the potential energies of a static quark-antiquark pair and three static quarks and study their screening at finite temperature."}
{"id": "2601.10211", "categories": ["cond-mat.stat-mech", "quant-ph"], "pdf": "https://arxiv.org/pdf/2601.10211", "abs": "https://arxiv.org/abs/2601.10211", "authors": ["Mariel Kempa", "Markus Kraft", "Robin Steinigeweg", "Jochen Gemmer", "Jiaozi Wang"], "title": "Random matrix theory universality of current operators in spin-$S$ Heisenberg chains", "comment": "7 pages, 3 figures", "summary": "Quantum chaotic systems exhibit certain universal statistical properties that closely resemble predictions from random matrix theory (RMT). With respect to observables, it has recently been conjectured that, when truncated to a sufficiently narrow energy window, their statistical properties can be described by an unitarily invariant ensemble, and testable criteria have been introduced, which are based on the scaling behavior of free cumulants. In this paper, we investigate the conjecture numerically in translationally invariant Heisenberg spin chains with spin quantum number $S =\\frac{1}{2},1,\\frac{3}{2}$. Combining a quantum-typicality-based numerical method with the exploitation of the system's symmetries, we study the spin current operator and find clear evidence of consistency with the proposed criteria in chaotic cases. Our findings further support the conjecture of the existence of RMT universality as manifest in the observable properties in quantum chaotic systems."}
